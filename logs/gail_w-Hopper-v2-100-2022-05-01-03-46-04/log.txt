2022-05-01 03:46:04.981635 - utils/flags.py:257 - log_dir = logs/gail_w-Hopper-v2-100-2022-05-01-03-46-04
2022-05-01 03:46:11.960541 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/project_2022_05_01/dataset/sac/Hopper-v2
2022-05-01 03:46:22.167012 - gail/main.py:75 - Expert Reward 3582.436530
2022-05-01 03:46:22.543993 - gail/main.py:79 - Original dataset size 3000
2022-05-01 03:46:22.590981 - gail/main.py:81 - Subsampled dataset size 3000
2022-05-01 03:46:22.604705 - gail/main.py:82 - np random: 864 random : 786
2022-05-01 03:46:22.607563 - gail/main.py:86 - Sampled obs: 0.4652, acs: 0.0749
2022-05-01 03:46:23.889436 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-05-01 03:46:35.486126 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-05-01 03:46:35.501041 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.3966653  -0.06165453 -0.19472611 -0.4584401   0.18350822  2.5732448
   0.00400542 -0.00549955 -0.04755233 -0.02386179  0.00759995]] 
 scale:[[0.16755195 0.05883223 0.15990146 0.34682125 0.5992658  0.6461788
  1.5187451  0.8811966  2.0685835  3.6282625  5.862049  ]]
2022-05-01 03:46:41.172758 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-05-01 03:46:41.174894 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(14, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-05-01 03:46:41.179615 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-05-01 03:46:42.331194 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-05-01 03:47:12.306732 - gail/main.py:132 - [Evaluate] iter = 0 episode={ returns = 240.1615 lengths = 229 } discounted_episode={ returns = 182.4166 lengths = 192 } 
2022-05-01 03:47:12.307395 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-05-01 03:47:24.883938 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-05-01 03:47:25.184850 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-05-01 03:47:25.811161 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-05-01 03:47:26.130912 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-05-01 03:47:27.846152 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-05-01 03:47:31.389923 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-05-01 03:47:31.829402 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-05-01 03:47:32.259504 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-05-01 03:47:32.900418 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-05-01 03:47:34.063657 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-05-01 03:47:34.456895 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-05-01 03:47:34.816980 - gail/main.py:164 - [TRPO] iter = 1000 dist_mean = -0.0000 dist_std = 1.0000 vf_loss = 0.3574 grad_norm = 0.2691 nat_grad_norm = 0.3367 cg_residual = 0.0000 step_size = 0.5255 reward = 0.0000 fps = 19 mse_loss = 0.3189 
2022-05-01 03:47:44.892246 - gail/main.py:164 - [TRPO] iter = 2000 dist_mean = -0.0418 dist_std = 0.9919 vf_loss = 0.2640 grad_norm = 0.3809 nat_grad_norm = 0.3659 cg_residual = 0.0000 step_size = 0.4041 reward = -0.0000 fps = 15 mse_loss = 0.3278 
2022-05-01 03:47:54.963038 - gail/main.py:164 - [TRPO] iter = 3000 dist_mean = -0.0849 dist_std = 0.9892 vf_loss = 0.4147 grad_norm = 0.4320 nat_grad_norm = 0.3771 cg_residual = 0.0000 step_size = 0.3703 reward = -0.0000 fps = 13 mse_loss = 0.3524 
2022-05-01 03:48:05.374271 - gail/main.py:164 - [TRPO] iter = 4000 dist_mean = -0.1135 dist_std = 0.9857 vf_loss = 0.3278 grad_norm = 0.5239 nat_grad_norm = 0.3955 cg_residual = 0.0000 step_size = 0.3332 reward = 0.0000 fps = 12 mse_loss = 0.3733 
2022-05-01 03:48:15.949729 - gail/main.py:164 - [TRPO] iter = 5000 dist_mean = -0.1550 dist_std = 0.9854 vf_loss = 0.1677 grad_norm = 0.5997 nat_grad_norm = 0.3996 cg_residual = 0.0000 step_size = 0.3147 reward = 0.0000 fps = 10 mse_loss = 0.4267 
2022-05-01 03:48:15.959812 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-05-01 03:48:19.090630 - gail/main.py:191 - [Discriminator] iter = 5000 loss = 1.8033 grad_norm = 14.1450 grad_penalty = 1.6640 regularization = 0.0000 true_logits = 0.1373 fake_logits = 0.2766 true_prob = 0.5342 fake_prob = 0.5681 
2022-05-01 03:48:20.246749 - gail/main.py:132 - [Evaluate] iter = 5000 episode={ returns = 6.3892 lengths = 8 } discounted_episode={ returns = 6.3658 lengths = 8 } 
2022-05-01 03:48:30.442401 - gail/main.py:164 - [TRPO] iter = 6000 dist_mean = -0.1886 dist_std = 0.9808 vf_loss = 0.1538 grad_norm = 0.6919 nat_grad_norm = 0.4945 cg_residual = 0.0000 step_size = 0.2684 reward = -0.0000 fps = 88 mse_loss = 0.4764 
2022-05-01 03:48:40.197876 - gail/main.py:164 - [TRPO] iter = 7000 dist_mean = -0.2040 dist_std = 0.9784 vf_loss = 0.1224 grad_norm = 0.6576 nat_grad_norm = 0.4556 cg_residual = 0.0000 step_size = 0.2908 reward = -0.0000 fps = 47 mse_loss = 0.5055 
2022-05-01 03:48:50.770303 - gail/main.py:164 - [TRPO] iter = 8000 dist_mean = -0.2119 dist_std = 0.9686 vf_loss = 0.0941 grad_norm = 0.6527 nat_grad_norm = 0.4851 cg_residual = 0.0000 step_size = 0.2902 reward = -0.0000 fps = 31 mse_loss = 0.6055 
2022-05-01 03:49:01.259442 - gail/main.py:164 - [TRPO] iter = 9000 dist_mean = -0.2275 dist_std = 0.9663 vf_loss = 0.0433 grad_norm = 0.6643 nat_grad_norm = 0.3796 cg_residual = 0.0000 step_size = 0.3156 reward = 0.0000 fps = 23 mse_loss = 0.5589 
2022-05-01 03:49:12.389860 - gail/main.py:164 - [TRPO] iter = 10000 dist_mean = -0.2371 dist_std = 0.9523 vf_loss = 0.0697 grad_norm = 0.9271 nat_grad_norm = 0.5174 cg_residual = 0.0000 step_size = 0.2397 reward = 0.0000 fps = 18 mse_loss = 0.6872 
2022-05-01 03:49:12.608669 - gail/main.py:191 - [Discriminator] iter = 10000 loss = 0.7527 grad_norm = 10.2307 grad_penalty = 0.9303 regularization = 0.0000 true_logits = 0.1793 fake_logits = 0.0016 true_prob = 0.5444 fake_prob = 0.5004 
2022-05-01 03:49:13.647179 - gail/main.py:132 - [Evaluate] iter = 10000 episode={ returns = 5.1844 lengths = 7 } discounted_episode={ returns = 5.1619 lengths = 7 } 
2022-05-01 03:49:24.079196 - gail/main.py:164 - [TRPO] iter = 11000 dist_mean = -0.2417 dist_std = 0.9433 vf_loss = 0.0765 grad_norm = 0.4937 nat_grad_norm = 0.4567 cg_residual = 0.0000 step_size = 0.3915 reward = 0.0000 fps = 87 mse_loss = 0.6568 
2022-05-01 03:49:37.197266 - gail/main.py:164 - [TRPO] iter = 12000 dist_mean = -0.1846 dist_std = 0.9488 vf_loss = 0.0802 grad_norm = 0.8081 nat_grad_norm = 0.4370 cg_residual = 0.0000 step_size = 0.2798 reward = -0.0000 fps = 40 mse_loss = 0.7678 
2022-05-01 03:49:47.865997 - gail/main.py:164 - [TRPO] iter = 13000 dist_mean = -0.1087 dist_std = 0.9544 vf_loss = 0.1944 grad_norm = 0.8456 nat_grad_norm = 0.4429 cg_residual = 0.0000 step_size = 0.2699 reward = 0.0000 fps = 28 mse_loss = 0.7624 
2022-05-01 03:49:58.412668 - gail/main.py:164 - [TRPO] iter = 14000 dist_mean = -0.0262 dist_std = 0.9598 vf_loss = 0.1499 grad_norm = 0.9175 nat_grad_norm = 0.4038 cg_residual = 0.0001 step_size = 0.2737 reward = 0.0000 fps = 21 mse_loss = 0.7241 
2022-05-01 03:50:09.085887 - gail/main.py:164 - [TRPO] iter = 15000 dist_mean = 0.0650 dist_std = 0.9696 vf_loss = 0.3418 grad_norm = 0.7095 nat_grad_norm = 0.3949 cg_residual = 0.0001 step_size = 0.3453 reward = 0.0000 fps = 17 mse_loss = 0.7733 
2022-05-01 03:50:09.343012 - gail/main.py:191 - [Discriminator] iter = 15000 loss = 0.2675 grad_norm = 9.3621 grad_penalty = 0.8053 regularization = 0.0000 true_logits = 0.1699 fake_logits = -0.3679 true_prob = 0.5421 fake_prob = 0.4098 
2022-05-01 03:50:10.561920 - gail/main.py:132 - [Evaluate] iter = 15000 episode={ returns = 7.0108 lengths = 8 } discounted_episode={ returns = 6.9284 lengths = 8 } 
2022-05-01 03:50:20.795397 - gail/main.py:164 - [TRPO] iter = 16000 dist_mean = 0.1152 dist_std = 0.9731 vf_loss = 0.7711 grad_norm = 0.6561 nat_grad_norm = 0.4857 cg_residual = 0.0002 step_size = 0.3495 reward = 0.0000 fps = 87 mse_loss = 0.7549 
2022-05-01 03:50:31.161439 - gail/main.py:164 - [TRPO] iter = 17000 dist_mean = 0.2029 dist_std = 0.9789 vf_loss = 1.0896 grad_norm = 0.9064 nat_grad_norm = 0.4460 cg_residual = 0.0002 step_size = 0.3226 reward = -0.0000 fps = 45 mse_loss = 0.6663 
2022-05-01 03:50:41.613919 - gail/main.py:164 - [TRPO] iter = 18000 dist_mean = 0.2949 dist_std = 0.9795 vf_loss = 1.1573 grad_norm = 0.6880 nat_grad_norm = 0.3413 cg_residual = 0.0001 step_size = 0.4171 reward = -0.0000 fps = 31 mse_loss = 0.6355 
2022-05-01 03:50:52.315008 - gail/main.py:164 - [TRPO] iter = 19000 dist_mean = 0.3943 dist_std = 0.9769 vf_loss = 0.9080 grad_norm = 0.6215 nat_grad_norm = 0.4148 cg_residual = 0.0003 step_size = 0.4252 reward = -0.0000 fps = 23 mse_loss = 0.6087 
2022-05-01 03:51:02.956842 - gail/main.py:164 - [TRPO] iter = 20000 dist_mean = 0.4520 dist_std = 0.9696 vf_loss = 0.6546 grad_norm = 0.5478 nat_grad_norm = 0.4193 cg_residual = 0.0005 step_size = 0.4513 reward = 0.0000 fps = 18 mse_loss = 0.6331 
2022-05-01 03:51:03.202284 - gail/main.py:191 - [Discriminator] iter = 20000 loss = 0.1251 grad_norm = 7.6418 grad_penalty = 0.7202 regularization = 0.0000 true_logits = 0.1707 fake_logits = -0.4244 true_prob = 0.5423 fake_prob = 0.3991 
2022-05-01 03:51:07.038909 - gail/main.py:132 - [Evaluate] iter = 20000 episode={ returns = 42.8683 lengths = 26 } discounted_episode={ returns = 42.4530 lengths = 26 } 
2022-05-01 03:51:17.703113 - gail/main.py:164 - [TRPO] iter = 21000 dist_mean = 0.5382 dist_std = 0.9672 vf_loss = 0.5598 grad_norm = 0.5099 nat_grad_norm = 0.4048 cg_residual = 0.0004 step_size = 0.5050 reward = 0.0000 fps = 69 mse_loss = 0.6479 
2022-05-01 03:51:28.049007 - gail/main.py:164 - [TRPO] iter = 22000 dist_mean = 0.5405 dist_std = 0.9656 vf_loss = 0.6143 grad_norm = 0.4433 nat_grad_norm = 0.4363 cg_residual = 0.0010 step_size = 0.5129 reward = 0.0000 fps = 40 mse_loss = 0.5843 
2022-05-01 03:51:38.215535 - gail/main.py:164 - [TRPO] iter = 23000 dist_mean = 0.5899 dist_std = 0.9749 vf_loss = 0.8410 grad_norm = 0.3414 nat_grad_norm = 0.4609 cg_residual = 0.0004 step_size = 0.5210 reward = 0.0000 fps = 28 mse_loss = 0.6219 
2022-05-01 03:51:48.363329 - gail/main.py:164 - [TRPO] iter = 24000 dist_mean = 0.6496 dist_std = 0.9712 vf_loss = 0.9662 grad_norm = 0.5478 nat_grad_norm = 0.4455 cg_residual = 0.0004 step_size = 0.4365 reward = 0.0000 fps = 22 mse_loss = 0.6610 
2022-05-01 03:51:58.302453 - gail/main.py:164 - [TRPO] iter = 25000 dist_mean = 0.6611 dist_std = 0.9753 vf_loss = 0.5531 grad_norm = 0.3767 nat_grad_norm = 0.4377 cg_residual = 0.0003 step_size = 0.4835 reward = -0.0000 fps = 18 mse_loss = 0.6643 
2022-05-01 03:51:58.509594 - gail/main.py:191 - [Discriminator] iter = 25000 loss = -0.1021 grad_norm = 7.0432 grad_penalty = 0.5863 regularization = 0.0000 true_logits = 0.1598 fake_logits = -0.5287 true_prob = 0.5398 fake_prob = 0.3761 
2022-05-01 03:52:04.636162 - gail/main.py:132 - [Evaluate] iter = 25000 episode={ returns = 80.3213 lengths = 44 } discounted_episode={ returns = 78.5132 lengths = 44 } 
2022-05-01 03:52:15.067739 - gail/main.py:164 - [TRPO] iter = 26000 dist_mean = 0.6915 dist_std = 0.9676 vf_loss = 0.7430 grad_norm = 0.5712 nat_grad_norm = 0.4634 cg_residual = 0.0003 step_size = 0.4300 reward = 0.0000 fps = 60 mse_loss = 0.7139 
2022-05-01 03:52:24.958227 - gail/main.py:164 - [TRPO] iter = 27000 dist_mean = 0.7139 dist_std = 0.9620 vf_loss = 0.4376 grad_norm = 0.3469 nat_grad_norm = 0.4704 cg_residual = 0.0003 step_size = 0.4709 reward = -0.0000 fps = 37 mse_loss = 0.7857 
2022-05-01 03:52:34.816588 - gail/main.py:164 - [TRPO] iter = 28000 dist_mean = 0.7171 dist_std = 0.9599 vf_loss = 0.4737 grad_norm = 0.2975 nat_grad_norm = 0.4382 cg_residual = 0.0004 step_size = 0.5348 reward = 0.0000 fps = 27 mse_loss = 0.7055 
2022-05-01 03:52:45.054584 - gail/main.py:164 - [TRPO] iter = 29000 dist_mean = 0.6848 dist_std = 0.9588 vf_loss = 0.3498 grad_norm = 0.5437 nat_grad_norm = 0.4116 cg_residual = 0.0007 step_size = 0.4977 reward = 0.0000 fps = 21 mse_loss = 0.6516 
2022-05-01 03:52:56.211185 - gail/main.py:164 - [TRPO] iter = 30000 dist_mean = 0.6475 dist_std = 0.9543 vf_loss = 0.8787 grad_norm = 0.4042 nat_grad_norm = 0.4178 cg_residual = 0.0006 step_size = 0.5598 reward = 0.0000 fps = 17 mse_loss = 0.7287 
2022-05-01 03:52:56.508577 - gail/main.py:191 - [Discriminator] iter = 30000 loss = -0.2172 grad_norm = 7.4411 grad_penalty = 0.5101 regularization = 0.0000 true_logits = 0.1679 fake_logits = -0.5594 true_prob = 0.5418 fake_prob = 0.3690 
2022-05-01 03:53:08.566037 - gail/main.py:132 - [Evaluate] iter = 30000 episode={ returns = 171.2379 lengths = 84 } discounted_episode={ returns = 164.5541 lengths = 84 } 
2022-05-01 03:53:18.670955 - gail/main.py:164 - [TRPO] iter = 31000 dist_mean = 0.6072 dist_std = 0.9559 vf_loss = 0.8505 grad_norm = 0.5007 nat_grad_norm = 0.5462 cg_residual = 0.0015 step_size = 0.4408 reward = 0.0000 fps = 45 mse_loss = 0.7205 
2022-05-01 03:53:28.210500 - gail/main.py:164 - [TRPO] iter = 32000 dist_mean = 0.5524 dist_std = 0.9509 vf_loss = 0.5582 grad_norm = 0.4587 nat_grad_norm = 0.4023 cg_residual = 0.0011 step_size = 0.5851 reward = -0.0000 fps = 31 mse_loss = 0.8649 
2022-05-01 03:53:38.537687 - gail/main.py:164 - [TRPO] iter = 33000 dist_mean = 0.5440 dist_std = 0.9468 vf_loss = 0.3167 grad_norm = 0.5022 nat_grad_norm = 0.3496 cg_residual = 0.0030 step_size = 0.6142 reward = 0.0000 fps = 23 mse_loss = 0.9506 
2022-05-01 03:53:48.564355 - gail/main.py:164 - [TRPO] iter = 34000 dist_mean = 0.5750 dist_std = 0.9398 vf_loss = 0.2201 grad_norm = 0.4639 nat_grad_norm = 0.4019 cg_residual = 0.0004 step_size = 0.5932 reward = -0.0000 fps = 19 mse_loss = 0.9313 
2022-05-01 03:53:58.762553 - gail/main.py:164 - [TRPO] iter = 35000 dist_mean = 0.5924 dist_std = 0.9284 vf_loss = 0.1280 grad_norm = 0.4011 nat_grad_norm = 0.4504 cg_residual = 0.0017 step_size = 0.5041 reward = -0.0000 fps = 16 mse_loss = 0.8704 
2022-05-01 03:53:59.007676 - gail/main.py:191 - [Discriminator] iter = 35000 loss = -0.3458 grad_norm = 5.7410 grad_penalty = 0.4682 regularization = 0.0000 true_logits = 0.1930 fake_logits = -0.6210 true_prob = 0.5478 fake_prob = 0.3563 
2022-05-01 03:54:11.446223 - gail/main.py:132 - [Evaluate] iter = 35000 episode={ returns = 170.6199 lengths = 86 } discounted_episode={ returns = 162.7403 lengths = 86 } 
2022-05-01 03:54:21.858064 - gail/main.py:164 - [TRPO] iter = 36000 dist_mean = 0.5679 dist_std = 0.9255 vf_loss = 0.0837 grad_norm = 0.3486 nat_grad_norm = 0.2668 cg_residual = 0.0021 step_size = 0.7435 reward = 0.0000 fps = 43 mse_loss = 0.9571 
2022-05-01 03:54:32.445116 - gail/main.py:164 - [TRPO] iter = 37000 dist_mean = 0.5615 dist_std = 0.9252 vf_loss = 0.0969 grad_norm = 0.4142 nat_grad_norm = 0.3741 cg_residual = 0.0014 step_size = 0.5699 reward = 0.0000 fps = 29 mse_loss = 1.2038 
2022-05-01 03:54:42.822825 - gail/main.py:164 - [TRPO] iter = 38000 dist_mean = 0.5496 dist_std = 0.9356 vf_loss = 0.1294 grad_norm = 0.7487 nat_grad_norm = 0.3533 cg_residual = 0.0064 step_size = 0.4746 reward = 0.0000 fps = 22 mse_loss = 1.3395 
2022-05-01 03:54:53.083977 - gail/main.py:164 - [TRPO] iter = 39000 dist_mean = 0.5248 dist_std = 0.9305 vf_loss = 0.0688 grad_norm = 0.4731 nat_grad_norm = 0.2910 cg_residual = 0.0010 step_size = 0.6347 reward = 0.0000 fps = 18 mse_loss = 1.4083 
2022-05-01 03:55:03.120121 - gail/main.py:164 - [TRPO] iter = 40000 dist_mean = 0.5204 dist_std = 0.9370 vf_loss = 0.0698 grad_norm = 0.5135 nat_grad_norm = 0.4070 cg_residual = 0.0031 step_size = 0.5138 reward = 0.0000 fps = 15 mse_loss = 1.3387 
2022-05-01 03:55:03.339350 - gail/main.py:191 - [Discriminator] iter = 40000 loss = -0.6515 grad_norm = 6.1956 grad_penalty = 0.4410 regularization = 0.0000 true_logits = 0.2236 fake_logits = -0.8689 true_prob = 0.5549 fake_prob = 0.3041 
2022-05-01 03:55:15.462187 - gail/main.py:132 - [Evaluate] iter = 40000 episode={ returns = 172.4663 lengths = 87 } discounted_episode={ returns = 163.1912 lengths = 86 } 
2022-05-01 03:55:25.385841 - gail/main.py:164 - [TRPO] iter = 41000 dist_mean = 0.5116 dist_std = 0.9319 vf_loss = 0.1640 grad_norm = 0.2215 nat_grad_norm = 0.3953 cg_residual = 0.0021 step_size = 0.6601 reward = -0.0000 fps = 45 mse_loss = 1.2283 
2022-05-01 03:55:35.376697 - gail/main.py:164 - [TRPO] iter = 42000 dist_mean = 0.5214 dist_std = 0.9312 vf_loss = 0.0981 grad_norm = 0.4585 nat_grad_norm = 0.5475 cg_residual = 0.0054 step_size = 0.4378 reward = 0.0000 fps = 31 mse_loss = 1.3698 
2022-05-01 03:55:45.320147 - gail/main.py:164 - [TRPO] iter = 43000 dist_mean = 0.5169 dist_std = 0.9220 vf_loss = 0.0407 grad_norm = 0.3926 nat_grad_norm = 0.3474 cg_residual = 0.0061 step_size = 0.5737 reward = 0.0000 fps = 23 mse_loss = 1.3983 
2022-05-01 03:55:55.121966 - gail/main.py:164 - [TRPO] iter = 44000 dist_mean = 0.4822 dist_std = 0.9139 vf_loss = 0.1417 grad_norm = 0.6740 nat_grad_norm = 0.4466 cg_residual = 0.0067 step_size = 0.3693 reward = -0.0000 fps = 19 mse_loss = 1.2628 
2022-05-01 03:56:05.092451 - gail/main.py:164 - [TRPO] iter = 45000 dist_mean = 0.4539 dist_std = 0.9122 vf_loss = 0.2885 grad_norm = 0.5709 nat_grad_norm = 0.3885 cg_residual = 0.0054 step_size = 0.5140 reward = 0.0000 fps = 16 mse_loss = 1.4788 
2022-05-01 03:56:05.336429 - gail/main.py:191 - [Discriminator] iter = 45000 loss = -0.9787 grad_norm = 5.2988 grad_penalty = 0.3740 regularization = 0.0000 true_logits = 0.2228 fake_logits = -1.1298 true_prob = 0.5555 fake_prob = 0.2550 
2022-05-01 03:56:20.935500 - gail/main.py:132 - [Evaluate] iter = 45000 episode={ returns = 280.7174 lengths = 113 } discounted_episode={ returns = 263.8350 lengths = 114 } 
2022-05-01 03:56:30.904128 - gail/main.py:164 - [TRPO] iter = 46000 dist_mean = 0.4201 dist_std = 0.9140 vf_loss = 0.7176 grad_norm = 0.5240 nat_grad_norm = 0.5261 cg_residual = 0.0042 step_size = 0.4313 reward = -0.0000 fps = 39 mse_loss = 1.3332 
2022-05-01 03:56:41.038367 - gail/main.py:164 - [TRPO] iter = 47000 dist_mean = 0.4044 dist_std = 0.9191 vf_loss = 0.8246 grad_norm = 0.5539 nat_grad_norm = 0.5065 cg_residual = 0.0138 step_size = 0.4429 reward = -0.0000 fps = 28 mse_loss = 1.4982 
2022-05-01 03:56:51.397577 - gail/main.py:164 - [TRPO] iter = 48000 dist_mean = 0.3588 dist_std = 0.9144 vf_loss = 0.5018 grad_norm = 0.3907 nat_grad_norm = 0.5322 cg_residual = 0.0034 step_size = 0.4597 reward = 0.0000 fps = 21 mse_loss = 1.4880 
2022-05-01 03:57:01.395203 - gail/main.py:164 - [TRPO] iter = 49000 dist_mean = 0.3949 dist_std = 0.9252 vf_loss = 0.6630 grad_norm = 0.5081 nat_grad_norm = 0.5406 cg_residual = 0.0026 step_size = 0.4559 reward = -0.0000 fps = 17 mse_loss = 1.5661 
2022-05-01 03:57:11.369414 - gail/main.py:164 - [TRPO] iter = 50000 dist_mean = 0.3532 dist_std = 0.9114 vf_loss = 0.5462 grad_norm = 0.6037 nat_grad_norm = 0.3377 cg_residual = 0.0072 step_size = 0.5603 reward = -0.0000 fps = 15 mse_loss = 1.5815 
2022-05-01 03:57:11.607721 - gail/main.py:191 - [Discriminator] iter = 50000 loss = -1.0419 grad_norm = 5.5806 grad_penalty = 0.3875 regularization = 0.0000 true_logits = 0.2419 fake_logits = -1.1875 true_prob = 0.5607 fake_prob = 0.2603 
2022-05-01 03:57:26.700623 - gail/main.py:132 - [Evaluate] iter = 50000 episode={ returns = 268.0156 lengths = 109 } discounted_episode={ returns = 252.6095 lengths = 109 } 
2022-05-01 03:57:36.777153 - gail/main.py:164 - [TRPO] iter = 51000 dist_mean = 0.3943 dist_std = 0.9030 vf_loss = 1.0841 grad_norm = 0.5607 nat_grad_norm = 0.4158 cg_residual = 0.0105 step_size = 0.4676 reward = -0.0000 fps = 39 mse_loss = 1.6320 
2022-05-01 03:57:46.517819 - gail/main.py:164 - [TRPO] iter = 52000 dist_mean = 0.3549 dist_std = 0.9042 vf_loss = 0.6686 grad_norm = 0.5742 nat_grad_norm = 0.4621 cg_residual = 0.0026 step_size = 0.4929 reward = 0.0000 fps = 28 mse_loss = 1.6946 
2022-05-01 03:57:56.514452 - gail/main.py:164 - [TRPO] iter = 53000 dist_mean = 0.3109 dist_std = 0.9004 vf_loss = 0.6231 grad_norm = 0.6195 nat_grad_norm = 0.4069 cg_residual = 0.0102 step_size = 0.5162 reward = -0.0000 fps = 22 mse_loss = 1.5690 
2022-05-01 03:58:06.734872 - gail/main.py:164 - [TRPO] iter = 54000 dist_mean = 0.3443 dist_std = 0.9011 vf_loss = 0.3571 grad_norm = 0.4074 nat_grad_norm = 0.3828 cg_residual = 0.0040 step_size = 0.5554 reward = -0.0000 fps = 18 mse_loss = 1.5835 
2022-05-01 03:58:16.849862 - gail/main.py:164 - [TRPO] iter = 55000 dist_mean = 0.3418 dist_std = 0.8900 vf_loss = 0.1484 grad_norm = 0.9006 nat_grad_norm = 0.5203 cg_residual = 0.0114 step_size = 0.3759 reward = -0.0000 fps = 15 mse_loss = 1.6274 
2022-05-01 03:58:17.079786 - gail/main.py:191 - [Discriminator] iter = 55000 loss = -1.1455 grad_norm = 4.8025 grad_penalty = 0.3675 regularization = 0.0000 true_logits = 0.2212 fake_logits = -1.2918 true_prob = 0.5558 fake_prob = 0.2500 
2022-05-01 03:58:32.259169 - gail/main.py:132 - [Evaluate] iter = 55000 episode={ returns = 256.7709 lengths = 109 } discounted_episode={ returns = 241.8682 lengths = 109 } 
2022-05-01 03:58:42.135091 - gail/main.py:164 - [TRPO] iter = 56000 dist_mean = 0.3101 dist_std = 0.8816 vf_loss = 0.3957 grad_norm = 0.7171 nat_grad_norm = 0.3730 cg_residual = 0.0116 step_size = 0.5155 reward = 0.0000 fps = 39 mse_loss = 1.3958 
2022-05-01 03:58:52.082916 - gail/main.py:164 - [TRPO] iter = 57000 dist_mean = 0.3145 dist_std = 0.8743 vf_loss = 0.2714 grad_norm = 0.6813 nat_grad_norm = 0.4527 cg_residual = 0.0111 step_size = 0.4616 reward = 0.0000 fps = 28 mse_loss = 1.4486 
2022-05-01 03:59:02.020663 - gail/main.py:164 - [TRPO] iter = 58000 dist_mean = 0.3363 dist_std = 0.8701 vf_loss = 0.2198 grad_norm = 0.5468 nat_grad_norm = 0.4160 cg_residual = 0.0072 step_size = 0.4651 reward = 0.0000 fps = 22 mse_loss = 1.4099 
2022-05-01 03:59:12.042782 - gail/main.py:164 - [TRPO] iter = 59000 dist_mean = 0.2848 dist_std = 0.8636 vf_loss = 0.1651 grad_norm = 0.7429 nat_grad_norm = 0.4037 cg_residual = 0.0118 step_size = 0.4774 reward = -0.0000 fps = 18 mse_loss = 1.4025 
2022-05-01 03:59:21.767342 - gail/main.py:164 - [TRPO] iter = 60000 dist_mean = 0.3123 dist_std = 0.8607 vf_loss = 0.2979 grad_norm = 0.6846 nat_grad_norm = 0.3328 cg_residual = 0.0032 step_size = 0.4783 reward = -0.0000 fps = 15 mse_loss = 1.3416 
2022-05-01 03:59:21.997156 - gail/main.py:191 - [Discriminator] iter = 60000 loss = -1.2781 grad_norm = 4.2361 grad_penalty = 0.2926 regularization = 0.0000 true_logits = 0.2775 fake_logits = -1.2932 true_prob = 0.5685 fake_prob = 0.2518 
2022-05-01 03:59:37.588880 - gail/main.py:132 - [Evaluate] iter = 60000 episode={ returns = 252.3704 lengths = 111 } discounted_episode={ returns = 236.2595 lengths = 111 } 
2022-05-01 03:59:48.660245 - gail/main.py:164 - [TRPO] iter = 61000 dist_mean = 0.2801 dist_std = 0.8548 vf_loss = 0.1371 grad_norm = 0.5965 nat_grad_norm = 0.3073 cg_residual = 0.0123 step_size = 0.5304 reward = -0.0000 fps = 37 mse_loss = 1.6594 
2022-05-01 03:59:58.489309 - gail/main.py:164 - [TRPO] iter = 62000 dist_mean = 0.2630 dist_std = 0.8510 vf_loss = 0.4217 grad_norm = 1.0848 nat_grad_norm = 0.6369 cg_residual = 0.0156 step_size = 0.3385 reward = 0.0000 fps = 27 mse_loss = 1.6839 
2022-05-01 04:00:08.510450 - gail/main.py:164 - [TRPO] iter = 63000 dist_mean = 0.2573 dist_std = 0.8522 vf_loss = 0.2607 grad_norm = 0.4778 nat_grad_norm = 0.3646 cg_residual = 0.0046 step_size = 0.5509 reward = 0.0000 fps = 21 mse_loss = 1.7115 
2022-05-01 04:00:18.565516 - gail/main.py:164 - [TRPO] iter = 64000 dist_mean = 0.2688 dist_std = 0.8448 vf_loss = 0.2987 grad_norm = 0.6563 nat_grad_norm = 0.3357 cg_residual = 0.0037 step_size = 0.5333 reward = 0.0000 fps = 17 mse_loss = 1.5862 
2022-05-01 04:00:28.488136 - gail/main.py:164 - [TRPO] iter = 65000 dist_mean = 0.2438 dist_std = 0.8364 vf_loss = 0.3265 grad_norm = 0.8204 nat_grad_norm = 0.4276 cg_residual = 0.0092 step_size = 0.4128 reward = -0.0000 fps = 15 mse_loss = 1.7067 
2022-05-01 04:00:28.714103 - gail/main.py:191 - [Discriminator] iter = 65000 loss = -1.2774 grad_norm = 5.0572 grad_penalty = 0.3314 regularization = 0.0000 true_logits = 0.2975 fake_logits = -1.3113 true_prob = 0.5746 fake_prob = 0.2473 
2022-05-01 04:00:44.792443 - gail/main.py:132 - [Evaluate] iter = 65000 episode={ returns = 273.3460 lengths = 118 } discounted_episode={ returns = 255.1368 lengths = 118 } 
2022-05-01 04:00:54.911597 - gail/main.py:164 - [TRPO] iter = 66000 dist_mean = 0.2259 dist_std = 0.8340 vf_loss = 0.2915 grad_norm = 0.5654 nat_grad_norm = 0.3674 cg_residual = 0.0051 step_size = 0.5258 reward = 0.0000 fps = 38 mse_loss = 1.5995 
2022-05-01 04:01:05.046935 - gail/main.py:164 - [TRPO] iter = 67000 dist_mean = 0.2321 dist_std = 0.8313 vf_loss = 0.3013 grad_norm = 0.7293 nat_grad_norm = 0.3811 cg_residual = 0.0124 step_size = 0.4797 reward = 0.0000 fps = 27 mse_loss = 1.5730 
2022-05-01 04:01:14.971285 - gail/main.py:164 - [TRPO] iter = 68000 dist_mean = 0.2277 dist_std = 0.8243 vf_loss = 0.6105 grad_norm = 0.7074 nat_grad_norm = 0.6170 cg_residual = 0.0163 step_size = 0.3838 reward = -0.0000 fps = 21 mse_loss = 1.5531 
2022-05-01 04:01:24.827570 - gail/main.py:164 - [TRPO] iter = 69000 dist_mean = 0.2406 dist_std = 0.8222 vf_loss = 0.5270 grad_norm = 0.6071 nat_grad_norm = 0.3387 cg_residual = 0.0093 step_size = 0.5447 reward = 0.0000 fps = 17 mse_loss = 1.6530 
2022-05-01 04:01:35.443683 - gail/main.py:164 - [TRPO] iter = 70000 dist_mean = 0.2239 dist_std = 0.8233 vf_loss = 0.3650 grad_norm = 0.6465 nat_grad_norm = 0.2800 cg_residual = 0.0111 step_size = 0.6260 reward = 0.0000 fps = 14 mse_loss = 1.6544 
2022-05-01 04:01:35.682662 - gail/main.py:191 - [Discriminator] iter = 70000 loss = -1.3061 grad_norm = 3.5694 grad_penalty = 0.2698 regularization = 0.0000 true_logits = 0.2844 fake_logits = -1.2916 true_prob = 0.5717 fake_prob = 0.2464 
2022-05-01 04:01:52.211184 - gail/main.py:132 - [Evaluate] iter = 70000 episode={ returns = 280.0644 lengths = 117 } discounted_episode={ returns = 260.5796 lengths = 116 } 
2022-05-01 04:02:01.999017 - gail/main.py:164 - [TRPO] iter = 71000 dist_mean = 0.2238 dist_std = 0.8291 vf_loss = 0.1409 grad_norm = 0.5294 nat_grad_norm = 0.3814 cg_residual = 0.0137 step_size = 0.5721 reward = 0.0000 fps = 38 mse_loss = 1.6797 
2022-05-01 04:02:12.227935 - gail/main.py:164 - [TRPO] iter = 72000 dist_mean = 0.1969 dist_std = 0.8232 vf_loss = 0.1536 grad_norm = 0.6035 nat_grad_norm = 0.3867 cg_residual = 0.0125 step_size = 0.4820 reward = 0.0000 fps = 27 mse_loss = 1.5718 
2022-05-01 04:02:22.229919 - gail/main.py:164 - [TRPO] iter = 73000 dist_mean = 0.1695 dist_std = 0.8159 vf_loss = 0.1305 grad_norm = 0.9332 nat_grad_norm = 0.2695 cg_residual = 0.0037 step_size = 0.4807 reward = 0.0000 fps = 21 mse_loss = 1.5247 
2022-05-01 04:02:32.130282 - gail/main.py:164 - [TRPO] iter = 74000 dist_mean = 0.1966 dist_std = 0.8211 vf_loss = 0.2071 grad_norm = 0.4744 nat_grad_norm = 0.4331 cg_residual = 0.0147 step_size = 0.5179 reward = 0.0000 fps = 17 mse_loss = 1.5095 
2022-05-01 04:02:42.103548 - gail/main.py:164 - [TRPO] iter = 75000 dist_mean = 0.2014 dist_std = 0.8203 vf_loss = 0.3447 grad_norm = 0.7465 nat_grad_norm = 0.5240 cg_residual = 0.0179 step_size = 0.4444 reward = 0.0000 fps = 15 mse_loss = 1.4764 
2022-05-01 04:02:42.333512 - gail/main.py:191 - [Discriminator] iter = 75000 loss = -1.3427 grad_norm = 3.7329 grad_penalty = 0.2550 regularization = 0.0000 true_logits = 0.3257 fake_logits = -1.2720 true_prob = 0.5818 fake_prob = 0.2451 
2022-05-01 04:03:01.348254 - gail/main.py:132 - [Evaluate] iter = 75000 episode={ returns = 367.2053 lengths = 140 } discounted_episode={ returns = 335.9384 lengths = 140 } 
2022-05-01 04:03:11.202861 - gail/main.py:164 - [TRPO] iter = 76000 dist_mean = 0.1793 dist_std = 0.8212 vf_loss = 0.4526 grad_norm = 0.4898 nat_grad_norm = 0.4504 cg_residual = 0.0086 step_size = 0.5053 reward = -0.0000 fps = 34 mse_loss = 1.4964 
2022-05-01 04:03:21.299533 - gail/main.py:164 - [TRPO] iter = 77000 dist_mean = 0.2017 dist_std = 0.8189 vf_loss = 0.4242 grad_norm = 0.5138 nat_grad_norm = 0.4222 cg_residual = 0.0200 step_size = 0.5134 reward = 0.0000 fps = 25 mse_loss = 1.5360 
2022-05-01 04:03:30.909728 - gail/main.py:164 - [TRPO] iter = 78000 dist_mean = 0.1729 dist_std = 0.8225 vf_loss = 0.2069 grad_norm = 0.7597 nat_grad_norm = 0.4533 cg_residual = 0.0137 step_size = 0.4492 reward = -0.0000 fps = 20 mse_loss = 1.3971 
2022-05-01 04:03:40.684173 - gail/main.py:164 - [TRPO] iter = 79000 dist_mean = 0.1992 dist_std = 0.8197 vf_loss = 0.2091 grad_norm = 0.5632 nat_grad_norm = 0.3570 cg_residual = 0.0080 step_size = 0.5517 reward = 0.0000 fps = 17 mse_loss = 1.3686 
2022-05-01 04:03:50.539043 - gail/main.py:164 - [TRPO] iter = 80000 dist_mean = 0.1934 dist_std = 0.8186 vf_loss = 0.3023 grad_norm = 0.4617 nat_grad_norm = 0.3923 cg_residual = 0.0088 step_size = 0.5826 reward = 0.0000 fps = 14 mse_loss = 1.4296 
2022-05-01 04:03:50.739360 - gail/main.py:191 - [Discriminator] iter = 80000 loss = -1.3894 grad_norm = 3.1236 grad_penalty = 0.2032 regularization = 0.0000 true_logits = 0.3171 fake_logits = -1.2755 true_prob = 0.5796 fake_prob = 0.2445 
2022-05-01 04:04:13.158707 - gail/main.py:132 - [Evaluate] iter = 80000 episode={ returns = 461.4200 lengths = 167 } discounted_episode={ returns = 417.9204 lengths = 166 } 
2022-05-01 04:04:23.037520 - gail/main.py:164 - [TRPO] iter = 81000 dist_mean = 0.1550 dist_std = 0.8124 vf_loss = 0.5138 grad_norm = 0.5131 nat_grad_norm = 0.3839 cg_residual = 0.0047 step_size = 0.5696 reward = -0.0000 fps = 30 mse_loss = 1.2740 
2022-05-01 04:04:32.918599 - gail/main.py:164 - [TRPO] iter = 82000 dist_mean = 0.1760 dist_std = 0.8106 vf_loss = 0.3904 grad_norm = 0.6984 nat_grad_norm = 0.3901 cg_residual = 0.0053 step_size = 0.4648 reward = 0.0000 fps = 23 mse_loss = 1.4278 
2022-05-01 04:04:42.990448 - gail/main.py:164 - [TRPO] iter = 83000 dist_mean = 0.1404 dist_std = 0.8144 vf_loss = 0.4107 grad_norm = 0.9097 nat_grad_norm = 0.4253 cg_residual = 0.0120 step_size = 0.3990 reward = 0.0000 fps = 19 mse_loss = 1.2101 
2022-05-01 04:04:53.038268 - gail/main.py:164 - [TRPO] iter = 84000 dist_mean = 0.1733 dist_std = 0.8125 vf_loss = 0.5561 grad_norm = 0.5271 nat_grad_norm = 0.3751 cg_residual = 0.0117 step_size = 0.5040 reward = -0.0000 fps = 16 mse_loss = 1.3802 
2022-05-01 04:05:03.122856 - gail/main.py:164 - [TRPO] iter = 85000 dist_mean = 0.1398 dist_std = 0.8120 vf_loss = 0.2316 grad_norm = 0.3929 nat_grad_norm = 0.4194 cg_residual = 0.0083 step_size = 0.5236 reward = -0.0000 fps = 13 mse_loss = 1.4100 
2022-05-01 04:05:03.357232 - gail/main.py:191 - [Discriminator] iter = 85000 loss = -1.3547 grad_norm = 3.2990 grad_penalty = 0.1964 regularization = 0.0000 true_logits = 0.3079 fake_logits = -1.2432 true_prob = 0.5794 fake_prob = 0.2549 
2022-05-01 04:05:27.069406 - gail/main.py:132 - [Evaluate] iter = 85000 episode={ returns = 509.9474 lengths = 178 } discounted_episode={ returns = 459.1635 lengths = 178 } 
2022-05-01 04:05:36.935571 - gail/main.py:164 - [TRPO] iter = 86000 dist_mean = 0.1763 dist_std = 0.7991 vf_loss = 0.3246 grad_norm = 0.5073 nat_grad_norm = 0.3115 cg_residual = 0.0058 step_size = 0.6310 reward = -0.0000 fps = 29 mse_loss = 1.3489 
2022-05-01 04:05:46.981117 - gail/main.py:164 - [TRPO] iter = 87000 dist_mean = 0.1318 dist_std = 0.7969 vf_loss = 0.4951 grad_norm = 0.4408 nat_grad_norm = 0.2944 cg_residual = 0.0072 step_size = 0.5919 reward = 0.0000 fps = 22 mse_loss = 1.2927 
2022-05-01 04:05:56.924954 - gail/main.py:164 - [TRPO] iter = 88000 dist_mean = 0.2148 dist_std = 0.7865 vf_loss = 0.3949 grad_norm = 0.3546 nat_grad_norm = 0.3131 cg_residual = 0.0059 step_size = 0.7130 reward = 0.0000 fps = 18 mse_loss = 1.1428 
2022-05-01 04:06:06.770503 - gail/main.py:164 - [TRPO] iter = 89000 dist_mean = 0.1581 dist_std = 0.7858 vf_loss = 0.5888 grad_norm = 0.5127 nat_grad_norm = 0.3484 cg_residual = 0.0055 step_size = 0.5411 reward = 0.0000 fps = 15 mse_loss = 1.0590 
2022-05-01 04:06:16.586196 - gail/main.py:164 - [TRPO] iter = 90000 dist_mean = 0.2104 dist_std = 0.7776 vf_loss = 0.7021 grad_norm = 0.6146 nat_grad_norm = 0.4463 cg_residual = 0.0199 step_size = 0.4369 reward = -0.0000 fps = 13 mse_loss = 1.1245 
2022-05-01 04:06:16.825467 - gail/main.py:191 - [Discriminator] iter = 90000 loss = -1.2759 grad_norm = 3.4125 grad_penalty = 0.1960 regularization = 0.0000 true_logits = 0.2908 fake_logits = -1.1811 true_prob = 0.5759 fake_prob = 0.2625 
2022-05-01 04:06:45.395492 - gail/main.py:132 - [Evaluate] iter = 90000 episode={ returns = 642.6171 lengths = 220 } discounted_episode={ returns = 555.3896 lengths = 214 } 
2022-05-01 04:06:55.365469 - gail/main.py:164 - [TRPO] iter = 91000 dist_mean = 0.1313 dist_std = 0.7693 vf_loss = 0.3271 grad_norm = 0.5339 nat_grad_norm = 0.2843 cg_residual = 0.0085 step_size = 0.6106 reward = -0.0000 fps = 25 mse_loss = 1.1960 
2022-05-01 04:07:05.565911 - gail/main.py:164 - [TRPO] iter = 92000 dist_mean = 0.1736 dist_std = 0.7772 vf_loss = 0.2176 grad_norm = 0.4615 nat_grad_norm = 0.3199 cg_residual = 0.0094 step_size = 0.5738 reward = 0.0000 fps = 20 mse_loss = 1.1082 
2022-05-01 04:07:15.124063 - gail/main.py:164 - [TRPO] iter = 93000 dist_mean = 0.1367 dist_std = 0.7796 vf_loss = 0.2490 grad_norm = 0.5892 nat_grad_norm = 0.3694 cg_residual = 0.0070 step_size = 0.5337 reward = 0.0000 fps = 17 mse_loss = 1.0312 
2022-05-01 04:07:25.013775 - gail/main.py:164 - [TRPO] iter = 94000 dist_mean = 0.1333 dist_std = 0.7864 vf_loss = 0.2633 grad_norm = 0.4418 nat_grad_norm = 0.3680 cg_residual = 0.0067 step_size = 0.5582 reward = -0.0000 fps = 14 mse_loss = 1.0926 
2022-05-01 04:07:34.461516 - gail/main.py:164 - [TRPO] iter = 95000 dist_mean = 0.1608 dist_std = 0.7896 vf_loss = 0.7491 grad_norm = 0.9989 nat_grad_norm = 0.4788 cg_residual = 0.0155 step_size = 0.3987 reward = 0.0000 fps = 12 mse_loss = 1.0620 
2022-05-01 04:07:34.695615 - gail/main.py:191 - [Discriminator] iter = 95000 loss = -1.2960 grad_norm = 3.0980 grad_penalty = 0.1809 regularization = 0.0000 true_logits = 0.3283 fake_logits = -1.1486 true_prob = 0.5841 fake_prob = 0.2695 
2022-05-01 04:07:54.507968 - gail/main.py:132 - [Evaluate] iter = 95000 episode={ returns = 383.3641 lengths = 150 } discounted_episode={ returns = 352.9531 lengths = 152 } 
2022-05-01 04:08:04.338310 - gail/main.py:164 - [TRPO] iter = 96000 dist_mean = 0.1441 dist_std = 0.7868 vf_loss = 0.2897 grad_norm = 0.3817 nat_grad_norm = 0.3568 cg_residual = 0.0116 step_size = 0.6187 reward = -0.0000 fps = 33 mse_loss = 1.0545 
2022-05-01 04:08:13.827948 - gail/main.py:164 - [TRPO] iter = 97000 dist_mean = 0.1496 dist_std = 0.7855 vf_loss = 0.2509 grad_norm = 0.5522 nat_grad_norm = 0.3793 cg_residual = 0.0083 step_size = 0.5544 reward = 0.0000 fps = 25 mse_loss = 1.0632 
2022-05-01 04:08:24.115372 - gail/main.py:164 - [TRPO] iter = 98000 dist_mean = 0.1022 dist_std = 0.7828 vf_loss = 0.6370 grad_norm = 0.8020 nat_grad_norm = 0.5792 cg_residual = 0.0170 step_size = 0.3720 reward = 0.0000 fps = 20 mse_loss = 1.2010 
2022-05-01 04:08:33.916411 - gail/main.py:164 - [TRPO] iter = 99000 dist_mean = 0.1177 dist_std = 0.7753 vf_loss = 0.2296 grad_norm = 0.4301 nat_grad_norm = 0.3693 cg_residual = 0.0244 step_size = 0.5239 reward = 0.0000 fps = 16 mse_loss = 1.2332 
2022-05-01 04:08:43.755224 - gail/main.py:164 - [TRPO] iter = 100000 dist_mean = 0.1672 dist_std = 0.7732 vf_loss = 0.3750 grad_norm = 0.7708 nat_grad_norm = 0.4013 cg_residual = 0.0224 step_size = 0.4350 reward = -0.0000 fps = 14 mse_loss = 1.1686 
2022-05-01 04:08:43.990222 - gail/main.py:191 - [Discriminator] iter = 100000 loss = -1.2351 grad_norm = 2.7721 grad_penalty = 0.1689 regularization = 0.0000 true_logits = 0.2876 fake_logits = -1.1164 true_prob = 0.5747 fake_prob = 0.2785 
2022-05-01 04:09:05.969039 - gail/main.py:132 - [Evaluate] iter = 100000 episode={ returns = 466.1908 lengths = 166 } discounted_episode={ returns = 429.1972 lengths = 168 } 
2022-05-01 04:09:15.792705 - gail/main.py:164 - [TRPO] iter = 101000 dist_mean = 0.0629 dist_std = 0.7749 vf_loss = 0.3919 grad_norm = 0.7571 nat_grad_norm = 0.3953 cg_residual = 0.0101 step_size = 0.4522 reward = 0.0000 fps = 31 mse_loss = 1.1309 
2022-05-01 04:09:25.646740 - gail/main.py:164 - [TRPO] iter = 102000 dist_mean = 0.1112 dist_std = 0.7706 vf_loss = 0.2943 grad_norm = 0.4455 nat_grad_norm = 0.3487 cg_residual = 0.0110 step_size = 0.5293 reward = -0.0000 fps = 24 mse_loss = 1.2235 
2022-05-01 04:09:35.039475 - gail/main.py:164 - [TRPO] iter = 103000 dist_mean = 0.0704 dist_std = 0.7686 vf_loss = 0.2820 grad_norm = 0.6508 nat_grad_norm = 0.3828 cg_residual = 0.0166 step_size = 0.5225 reward = -0.0000 fps = 19 mse_loss = 1.2523 
2022-05-01 04:09:44.648984 - gail/main.py:164 - [TRPO] iter = 104000 dist_mean = 0.0957 dist_std = 0.7624 vf_loss = 0.2577 grad_norm = 0.6540 nat_grad_norm = 0.4212 cg_residual = 0.0107 step_size = 0.4512 reward = 0.0000 fps = 16 mse_loss = 1.2843 
2022-05-01 04:09:55.055920 - gail/main.py:164 - [TRPO] iter = 105000 dist_mean = 0.1289 dist_std = 0.7631 vf_loss = 0.4534 grad_norm = 0.6678 nat_grad_norm = 0.4008 cg_residual = 0.0180 step_size = 0.3959 reward = -0.0000 fps = 14 mse_loss = 1.2558 
2022-05-01 04:09:55.273662 - gail/main.py:191 - [Discriminator] iter = 105000 loss = -1.2357 grad_norm = 2.5428 grad_penalty = 0.1626 regularization = 0.0000 true_logits = 0.2881 fake_logits = -1.1101 true_prob = 0.5757 fake_prob = 0.2773 
2022-05-01 04:10:22.696135 - gail/main.py:132 - [Evaluate] iter = 105000 episode={ returns = 611.8145 lengths = 198 } discounted_episode={ returns = 540.8771 lengths = 199 } 
2022-05-01 04:10:32.437684 - gail/main.py:164 - [TRPO] iter = 106000 dist_mean = 0.1755 dist_std = 0.7644 vf_loss = 0.4491 grad_norm = 0.7088 nat_grad_norm = 0.5117 cg_residual = 0.0109 step_size = 0.4159 reward = 0.0000 fps = 26 mse_loss = 1.3727 
2022-05-01 04:10:41.954542 - gail/main.py:164 - [TRPO] iter = 107000 dist_mean = 0.1721 dist_std = 0.7681 vf_loss = 0.5300 grad_norm = 1.0153 nat_grad_norm = 0.6949 cg_residual = 0.0332 step_size = 0.3504 reward = 0.0000 fps = 21 mse_loss = 1.3849 
2022-05-01 04:10:51.968860 - gail/main.py:164 - [TRPO] iter = 108000 dist_mean = 0.1537 dist_std = 0.7672 vf_loss = 0.4471 grad_norm = 0.5678 nat_grad_norm = 0.3743 cg_residual = 0.0133 step_size = 0.4873 reward = 0.0000 fps = 17 mse_loss = 1.4109 
2022-05-01 04:11:01.876928 - gail/main.py:164 - [TRPO] iter = 109000 dist_mean = 0.1724 dist_std = 0.7677 vf_loss = 0.3624 grad_norm = 0.4808 nat_grad_norm = 0.3249 cg_residual = 0.0096 step_size = 0.6285 reward = -0.0000 fps = 15 mse_loss = 1.2749 
2022-05-01 04:11:11.852604 - gail/main.py:164 - [TRPO] iter = 110000 dist_mean = 0.0713 dist_std = 0.7680 vf_loss = 0.3121 grad_norm = 0.7418 nat_grad_norm = 0.3982 cg_residual = 0.0169 step_size = 0.4710 reward = -0.0000 fps = 13 mse_loss = 1.2973 
2022-05-01 04:11:12.104112 - gail/main.py:191 - [Discriminator] iter = 110000 loss = -1.1045 grad_norm = 2.6163 grad_penalty = 0.1400 regularization = 0.0000 true_logits = 0.3056 fake_logits = -0.9389 true_prob = 0.5777 fake_prob = 0.3142 
2022-05-01 04:11:31.899527 - gail/main.py:132 - [Evaluate] iter = 110000 episode={ returns = 421.6899 lengths = 148 } discounted_episode={ returns = 370.2945 lengths = 144 } 
2022-05-01 04:11:41.627371 - gail/main.py:164 - [TRPO] iter = 111000 dist_mean = 0.0812 dist_std = 0.7646 vf_loss = 0.1728 grad_norm = 0.7447 nat_grad_norm = 0.3555 cg_residual = 0.0131 step_size = 0.4431 reward = 0.0000 fps = 33 mse_loss = 1.2748 
2022-05-01 04:11:51.360784 - gail/main.py:164 - [TRPO] iter = 112000 dist_mean = 0.2555 dist_std = 0.7685 vf_loss = 0.5345 grad_norm = 0.5365 nat_grad_norm = 0.3271 cg_residual = 0.0108 step_size = 0.5541 reward = -0.0000 fps = 25 mse_loss = 1.2498 
2022-05-01 04:12:00.942782 - gail/main.py:164 - [TRPO] iter = 113000 dist_mean = 0.0862 dist_std = 0.7731 vf_loss = 0.4539 grad_norm = 0.5223 nat_grad_norm = 0.4110 cg_residual = 0.0094 step_size = 0.5115 reward = -0.0000 fps = 20 mse_loss = 1.4371 
2022-05-01 04:12:10.961045 - gail/main.py:164 - [TRPO] iter = 114000 dist_mean = 0.0683 dist_std = 0.7693 vf_loss = 0.6279 grad_norm = 0.7494 nat_grad_norm = 0.2838 cg_residual = 0.0153 step_size = 0.5079 reward = -0.0000 fps = 16 mse_loss = 1.4037 
2022-05-01 04:12:20.772693 - gail/main.py:164 - [TRPO] iter = 115000 dist_mean = 0.1490 dist_std = 0.7705 vf_loss = 0.4220 grad_norm = 0.4546 nat_grad_norm = 0.3222 cg_residual = 0.0066 step_size = 0.6250 reward = -0.0000 fps = 14 mse_loss = 1.5063 
2022-05-01 04:12:21.011157 - gail/main.py:191 - [Discriminator] iter = 115000 loss = -0.8160 grad_norm = 2.5741 grad_penalty = 0.1361 regularization = 0.0000 true_logits = 0.2546 fake_logits = -0.6976 true_prob = 0.5668 fake_prob = 0.3618 
2022-05-01 04:13:11.192840 - gail/main.py:132 - [Evaluate] iter = 115000 episode={ returns = 1156.3863 lengths = 385 } discounted_episode={ returns = 945.4270 lengths = 372 } 
2022-05-01 04:13:20.970561 - gail/main.py:164 - [TRPO] iter = 116000 dist_mean = 0.1332 dist_std = 0.7723 vf_loss = 0.2656 grad_norm = 0.4875 nat_grad_norm = 0.3625 cg_residual = 0.0086 step_size = 0.5298 reward = -0.0000 fps = 16 mse_loss = 1.4963 
2022-05-01 04:13:31.257028 - gail/main.py:164 - [TRPO] iter = 117000 dist_mean = 0.1094 dist_std = 0.7680 vf_loss = 0.5147 grad_norm = 0.5001 nat_grad_norm = 0.3532 cg_residual = 0.0301 step_size = 0.5057 reward = -0.0000 fps = 14 mse_loss = 1.5633 
2022-05-01 04:13:41.069694 - gail/main.py:164 - [TRPO] iter = 118000 dist_mean = 0.1128 dist_std = 0.7707 vf_loss = 0.2899 grad_norm = 0.5447 nat_grad_norm = 0.3766 cg_residual = 0.0157 step_size = 0.4886 reward = 0.0000 fps = 12 mse_loss = 1.7471 
2022-05-01 04:13:51.081824 - gail/main.py:164 - [TRPO] iter = 119000 dist_mean = 0.1132 dist_std = 0.7698 vf_loss = 0.3998 grad_norm = 0.3896 nat_grad_norm = 0.4384 cg_residual = 0.0190 step_size = 0.5187 reward = 0.0000 fps = 11 mse_loss = 1.6121 
2022-05-01 04:14:01.141086 - gail/main.py:164 - [TRPO] iter = 120000 dist_mean = 0.0543 dist_std = 0.7682 vf_loss = 0.2604 grad_norm = 0.5499 nat_grad_norm = 0.4091 cg_residual = 0.0201 step_size = 0.4976 reward = 0.0000 fps = 9 mse_loss = 1.6195 
2022-05-01 04:14:01.355816 - gail/main.py:191 - [Discriminator] iter = 120000 loss = -0.8781 grad_norm = 2.6222 grad_penalty = 0.1430 regularization = 0.0000 true_logits = 0.2273 fake_logits = -0.7938 true_prob = 0.5612 fake_prob = 0.3486 
2022-05-01 04:14:52.718459 - gail/main.py:132 - [Evaluate] iter = 120000 episode={ returns = 1287.1633 lengths = 369 } discounted_episode={ returns = 1095.8074 lengths = 391 } 
2022-05-01 04:15:02.773541 - gail/main.py:164 - [TRPO] iter = 121000 dist_mean = 0.0521 dist_std = 0.7538 vf_loss = 0.3929 grad_norm = 0.5288 nat_grad_norm = 0.3509 cg_residual = 0.0139 step_size = 0.5617 reward = -0.0000 fps = 16 mse_loss = 1.4845 
2022-05-01 04:15:12.581918 - gail/main.py:164 - [TRPO] iter = 122000 dist_mean = 0.0390 dist_std = 0.7579 vf_loss = 0.2553 grad_norm = 0.5292 nat_grad_norm = 0.3307 cg_residual = 0.0254 step_size = 0.5124 reward = -0.0000 fps = 14 mse_loss = 1.6805 
2022-05-01 04:15:22.213619 - gail/main.py:164 - [TRPO] iter = 123000 dist_mean = 0.1030 dist_std = 0.7655 vf_loss = 0.2532 grad_norm = 0.5733 nat_grad_norm = 0.4336 cg_residual = 0.0147 step_size = 0.4449 reward = -0.0000 fps = 12 mse_loss = 1.5884 
2022-05-01 04:15:31.902568 - gail/main.py:164 - [TRPO] iter = 124000 dist_mean = 0.0849 dist_std = 0.7605 vf_loss = 0.5752 grad_norm = 0.6961 nat_grad_norm = 0.5004 cg_residual = 0.0341 step_size = 0.3655 reward = 0.0000 fps = 11 mse_loss = 1.5960 
2022-05-01 04:15:42.163878 - gail/main.py:164 - [TRPO] iter = 125000 dist_mean = -0.0525 dist_std = 0.7539 vf_loss = 0.4339 grad_norm = 0.7930 nat_grad_norm = 0.3563 cg_residual = 0.0494 step_size = 0.4475 reward = -0.0000 fps = 9 mse_loss = 1.7173 
2022-05-01 04:15:42.422256 - gail/main.py:191 - [Discriminator] iter = 125000 loss = -0.9765 grad_norm = 2.8370 grad_penalty = 0.1365 regularization = 0.0000 true_logits = 0.1618 fake_logits = -0.9511 true_prob = 0.5443 fake_prob = 0.3215 
2022-05-01 04:16:12.549901 - gail/main.py:132 - [Evaluate] iter = 125000 episode={ returns = 727.6708 lengths = 221 } discounted_episode={ returns = 621.5763 lengths = 218 } 
2022-05-01 04:16:22.660057 - gail/main.py:164 - [TRPO] iter = 126000 dist_mean = 0.1410 dist_std = 0.7463 vf_loss = 1.3261 grad_norm = 0.7570 nat_grad_norm = 0.4587 cg_residual = 0.0217 step_size = 0.4385 reward = 0.0000 fps = 24 mse_loss = 1.6367 
2022-05-01 04:16:33.733901 - gail/main.py:164 - [TRPO] iter = 127000 dist_mean = 0.0387 dist_std = 0.7456 vf_loss = 0.6525 grad_norm = 0.5262 nat_grad_norm = 0.3727 cg_residual = 0.0124 step_size = 0.5038 reward = -0.0000 fps = 19 mse_loss = 1.5149 
2022-05-01 04:16:44.569480 - gail/main.py:164 - [TRPO] iter = 128000 dist_mean = 0.0630 dist_std = 0.7389 vf_loss = 0.3494 grad_norm = 0.4691 nat_grad_norm = 0.3535 cg_residual = 0.0163 step_size = 0.5473 reward = -0.0000 fps = 16 mse_loss = 1.7843 
2022-05-01 04:16:55.370518 - gail/main.py:164 - [TRPO] iter = 129000 dist_mean = 0.1609 dist_std = 0.7430 vf_loss = 0.1857 grad_norm = 0.6244 nat_grad_norm = 0.4000 cg_residual = 0.0182 step_size = 0.4565 reward = -0.0000 fps = 13 mse_loss = 1.7184 
2022-05-01 04:17:06.612608 - gail/main.py:164 - [TRPO] iter = 130000 dist_mean = 0.0355 dist_std = 0.7474 vf_loss = 0.2876 grad_norm = 0.4933 nat_grad_norm = 0.3404 cg_residual = 0.0226 step_size = 0.5556 reward = 0.0000 fps = 11 mse_loss = 1.7135 
2022-05-01 04:17:06.855533 - gail/main.py:191 - [Discriminator] iter = 130000 loss = -0.8185 grad_norm = 2.6661 grad_penalty = 0.1331 regularization = 0.0000 true_logits = 0.1153 fake_logits = -0.8363 true_prob = 0.5347 fake_prob = 0.3424 
2022-05-01 04:17:55.921627 - gail/main.py:132 - [Evaluate] iter = 130000 episode={ returns = 1082.7992 lengths = 331 } discounted_episode={ returns = 925.9149 lengths = 343 } 
2022-05-01 04:18:07.334080 - gail/main.py:164 - [TRPO] iter = 131000 dist_mean = 0.0112 dist_std = 0.7370 vf_loss = 0.2054 grad_norm = 0.8662 nat_grad_norm = 0.4010 cg_residual = 0.0402 step_size = 0.3709 reward = 0.0000 fps = 16 mse_loss = 1.5015 
2022-05-01 04:18:18.287007 - gail/main.py:164 - [TRPO] iter = 132000 dist_mean = 0.0011 dist_std = 0.7375 vf_loss = 0.1789 grad_norm = 0.6629 nat_grad_norm = 0.3758 cg_residual = 0.0329 step_size = 0.4541 reward = 0.0000 fps = 14 mse_loss = 1.6582 
2022-05-01 04:18:29.527341 - gail/main.py:164 - [TRPO] iter = 133000 dist_mean = 0.1037 dist_std = 0.7325 vf_loss = 0.3440 grad_norm = 0.6934 nat_grad_norm = 0.3471 cg_residual = 0.0228 step_size = 0.4755 reward = 0.0000 fps = 12 mse_loss = 1.5896 
2022-05-01 04:18:40.673824 - gail/main.py:164 - [TRPO] iter = 134000 dist_mean = 0.2764 dist_std = 0.7293 vf_loss = 0.2093 grad_norm = 0.6171 nat_grad_norm = 0.3960 cg_residual = 0.0379 step_size = 0.4672 reward = 0.0000 fps = 10 mse_loss = 1.4967 
2022-05-01 04:18:51.368369 - gail/main.py:164 - [TRPO] iter = 135000 dist_mean = 0.2909 dist_std = 0.7240 vf_loss = 0.2892 grad_norm = 0.7174 nat_grad_norm = 0.3946 cg_residual = 0.0258 step_size = 0.4607 reward = 0.0000 fps = 9 mse_loss = 1.4860 
2022-05-01 04:18:51.615069 - gail/main.py:191 - [Discriminator] iter = 135000 loss = -1.2188 grad_norm = 2.7195 grad_penalty = 0.1336 regularization = 0.0000 true_logits = 0.0882 fake_logits = -1.2642 true_prob = 0.5292 fake_prob = 0.2656 
2022-05-01 04:19:38.979981 - gail/main.py:132 - [Evaluate] iter = 135000 episode={ returns = 1010.8653 lengths = 319 } discounted_episode={ returns = 846.5218 lengths = 322 } 
2022-05-01 04:19:49.938549 - gail/main.py:164 - [TRPO] iter = 136000 dist_mean = 0.1083 dist_std = 0.7227 vf_loss = 0.1684 grad_norm = 0.5590 nat_grad_norm = 0.3683 cg_residual = 0.0305 step_size = 0.4926 reward = -0.0000 fps = 17 mse_loss = 1.3744 
2022-05-01 04:20:00.516675 - gail/main.py:164 - [TRPO] iter = 137000 dist_mean = 0.0991 dist_std = 0.7221 vf_loss = 0.1617 grad_norm = 0.5404 nat_grad_norm = 0.3241 cg_residual = 0.0202 step_size = 0.5090 reward = 0.0000 fps = 14 mse_loss = 1.4103 
2022-05-01 04:20:11.439808 - gail/main.py:164 - [TRPO] iter = 138000 dist_mean = 0.2274 dist_std = 0.7192 vf_loss = 0.1786 grad_norm = 0.4967 nat_grad_norm = 0.4269 cg_residual = 0.0242 step_size = 0.4541 reward = -0.0000 fps = 12 mse_loss = 1.4260 
2022-05-01 04:20:22.393027 - gail/main.py:164 - [TRPO] iter = 139000 dist_mean = 0.1962 dist_std = 0.7164 vf_loss = 0.3797 grad_norm = 0.5602 nat_grad_norm = 0.4383 cg_residual = 0.0305 step_size = 0.4602 reward = -0.0000 fps = 11 mse_loss = 1.3729 
2022-05-01 04:20:32.991816 - gail/main.py:164 - [TRPO] iter = 140000 dist_mean = 0.1226 dist_std = 0.7163 vf_loss = 0.4549 grad_norm = 0.5493 nat_grad_norm = 0.3043 cg_residual = 0.0206 step_size = 0.5514 reward = 0.0000 fps = 9 mse_loss = 1.4610 
2022-05-01 04:20:33.215555 - gail/main.py:191 - [Discriminator] iter = 140000 loss = -0.8093 grad_norm = 2.4785 grad_penalty = 0.1433 regularization = 0.0000 true_logits = 0.1014 fake_logits = -0.8512 true_prob = 0.5321 fake_prob = 0.3424 
2022-05-01 04:21:25.019994 - gail/main.py:132 - [Evaluate] iter = 140000 episode={ returns = 1284.5225 lengths = 384 } discounted_episode={ returns = 938.6836 lengths = 343 } 
2022-05-01 04:21:35.359820 - gail/main.py:164 - [TRPO] iter = 141000 dist_mean = 0.0858 dist_std = 0.7131 vf_loss = 0.3604 grad_norm = 0.7660 nat_grad_norm = 0.3635 cg_residual = 0.0242 step_size = 0.4754 reward = 0.0000 fps = 16 mse_loss = 1.4915 
2022-05-01 04:21:45.752919 - gail/main.py:164 - [TRPO] iter = 142000 dist_mean = 0.0669 dist_std = 0.7120 vf_loss = 0.2059 grad_norm = 0.5599 nat_grad_norm = 0.4002 cg_residual = 0.0366 step_size = 0.4342 reward = -0.0000 fps = 13 mse_loss = 1.2659 
2022-05-01 04:21:56.095171 - gail/main.py:164 - [TRPO] iter = 143000 dist_mean = 0.5588 dist_std = 0.7018 vf_loss = 0.3643 grad_norm = 0.4813 nat_grad_norm = 0.3742 cg_residual = 0.0137 step_size = 0.5093 reward = -0.0000 fps = 12 mse_loss = 1.3136 
2022-05-01 04:22:06.277685 - gail/main.py:164 - [TRPO] iter = 144000 dist_mean = 0.2846 dist_std = 0.7043 vf_loss = 0.1294 grad_norm = 0.5347 nat_grad_norm = 0.4319 cg_residual = 0.0323 step_size = 0.4650 reward = -0.0000 fps = 10 mse_loss = 1.1065 
2022-05-01 04:22:16.463693 - gail/main.py:164 - [TRPO] iter = 145000 dist_mean = 0.2410 dist_std = 0.6999 vf_loss = 0.1560 grad_norm = 0.5718 nat_grad_norm = 0.4094 cg_residual = 0.0160 step_size = 0.5155 reward = -0.0000 fps = 9 mse_loss = 1.2359 
2022-05-01 04:22:16.678532 - gail/main.py:191 - [Discriminator] iter = 145000 loss = -1.1693 grad_norm = 2.6674 grad_penalty = 0.1359 regularization = 0.0000 true_logits = 0.0564 fake_logits = -1.2488 true_prob = 0.5226 fake_prob = 0.2728 
2022-05-01 04:22:21.949279 - gail/main.py:132 - [Evaluate] iter = 145000 episode={ returns = 65.6095 lengths = 37 } discounted_episode={ returns = 64.6987 lengths = 37 } 
2022-05-01 04:22:32.053708 - gail/main.py:164 - [TRPO] iter = 146000 dist_mean = 0.1988 dist_std = 0.7062 vf_loss = 0.2831 grad_norm = 0.7660 nat_grad_norm = 0.4090 cg_residual = 0.0171 step_size = 0.4758 reward = -0.0000 fps = 65 mse_loss = 1.2444 
2022-05-01 04:22:42.185551 - gail/main.py:164 - [TRPO] iter = 147000 dist_mean = 0.1531 dist_std = 0.7025 vf_loss = 0.5349 grad_norm = 0.7141 nat_grad_norm = 0.4660 cg_residual = 0.0462 step_size = 0.3879 reward = 0.0000 fps = 39 mse_loss = 1.3116 
2022-05-01 04:22:52.758119 - gail/main.py:164 - [TRPO] iter = 148000 dist_mean = 0.3162 dist_std = 0.6993 vf_loss = 0.4866 grad_norm = 0.7567 nat_grad_norm = 0.4026 cg_residual = 0.0205 step_size = 0.4024 reward = 0.0000 fps = 27 mse_loss = 1.4390 
2022-05-01 04:23:03.065645 - gail/main.py:164 - [TRPO] iter = 149000 dist_mean = 0.3569 dist_std = 0.6990 vf_loss = 0.2915 grad_norm = 0.7244 nat_grad_norm = 0.4921 cg_residual = 0.0264 step_size = 0.3770 reward = 0.0000 fps = 21 mse_loss = 1.3964 
2022-05-01 04:23:13.020515 - gail/main.py:164 - [TRPO] iter = 150000 dist_mean = 0.2221 dist_std = 0.6926 vf_loss = 2.0251 grad_norm = 0.7154 nat_grad_norm = 0.4471 cg_residual = 0.0418 step_size = 0.3898 reward = -0.0000 fps = 17 mse_loss = 1.4894 
2022-05-01 04:23:13.271457 - gail/main.py:191 - [Discriminator] iter = 150000 loss = -1.1680 grad_norm = 2.5352 grad_penalty = 0.1235 regularization = 0.0000 true_logits = 0.1078 fake_logits = -1.1837 true_prob = 0.5340 fake_prob = 0.2778 
2022-05-01 04:23:18.591943 - gail/main.py:132 - [Evaluate] iter = 150000 episode={ returns = 66.3445 lengths = 37 } discounted_episode={ returns = 64.9678 lengths = 37 } 
2022-05-01 04:23:28.596944 - gail/main.py:164 - [TRPO] iter = 151000 dist_mean = 0.0070 dist_std = 0.6876 vf_loss = 0.3985 grad_norm = 0.5429 nat_grad_norm = 0.4201 cg_residual = 0.0497 step_size = 0.4562 reward = 0.0000 fps = 65 mse_loss = 1.6050 
2022-05-01 04:23:38.974577 - gail/main.py:164 - [TRPO] iter = 152000 dist_mean = 0.0849 dist_std = 0.6924 vf_loss = 0.2883 grad_norm = 0.6674 nat_grad_norm = 0.3666 cg_residual = 0.0297 step_size = 0.4652 reward = 0.0000 fps = 38 mse_loss = 1.6525 
2022-05-01 04:23:49.185688 - gail/main.py:164 - [TRPO] iter = 153000 dist_mean = 0.0790 dist_std = 0.6868 vf_loss = 0.3099 grad_norm = 0.7288 nat_grad_norm = 0.3140 cg_residual = 0.0340 step_size = 0.5008 reward = -0.0000 fps = 27 mse_loss = 1.4476 
2022-05-01 04:23:59.194008 - gail/main.py:164 - [TRPO] iter = 154000 dist_mean = 0.0418 dist_std = 0.6845 vf_loss = 0.3445 grad_norm = 0.6988 nat_grad_norm = 0.3450 cg_residual = 0.0383 step_size = 0.5035 reward = -0.0000 fps = 21 mse_loss = 1.4538 
2022-05-01 04:24:09.073164 - gail/main.py:164 - [TRPO] iter = 155000 dist_mean = 0.1249 dist_std = 0.6770 vf_loss = 0.3592 grad_norm = 0.6592 nat_grad_norm = 0.3244 cg_residual = 0.0455 step_size = 0.4865 reward = -0.0000 fps = 17 mse_loss = 1.4688 
2022-05-01 04:24:09.325452 - gail/main.py:191 - [Discriminator] iter = 155000 loss = -0.7376 grad_norm = 2.5987 grad_penalty = 0.1447 regularization = 0.0000 true_logits = 0.0752 fake_logits = -0.8071 true_prob = 0.5266 fake_prob = 0.3515 
2022-05-01 04:24:14.230273 - gail/main.py:132 - [Evaluate] iter = 155000 episode={ returns = 59.8596 lengths = 34 } discounted_episode={ returns = 58.8763 lengths = 34 } 
2022-05-01 04:24:24.319694 - gail/main.py:164 - [TRPO] iter = 156000 dist_mean = 0.1203 dist_std = 0.6775 vf_loss = 0.5171 grad_norm = 0.7639 nat_grad_norm = 0.6306 cg_residual = 0.0712 step_size = 0.3223 reward = -0.0000 fps = 66 mse_loss = 1.4036 
2022-05-01 04:24:34.484817 - gail/main.py:164 - [TRPO] iter = 157000 dist_mean = 0.2206 dist_std = 0.6752 vf_loss = 0.3127 grad_norm = 0.6593 nat_grad_norm = 0.3567 cg_residual = 0.0305 step_size = 0.4464 reward = 0.0000 fps = 39 mse_loss = 1.5422 
2022-05-01 04:24:44.616557 - gail/main.py:164 - [TRPO] iter = 158000 dist_mean = 0.1292 dist_std = 0.6713 vf_loss = 0.3217 grad_norm = 0.7234 nat_grad_norm = 0.4224 cg_residual = 0.0379 step_size = 0.4251 reward = -0.0000 fps = 28 mse_loss = 1.5547 
2022-05-01 04:24:54.506207 - gail/main.py:164 - [TRPO] iter = 159000 dist_mean = 0.0420 dist_std = 0.6758 vf_loss = 0.2378 grad_norm = 0.6231 nat_grad_norm = 0.3101 cg_residual = 0.0360 step_size = 0.5437 reward = 0.0000 fps = 22 mse_loss = 1.3912 
2022-05-01 04:25:04.706442 - gail/main.py:164 - [TRPO] iter = 160000 dist_mean = 0.0242 dist_std = 0.6714 vf_loss = 0.4325 grad_norm = 0.5972 nat_grad_norm = 0.4012 cg_residual = 0.0345 step_size = 0.4577 reward = 0.0000 fps = 18 mse_loss = 1.4646 
2022-05-01 04:25:04.974946 - gail/main.py:191 - [Discriminator] iter = 160000 loss = -0.5567 grad_norm = 2.3537 grad_penalty = 0.1150 regularization = 0.0000 true_logits = 0.0307 fake_logits = -0.6410 true_prob = 0.5168 fake_prob = 0.3727 
2022-05-01 04:25:09.367651 - gail/main.py:132 - [Evaluate] iter = 160000 episode={ returns = 54.2678 lengths = 30 } discounted_episode={ returns = 53.2867 lengths = 30 } 
2022-05-01 04:25:19.510564 - gail/main.py:164 - [TRPO] iter = 161000 dist_mean = 0.2116 dist_std = 0.6700 vf_loss = 0.3661 grad_norm = 0.7884 nat_grad_norm = 0.3757 cg_residual = 0.0567 step_size = 0.4238 reward = -0.0000 fps = 68 mse_loss = 1.5418 
2022-05-01 04:25:29.906000 - gail/main.py:164 - [TRPO] iter = 162000 dist_mean = 0.6271 dist_std = 0.6731 vf_loss = 0.2040 grad_norm = 0.5124 nat_grad_norm = 0.3312 cg_residual = 0.0122 step_size = 0.5621 reward = 0.0000 fps = 40 mse_loss = 1.5627 
2022-05-01 04:25:40.299287 - gail/main.py:164 - [TRPO] iter = 163000 dist_mean = 0.2782 dist_std = 0.6766 vf_loss = 0.2388 grad_norm = 0.8328 nat_grad_norm = 0.3396 cg_residual = 0.0359 step_size = 0.5300 reward = -0.0000 fps = 28 mse_loss = 1.3594 
2022-05-01 04:25:50.534946 - gail/main.py:164 - [TRPO] iter = 164000 dist_mean = 0.5516 dist_std = 0.6775 vf_loss = 0.3258 grad_norm = 0.9758 nat_grad_norm = 0.5763 cg_residual = 0.0429 step_size = 0.3366 reward = -0.0000 fps = 21 mse_loss = 1.3929 
2022-05-01 04:26:00.557836 - gail/main.py:164 - [TRPO] iter = 165000 dist_mean = 0.4436 dist_std = 0.6791 vf_loss = 0.5168 grad_norm = 0.6208 nat_grad_norm = 0.4006 cg_residual = 0.0244 step_size = 0.4858 reward = 0.0000 fps = 17 mse_loss = 1.3453 
2022-05-01 04:26:00.769962 - gail/main.py:191 - [Discriminator] iter = 165000 loss = -1.5679 grad_norm = 2.7192 grad_penalty = 0.1294 regularization = 0.0000 true_logits = 0.0478 fake_logits = -1.6495 true_prob = 0.5211 fake_prob = 0.2149 
2022-05-01 04:26:04.305611 - gail/main.py:132 - [Evaluate] iter = 165000 episode={ returns = 41.6909 lengths = 23 } discounted_episode={ returns = 40.7629 lengths = 23 } 
2022-05-01 04:26:14.527487 - gail/main.py:164 - [TRPO] iter = 166000 dist_mean = 0.5394 dist_std = 0.6766 vf_loss = 0.1010 grad_norm = 0.6116 nat_grad_norm = 0.5447 cg_residual = 0.0228 step_size = 0.3794 reward = 0.0000 fps = 72 mse_loss = 1.4480 
2022-05-01 04:26:24.817199 - gail/main.py:164 - [TRPO] iter = 167000 dist_mean = 0.2620 dist_std = 0.6799 vf_loss = 0.6104 grad_norm = 0.5058 nat_grad_norm = 0.3837 cg_residual = 0.0185 step_size = 0.5191 reward = -0.0000 fps = 41 mse_loss = 1.7258 
2022-05-01 04:26:35.179480 - gail/main.py:164 - [TRPO] iter = 168000 dist_mean = 0.4803 dist_std = 0.6783 vf_loss = 1.2073 grad_norm = 0.7999 nat_grad_norm = 0.3544 cg_residual = 0.0113 step_size = 0.4794 reward = -0.0000 fps = 29 mse_loss = 1.6059 
2022-05-01 04:26:45.190599 - gail/main.py:164 - [TRPO] iter = 169000 dist_mean = 0.0035 dist_std = 0.6778 vf_loss = 0.4330 grad_norm = 0.6750 nat_grad_norm = 0.3949 cg_residual = 0.0326 step_size = 0.4461 reward = -0.0000 fps = 22 mse_loss = 1.7051 
2022-05-01 04:26:55.392744 - gail/main.py:164 - [TRPO] iter = 170000 dist_mean = 0.0341 dist_std = 0.6805 vf_loss = 0.3791 grad_norm = 0.5437 nat_grad_norm = 0.4223 cg_residual = 0.0415 step_size = 0.4593 reward = -0.0000 fps = 18 mse_loss = 1.5053 
2022-05-01 04:26:55.601018 - gail/main.py:191 - [Discriminator] iter = 170000 loss = -0.7430 grad_norm = 2.7525 grad_penalty = 0.1244 regularization = 0.0000 true_logits = 0.0752 fake_logits = -0.7923 true_prob = 0.5273 fake_prob = 0.3484 
2022-05-01 04:26:59.492329 - gail/main.py:132 - [Evaluate] iter = 170000 episode={ returns = 49.2074 lengths = 28 } discounted_episode={ returns = 48.1316 lengths = 27 } 
2022-05-01 04:27:09.693348 - gail/main.py:164 - [TRPO] iter = 171000 dist_mean = -0.0060 dist_std = 0.6702 vf_loss = 0.4258 grad_norm = 0.6823 nat_grad_norm = 0.3468 cg_residual = 0.0586 step_size = 0.4836 reward = -0.0000 fps = 71 mse_loss = 1.5322 
2022-05-01 04:27:19.518593 - gail/main.py:164 - [TRPO] iter = 172000 dist_mean = 0.0914 dist_std = 0.6697 vf_loss = 0.2556 grad_norm = 0.6928 nat_grad_norm = 0.3596 cg_residual = 0.0320 step_size = 0.4036 reward = 0.0000 fps = 41 mse_loss = 1.5089 
2022-05-01 04:27:29.401081 - gail/main.py:164 - [TRPO] iter = 173000 dist_mean = 0.0331 dist_std = 0.6668 vf_loss = 0.2695 grad_norm = 0.5782 nat_grad_norm = 0.4474 cg_residual = 0.0582 step_size = 0.4177 reward = 0.0000 fps = 29 mse_loss = 1.5665 
2022-05-01 04:27:39.322245 - gail/main.py:164 - [TRPO] iter = 174000 dist_mean = 0.0784 dist_std = 0.6626 vf_loss = 0.2025 grad_norm = 0.6211 nat_grad_norm = 0.3503 cg_residual = 0.0319 step_size = 0.5366 reward = -0.0000 fps = 22 mse_loss = 1.4303 
2022-05-01 04:27:49.086745 - gail/main.py:164 - [TRPO] iter = 175000 dist_mean = 0.0743 dist_std = 0.6727 vf_loss = 0.3241 grad_norm = 0.7487 nat_grad_norm = 0.3396 cg_residual = 0.0301 step_size = 0.4786 reward = -0.0000 fps = 18 mse_loss = 1.6013 
2022-05-01 04:27:49.295862 - gail/main.py:191 - [Discriminator] iter = 175000 loss = -0.7541 grad_norm = 2.4835 grad_penalty = 0.1165 regularization = 0.0000 true_logits = 0.0944 fake_logits = -0.7763 true_prob = 0.5281 fake_prob = 0.3535 
2022-05-01 04:28:47.985694 - gail/main.py:132 - [Evaluate] iter = 175000 episode={ returns = 1498.2920 lengths = 438 } discounted_episode={ returns = 1177.5389 lengths = 437 } 
2022-05-01 04:28:57.751699 - gail/main.py:164 - [TRPO] iter = 176000 dist_mean = 0.0591 dist_std = 0.6634 vf_loss = 0.1338 grad_norm = 0.5565 nat_grad_norm = 0.3612 cg_residual = 0.0227 step_size = 0.4495 reward = -0.0000 fps = 14 mse_loss = 1.6950 
2022-05-01 04:29:07.855558 - gail/main.py:164 - [TRPO] iter = 177000 dist_mean = 0.0728 dist_std = 0.6573 vf_loss = 0.3057 grad_norm = 0.5305 nat_grad_norm = 0.3151 cg_residual = 0.0210 step_size = 0.5037 reward = 0.0000 fps = 12 mse_loss = 1.6506 
2022-05-01 04:29:17.543372 - gail/main.py:164 - [TRPO] iter = 178000 dist_mean = 0.0446 dist_std = 0.6455 vf_loss = 0.2951 grad_norm = 0.7352 nat_grad_norm = 0.2900 cg_residual = 0.0362 step_size = 0.5052 reward = 0.0000 fps = 11 mse_loss = 1.6525 
2022-05-01 04:29:27.439855 - gail/main.py:164 - [TRPO] iter = 179000 dist_mean = 0.1792 dist_std = 0.6296 vf_loss = 0.8319 grad_norm = 0.6805 nat_grad_norm = 0.3087 cg_residual = 0.0253 step_size = 0.4326 reward = -0.0000 fps = 10 mse_loss = 1.5628 
2022-05-01 04:29:37.863477 - gail/main.py:164 - [TRPO] iter = 180000 dist_mean = 0.1512 dist_std = 0.6293 vf_loss = 0.2486 grad_norm = 0.7248 nat_grad_norm = 0.3230 cg_residual = 0.0601 step_size = 0.4156 reward = -0.0000 fps = 9 mse_loss = 1.4698 
2022-05-01 04:29:38.139180 - gail/main.py:191 - [Discriminator] iter = 180000 loss = -0.6846 grad_norm = 2.4436 grad_penalty = 0.1089 regularization = 0.0000 true_logits = 0.0684 fake_logits = -0.7251 true_prob = 0.5239 fake_prob = 0.3601 
2022-05-01 04:31:53.476335 - gail/main.py:132 - [Evaluate] iter = 180000 episode={ returns = 3415.2423 lengths = 987 } discounted_episode={ returns = 2097.7313 lengths = 985 } 
2022-05-01 04:32:03.358209 - gail/main.py:164 - [TRPO] iter = 181000 dist_mean = 0.1785 dist_std = 0.6271 vf_loss = 0.5715 grad_norm = 0.5534 nat_grad_norm = 0.3121 cg_residual = 0.0391 step_size = 0.5176 reward = -0.0000 fps = 6 mse_loss = 1.4477 
2022-05-01 04:32:12.991394 - gail/main.py:164 - [TRPO] iter = 182000 dist_mean = 0.0987 dist_std = 0.6346 vf_loss = 0.6282 grad_norm = 0.8863 nat_grad_norm = 0.3035 cg_residual = 0.0504 step_size = 0.4496 reward = -0.0000 fps = 6 mse_loss = 1.6384 
2022-05-01 04:32:22.714170 - gail/main.py:164 - [TRPO] iter = 183000 dist_mean = 0.1315 dist_std = 0.6273 vf_loss = 0.5678 grad_norm = 0.9590 nat_grad_norm = 0.3427 cg_residual = 0.0444 step_size = 0.4337 reward = 0.0000 fps = 6 mse_loss = 1.5113 
2022-05-01 04:32:32.839362 - gail/main.py:164 - [TRPO] iter = 184000 dist_mean = 0.3031 dist_std = 0.6249 vf_loss = 0.6590 grad_norm = 1.2713 nat_grad_norm = 0.2614 cg_residual = 0.0397 step_size = 0.4196 reward = 0.0000 fps = 5 mse_loss = 1.4612 
2022-05-01 04:32:43.379579 - gail/main.py:164 - [TRPO] iter = 185000 dist_mean = 0.6276 dist_std = 0.6200 vf_loss = 0.1055 grad_norm = 0.5710 nat_grad_norm = 0.2915 cg_residual = 0.0467 step_size = 0.5392 reward = -0.0000 fps = 5 mse_loss = 1.4329 
2022-05-01 04:32:43.642701 - gail/main.py:191 - [Discriminator] iter = 185000 loss = -2.2052 grad_norm = 3.4300 grad_penalty = 0.1881 regularization = 0.0000 true_logits = 0.0410 fake_logits = -2.3523 true_prob = 0.5173 fake_prob = 0.1241 
2022-05-01 04:32:47.026711 - gail/main.py:132 - [Evaluate] iter = 185000 episode={ returns = 39.6113 lengths = 22 } discounted_episode={ returns = 39.1150 lengths = 22 } 
2022-05-01 04:32:57.737317 - gail/main.py:164 - [TRPO] iter = 186000 dist_mean = 0.7595 dist_std = 0.6229 vf_loss = 0.0818 grad_norm = 0.4514 nat_grad_norm = 0.1746 cg_residual = 0.0031 step_size = 0.8360 reward = 0.0000 fps = 71 mse_loss = 1.5088 
2022-05-01 04:33:08.022498 - gail/main.py:164 - [TRPO] iter = 187000 dist_mean = 0.7444 dist_std = 0.6167 vf_loss = 0.0850 grad_norm = 1.9065 nat_grad_norm = 0.1959 cg_residual = 0.0094 step_size = 0.5468 reward = 0.0000 fps = 41 mse_loss = 1.6926 
2022-05-01 04:33:18.047992 - gail/main.py:164 - [TRPO] iter = 188000 dist_mean = 0.6267 dist_std = 0.6167 vf_loss = 0.2675 grad_norm = 0.4465 nat_grad_norm = 0.4540 cg_residual = 0.2619 step_size = 0.4297 reward = 0.0000 fps = 29 mse_loss = 1.5923 
2022-05-01 04:33:28.266764 - gail/main.py:164 - [TRPO] iter = 189000 dist_mean = 0.7030 dist_std = 0.6128 vf_loss = 0.0691 grad_norm = 1.7333 nat_grad_norm = 0.1736 cg_residual = 0.0068 step_size = 0.5480 reward = 0.0000 fps = 22 mse_loss = 1.6496 
2022-05-01 04:33:38.610748 - gail/main.py:164 - [TRPO] iter = 190000 dist_mean = 0.4310 dist_std = 0.6096 vf_loss = 0.1811 grad_norm = 0.7929 nat_grad_norm = 0.4449 cg_residual = 0.0738 step_size = 0.4178 reward = -0.0000 fps = 18 mse_loss = 1.7216 
2022-05-01 04:33:38.833011 - gail/main.py:191 - [Discriminator] iter = 190000 loss = -1.9263 grad_norm = 2.6285 grad_penalty = 0.1813 regularization = 0.0000 true_logits = 0.0967 fake_logits = -2.0109 true_prob = 0.5303 fake_prob = 0.1790 
2022-05-01 04:33:42.051744 - gail/main.py:132 - [Evaluate] iter = 190000 episode={ returns = 40.6104 lengths = 23 } discounted_episode={ returns = 39.9809 lengths = 23 } 
2022-05-01 04:33:52.260994 - gail/main.py:164 - [TRPO] iter = 191000 dist_mean = 0.3253 dist_std = 0.6182 vf_loss = 0.1957 grad_norm = 0.6583 nat_grad_norm = 0.2628 cg_residual = 0.0203 step_size = 0.5748 reward = -0.0000 fps = 74 mse_loss = 1.6889 
2022-05-01 04:34:02.579695 - gail/main.py:164 - [TRPO] iter = 192000 dist_mean = 0.4275 dist_std = 0.6226 vf_loss = 0.5471 grad_norm = 0.8425 nat_grad_norm = 0.4579 cg_residual = 0.0438 step_size = 0.3335 reward = -0.0000 fps = 42 mse_loss = 1.3105 
2022-05-01 04:34:12.770104 - gail/main.py:164 - [TRPO] iter = 193000 dist_mean = 0.1574 dist_std = 0.6203 vf_loss = 0.3114 grad_norm = 0.8192 nat_grad_norm = 0.4392 cg_residual = 0.0476 step_size = 0.4082 reward = -0.0000 fps = 29 mse_loss = 1.3621 
2022-05-01 04:34:23.056007 - gail/main.py:164 - [TRPO] iter = 194000 dist_mean = 0.4588 dist_std = 0.6102 vf_loss = 0.7242 grad_norm = 0.5204 nat_grad_norm = 0.3501 cg_residual = 0.0399 step_size = 0.5173 reward = -0.0000 fps = 22 mse_loss = 1.4086 
2022-05-01 04:34:32.745825 - gail/main.py:164 - [TRPO] iter = 195000 dist_mean = 0.2589 dist_std = 0.6094 vf_loss = 0.3140 grad_norm = 0.4995 nat_grad_norm = 0.2622 cg_residual = 0.0282 step_size = 0.5698 reward = -0.0000 fps = 18 mse_loss = 1.4643 
2022-05-01 04:34:32.990363 - gail/main.py:191 - [Discriminator] iter = 195000 loss = -1.2164 grad_norm = 2.6244 grad_penalty = 0.1384 regularization = 0.0000 true_logits = 0.1216 fake_logits = -1.2332 true_prob = 0.5336 fake_prob = 0.2813 
2022-05-01 04:34:36.377875 - gail/main.py:132 - [Evaluate] iter = 195000 episode={ returns = 40.8049 lengths = 23 } discounted_episode={ returns = 41.0056 lengths = 23 } 
2022-05-01 04:34:46.221247 - gail/main.py:164 - [TRPO] iter = 196000 dist_mean = 0.0977 dist_std = 0.6082 vf_loss = 0.3113 grad_norm = 0.7619 nat_grad_norm = 0.4025 cg_residual = 0.0407 step_size = 0.4542 reward = -0.0000 fps = 75 mse_loss = 1.5802 
2022-05-01 04:34:56.172970 - gail/main.py:164 - [TRPO] iter = 197000 dist_mean = 0.3087 dist_std = 0.6035 vf_loss = 0.4975 grad_norm = 0.6938 nat_grad_norm = 0.3619 cg_residual = 0.0275 step_size = 0.4737 reward = 0.0000 fps = 43 mse_loss = 1.6552 
2022-05-01 04:35:06.352462 - gail/main.py:164 - [TRPO] iter = 198000 dist_mean = 0.1384 dist_std = 0.6105 vf_loss = 0.3901 grad_norm = 0.6310 nat_grad_norm = 0.3679 cg_residual = 0.1076 step_size = 0.4548 reward = -0.0000 fps = 29 mse_loss = 1.8947 
2022-05-01 04:35:16.418034 - gail/main.py:164 - [TRPO] iter = 199000 dist_mean = 0.0695 dist_std = 0.6036 vf_loss = 0.3899 grad_norm = 0.5770 nat_grad_norm = 0.2742 cg_residual = 0.0177 step_size = 0.6068 reward = -0.0000 fps = 23 mse_loss = 1.6655 
2022-05-01 04:35:26.415318 - gail/main.py:164 - [TRPO] iter = 200000 dist_mean = 0.1436 dist_std = 0.6055 vf_loss = 0.3868 grad_norm = 0.6696 nat_grad_norm = 0.3930 cg_residual = 0.0465 step_size = 0.4487 reward = 0.0000 fps = 18 mse_loss = 1.7160 
2022-05-01 04:35:26.626679 - gail/main.py:191 - [Discriminator] iter = 200000 loss = -0.9364 grad_norm = 2.8019 grad_penalty = 0.1318 regularization = 0.0000 true_logits = 0.1181 fake_logits = -0.9501 true_prob = 0.5335 fake_prob = 0.3270 
2022-05-01 04:36:04.662686 - gail/main.py:132 - [Evaluate] iter = 200000 episode={ returns = 388.8472 lengths = 127 } discounted_episode={ returns = 872.9684 lengths = 418 } 
2022-05-01 04:36:14.678724 - gail/main.py:164 - [TRPO] iter = 201000 dist_mean = 0.0989 dist_std = 0.5914 vf_loss = 0.3755 grad_norm = 0.6185 nat_grad_norm = 0.3795 cg_residual = 0.0581 step_size = 0.4409 reward = 0.0000 fps = 20 mse_loss = 1.8339 
2022-05-01 04:36:24.522915 - gail/main.py:164 - [TRPO] iter = 202000 dist_mean = 0.1375 dist_std = 0.5860 vf_loss = 0.4832 grad_norm = 0.6989 nat_grad_norm = 0.3315 cg_residual = 0.0619 step_size = 0.4979 reward = 0.0000 fps = 17 mse_loss = 1.6028 
2022-05-01 04:36:34.693422 - gail/main.py:164 - [TRPO] iter = 203000 dist_mean = 0.4411 dist_std = 0.5820 vf_loss = 0.1800 grad_norm = 0.6778 nat_grad_norm = 0.4567 cg_residual = 0.0886 step_size = 0.3463 reward = -0.0000 fps = 14 mse_loss = 1.5635 
2022-05-01 04:36:44.795320 - gail/main.py:164 - [TRPO] iter = 204000 dist_mean = 0.2058 dist_std = 0.5801 vf_loss = 0.1575 grad_norm = 0.7048 nat_grad_norm = 0.3111 cg_residual = 0.0329 step_size = 0.5033 reward = -0.0000 fps = 12 mse_loss = 1.5497 
2022-05-01 04:36:54.836687 - gail/main.py:164 - [TRPO] iter = 205000 dist_mean = 0.1783 dist_std = 0.5823 vf_loss = 0.2275 grad_norm = 0.7441 nat_grad_norm = 0.3353 cg_residual = 0.0770 step_size = 0.4833 reward = 0.0000 fps = 11 mse_loss = 1.2905 
2022-05-01 04:36:55.071432 - gail/main.py:191 - [Discriminator] iter = 205000 loss = -1.0148 grad_norm = 2.6593 grad_penalty = 0.1101 regularization = 0.0000 true_logits = 0.0431 fake_logits = -1.0819 true_prob = 0.5188 fake_prob = 0.3017 
2022-05-01 04:36:58.476081 - gail/main.py:132 - [Evaluate] iter = 205000 episode={ returns = 40.1673 lengths = 22 } discounted_episode={ returns = 40.2972 lengths = 23 } 
2022-05-01 04:37:08.701188 - gail/main.py:164 - [TRPO] iter = 206000 dist_mean = 0.1452 dist_std = 0.5817 vf_loss = 0.2407 grad_norm = 0.5829 nat_grad_norm = 0.3090 cg_residual = 0.0485 step_size = 0.5385 reward = -0.0000 fps = 73 mse_loss = 1.4498 
2022-05-01 04:37:18.377450 - gail/main.py:164 - [TRPO] iter = 207000 dist_mean = 0.1221 dist_std = 0.5716 vf_loss = 1.1236 grad_norm = 0.8283 nat_grad_norm = 0.2651 cg_residual = 0.0327 step_size = 0.5839 reward = 0.0000 fps = 42 mse_loss = 1.3744 
2022-05-01 04:37:28.220489 - gail/main.py:164 - [TRPO] iter = 208000 dist_mean = 0.0877 dist_std = 0.5724 vf_loss = 0.7075 grad_norm = 0.7068 nat_grad_norm = 0.2860 cg_residual = 0.0373 step_size = 0.5193 reward = -0.0000 fps = 30 mse_loss = 1.4712 
2022-05-01 04:37:38.669148 - gail/main.py:164 - [TRPO] iter = 209000 dist_mean = 0.3170 dist_std = 0.5733 vf_loss = 0.2851 grad_norm = 0.6495 nat_grad_norm = 0.4881 cg_residual = 0.0475 step_size = 0.3936 reward = 0.0000 fps = 22 mse_loss = 1.4854 
2022-05-01 04:37:48.558321 - gail/main.py:164 - [TRPO] iter = 210000 dist_mean = 0.1502 dist_std = 0.5740 vf_loss = 0.2085 grad_norm = 0.9044 nat_grad_norm = 0.3176 cg_residual = 0.0311 step_size = 0.4773 reward = 0.0000 fps = 18 mse_loss = 1.6633 
2022-05-01 04:37:48.804666 - gail/main.py:191 - [Discriminator] iter = 210000 loss = -0.6539 grad_norm = 2.2997 grad_penalty = 0.0974 regularization = 0.0000 true_logits = 0.0487 fake_logits = -0.7026 true_prob = 0.5174 fake_prob = 0.3736 
2022-05-01 04:37:51.984267 - gail/main.py:132 - [Evaluate] iter = 210000 episode={ returns = 39.9221 lengths = 22 } discounted_episode={ returns = 39.0150 lengths = 22 } 
2022-05-01 04:38:01.568519 - gail/main.py:164 - [TRPO] iter = 211000 dist_mean = 0.0748 dist_std = 0.5671 vf_loss = 0.1661 grad_norm = 0.7337 nat_grad_norm = 0.3137 cg_residual = 0.0575 step_size = 0.4655 reward = 0.0000 fps = 78 mse_loss = 1.5180 
2022-05-01 04:38:11.701609 - gail/main.py:164 - [TRPO] iter = 212000 dist_mean = 0.2206 dist_std = 0.5573 vf_loss = 0.2408 grad_norm = 0.9538 nat_grad_norm = 0.2725 cg_residual = 0.0379 step_size = 0.4888 reward = -0.0000 fps = 43 mse_loss = 1.3822 
2022-05-01 04:38:21.544781 - gail/main.py:164 - [TRPO] iter = 213000 dist_mean = 0.1883 dist_std = 0.5528 vf_loss = 0.1777 grad_norm = 0.7584 nat_grad_norm = 0.3083 cg_residual = 0.0368 step_size = 0.4484 reward = 0.0000 fps = 30 mse_loss = 1.3124 
2022-05-01 04:38:31.979712 - gail/main.py:164 - [TRPO] iter = 214000 dist_mean = 0.4026 dist_std = 0.5406 vf_loss = 0.0808 grad_norm = 0.8207 nat_grad_norm = 0.4017 cg_residual = 0.0385 step_size = 0.4245 reward = 0.0000 fps = 23 mse_loss = 1.4880 
2022-05-01 04:38:42.120674 - gail/main.py:164 - [TRPO] iter = 215000 dist_mean = 0.2653 dist_std = 0.5437 vf_loss = 0.1862 grad_norm = 0.7550 nat_grad_norm = 0.3265 cg_residual = 0.0264 step_size = 0.4560 reward = 0.0000 fps = 18 mse_loss = 1.3196 
2022-05-01 04:38:42.363258 - gail/main.py:191 - [Discriminator] iter = 215000 loss = -1.5097 grad_norm = 2.1588 grad_penalty = 0.1203 regularization = 0.0000 true_logits = 0.0604 fake_logits = -1.5696 true_prob = 0.5217 fake_prob = 0.2351 
2022-05-01 04:38:45.627878 - gail/main.py:132 - [Evaluate] iter = 215000 episode={ returns = 39.5610 lengths = 22 } discounted_episode={ returns = 39.0963 lengths = 22 } 
2022-05-01 04:38:56.012903 - gail/main.py:164 - [TRPO] iter = 216000 dist_mean = 0.0962 dist_std = 0.5396 vf_loss = 0.2166 grad_norm = 0.6681 nat_grad_norm = 0.2752 cg_residual = 0.0401 step_size = 0.5111 reward = 0.0000 fps = 73 mse_loss = 1.4341 
2022-05-01 04:39:06.256621 - gail/main.py:164 - [TRPO] iter = 217000 dist_mean = 0.2914 dist_std = 0.5357 vf_loss = 0.1311 grad_norm = 0.8131 nat_grad_norm = 0.4593 cg_residual = 0.0477 step_size = 0.3857 reward = 0.0000 fps = 41 mse_loss = 1.4364 
2022-05-01 04:39:16.303389 - gail/main.py:164 - [TRPO] iter = 218000 dist_mean = 0.1889 dist_std = 0.5331 vf_loss = 1.0454 grad_norm = 0.7802 nat_grad_norm = 0.2385 cg_residual = 0.0343 step_size = 0.5190 reward = -0.0000 fps = 29 mse_loss = 1.3879 
2022-05-01 04:39:26.289592 - gail/main.py:164 - [TRPO] iter = 219000 dist_mean = 0.1548 dist_std = 0.5396 vf_loss = 0.1874 grad_norm = 0.9306 nat_grad_norm = 0.3752 cg_residual = 0.0828 step_size = 0.4139 reward = 0.0000 fps = 22 mse_loss = 1.6717 
2022-05-01 04:39:36.200710 - gail/main.py:164 - [TRPO] iter = 220000 dist_mean = 0.1766 dist_std = 0.5340 vf_loss = 0.1927 grad_norm = 0.8064 nat_grad_norm = 0.3206 cg_residual = 0.0309 step_size = 0.5151 reward = -0.0000 fps = 18 mse_loss = 1.3762 
2022-05-01 04:39:36.436323 - gail/main.py:191 - [Discriminator] iter = 220000 loss = -1.0744 grad_norm = 2.9555 grad_penalty = 0.1215 regularization = 0.0000 true_logits = 0.0342 fake_logits = -1.1617 true_prob = 0.5148 fake_prob = 0.2977 
2022-05-01 04:39:39.800098 - gail/main.py:132 - [Evaluate] iter = 220000 episode={ returns = 39.6580 lengths = 22 } discounted_episode={ returns = 39.6374 lengths = 22 } 
2022-05-01 04:39:49.844199 - gail/main.py:164 - [TRPO] iter = 221000 dist_mean = 0.1390 dist_std = 0.5269 vf_loss = 0.2294 grad_norm = 0.6727 nat_grad_norm = 0.3815 cg_residual = 0.1049 step_size = 0.4390 reward = 0.0000 fps = 74 mse_loss = 1.5086 
2022-05-01 04:40:00.285214 - gail/main.py:164 - [TRPO] iter = 222000 dist_mean = 0.2721 dist_std = 0.5219 vf_loss = 0.7529 grad_norm = 0.6324 nat_grad_norm = 0.2561 cg_residual = 0.0284 step_size = 0.5702 reward = -0.0000 fps = 41 mse_loss = 1.3023 
2022-05-01 04:40:10.709826 - gail/main.py:164 - [TRPO] iter = 223000 dist_mean = 0.2147 dist_std = 0.5161 vf_loss = 0.1624 grad_norm = 0.8473 nat_grad_norm = 0.3247 cg_residual = 0.0469 step_size = 0.4683 reward = -0.0000 fps = 29 mse_loss = 1.2480 
2022-05-01 04:40:20.836091 - gail/main.py:164 - [TRPO] iter = 224000 dist_mean = 0.1113 dist_std = 0.4999 vf_loss = 0.1127 grad_norm = 0.5460 nat_grad_norm = 0.3107 cg_residual = 0.1168 step_size = 0.5134 reward = 0.0000 fps = 22 mse_loss = 1.3656 
2022-05-01 04:40:31.139154 - gail/main.py:164 - [TRPO] iter = 225000 dist_mean = 0.2101 dist_std = 0.4912 vf_loss = 0.0880 grad_norm = 0.5163 nat_grad_norm = 0.2956 cg_residual = 0.0618 step_size = 0.5647 reward = -0.0000 fps = 18 mse_loss = 1.3897 
2022-05-01 04:40:31.361292 - gail/main.py:191 - [Discriminator] iter = 225000 loss = -1.2611 grad_norm = 2.8645 grad_penalty = 0.1048 regularization = 0.0000 true_logits = 0.0485 fake_logits = -1.3173 true_prob = 0.5186 fake_prob = 0.2788 
2022-05-01 04:40:34.855051 - gail/main.py:132 - [Evaluate] iter = 225000 episode={ returns = 39.4898 lengths = 22 } discounted_episode={ returns = 39.7720 lengths = 23 } 
2022-05-01 04:40:45.410258 - gail/main.py:164 - [TRPO] iter = 226000 dist_mean = 0.1893 dist_std = 0.4951 vf_loss = 0.1560 grad_norm = 0.8538 nat_grad_norm = 0.3504 cg_residual = 0.0830 step_size = 0.4625 reward = 0.0000 fps = 71 mse_loss = 1.4414 
2022-05-01 04:40:55.832033 - gail/main.py:164 - [TRPO] iter = 227000 dist_mean = 0.2302 dist_std = 0.4861 vf_loss = 2.5673 grad_norm = 1.0606 nat_grad_norm = 0.2636 cg_residual = 0.0501 step_size = 0.4605 reward = 0.0000 fps = 40 mse_loss = 1.4063 
2022-05-01 04:41:06.596826 - gail/main.py:164 - [TRPO] iter = 228000 dist_mean = 0.3273 dist_std = 0.4735 vf_loss = 0.2229 grad_norm = 0.7043 nat_grad_norm = 0.3479 cg_residual = 0.0480 step_size = 0.4381 reward = -0.0000 fps = 28 mse_loss = 1.2362 
2022-05-01 04:41:16.611421 - gail/main.py:164 - [TRPO] iter = 229000 dist_mean = 0.2409 dist_std = 0.4744 vf_loss = 0.3323 grad_norm = 0.7118 nat_grad_norm = 0.2808 cg_residual = 0.0647 step_size = 0.5214 reward = -0.0000 fps = 22 mse_loss = 1.1786 
2022-05-01 04:41:26.506252 - gail/main.py:164 - [TRPO] iter = 230000 dist_mean = 0.0390 dist_std = 0.4709 vf_loss = 1.3405 grad_norm = 0.6253 nat_grad_norm = 0.1842 cg_residual = 0.0375 step_size = 0.7006 reward = -0.0000 fps = 18 mse_loss = 1.0990 
2022-05-01 04:41:26.733464 - gail/main.py:191 - [Discriminator] iter = 230000 loss = -0.5835 grad_norm = 2.5192 grad_penalty = 0.0835 regularization = 0.0000 true_logits = 0.0798 fake_logits = -0.5872 true_prob = 0.5260 fake_prob = 0.3909 
2022-05-01 04:41:30.230892 - gail/main.py:132 - [Evaluate] iter = 230000 episode={ returns = 39.7980 lengths = 22 } discounted_episode={ returns = 39.7787 lengths = 23 } 
2022-05-01 04:41:40.913167 - gail/main.py:164 - [TRPO] iter = 231000 dist_mean = 0.2983 dist_std = 0.4664 vf_loss = 0.2926 grad_norm = 0.9123 nat_grad_norm = 0.3338 cg_residual = 0.0590 step_size = 0.3959 reward = 0.0000 fps = 70 mse_loss = 1.1721 
2022-05-01 04:41:51.604624 - gail/main.py:164 - [TRPO] iter = 232000 dist_mean = 0.4878 dist_std = 0.4654 vf_loss = 0.3467 grad_norm = 1.8358 nat_grad_norm = 0.2826 cg_residual = 0.5049 step_size = 0.4066 reward = -0.0000 fps = 40 mse_loss = 1.2744 
2022-05-01 04:42:01.749064 - gail/main.py:164 - [TRPO] iter = 233000 dist_mean = 0.1879 dist_std = 0.4692 vf_loss = 0.3168 grad_norm = 0.7140 nat_grad_norm = 0.2759 cg_residual = 0.0951 step_size = 0.4628 reward = -0.0000 fps = 28 mse_loss = 1.2352 
2022-05-01 04:42:12.053242 - gail/main.py:164 - [TRPO] iter = 234000 dist_mean = 0.0890 dist_std = 0.4630 vf_loss = 1.0967 grad_norm = 0.6792 nat_grad_norm = 0.2299 cg_residual = 0.0384 step_size = 0.5359 reward = 0.0000 fps = 22 mse_loss = 1.1297 
2022-05-01 04:42:22.340309 - gail/main.py:164 - [TRPO] iter = 235000 dist_mean = 0.2394 dist_std = 0.4590 vf_loss = 0.1147 grad_norm = 0.8445 nat_grad_norm = 0.3445 cg_residual = 0.0635 step_size = 0.4421 reward = 0.0000 fps = 17 mse_loss = 1.1696 
2022-05-01 04:42:22.540253 - gail/main.py:191 - [Discriminator] iter = 235000 loss = -1.3707 grad_norm = 2.5858 grad_penalty = 0.1141 regularization = 0.0000 true_logits = 0.1079 fake_logits = -1.3770 true_prob = 0.5317 fake_prob = 0.2647 
2022-05-01 04:42:25.944980 - gail/main.py:132 - [Evaluate] iter = 235000 episode={ returns = 40.4288 lengths = 23 } discounted_episode={ returns = 39.4129 lengths = 22 } 
2022-05-01 04:42:36.485929 - gail/main.py:164 - [TRPO] iter = 236000 dist_mean = 0.0908 dist_std = 0.4553 vf_loss = 0.2564 grad_norm = 0.9128 nat_grad_norm = 0.2680 cg_residual = 0.1030 step_size = 0.4780 reward = 0.0000 fps = 71 mse_loss = 1.2296 
2022-05-01 04:42:46.819137 - gail/main.py:164 - [TRPO] iter = 237000 dist_mean = 0.1138 dist_std = 0.4551 vf_loss = 0.3187 grad_norm = 0.7837 nat_grad_norm = 0.3218 cg_residual = 0.1309 step_size = 0.4370 reward = -0.0000 fps = 41 mse_loss = 1.2552 
2022-05-01 04:42:57.256899 - gail/main.py:164 - [TRPO] iter = 238000 dist_mean = 0.2638 dist_std = 0.4451 vf_loss = 0.1759 grad_norm = 1.0484 nat_grad_norm = 0.2975 cg_residual = 0.1141 step_size = 0.4525 reward = 0.0000 fps = 28 mse_loss = 1.2731 
2022-05-01 04:43:07.650639 - gail/main.py:164 - [TRPO] iter = 239000 dist_mean = 0.1274 dist_std = 0.4431 vf_loss = 0.0859 grad_norm = 1.0117 nat_grad_norm = 0.2937 cg_residual = 0.0840 step_size = 0.5396 reward = -0.0000 fps = 22 mse_loss = 1.1870 
2022-05-01 04:43:17.971370 - gail/main.py:164 - [TRPO] iter = 240000 dist_mean = 0.1564 dist_std = 0.4426 vf_loss = 1.1834 grad_norm = 1.2073 nat_grad_norm = 0.2590 cg_residual = 0.0761 step_size = 0.4670 reward = -0.0000 fps = 18 mse_loss = 1.2805 
2022-05-01 04:43:18.186772 - gail/main.py:191 - [Discriminator] iter = 240000 loss = -1.2087 grad_norm = 2.4272 grad_penalty = 0.1071 regularization = 0.0000 true_logits = 0.1266 fake_logits = -1.1892 true_prob = 0.5343 fake_prob = 0.2986 
2022-05-01 04:43:21.528840 - gail/main.py:132 - [Evaluate] iter = 240000 episode={ returns = 39.1825 lengths = 22 } discounted_episode={ returns = 38.6463 lengths = 22 } 
2022-05-01 04:43:32.045189 - gail/main.py:164 - [TRPO] iter = 241000 dist_mean = 0.0762 dist_std = 0.4343 vf_loss = 0.1926 grad_norm = 1.1499 nat_grad_norm = 0.2914 cg_residual = 0.0847 step_size = 0.4514 reward = 0.0000 fps = 72 mse_loss = 1.3795 
2022-05-01 04:43:42.082968 - gail/main.py:164 - [TRPO] iter = 242000 dist_mean = 0.0565 dist_std = 0.4318 vf_loss = 0.2052 grad_norm = 1.1276 nat_grad_norm = 0.2031 cg_residual = 0.0983 step_size = 0.5345 reward = -0.0000 fps = 41 mse_loss = 1.2524 
2022-05-01 04:43:52.252414 - gail/main.py:164 - [TRPO] iter = 243000 dist_mean = 0.2167 dist_std = 0.4243 vf_loss = 1.3959 grad_norm = 0.8892 nat_grad_norm = 0.2457 cg_residual = 0.0501 step_size = 0.5647 reward = -0.0000 fps = 29 mse_loss = 1.1495 
2022-05-01 04:44:02.377596 - gail/main.py:164 - [TRPO] iter = 244000 dist_mean = 0.2908 dist_std = 0.4247 vf_loss = 1.7061 grad_norm = 0.8785 nat_grad_norm = 0.2381 cg_residual = 0.0455 step_size = 0.4815 reward = -0.0000 fps = 22 mse_loss = 1.1811 
2022-05-01 04:44:12.858482 - gail/main.py:164 - [TRPO] iter = 245000 dist_mean = 0.2006 dist_std = 0.4217 vf_loss = 0.3501 grad_norm = 1.1966 nat_grad_norm = 0.3729 cg_residual = 0.1678 step_size = 0.3484 reward = -0.0000 fps = 18 mse_loss = 1.2593 
2022-05-01 04:44:13.117854 - gail/main.py:191 - [Discriminator] iter = 245000 loss = -1.5236 grad_norm = 2.2100 grad_penalty = 0.1157 regularization = 0.0000 true_logits = 0.0704 fake_logits = -1.5689 true_prob = 0.5246 fake_prob = 0.2457 
2022-05-01 04:44:16.457086 - gail/main.py:132 - [Evaluate] iter = 245000 episode={ returns = 39.0444 lengths = 22 } discounted_episode={ returns = 38.8272 lengths = 22 } 
2022-05-01 04:44:26.813837 - gail/main.py:164 - [TRPO] iter = 246000 dist_mean = 0.2150 dist_std = 0.4215 vf_loss = 0.1745 grad_norm = 0.8704 nat_grad_norm = 0.2847 cg_residual = 0.0887 step_size = 0.4768 reward = -0.0000 fps = 73 mse_loss = 1.0895 
2022-05-01 04:44:36.941369 - gail/main.py:164 - [TRPO] iter = 247000 dist_mean = 0.1109 dist_std = 0.4152 vf_loss = 0.2663 grad_norm = 0.9019 nat_grad_norm = 0.2697 cg_residual = 0.0952 step_size = 0.4672 reward = 0.0000 fps = 42 mse_loss = 1.2120 
2022-05-01 04:44:47.263675 - gail/main.py:164 - [TRPO] iter = 248000 dist_mean = 0.1514 dist_std = 0.4103 vf_loss = 0.2452 grad_norm = 0.8638 nat_grad_norm = 0.2748 cg_residual = 0.1317 step_size = 0.4751 reward = 0.0000 fps = 29 mse_loss = 1.0766 
2022-05-01 04:44:57.465701 - gail/main.py:164 - [TRPO] iter = 249000 dist_mean = 0.1385 dist_std = 0.4065 vf_loss = 0.2428 grad_norm = 0.7884 nat_grad_norm = 0.2413 cg_residual = 0.0656 step_size = 0.4905 reward = 0.0000 fps = 22 mse_loss = 1.1255 
2022-05-01 04:45:07.916184 - gail/main.py:164 - [TRPO] iter = 250000 dist_mean = 0.0693 dist_std = 0.4025 vf_loss = 0.2377 grad_norm = 0.8899 nat_grad_norm = 0.2641 cg_residual = 0.0912 step_size = 0.4648 reward = -0.0000 fps = 18 mse_loss = 1.0753 
2022-05-01 04:45:08.135057 - gail/main.py:191 - [Discriminator] iter = 250000 loss = -0.7548 grad_norm = 2.7593 grad_penalty = 0.1013 regularization = 0.0000 true_logits = 0.1662 fake_logits = -0.6899 true_prob = 0.5433 fake_prob = 0.3763 
2022-05-01 04:45:11.452621 - gail/main.py:132 - [Evaluate] iter = 250000 episode={ returns = 39.3404 lengths = 22 } discounted_episode={ returns = 38.0312 lengths = 21 } 
2022-05-01 04:45:21.828842 - gail/main.py:164 - [TRPO] iter = 251000 dist_mean = 0.1029 dist_std = 0.4004 vf_loss = 0.1457 grad_norm = 1.0233 nat_grad_norm = 0.2184 cg_residual = 0.0784 step_size = 0.4852 reward = -0.0000 fps = 73 mse_loss = 1.1353 
2022-05-01 04:45:31.871238 - gail/main.py:164 - [TRPO] iter = 252000 dist_mean = 0.0442 dist_std = 0.3956 vf_loss = 0.1345 grad_norm = 0.8075 nat_grad_norm = 0.2788 cg_residual = 0.2577 step_size = 0.4672 reward = 0.0000 fps = 42 mse_loss = 1.1322 
2022-05-01 04:45:42.047357 - gail/main.py:164 - [TRPO] iter = 253000 dist_mean = 0.0072 dist_std = 0.3932 vf_loss = 0.1845 grad_norm = 1.0211 nat_grad_norm = 0.2357 cg_residual = 0.0872 step_size = 0.4665 reward = 0.0000 fps = 29 mse_loss = 1.0459 
2022-05-01 04:45:52.543562 - gail/main.py:164 - [TRPO] iter = 254000 dist_mean = 0.0755 dist_std = 0.3914 vf_loss = 0.2576 grad_norm = 0.9441 nat_grad_norm = 0.2565 cg_residual = 0.1869 step_size = 0.4601 reward = 0.0000 fps = 22 mse_loss = 1.0148 
2022-05-01 04:46:02.783130 - gail/main.py:164 - [TRPO] iter = 255000 dist_mean = 0.2353 dist_std = 0.3868 vf_loss = 0.1213 grad_norm = 0.8692 nat_grad_norm = 0.3174 cg_residual = 0.1367 step_size = 0.4375 reward = -0.0000 fps = 18 mse_loss = 1.1153 
2022-05-01 04:46:02.988180 - gail/main.py:191 - [Discriminator] iter = 255000 loss = -1.5975 grad_norm = 2.3761 grad_penalty = 0.1140 regularization = 0.0000 true_logits = 0.1199 fake_logits = -1.5915 true_prob = 0.5345 fake_prob = 0.2411 
2022-05-01 04:46:06.387573 - gail/main.py:132 - [Evaluate] iter = 255000 episode={ returns = 38.4544 lengths = 21 } discounted_episode={ returns = 38.4319 lengths = 22 } 
2022-05-01 04:46:16.450854 - gail/main.py:164 - [TRPO] iter = 256000 dist_mean = 0.1373 dist_std = 0.3866 vf_loss = 1.3842 grad_norm = 0.6026 nat_grad_norm = 0.2146 cg_residual = 0.0726 step_size = 0.6127 reward = 0.0000 fps = 74 mse_loss = 1.1532 
2022-05-01 04:46:26.160373 - gail/main.py:164 - [TRPO] iter = 257000 dist_mean = 0.0259 dist_std = 0.3916 vf_loss = 1.0749 grad_norm = 1.0529 nat_grad_norm = 0.1882 cg_residual = 0.0733 step_size = 0.5601 reward = -0.0000 fps = 43 mse_loss = 1.0332 
2022-05-01 04:46:36.247706 - gail/main.py:164 - [TRPO] iter = 258000 dist_mean = 0.0203 dist_std = 0.3903 vf_loss = 0.2739 grad_norm = 0.8443 nat_grad_norm = 0.2440 cg_residual = 0.0869 step_size = 0.4909 reward = -0.0000 fps = 30 mse_loss = 1.0657 
2022-05-01 04:46:46.147650 - gail/main.py:164 - [TRPO] iter = 259000 dist_mean = 0.0377 dist_std = 0.3867 vf_loss = 0.2101 grad_norm = 1.1444 nat_grad_norm = 0.2040 cg_residual = 0.0765 step_size = 0.4774 reward = -0.0000 fps = 23 mse_loss = 1.0151 
2022-05-01 04:46:55.868679 - gail/main.py:164 - [TRPO] iter = 260000 dist_mean = 0.1144 dist_std = 0.3863 vf_loss = 0.2047 grad_norm = 0.9722 nat_grad_norm = 0.3011 cg_residual = 0.2134 step_size = 0.4574 reward = -0.0000 fps = 18 mse_loss = 1.0870 
2022-05-01 04:46:56.090288 - gail/main.py:191 - [Discriminator] iter = 260000 loss = -1.0957 grad_norm = 2.2592 grad_penalty = 0.1021 regularization = 0.0000 true_logits = 0.1409 fake_logits = -1.0569 true_prob = 0.5382 fake_prob = 0.3209 
2022-05-01 04:46:59.209897 - gail/main.py:132 - [Evaluate] iter = 260000 episode={ returns = 38.3493 lengths = 21 } discounted_episode={ returns = 38.4516 lengths = 22 } 
2022-05-01 04:47:09.397500 - gail/main.py:164 - [TRPO] iter = 261000 dist_mean = 0.0917 dist_std = 0.3906 vf_loss = 0.7915 grad_norm = 0.9999 nat_grad_norm = 0.1725 cg_residual = 0.0630 step_size = 0.5615 reward = -0.0000 fps = 75 mse_loss = 1.1019 
2022-05-01 04:47:19.545926 - gail/main.py:164 - [TRPO] iter = 262000 dist_mean = 0.1719 dist_std = 0.3876 vf_loss = 0.1607 grad_norm = 0.8131 nat_grad_norm = 0.2511 cg_residual = 0.1183 step_size = 0.4815 reward = -0.0000 fps = 42 mse_loss = 1.0416 
2022-05-01 04:47:29.942329 - gail/main.py:164 - [TRPO] iter = 263000 dist_mean = 0.4521 dist_std = 0.3805 vf_loss = 0.1083 grad_norm = 0.8464 nat_grad_norm = 0.1032 cg_residual = 0.0349 step_size = 0.9731 reward = 0.0000 fps = 29 mse_loss = 1.0332 
2022-05-01 04:47:40.260352 - gail/main.py:164 - [TRPO] iter = 264000 dist_mean = 0.1799 dist_std = 0.3869 vf_loss = 0.1955 grad_norm = 0.8962 nat_grad_norm = 0.2136 cg_residual = 0.1427 step_size = 0.5084 reward = 0.0000 fps = 22 mse_loss = 1.0193 
2022-05-01 04:47:50.058522 - gail/main.py:164 - [TRPO] iter = 265000 dist_mean = 0.1074 dist_std = 0.3847 vf_loss = 0.5754 grad_norm = 1.3647 nat_grad_norm = 0.2298 cg_residual = 0.0840 step_size = 0.4826 reward = -0.0000 fps = 18 mse_loss = 1.1292 
2022-05-01 04:47:50.282451 - gail/main.py:191 - [Discriminator] iter = 265000 loss = -0.3969 grad_norm = 2.3963 grad_penalty = 0.0604 regularization = 0.0000 true_logits = 0.1044 fake_logits = -0.3529 true_prob = 0.5301 fake_prob = 0.4260 
2022-05-01 04:47:53.602640 - gail/main.py:132 - [Evaluate] iter = 265000 episode={ returns = 38.2279 lengths = 21 } discounted_episode={ returns = 38.7283 lengths = 22 } 
2022-05-01 04:48:03.505345 - gail/main.py:164 - [TRPO] iter = 266000 dist_mean = 0.1963 dist_std = 0.3824 vf_loss = 0.8198 grad_norm = 0.9874 nat_grad_norm = 0.2197 cg_residual = 0.1355 step_size = 0.5120 reward = -0.0000 fps = 75 mse_loss = 0.9534 
2022-05-01 04:48:13.927966 - gail/main.py:164 - [TRPO] iter = 267000 dist_mean = 0.4008 dist_std = 0.3827 vf_loss = 0.4263 grad_norm = 1.2861 nat_grad_norm = 0.3514 cg_residual = 0.2292 step_size = 0.3256 reward = -0.0000 fps = 42 mse_loss = 1.0992 
2022-05-01 04:48:23.937005 - gail/main.py:164 - [TRPO] iter = 268000 dist_mean = 0.1710 dist_std = 0.3847 vf_loss = 1.3742 grad_norm = 1.1528 nat_grad_norm = 0.1617 cg_residual = 0.0906 step_size = 0.5558 reward = -0.0000 fps = 29 mse_loss = 1.1722 
2022-05-01 04:48:33.928133 - gail/main.py:164 - [TRPO] iter = 269000 dist_mean = 0.1714 dist_std = 0.3852 vf_loss = 0.1113 grad_norm = 0.7956 nat_grad_norm = 0.2263 cg_residual = 0.1342 step_size = 0.5257 reward = 0.0000 fps = 22 mse_loss = 1.0674 
2022-05-01 04:48:43.862220 - gail/main.py:164 - [TRPO] iter = 270000 dist_mean = 0.1478 dist_std = 0.3818 vf_loss = 1.0762 grad_norm = 1.3157 nat_grad_norm = 0.1657 cg_residual = 0.0682 step_size = 0.5548 reward = -0.0000 fps = 18 mse_loss = 1.0865 
2022-05-01 04:48:44.135417 - gail/main.py:191 - [Discriminator] iter = 270000 loss = -0.6214 grad_norm = 2.3088 grad_penalty = 0.0736 regularization = 0.0000 true_logits = 0.0827 fake_logits = -0.6124 true_prob = 0.5247 fake_prob = 0.3859 
2022-05-01 04:48:47.202954 - gail/main.py:132 - [Evaluate] iter = 270000 episode={ returns = 38.9106 lengths = 22 } discounted_episode={ returns = 37.8413 lengths = 21 } 
2022-05-01 04:48:57.424452 - gail/main.py:164 - [TRPO] iter = 271000 dist_mean = 0.3138 dist_std = 0.3791 vf_loss = 1.3006 grad_norm = 0.8949 nat_grad_norm = 0.1975 cg_residual = 0.0380 step_size = 0.5112 reward = 0.0000 fps = 75 mse_loss = 1.0419 
2022-05-01 04:49:07.552130 - gail/main.py:164 - [TRPO] iter = 272000 dist_mean = 0.3886 dist_std = 0.3779 vf_loss = 0.3764 grad_norm = 1.6786 nat_grad_norm = 0.3570 cg_residual = 0.1584 step_size = 0.3459 reward = -0.0000 fps = 42 mse_loss = 1.2291 
2022-05-01 04:49:17.731571 - gail/main.py:164 - [TRPO] iter = 273000 dist_mean = 0.1220 dist_std = 0.3793 vf_loss = 1.7641 grad_norm = 1.1681 nat_grad_norm = 0.1328 cg_residual = 0.0565 step_size = 0.5873 reward = 0.0000 fps = 29 mse_loss = 1.0462 
2022-05-01 04:49:27.819620 - gail/main.py:164 - [TRPO] iter = 274000 dist_mean = 0.2822 dist_std = 0.3774 vf_loss = 0.4861 grad_norm = 0.8844 nat_grad_norm = 0.2366 cg_residual = 0.1837 step_size = 0.5351 reward = 0.0000 fps = 22 mse_loss = 1.1588 
2022-05-01 04:49:37.929726 - gail/main.py:164 - [TRPO] iter = 275000 dist_mean = 0.0952 dist_std = 0.3797 vf_loss = 0.2407 grad_norm = 0.9051 nat_grad_norm = 0.2536 cg_residual = 0.1528 step_size = 0.4608 reward = -0.0000 fps = 18 mse_loss = 1.0600 
2022-05-01 04:49:38.128512 - gail/main.py:191 - [Discriminator] iter = 275000 loss = -0.7151 grad_norm = 2.9744 grad_penalty = 0.0760 regularization = 0.0000 true_logits = 0.0506 fake_logits = -0.7405 true_prob = 0.5169 fake_prob = 0.3636 
2022-05-01 04:49:41.473658 - gail/main.py:132 - [Evaluate] iter = 275000 episode={ returns = 39.3449 lengths = 22 } discounted_episode={ returns = 39.1415 lengths = 22 } 
2022-05-01 04:49:51.461568 - gail/main.py:164 - [TRPO] iter = 276000 dist_mean = 0.0623 dist_std = 0.3802 vf_loss = 0.3260 grad_norm = 1.3414 nat_grad_norm = 0.2948 cg_residual = 0.1977 step_size = 0.4342 reward = -0.0000 fps = 75 mse_loss = 1.0664 
2022-05-01 04:50:01.588841 - gail/main.py:164 - [TRPO] iter = 277000 dist_mean = 0.0705 dist_std = 0.3810 vf_loss = 0.1225 grad_norm = 1.5500 nat_grad_norm = 0.2616 cg_residual = 0.1515 step_size = 0.3948 reward = 0.0000 fps = 42 mse_loss = 1.1156 
2022-05-01 04:50:11.540473 - gail/main.py:164 - [TRPO] iter = 278000 dist_mean = 0.0890 dist_std = 0.3808 vf_loss = 1.1167 grad_norm = 1.2914 nat_grad_norm = 0.1933 cg_residual = 0.0811 step_size = 0.4756 reward = 0.0000 fps = 29 mse_loss = 1.0538 
2022-05-01 04:50:21.674649 - gail/main.py:164 - [TRPO] iter = 279000 dist_mean = 0.0913 dist_std = 0.3788 vf_loss = 0.1568 grad_norm = 1.0210 nat_grad_norm = 0.2774 cg_residual = 0.2264 step_size = 0.4551 reward = 0.0000 fps = 22 mse_loss = 1.0118 
2022-05-01 04:50:31.718262 - gail/main.py:164 - [TRPO] iter = 280000 dist_mean = 0.1245 dist_std = 0.3817 vf_loss = 0.0964 grad_norm = 1.1172 nat_grad_norm = 0.2216 cg_residual = 0.0759 step_size = 0.4643 reward = -0.0000 fps = 18 mse_loss = 0.9946 
2022-05-01 04:50:31.920117 - gail/main.py:191 - [Discriminator] iter = 280000 loss = -0.6050 grad_norm = 2.9021 grad_penalty = 0.0742 regularization = 0.0000 true_logits = 0.0455 fake_logits = -0.6336 true_prob = 0.5142 fake_prob = 0.3760 
2022-05-01 04:50:35.105583 - gail/main.py:132 - [Evaluate] iter = 280000 episode={ returns = 39.5931 lengths = 22 } discounted_episode={ returns = 38.7593 lengths = 22 } 
2022-05-01 04:50:44.966683 - gail/main.py:164 - [TRPO] iter = 281000 dist_mean = 0.1403 dist_std = 0.3814 vf_loss = 0.1103 grad_norm = 0.8831 nat_grad_norm = 0.2971 cg_residual = 0.1527 step_size = 0.4784 reward = 0.0000 fps = 76 mse_loss = 1.1250 
2022-05-01 04:50:55.021750 - gail/main.py:164 - [TRPO] iter = 282000 dist_mean = 0.1408 dist_std = 0.3830 vf_loss = 0.2744 grad_norm = 1.2548 nat_grad_norm = 0.2964 cg_residual = 0.1165 step_size = 0.3857 reward = 0.0000 fps = 43 mse_loss = 1.0800 
2022-05-01 04:51:05.009540 - gail/main.py:164 - [TRPO] iter = 283000 dist_mean = 0.1040 dist_std = 0.3794 vf_loss = 0.5991 grad_norm = 1.0252 nat_grad_norm = 0.1848 cg_residual = 0.0765 step_size = 0.5680 reward = 0.0000 fps = 30 mse_loss = 1.0247 
2022-05-01 04:51:14.700704 - gail/main.py:164 - [TRPO] iter = 284000 dist_mean = 0.1091 dist_std = 0.3775 vf_loss = 0.6806 grad_norm = 1.0808 nat_grad_norm = 0.2075 cg_residual = 0.0915 step_size = 0.4814 reward = -0.0000 fps = 23 mse_loss = 1.0504 
2022-05-01 04:51:24.605808 - gail/main.py:164 - [TRPO] iter = 285000 dist_mean = 0.0435 dist_std = 0.3780 vf_loss = 0.1311 grad_norm = 1.0905 nat_grad_norm = 0.2565 cg_residual = 0.1067 step_size = 0.3966 reward = 0.0000 fps = 18 mse_loss = 1.1597 
2022-05-01 04:51:24.842164 - gail/main.py:191 - [Discriminator] iter = 285000 loss = -0.5009 grad_norm = 2.5072 grad_penalty = 0.0682 regularization = 0.0000 true_logits = -0.0167 fake_logits = -0.5859 true_prob = 0.5011 fake_prob = 0.3750 
2022-05-01 04:51:28.134067 - gail/main.py:132 - [Evaluate] iter = 285000 episode={ returns = 39.6822 lengths = 22 } discounted_episode={ returns = 39.3825 lengths = 22 } 
2022-05-01 04:51:37.876683 - gail/main.py:164 - [TRPO] iter = 286000 dist_mean = 0.1111 dist_std = 0.3746 vf_loss = 0.3866 grad_norm = 1.4551 nat_grad_norm = 0.2423 cg_residual = 0.1385 step_size = 0.4467 reward = -0.0000 fps = 76 mse_loss = 1.0906 
2022-05-01 04:51:48.080449 - gail/main.py:164 - [TRPO] iter = 287000 dist_mean = 0.1888 dist_std = 0.3778 vf_loss = 0.3843 grad_norm = 1.0880 nat_grad_norm = 0.1884 cg_residual = 0.0956 step_size = 0.5298 reward = -0.0000 fps = 43 mse_loss = 1.0349 
2022-05-01 04:51:58.177064 - gail/main.py:164 - [TRPO] iter = 288000 dist_mean = 0.1216 dist_std = 0.3738 vf_loss = 0.1290 grad_norm = 1.2707 nat_grad_norm = 0.2434 cg_residual = 0.1451 step_size = 0.4020 reward = -0.0000 fps = 30 mse_loss = 1.0429 
2022-05-01 04:52:08.121084 - gail/main.py:164 - [TRPO] iter = 289000 dist_mean = 0.1056 dist_std = 0.3681 vf_loss = 0.7385 grad_norm = 1.1499 nat_grad_norm = 0.2251 cg_residual = 0.0956 step_size = 0.5013 reward = -0.0000 fps = 23 mse_loss = 0.9626 
2022-05-01 04:52:18.130422 - gail/main.py:164 - [TRPO] iter = 290000 dist_mean = 0.1814 dist_std = 0.3640 vf_loss = 0.6575 grad_norm = 0.4442 nat_grad_norm = 0.1612 cg_residual = 0.0662 step_size = 0.8192 reward = -0.0000 fps = 18 mse_loss = 1.0268 
2022-05-01 04:52:18.427936 - gail/main.py:191 - [Discriminator] iter = 290000 loss = -0.9860 grad_norm = 2.4722 grad_penalty = 0.0767 regularization = 0.0000 true_logits = -0.0442 fake_logits = -1.1069 true_prob = 0.4953 fake_prob = 0.3077 
2022-05-01 04:52:21.510085 - gail/main.py:132 - [Evaluate] iter = 290000 episode={ returns = 39.7946 lengths = 22 } discounted_episode={ returns = 38.0429 lengths = 22 } 
2022-05-01 04:52:31.991472 - gail/main.py:164 - [TRPO] iter = 291000 dist_mean = 0.3756 dist_std = 0.3592 vf_loss = 0.1459 grad_norm = 2.1587 nat_grad_norm = 0.1320 cg_residual = 0.2099 step_size = 0.5967 reward = 0.0000 fps = 73 mse_loss = 0.9189 
2022-05-01 04:52:42.065137 - gail/main.py:164 - [TRPO] iter = 292000 dist_mean = 0.1906 dist_std = 0.3635 vf_loss = 0.1213 grad_norm = 0.7712 nat_grad_norm = 0.2118 cg_residual = 0.1195 step_size = 0.5210 reward = -0.0000 fps = 42 mse_loss = 1.0751 
2022-05-01 04:52:51.921118 - gail/main.py:164 - [TRPO] iter = 293000 dist_mean = 0.1042 dist_std = 0.3599 vf_loss = 0.8123 grad_norm = 1.4098 nat_grad_norm = 0.2231 cg_residual = 0.1348 step_size = 0.4367 reward = 0.0000 fps = 29 mse_loss = 1.1258 
2022-05-01 04:53:01.793632 - gail/main.py:164 - [TRPO] iter = 294000 dist_mean = 0.2229 dist_std = 0.3574 vf_loss = 0.6067 grad_norm = 1.8722 nat_grad_norm = 0.2730 cg_residual = 0.1320 step_size = 0.3672 reward = -0.0000 fps = 23 mse_loss = 0.9878 
2022-05-01 04:53:12.336166 - gail/main.py:164 - [TRPO] iter = 295000 dist_mean = 0.3945 dist_std = 0.3525 vf_loss = 0.1383 grad_norm = 2.1236 nat_grad_norm = 0.1482 cg_residual = 0.0194 step_size = 0.6006 reward = -0.0000 fps = 18 mse_loss = 0.9675 
2022-05-01 04:53:12.596765 - gail/main.py:191 - [Discriminator] iter = 295000 loss = -2.7644 grad_norm = 3.0763 grad_penalty = 0.1818 regularization = 0.0000 true_logits = -0.0548 fake_logits = -3.0011 true_prob = 0.4951 fake_prob = 0.0524 
2022-05-01 04:53:15.914709 - gail/main.py:132 - [Evaluate] iter = 295000 episode={ returns = 38.4518 lengths = 22 } discounted_episode={ returns = 38.2339 lengths = 22 } 
2022-05-01 04:53:26.463600 - gail/main.py:164 - [TRPO] iter = 296000 dist_mean = 0.2154 dist_std = 0.3583 vf_loss = 0.0861 grad_norm = 0.9076 nat_grad_norm = 0.2133 cg_residual = 0.1104 step_size = 0.4961 reward = 0.0000 fps = 72 mse_loss = 0.9805 
2022-05-01 04:53:36.536311 - gail/main.py:164 - [TRPO] iter = 297000 dist_mean = 0.1986 dist_std = 0.3522 vf_loss = 1.0716 grad_norm = 0.9391 nat_grad_norm = 0.1650 cg_residual = 0.0459 step_size = 0.5636 reward = -0.0000 fps = 41 mse_loss = 0.9738 
2022-05-01 04:53:46.521334 - gail/main.py:164 - [TRPO] iter = 298000 dist_mean = 0.1083 dist_std = 0.3475 vf_loss = 1.1401 grad_norm = 0.8287 nat_grad_norm = 0.1985 cg_residual = 0.1416 step_size = 0.5150 reward = -0.0000 fps = 29 mse_loss = 0.9840 
2022-05-01 04:53:56.342789 - gail/main.py:164 - [TRPO] iter = 299000 dist_mean = 0.1456 dist_std = 0.3458 vf_loss = 0.7368 grad_norm = 0.9957 nat_grad_norm = 0.2108 cg_residual = 0.1717 step_size = 0.4794 reward = 0.0000 fps = 22 mse_loss = 0.9223 
2022-05-01 04:54:06.631669 - gail/main.py:164 - [TRPO] iter = 300000 dist_mean = 0.3586 dist_std = 0.3433 vf_loss = 0.1924 grad_norm = 1.0786 nat_grad_norm = 0.1634 cg_residual = 0.0316 step_size = 0.6861 reward = 0.0000 fps = 18 mse_loss = 1.0472 
2022-05-01 04:54:06.840320 - gail/main.py:191 - [Discriminator] iter = 300000 loss = -3.0751 grad_norm = 3.0034 grad_penalty = 0.2429 regularization = 0.0000 true_logits = 0.2588 fake_logits = -3.0592 true_prob = 0.5606 fake_prob = 0.0517 
2022-05-01 04:54:10.217743 - gail/main.py:132 - [Evaluate] iter = 300000 episode={ returns = 38.1354 lengths = 21 } discounted_episode={ returns = 37.6758 lengths = 21 } 
2022-05-01 04:54:20.517527 - gail/main.py:164 - [TRPO] iter = 301000 dist_mean = 0.2285 dist_std = 0.3441 vf_loss = 0.1182 grad_norm = 1.3503 nat_grad_norm = 0.2048 cg_residual = 0.1073 step_size = 0.4799 reward = 0.0000 fps = 73 mse_loss = 1.0440 
2022-05-01 04:54:30.692928 - gail/main.py:164 - [TRPO] iter = 302000 dist_mean = 0.1987 dist_std = 0.3407 vf_loss = 1.1950 grad_norm = 1.0045 nat_grad_norm = 0.2739 cg_residual = 0.1880 step_size = 0.4221 reward = 0.0000 fps = 41 mse_loss = 1.0626 
2022-05-01 04:54:41.265567 - gail/main.py:164 - [TRPO] iter = 303000 dist_mean = 0.1384 dist_std = 0.3387 vf_loss = 0.2105 grad_norm = 1.1717 nat_grad_norm = 0.2420 cg_residual = 0.1162 step_size = 0.4549 reward = 0.0000 fps = 29 mse_loss = 1.0707 
2022-05-01 04:54:51.374371 - gail/main.py:164 - [TRPO] iter = 304000 dist_mean = 0.2708 dist_std = 0.3421 vf_loss = 0.2757 grad_norm = 2.0307 nat_grad_norm = 0.3209 cg_residual = 0.2757 step_size = 0.3219 reward = -0.0000 fps = 22 mse_loss = 1.0143 
2022-05-01 04:55:01.463930 - gail/main.py:164 - [TRPO] iter = 305000 dist_mean = 0.1162 dist_std = 0.3401 vf_loss = 0.2129 grad_norm = 0.8924 nat_grad_norm = 0.3258 cg_residual = 0.2609 step_size = 0.4391 reward = -0.0000 fps = 18 mse_loss = 1.0018 
2022-05-01 04:55:01.701469 - gail/main.py:191 - [Discriminator] iter = 305000 loss = -1.2076 grad_norm = 2.2277 grad_penalty = 0.1105 regularization = 0.0000 true_logits = 0.2199 fake_logits = -1.0982 true_prob = 0.5498 fake_prob = 0.3060 
2022-05-01 04:55:05.022214 - gail/main.py:132 - [Evaluate] iter = 305000 episode={ returns = 39.0454 lengths = 22 } discounted_episode={ returns = 39.1843 lengths = 22 } 
2022-05-01 04:55:15.246768 - gail/main.py:164 - [TRPO] iter = 306000 dist_mean = 0.1757 dist_std = 0.3395 vf_loss = 0.7401 grad_norm = 1.0953 nat_grad_norm = 0.2945 cg_residual = 0.2207 step_size = 0.4350 reward = -0.0000 fps = 73 mse_loss = 0.9981 
2022-05-01 04:55:24.844508 - gail/main.py:164 - [TRPO] iter = 307000 dist_mean = 0.1372 dist_std = 0.3396 vf_loss = 0.2666 grad_norm = 1.5527 nat_grad_norm = 0.2728 cg_residual = 0.1519 step_size = 0.3499 reward = -0.0000 fps = 43 mse_loss = 1.0594 
2022-05-01 04:55:35.057625 - gail/main.py:164 - [TRPO] iter = 308000 dist_mean = 0.1481 dist_std = 0.3399 vf_loss = 0.7363 grad_norm = 1.1003 nat_grad_norm = 0.2167 cg_residual = 0.2510 step_size = 0.4497 reward = 0.0000 fps = 29 mse_loss = 1.0080 
2022-05-01 04:55:45.105336 - gail/main.py:164 - [TRPO] iter = 309000 dist_mean = 0.1311 dist_std = 0.3360 vf_loss = 0.3106 grad_norm = 1.4968 nat_grad_norm = 0.2116 cg_residual = 0.2521 step_size = 0.5158 reward = -0.0000 fps = 23 mse_loss = 1.0740 
2022-05-01 04:55:55.092265 - gail/main.py:164 - [TRPO] iter = 310000 dist_mean = 0.0908 dist_std = 0.3322 vf_loss = 0.5480 grad_norm = 1.1873 nat_grad_norm = 0.1831 cg_residual = 0.2435 step_size = 0.5310 reward = -0.0000 fps = 18 mse_loss = 1.0762 
2022-05-01 04:55:55.286105 - gail/main.py:191 - [Discriminator] iter = 310000 loss = -0.4954 grad_norm = 2.2290 grad_penalty = 0.0681 regularization = 0.0000 true_logits = 0.2448 fake_logits = -0.3187 true_prob = 0.5546 fake_prob = 0.4351 
2022-05-01 04:57:43.102803 - gail/main.py:132 - [Evaluate] iter = 310000 episode={ returns = 2601.3150 lengths = 755 } discounted_episode={ returns = 1762.0300 lengths = 838 } 
2022-05-01 04:57:52.970436 - gail/main.py:164 - [TRPO] iter = 311000 dist_mean = 0.1508 dist_std = 0.3309 vf_loss = 0.6225 grad_norm = 1.3477 nat_grad_norm = 0.1475 cg_residual = 0.1129 step_size = 0.5278 reward = -0.0000 fps = 8 mse_loss = 0.9951 
2022-05-01 04:58:03.058268 - gail/main.py:164 - [TRPO] iter = 312000 dist_mean = 0.0975 dist_std = 0.3323 vf_loss = 0.3906 grad_norm = 0.8566 nat_grad_norm = 0.1848 cg_residual = 0.1434 step_size = 0.5377 reward = 0.0000 fps = 7 mse_loss = 1.0386 
2022-05-01 04:58:13.046335 - gail/main.py:164 - [TRPO] iter = 313000 dist_mean = 0.1047 dist_std = 0.3333 vf_loss = 0.2038 grad_norm = 1.8882 nat_grad_norm = 0.4635 cg_residual = 0.3921 step_size = 0.2360 reward = 0.0000 fps = 7 mse_loss = 1.0299 
2022-05-01 04:58:22.925046 - gail/main.py:164 - [TRPO] iter = 314000 dist_mean = 0.0917 dist_std = 0.3343 vf_loss = 0.4209 grad_norm = 1.1924 nat_grad_norm = 0.2280 cg_residual = 0.2814 step_size = 0.4065 reward = 0.0000 fps = 6 mse_loss = 1.0783 
2022-05-01 04:58:33.133817 - gail/main.py:164 - [TRPO] iter = 315000 dist_mean = 0.0603 dist_std = 0.3338 vf_loss = 0.1315 grad_norm = 1.1784 nat_grad_norm = 0.2956 cg_residual = 0.2704 step_size = 0.3780 reward = -0.0000 fps = 6 mse_loss = 1.0178 
2022-05-01 04:58:33.359169 - gail/main.py:191 - [Discriminator] iter = 315000 loss = -1.1007 grad_norm = 2.6350 grad_penalty = 0.0799 regularization = 0.0000 true_logits = 0.1380 fake_logits = -1.0426 true_prob = 0.5338 fake_prob = 0.3248 
2022-05-01 04:58:36.665285 - gail/main.py:132 - [Evaluate] iter = 315000 episode={ returns = 40.7323 lengths = 23 } discounted_episode={ returns = 40.9728 lengths = 23 } 
2022-05-01 04:58:46.793716 - gail/main.py:164 - [TRPO] iter = 316000 dist_mean = 0.0602 dist_std = 0.3299 vf_loss = 0.0945 grad_norm = 1.3945 nat_grad_norm = 0.2434 cg_residual = 0.2338 step_size = 0.4288 reward = 0.0000 fps = 74 mse_loss = 0.9462 
2022-05-01 04:58:56.916933 - gail/main.py:164 - [TRPO] iter = 317000 dist_mean = 0.2263 dist_std = 0.3285 vf_loss = 0.5301 grad_norm = 0.9446 nat_grad_norm = 0.2195 cg_residual = 0.1595 step_size = 0.4981 reward = -0.0000 fps = 42 mse_loss = 0.9278 
2022-05-01 04:59:06.711284 - gail/main.py:164 - [TRPO] iter = 318000 dist_mean = 0.0906 dist_std = 0.3245 vf_loss = 0.4024 grad_norm = 1.0270 nat_grad_norm = 0.2013 cg_residual = 0.1834 step_size = 0.4754 reward = -0.0000 fps = 29 mse_loss = 1.0443 
2022-05-01 04:59:16.604469 - gail/main.py:164 - [TRPO] iter = 319000 dist_mean = 0.2096 dist_std = 0.3205 vf_loss = 0.0715 grad_norm = 1.5325 nat_grad_norm = 0.1864 cg_residual = 0.1702 step_size = 0.4627 reward = -0.0000 fps = 23 mse_loss = 1.0394 
2022-05-01 04:59:26.474429 - gail/main.py:164 - [TRPO] iter = 320000 dist_mean = 0.1474 dist_std = 0.3160 vf_loss = 0.2347 grad_norm = 1.3356 nat_grad_norm = 0.2123 cg_residual = 0.1527 step_size = 0.4679 reward = 0.0000 fps = 18 mse_loss = 1.0158 
2022-05-01 04:59:26.694735 - gail/main.py:191 - [Discriminator] iter = 320000 loss = -1.4328 grad_norm = 2.2281 grad_penalty = 0.0859 regularization = 0.0000 true_logits = 0.0476 fake_logits = -1.4711 true_prob = 0.5138 fake_prob = 0.2626 
2022-05-01 04:59:29.814254 - gail/main.py:132 - [Evaluate] iter = 320000 episode={ returns = 38.2001 lengths = 21 } discounted_episode={ returns = 37.7301 lengths = 21 } 
2022-05-01 04:59:39.980099 - gail/main.py:164 - [TRPO] iter = 321000 dist_mean = 0.1867 dist_std = 0.3118 vf_loss = 0.8367 grad_norm = 1.5095 nat_grad_norm = 0.1611 cg_residual = 0.1623 step_size = 0.5008 reward = 0.0000 fps = 75 mse_loss = 1.1241 
2022-05-01 04:59:49.585536 - gail/main.py:164 - [TRPO] iter = 322000 dist_mean = 0.0852 dist_std = 0.3128 vf_loss = 0.0854 grad_norm = 1.3429 nat_grad_norm = 0.1876 cg_residual = 0.1497 step_size = 0.4804 reward = 0.0000 fps = 43 mse_loss = 0.8964 
2022-05-01 04:59:59.735937 - gail/main.py:164 - [TRPO] iter = 323000 dist_mean = 0.3033 dist_std = 0.3099 vf_loss = 0.1056 grad_norm = 1.2016 nat_grad_norm = 0.1870 cg_residual = 0.0675 step_size = 0.4786 reward = -0.0000 fps = 30 mse_loss = 1.0628 
2022-05-01 05:00:09.955556 - gail/main.py:164 - [TRPO] iter = 324000 dist_mean = 0.1286 dist_std = 0.3079 vf_loss = 1.2573 grad_norm = 1.3515 nat_grad_norm = 0.1490 cg_residual = 0.1188 step_size = 0.4921 reward = -0.0000 fps = 23 mse_loss = 0.9595 
2022-05-01 05:00:20.109257 - gail/main.py:164 - [TRPO] iter = 325000 dist_mean = 0.1229 dist_std = 0.3096 vf_loss = 0.3953 grad_norm = 1.5511 nat_grad_norm = 0.2272 cg_residual = 0.2073 step_size = 0.4118 reward = -0.0000 fps = 18 mse_loss = 0.9743 
2022-05-01 05:00:20.362931 - gail/main.py:191 - [Discriminator] iter = 325000 loss = -0.7002 grad_norm = 2.1308 grad_penalty = 0.0606 regularization = 0.0000 true_logits = 0.0473 fake_logits = -0.7135 true_prob = 0.5140 fake_prob = 0.3783 
2022-05-01 05:00:23.385008 - gail/main.py:132 - [Evaluate] iter = 325000 episode={ returns = 38.5115 lengths = 22 } discounted_episode={ returns = 38.4627 lengths = 22 } 
2022-05-01 05:00:33.284085 - gail/main.py:164 - [TRPO] iter = 326000 dist_mean = 0.1477 dist_std = 0.3091 vf_loss = 0.7456 grad_norm = 1.4922 nat_grad_norm = 0.1755 cg_residual = 0.1590 step_size = 0.5149 reward = -0.0000 fps = 77 mse_loss = 0.9634 
2022-05-01 05:00:43.369629 - gail/main.py:164 - [TRPO] iter = 327000 dist_mean = 0.0849 dist_std = 0.3104 vf_loss = 0.5045 grad_norm = 1.1894 nat_grad_norm = 0.1922 cg_residual = 0.1127 step_size = 0.5259 reward = 0.0000 fps = 43 mse_loss = 1.0454 
2022-05-01 05:00:53.443251 - gail/main.py:164 - [TRPO] iter = 328000 dist_mean = 0.0576 dist_std = 0.3116 vf_loss = 0.3865 grad_norm = 1.1619 nat_grad_norm = 0.2079 cg_residual = 0.0756 step_size = 0.5044 reward = -0.0000 fps = 30 mse_loss = 0.9120 
2022-05-01 05:01:03.340122 - gail/main.py:164 - [TRPO] iter = 329000 dist_mean = 0.0911 dist_std = 0.3128 vf_loss = 0.3419 grad_norm = 1.7555 nat_grad_norm = 0.1748 cg_residual = 0.2146 step_size = 0.4697 reward = -0.0000 fps = 23 mse_loss = 0.8740 
2022-05-01 05:01:13.030827 - gail/main.py:164 - [TRPO] iter = 330000 dist_mean = 0.0949 dist_std = 0.3144 vf_loss = 0.1632 grad_norm = 1.0970 nat_grad_norm = 0.2192 cg_residual = 0.1875 step_size = 0.4314 reward = 0.0000 fps = 18 mse_loss = 0.9483 
2022-05-01 05:01:13.232163 - gail/main.py:191 - [Discriminator] iter = 330000 loss = -0.5330 grad_norm = 2.1118 grad_penalty = 0.0497 regularization = 0.0000 true_logits = 0.0091 fake_logits = -0.5736 true_prob = 0.5064 fake_prob = 0.3816 
2022-05-01 05:01:16.562374 - gail/main.py:132 - [Evaluate] iter = 330000 episode={ returns = 40.7694 lengths = 23 } discounted_episode={ returns = 40.1304 lengths = 23 } 
2022-05-01 05:01:26.425233 - gail/main.py:164 - [TRPO] iter = 331000 dist_mean = 0.1254 dist_std = 0.3104 vf_loss = 0.4878 grad_norm = 1.5159 nat_grad_norm = 0.1925 cg_residual = 0.2569 step_size = 0.4470 reward = -0.0000 fps = 75 mse_loss = 0.9939 
2022-05-01 05:01:36.498343 - gail/main.py:164 - [TRPO] iter = 332000 dist_mean = 0.0639 dist_std = 0.3097 vf_loss = 0.0837 grad_norm = 0.8559 nat_grad_norm = 0.2562 cg_residual = 0.3365 step_size = 0.4373 reward = -0.0000 fps = 43 mse_loss = 0.9022 
2022-05-01 05:01:46.085739 - gail/main.py:164 - [TRPO] iter = 333000 dist_mean = 0.1297 dist_std = 0.3100 vf_loss = 0.1137 grad_norm = 0.8522 nat_grad_norm = 0.2532 cg_residual = 0.2008 step_size = 0.4526 reward = 0.0000 fps = 30 mse_loss = 0.9506 
2022-05-01 05:01:56.331085 - gail/main.py:164 - [TRPO] iter = 334000 dist_mean = 0.0917 dist_std = 0.3105 vf_loss = 0.3975 grad_norm = 1.2829 nat_grad_norm = 0.2155 cg_residual = 0.1848 step_size = 0.4488 reward = -0.0000 fps = 23 mse_loss = 0.8969 
2022-05-01 05:02:06.754706 - gail/main.py:164 - [TRPO] iter = 335000 dist_mean = 0.2052 dist_std = 0.3109 vf_loss = 0.1483 grad_norm = 1.6648 nat_grad_norm = 0.2775 cg_residual = 0.3123 step_size = 0.3714 reward = 0.0000 fps = 18 mse_loss = 0.9402 
2022-05-01 05:02:06.960884 - gail/main.py:191 - [Discriminator] iter = 335000 loss = -1.6791 grad_norm = 2.6202 grad_penalty = 0.0956 regularization = 0.0000 true_logits = -0.0271 fake_logits = -1.8018 true_prob = 0.4978 fake_prob = 0.2229 
2022-05-01 05:02:09.857906 - gail/main.py:132 - [Evaluate] iter = 335000 episode={ returns = 37.3134 lengths = 21 } discounted_episode={ returns = 36.6836 lengths = 21 } 
2022-05-01 05:02:20.070618 - gail/main.py:164 - [TRPO] iter = 336000 dist_mean = 0.2743 dist_std = 0.3114 vf_loss = 0.0986 grad_norm = 0.9457 nat_grad_norm = 0.2345 cg_residual = 0.2676 step_size = 0.4872 reward = 0.0000 fps = 76 mse_loss = 0.8420 
2022-05-01 05:02:30.122656 - gail/main.py:164 - [TRPO] iter = 337000 dist_mean = 0.1382 dist_std = 0.3096 vf_loss = 0.7755 grad_norm = 1.3130 nat_grad_norm = 0.1449 cg_residual = 0.1338 step_size = 0.5375 reward = -0.0000 fps = 43 mse_loss = 0.9186 
2022-05-01 05:02:40.447574 - gail/main.py:164 - [TRPO] iter = 338000 dist_mean = 0.1249 dist_std = 0.3075 vf_loss = 0.0542 grad_norm = 1.0765 nat_grad_norm = 0.1376 cg_residual = 0.0805 step_size = 0.6534 reward = -0.0000 fps = 29 mse_loss = 0.7903 
2022-05-01 05:02:50.845174 - gail/main.py:164 - [TRPO] iter = 339000 dist_mean = 0.1445 dist_std = 0.3029 vf_loss = 0.5436 grad_norm = 1.1975 nat_grad_norm = 0.1749 cg_residual = 0.1547 step_size = 0.5145 reward = -0.0000 fps = 22 mse_loss = 0.8859 
2022-05-01 05:03:00.646105 - gail/main.py:164 - [TRPO] iter = 340000 dist_mean = 0.2462 dist_std = 0.3037 vf_loss = 0.8237 grad_norm = 1.5088 nat_grad_norm = 0.2877 cg_residual = 0.2482 step_size = 0.3348 reward = -0.0000 fps = 18 mse_loss = 0.8623 
2022-05-01 05:03:00.837309 - gail/main.py:191 - [Discriminator] iter = 340000 loss = -1.9880 grad_norm = 2.2124 grad_penalty = 0.1252 regularization = 0.0000 true_logits = 0.0710 fake_logits = -2.0422 true_prob = 0.5202 fake_prob = 0.2140 
2022-05-01 05:03:03.892094 - gail/main.py:132 - [Evaluate] iter = 340000 episode={ returns = 37.3510 lengths = 21 } discounted_episode={ returns = 36.9093 lengths = 21 } 
2022-05-01 05:03:13.783887 - gail/main.py:164 - [TRPO] iter = 341000 dist_mean = 0.1380 dist_std = 0.2981 vf_loss = 0.0838 grad_norm = 1.7726 nat_grad_norm = 0.2277 cg_residual = 0.2573 step_size = 0.3352 reward = -0.0000 fps = 77 mse_loss = 0.9208 
2022-05-01 05:03:23.846027 - gail/main.py:164 - [TRPO] iter = 342000 dist_mean = 0.1896 dist_std = 0.2987 vf_loss = 0.2002 grad_norm = 1.1331 nat_grad_norm = 0.2437 cg_residual = 0.3125 step_size = 0.4351 reward = -0.0000 fps = 43 mse_loss = 0.8820 
2022-05-01 05:03:33.941562 - gail/main.py:164 - [TRPO] iter = 343000 dist_mean = 0.0616 dist_std = 0.2962 vf_loss = 0.1046 grad_norm = 1.8301 nat_grad_norm = 0.2141 cg_residual = 0.1461 step_size = 0.4018 reward = -0.0000 fps = 30 mse_loss = 0.9397 
2022-05-01 05:03:43.647759 - gail/main.py:164 - [TRPO] iter = 344000 dist_mean = 0.0814 dist_std = 0.2974 vf_loss = 1.0564 grad_norm = 1.7740 nat_grad_norm = 0.1628 cg_residual = 0.2798 step_size = 0.4870 reward = 0.0000 fps = 23 mse_loss = 0.8520 
2022-05-01 05:03:53.812896 - gail/main.py:164 - [TRPO] iter = 345000 dist_mean = 0.1073 dist_std = 0.2986 vf_loss = 0.1046 grad_norm = 1.1859 nat_grad_norm = 0.2374 cg_residual = 0.2233 step_size = 0.4751 reward = -0.0000 fps = 18 mse_loss = 0.8944 
2022-05-01 05:03:54.119916 - gail/main.py:191 - [Discriminator] iter = 345000 loss = -1.0600 grad_norm = 2.3552 grad_penalty = 0.0875 regularization = 0.0000 true_logits = 0.1168 fake_logits = -1.0306 true_prob = 0.5260 fake_prob = 0.3357 
2022-05-01 05:03:57.226264 - gail/main.py:132 - [Evaluate] iter = 345000 episode={ returns = 38.5804 lengths = 22 } discounted_episode={ returns = 38.2794 lengths = 22 } 
2022-05-01 05:04:07.177741 - gail/main.py:164 - [TRPO] iter = 346000 dist_mean = 0.0321 dist_std = 0.2953 vf_loss = 0.1700 grad_norm = 1.6155 nat_grad_norm = 0.2253 cg_residual = 0.3181 step_size = 0.4339 reward = 0.0000 fps = 76 mse_loss = 0.8419 
2022-05-01 05:04:17.004861 - gail/main.py:164 - [TRPO] iter = 347000 dist_mean = 0.0975 dist_std = 0.2957 vf_loss = 0.1165 grad_norm = 1.5281 nat_grad_norm = 0.2573 cg_residual = 0.1634 step_size = 0.4224 reward = 0.0000 fps = 43 mse_loss = 0.8282 
2022-05-01 05:04:26.390888 - gail/main.py:164 - [TRPO] iter = 348000 dist_mean = 0.0674 dist_std = 0.2934 vf_loss = 0.7240 grad_norm = 0.7397 nat_grad_norm = 0.1981 cg_residual = 0.1892 step_size = 0.5796 reward = -0.0000 fps = 31 mse_loss = 0.9308 
2022-05-01 05:04:36.627718 - gail/main.py:164 - [TRPO] iter = 349000 dist_mean = 0.0297 dist_std = 0.2927 vf_loss = 0.1025 grad_norm = 1.5975 nat_grad_norm = 0.2081 cg_residual = 0.2935 step_size = 0.4147 reward = 0.0000 fps = 23 mse_loss = 0.9740 
2022-05-01 05:04:46.489177 - gail/main.py:164 - [TRPO] iter = 350000 dist_mean = 0.0804 dist_std = 0.2906 vf_loss = 0.3056 grad_norm = 1.3791 nat_grad_norm = 0.1686 cg_residual = 0.1097 step_size = 0.5520 reward = 0.0000 fps = 19 mse_loss = 0.9269 
2022-05-01 05:04:46.741573 - gail/main.py:191 - [Discriminator] iter = 350000 loss = -0.6845 grad_norm = 2.0453 grad_penalty = 0.0579 regularization = 0.0000 true_logits = 0.0815 fake_logits = -0.6610 true_prob = 0.5200 fake_prob = 0.3869 
2022-05-01 05:04:49.884980 - gail/main.py:132 - [Evaluate] iter = 350000 episode={ returns = 40.5200 lengths = 23 } discounted_episode={ returns = 40.2902 lengths = 23 } 
2022-05-01 05:04:59.632912 - gail/main.py:164 - [TRPO] iter = 351000 dist_mean = 0.0823 dist_std = 0.2891 vf_loss = 0.5137 grad_norm = 0.9683 nat_grad_norm = 0.1878 cg_residual = 0.1077 step_size = 0.5061 reward = -0.0000 fps = 77 mse_loss = 0.8254 
2022-05-01 05:05:09.484203 - gail/main.py:164 - [TRPO] iter = 352000 dist_mean = 0.0708 dist_std = 0.2896 vf_loss = 0.1066 grad_norm = 1.5886 nat_grad_norm = 0.2113 cg_residual = 0.2613 step_size = 0.4346 reward = 0.0000 fps = 43 mse_loss = 0.8735 
2022-05-01 05:05:19.477679 - gail/main.py:164 - [TRPO] iter = 353000 dist_mean = 0.0668 dist_std = 0.2851 vf_loss = 0.3467 grad_norm = 1.0838 nat_grad_norm = 0.2361 cg_residual = 0.1839 step_size = 0.4264 reward = -0.0000 fps = 30 mse_loss = 0.8685 
2022-05-01 05:05:29.466998 - gail/main.py:164 - [TRPO] iter = 354000 dist_mean = 0.0508 dist_std = 0.2852 vf_loss = 0.5614 grad_norm = 2.0122 nat_grad_norm = 0.1630 cg_residual = 0.1940 step_size = 0.4602 reward = 0.0000 fps = 23 mse_loss = 0.9243 
2022-05-01 05:05:39.469360 - gail/main.py:164 - [TRPO] iter = 355000 dist_mean = 0.1414 dist_std = 0.2837 vf_loss = 0.1071 grad_norm = 1.7155 nat_grad_norm = 0.2788 cg_residual = 0.2378 step_size = 0.3626 reward = -0.0000 fps = 18 mse_loss = 0.9004 
2022-05-01 05:05:39.726895 - gail/main.py:191 - [Discriminator] iter = 355000 loss = -1.7945 grad_norm = 3.0344 grad_penalty = 0.1095 regularization = 0.0000 true_logits = 0.0935 fake_logits = -1.8105 true_prob = 0.5234 fake_prob = 0.2310 
2022-05-01 05:05:43.009245 - gail/main.py:132 - [Evaluate] iter = 355000 episode={ returns = 40.5678 lengths = 23 } discounted_episode={ returns = 40.1038 lengths = 23 } 
2022-05-01 05:05:53.130155 - gail/main.py:164 - [TRPO] iter = 356000 dist_mean = 0.0998 dist_std = 0.2826 vf_loss = 0.3826 grad_norm = 1.3454 nat_grad_norm = 0.2546 cg_residual = 0.5182 step_size = 0.3700 reward = -0.0000 fps = 74 mse_loss = 0.7802 
2022-05-01 05:06:03.008595 - gail/main.py:164 - [TRPO] iter = 357000 dist_mean = 0.0825 dist_std = 0.2789 vf_loss = 0.3562 grad_norm = 1.1471 nat_grad_norm = 0.2657 cg_residual = 0.2790 step_size = 0.4252 reward = 0.0000 fps = 42 mse_loss = 0.9267 
2022-05-01 05:06:13.019583 - gail/main.py:164 - [TRPO] iter = 358000 dist_mean = 0.0896 dist_std = 0.2817 vf_loss = 0.2607 grad_norm = 1.3943 nat_grad_norm = 0.2602 cg_residual = 0.3489 step_size = 0.4136 reward = -0.0000 fps = 30 mse_loss = 0.8775 
2022-05-01 05:06:22.991024 - gail/main.py:164 - [TRPO] iter = 359000 dist_mean = 0.0685 dist_std = 0.2810 vf_loss = 0.1868 grad_norm = 1.5340 nat_grad_norm = 0.2105 cg_residual = 0.2275 step_size = 0.4310 reward = 0.0000 fps = 23 mse_loss = 0.8780 
2022-05-01 05:06:33.237295 - gail/main.py:164 - [TRPO] iter = 360000 dist_mean = 0.1278 dist_std = 0.2790 vf_loss = 0.1187 grad_norm = 1.3958 nat_grad_norm = 0.2317 cg_residual = 0.2845 step_size = 0.4266 reward = -0.0000 fps = 18 mse_loss = 0.7706 
2022-05-01 05:06:33.456348 - gail/main.py:191 - [Discriminator] iter = 360000 loss = -0.8517 grad_norm = 2.4150 grad_penalty = 0.0761 regularization = 0.0000 true_logits = 0.1457 fake_logits = -0.7821 true_prob = 0.5321 fake_prob = 0.3586 
2022-05-01 05:07:31.478896 - gail/main.py:132 - [Evaluate] iter = 360000 episode={ returns = 1372.1880 lengths = 426 } discounted_episode={ returns = 1030.7437 lengths = 426 } 
2022-05-01 05:07:41.518481 - gail/main.py:164 - [TRPO] iter = 361000 dist_mean = 0.0519 dist_std = 0.2745 vf_loss = 0.1054 grad_norm = 1.7208 nat_grad_norm = 0.1969 cg_residual = 0.3738 step_size = 0.4229 reward = 0.0000 fps = 14 mse_loss = 0.7012 
2022-05-01 05:07:51.280682 - gail/main.py:164 - [TRPO] iter = 362000 dist_mean = 0.0272 dist_std = 0.2709 vf_loss = 0.3093 grad_norm = 1.3442 nat_grad_norm = 0.1645 cg_residual = 0.2022 step_size = 0.5301 reward = 0.0000 fps = 12 mse_loss = 0.6875 
2022-05-01 05:08:01.508459 - gail/main.py:164 - [TRPO] iter = 363000 dist_mean = 0.0083 dist_std = 0.2697 vf_loss = 0.1046 grad_norm = 1.3727 nat_grad_norm = 0.1821 cg_residual = 0.3096 step_size = 0.4687 reward = 0.0000 fps = 11 mse_loss = 0.6906 
2022-05-01 05:08:11.614273 - gail/main.py:164 - [TRPO] iter = 364000 dist_mean = 0.0202 dist_std = 0.2676 vf_loss = 0.1028 grad_norm = 1.1633 nat_grad_norm = 0.1763 cg_residual = 0.3489 step_size = 0.4923 reward = -0.0000 fps = 10 mse_loss = 0.6541 
2022-05-01 05:08:21.600168 - gail/main.py:164 - [TRPO] iter = 365000 dist_mean = 0.0651 dist_std = 0.2704 vf_loss = 0.0705 grad_norm = 1.3282 nat_grad_norm = 0.1592 cg_residual = 0.2381 step_size = 0.4790 reward = 0.0000 fps = 9 mse_loss = 0.7738 
2022-05-01 05:08:21.819252 - gail/main.py:191 - [Discriminator] iter = 365000 loss = -0.4498 grad_norm = 2.0059 grad_penalty = 0.0513 regularization = 0.0000 true_logits = -0.0136 fake_logits = -0.5147 true_prob = 0.5000 fake_prob = 0.3983 
2022-05-01 05:09:42.681517 - gail/main.py:132 - [Evaluate] iter = 365000 episode={ returns = 2171.9587 lengths = 631 } discounted_episode={ returns = 1358.9758 lengths = 570 } 
2022-05-01 05:09:52.501084 - gail/main.py:164 - [TRPO] iter = 366000 dist_mean = 0.0948 dist_std = 0.2684 vf_loss = 0.1598 grad_norm = 1.5794 nat_grad_norm = 0.1751 cg_residual = 0.3509 step_size = 0.4516 reward = 0.0000 fps = 11 mse_loss = 0.6786 
2022-05-01 05:10:02.449785 - gail/main.py:164 - [TRPO] iter = 367000 dist_mean = 0.0294 dist_std = 0.2676 vf_loss = 0.0799 grad_norm = 1.4497 nat_grad_norm = 0.2090 cg_residual = 0.4774 step_size = 0.4429 reward = -0.0000 fps = 9 mse_loss = 0.7117 
2022-05-01 05:10:11.966108 - gail/main.py:164 - [TRPO] iter = 368000 dist_mean = 0.0086 dist_std = 0.2661 vf_loss = 0.1067 grad_norm = 1.4346 nat_grad_norm = 0.1471 cg_residual = 0.1885 step_size = 0.4712 reward = 0.0000 fps = 9 mse_loss = 0.7349 
2022-05-01 05:10:21.552203 - gail/main.py:164 - [TRPO] iter = 369000 dist_mean = -0.0140 dist_std = 0.2677 vf_loss = 0.1101 grad_norm = 1.3132 nat_grad_norm = 0.2214 cg_residual = 0.3539 step_size = 0.4271 reward = -0.0000 fps = 8 mse_loss = 0.8062 
2022-05-01 05:10:31.662783 - gail/main.py:164 - [TRPO] iter = 370000 dist_mean = 0.0636 dist_std = 0.2681 vf_loss = 0.1467 grad_norm = 0.9808 nat_grad_norm = 0.1687 cg_residual = 0.4792 step_size = 0.4781 reward = -0.0000 fps = 7 mse_loss = 0.7219 
2022-05-01 05:10:31.934156 - gail/main.py:191 - [Discriminator] iter = 370000 loss = -0.4222 grad_norm = 2.0255 grad_penalty = 0.0423 regularization = 0.0000 true_logits = 0.0269 fake_logits = -0.4376 true_prob = 0.5083 fake_prob = 0.4115 
2022-05-01 05:10:35.442407 - gail/main.py:132 - [Evaluate] iter = 370000 episode={ returns = 42.0128 lengths = 23 } discounted_episode={ returns = 41.9279 lengths = 24 } 
2022-05-01 05:10:45.506417 - gail/main.py:164 - [TRPO] iter = 371000 dist_mean = 0.0030 dist_std = 0.2693 vf_loss = 0.2602 grad_norm = 1.7121 nat_grad_norm = 0.1667 cg_residual = 0.2304 step_size = 0.4990 reward = -0.0000 fps = 73 mse_loss = 0.7219 
2022-05-01 05:10:55.657439 - gail/main.py:164 - [TRPO] iter = 372000 dist_mean = 0.0346 dist_std = 0.2681 vf_loss = 0.0663 grad_norm = 1.5980 nat_grad_norm = 0.2426 cg_residual = 0.4467 step_size = 0.3538 reward = -0.0000 fps = 42 mse_loss = 0.7902 
2022-05-01 05:11:05.844888 - gail/main.py:164 - [TRPO] iter = 373000 dist_mean = 0.1396 dist_std = 0.2693 vf_loss = 0.1909 grad_norm = 1.2690 nat_grad_norm = 0.1787 cg_residual = 0.1461 step_size = 0.4906 reward = 0.0000 fps = 29 mse_loss = 0.7212 
2022-05-01 05:11:16.110261 - gail/main.py:164 - [TRPO] iter = 374000 dist_mean = 0.1434 dist_std = 0.2718 vf_loss = 0.2233 grad_norm = 1.1863 nat_grad_norm = 0.2356 cg_residual = 0.2227 step_size = 0.4219 reward = 0.0000 fps = 22 mse_loss = 0.6830 
2022-05-01 05:11:26.359321 - gail/main.py:164 - [TRPO] iter = 375000 dist_mean = 0.3252 dist_std = 0.2696 vf_loss = 0.1436 grad_norm = 0.9851 nat_grad_norm = 0.2154 cg_residual = 0.1776 step_size = 0.4685 reward = 0.0000 fps = 18 mse_loss = 0.6474 
2022-05-01 05:11:26.604643 - gail/main.py:191 - [Discriminator] iter = 375000 loss = -2.7605 grad_norm = 2.9646 grad_penalty = 0.1641 regularization = 0.0000 true_logits = -0.0477 fake_logits = -2.9723 true_prob = 0.4929 fake_prob = 0.0850 
2022-05-01 05:11:29.619161 - gail/main.py:132 - [Evaluate] iter = 375000 episode={ returns = 37.1739 lengths = 21 } discounted_episode={ returns = 36.3759 lengths = 20 } 
2022-05-01 05:11:39.523209 - gail/main.py:164 - [TRPO] iter = 376000 dist_mean = 0.1435 dist_std = 0.2692 vf_loss = 0.8846 grad_norm = 1.4145 nat_grad_norm = 0.1657 cg_residual = 0.1310 step_size = 0.4983 reward = 0.0000 fps = 77 mse_loss = 0.6786 
2022-05-01 05:11:49.363043 - gail/main.py:164 - [TRPO] iter = 377000 dist_mean = 0.3083 dist_std = 0.2690 vf_loss = 0.3757 grad_norm = 1.8703 nat_grad_norm = 0.2347 cg_residual = 0.3332 step_size = 0.3523 reward = 0.0000 fps = 43 mse_loss = 0.6727 
2022-05-01 05:11:59.146876 - gail/main.py:164 - [TRPO] iter = 378000 dist_mean = 0.1044 dist_std = 0.2688 vf_loss = 0.5868 grad_norm = 1.5610 nat_grad_norm = 0.1729 cg_residual = 0.2179 step_size = 0.5229 reward = 0.0000 fps = 30 mse_loss = 0.6412 
2022-05-01 05:12:08.781485 - gail/main.py:164 - [TRPO] iter = 379000 dist_mean = 0.0572 dist_std = 0.2697 vf_loss = 0.3240 grad_norm = 2.0105 nat_grad_norm = 0.1819 cg_residual = 0.2139 step_size = 0.4168 reward = 0.0000 fps = 23 mse_loss = 0.7424 
2022-05-01 05:12:18.948239 - gail/main.py:164 - [TRPO] iter = 380000 dist_mean = 0.1222 dist_std = 0.2707 vf_loss = 0.5604 grad_norm = 0.9440 nat_grad_norm = 0.1836 cg_residual = 0.1893 step_size = 0.5426 reward = 0.0000 fps = 19 mse_loss = 0.7092 
2022-05-01 05:12:19.157192 - gail/main.py:191 - [Discriminator] iter = 380000 loss = -0.8496 grad_norm = 2.6621 grad_penalty = 0.0934 regularization = 0.0000 true_logits = 0.1243 fake_logits = -0.8188 true_prob = 0.5275 fake_prob = 0.3743 
2022-05-01 05:12:24.583875 - gail/main.py:132 - [Evaluate] iter = 380000 episode={ returns = 61.7140 lengths = 33 } discounted_episode={ returns = 83.5096 lengths = 44 } 
2022-05-01 05:12:34.541211 - gail/main.py:164 - [TRPO] iter = 381000 dist_mean = 0.0484 dist_std = 0.2730 vf_loss = 0.1458 grad_norm = 1.6467 nat_grad_norm = 0.2276 cg_residual = 0.4024 step_size = 0.4131 reward = -0.0000 fps = 65 mse_loss = 0.7085 
2022-05-01 05:12:44.615221 - gail/main.py:164 - [TRPO] iter = 382000 dist_mean = 0.0939 dist_std = 0.2717 vf_loss = 0.6335 grad_norm = 1.4823 nat_grad_norm = 0.1548 cg_residual = 0.1575 step_size = 0.4812 reward = 0.0000 fps = 39 mse_loss = 0.8038 
2022-05-01 05:12:54.712695 - gail/main.py:164 - [TRPO] iter = 383000 dist_mean = 0.0151 dist_std = 0.2688 vf_loss = 0.4767 grad_norm = 1.1188 nat_grad_norm = 0.1365 cg_residual = 0.1406 step_size = 0.6050 reward = -0.0000 fps = 28 mse_loss = 0.7193 
2022-05-01 05:13:04.490800 - gail/main.py:164 - [TRPO] iter = 384000 dist_mean = 0.0297 dist_std = 0.2690 vf_loss = 0.1738 grad_norm = 1.5988 nat_grad_norm = 0.2346 cg_residual = 0.4194 step_size = 0.3873 reward = -0.0000 fps = 22 mse_loss = 0.6911 
2022-05-01 05:13:14.596123 - gail/main.py:164 - [TRPO] iter = 385000 dist_mean = 0.0200 dist_std = 0.2696 vf_loss = 0.0786 grad_norm = 1.2888 nat_grad_norm = 0.2510 cg_residual = 0.3656 step_size = 0.3989 reward = -0.0000 fps = 18 mse_loss = 0.6270 
2022-05-01 05:13:14.825258 - gail/main.py:191 - [Discriminator] iter = 385000 loss = -0.6601 grad_norm = 2.5605 grad_penalty = 0.0522 regularization = 0.0000 true_logits = 0.1501 fake_logits = -0.5622 true_prob = 0.5319 fake_prob = 0.3963 
2022-05-01 05:13:18.032296 - gail/main.py:132 - [Evaluate] iter = 385000 episode={ returns = 39.7018 lengths = 22 } discounted_episode={ returns = 39.5585 lengths = 23 } 
2022-05-01 05:13:27.732585 - gail/main.py:164 - [TRPO] iter = 386000 dist_mean = 0.0616 dist_std = 0.2714 vf_loss = 0.1184 grad_norm = 1.4413 nat_grad_norm = 0.2349 cg_residual = 0.1768 step_size = 0.3738 reward = -0.0000 fps = 77 mse_loss = 0.5979 
2022-05-01 05:13:37.766135 - gail/main.py:164 - [TRPO] iter = 387000 dist_mean = 0.2465 dist_std = 0.2690 vf_loss = 0.0869 grad_norm = 1.0801 nat_grad_norm = 0.1726 cg_residual = 0.2012 step_size = 0.4970 reward = 0.0000 fps = 43 mse_loss = 0.6150 
2022-05-01 05:13:47.430471 - gail/main.py:164 - [TRPO] iter = 388000 dist_mean = 0.0756 dist_std = 0.2701 vf_loss = 0.9335 grad_norm = 1.1415 nat_grad_norm = 0.1111 cg_residual = 0.1739 step_size = 0.6674 reward = 0.0000 fps = 30 mse_loss = 0.6401 
2022-05-01 05:13:57.384790 - gail/main.py:164 - [TRPO] iter = 389000 dist_mean = 0.0304 dist_std = 0.2697 vf_loss = 0.1032 grad_norm = 1.2443 nat_grad_norm = 0.2062 cg_residual = 0.2772 step_size = 0.4827 reward = 0.0000 fps = 23 mse_loss = 0.5611 
2022-05-01 05:14:07.511609 - gail/main.py:164 - [TRPO] iter = 390000 dist_mean = 0.0404 dist_std = 0.2689 vf_loss = 0.8023 grad_norm = 0.8019 nat_grad_norm = 0.2799 cg_residual = 0.3959 step_size = 0.3912 reward = 0.0000 fps = 18 mse_loss = 0.6678 
2022-05-01 05:14:07.795264 - gail/main.py:191 - [Discriminator] iter = 390000 loss = -1.1940 grad_norm = 2.2460 grad_penalty = 0.0730 regularization = 0.0000 true_logits = 0.1915 fake_logits = -1.0756 true_prob = 0.5395 fake_prob = 0.3196 
2022-05-01 05:14:17.586608 - gail/main.py:132 - [Evaluate] iter = 390000 episode={ returns = 90.1953 lengths = 44 } discounted_episode={ returns = 221.7426 lengths = 100 } 
2022-05-01 05:14:27.220814 - gail/main.py:164 - [TRPO] iter = 391000 dist_mean = 0.0295 dist_std = 0.2664 vf_loss = 0.0683 grad_norm = 1.1893 nat_grad_norm = 0.1702 cg_residual = 0.3503 step_size = 0.5101 reward = 0.0000 fps = 51 mse_loss = 0.5208 
2022-05-01 05:14:37.179045 - gail/main.py:164 - [TRPO] iter = 392000 dist_mean = 0.0396 dist_std = 0.2637 vf_loss = 0.2720 grad_norm = 2.5760 nat_grad_norm = 0.1600 cg_residual = 0.1629 step_size = 0.4825 reward = -0.0000 fps = 34 mse_loss = 0.6363 
2022-05-01 05:14:46.482957 - gail/main.py:164 - [TRPO] iter = 393000 dist_mean = 0.0759 dist_std = 0.2635 vf_loss = 0.0953 grad_norm = 1.2451 nat_grad_norm = 0.2263 cg_residual = 0.2436 step_size = 0.4302 reward = 0.0000 fps = 25 mse_loss = 0.6131 
2022-05-01 05:14:56.305367 - gail/main.py:164 - [TRPO] iter = 394000 dist_mean = 0.0604 dist_std = 0.2631 vf_loss = 0.1052 grad_norm = 1.5068 nat_grad_norm = 0.1777 cg_residual = 0.4186 step_size = 0.4356 reward = 0.0000 fps = 20 mse_loss = 0.6414 
2022-05-01 05:15:06.270567 - gail/main.py:164 - [TRPO] iter = 395000 dist_mean = 0.0904 dist_std = 0.2619 vf_loss = 0.2484 grad_norm = 1.3724 nat_grad_norm = 0.1662 cg_residual = 0.2150 step_size = 0.4440 reward = 0.0000 fps = 17 mse_loss = 0.6566 
2022-05-01 05:15:06.503424 - gail/main.py:191 - [Discriminator] iter = 395000 loss = -0.7111 grad_norm = 2.0679 grad_penalty = 0.0665 regularization = 0.0000 true_logits = 0.1481 fake_logits = -0.6295 true_prob = 0.5309 fake_prob = 0.3899 
2022-05-01 05:15:09.825253 - gail/main.py:132 - [Evaluate] iter = 395000 episode={ returns = 39.3795 lengths = 22 } discounted_episode={ returns = 38.3461 lengths = 22 } 
2022-05-01 05:15:19.852672 - gail/main.py:164 - [TRPO] iter = 396000 dist_mean = 0.0620 dist_std = 0.2624 vf_loss = 0.1810 grad_norm = 1.1124 nat_grad_norm = 0.2050 cg_residual = 0.1499 step_size = 0.4260 reward = -0.0000 fps = 75 mse_loss = 0.6094 
2022-05-01 05:15:29.690958 - gail/main.py:164 - [TRPO] iter = 397000 dist_mean = 0.0869 dist_std = 0.2619 vf_loss = 0.2452 grad_norm = 1.4307 nat_grad_norm = 0.1530 cg_residual = 0.2910 step_size = 0.4527 reward = 0.0000 fps = 43 mse_loss = 0.6320 
2022-05-01 05:15:39.797702 - gail/main.py:164 - [TRPO] iter = 398000 dist_mean = 0.0845 dist_std = 0.2617 vf_loss = 0.3314 grad_norm = 1.7517 nat_grad_norm = 0.1659 cg_residual = 0.5295 step_size = 0.4212 reward = -0.0000 fps = 30 mse_loss = 0.6282 
2022-05-01 05:15:50.268124 - gail/main.py:164 - [TRPO] iter = 399000 dist_mean = 0.3351 dist_std = 0.2595 vf_loss = 0.2075 grad_norm = 1.5739 nat_grad_norm = 0.2085 cg_residual = 0.3585 step_size = 0.4427 reward = -0.0000 fps = 22 mse_loss = 0.5328 
2022-05-01 05:16:00.363076 - gail/main.py:164 - [TRPO] iter = 400000 dist_mean = 0.0880 dist_std = 0.2622 vf_loss = 0.2265 grad_norm = 1.7282 nat_grad_norm = 0.1898 cg_residual = 0.2326 step_size = 0.4480 reward = 0.0000 fps = 18 mse_loss = 0.6401 
2022-05-01 05:16:00.588852 - gail/main.py:191 - [Discriminator] iter = 400000 loss = -0.4145 grad_norm = 2.0430 grad_penalty = 0.0481 regularization = 0.0000 true_logits = -0.0151 fake_logits = -0.4776 true_prob = 0.4989 fake_prob = 0.4069 
2022-05-01 05:16:03.711398 - gail/main.py:132 - [Evaluate] iter = 400000 episode={ returns = 39.0819 lengths = 22 } discounted_episode={ returns = 38.8884 lengths = 22 } 
2022-05-01 05:16:13.941985 - gail/main.py:164 - [TRPO] iter = 401000 dist_mean = 0.4363 dist_std = 0.2603 vf_loss = 0.0926 grad_norm = 1.5571 nat_grad_norm = 0.1245 cg_residual = 0.0639 step_size = 0.7055 reward = 0.0000 fps = 74 mse_loss = 0.5687 
2022-05-01 05:16:24.062067 - gail/main.py:164 - [TRPO] iter = 402000 dist_mean = 0.4120 dist_std = 0.2637 vf_loss = 0.5612 grad_norm = 1.8169 nat_grad_norm = 0.3254 cg_residual = 0.2798 step_size = 0.3101 reward = -0.0000 fps = 42 mse_loss = 0.5567 
2022-05-01 05:16:34.137894 - gail/main.py:164 - [TRPO] iter = 403000 dist_mean = 0.3281 dist_std = 0.2647 vf_loss = 2.2989 grad_norm = 2.4060 nat_grad_norm = 0.1701 cg_residual = 0.0924 step_size = 0.4237 reward = -0.0000 fps = 29 mse_loss = 0.5184 
2022-05-01 05:16:44.348237 - gail/main.py:164 - [TRPO] iter = 404000 dist_mean = 0.1782 dist_std = 0.2658 vf_loss = 1.2398 grad_norm = 1.6238 nat_grad_norm = 0.1976 cg_residual = 0.3365 step_size = 0.4384 reward = 0.0000 fps = 22 mse_loss = 0.6278 
2022-05-01 05:16:54.485177 - gail/main.py:164 - [TRPO] iter = 405000 dist_mean = 0.1650 dist_std = 0.2644 vf_loss = 1.5808 grad_norm = 1.1430 nat_grad_norm = 0.1803 cg_residual = 0.3316 step_size = 0.4612 reward = 0.0000 fps = 18 mse_loss = 0.5575 
2022-05-01 05:16:54.739345 - gail/main.py:191 - [Discriminator] iter = 405000 loss = -2.3108 grad_norm = 3.1576 grad_penalty = 0.1391 regularization = 0.0000 true_logits = 0.0453 fake_logits = -2.4047 true_prob = 0.5119 fake_prob = 0.1285 
2022-05-01 05:16:58.791144 - gail/main.py:132 - [Evaluate] iter = 405000 episode={ returns = 57.8506 lengths = 32 } discounted_episode={ returns = 54.8070 lengths = 31 } 
2022-05-01 05:17:08.977700 - gail/main.py:164 - [TRPO] iter = 406000 dist_mean = 0.1657 dist_std = 0.2630 vf_loss = 0.3917 grad_norm = 2.1127 nat_grad_norm = 0.1651 cg_residual = 0.3498 step_size = 0.4441 reward = 0.0000 fps = 70 mse_loss = 0.5614 
2022-05-01 05:17:18.858880 - gail/main.py:164 - [TRPO] iter = 407000 dist_mean = 0.0523 dist_std = 0.2602 vf_loss = 0.2308 grad_norm = 1.7195 nat_grad_norm = 0.1739 cg_residual = 0.1907 step_size = 0.4381 reward = 0.0000 fps = 41 mse_loss = 0.5691 
2022-05-01 05:17:28.692170 - gail/main.py:164 - [TRPO] iter = 408000 dist_mean = 0.0003 dist_std = 0.2588 vf_loss = 0.1532 grad_norm = 1.6218 nat_grad_norm = 0.2391 cg_residual = 0.4135 step_size = 0.3679 reward = 0.0000 fps = 29 mse_loss = 0.5743 
2022-05-01 05:17:38.389352 - gail/main.py:164 - [TRPO] iter = 409000 dist_mean = 0.0596 dist_std = 0.2599 vf_loss = 0.3450 grad_norm = 1.4595 nat_grad_norm = 0.1759 cg_residual = 0.3097 step_size = 0.4805 reward = 0.0000 fps = 22 mse_loss = 0.5089 
2022-05-01 05:17:48.647956 - gail/main.py:164 - [TRPO] iter = 410000 dist_mean = -0.0036 dist_std = 0.2611 vf_loss = 0.1566 grad_norm = 1.4760 nat_grad_norm = 0.2163 cg_residual = 0.1722 step_size = 0.4216 reward = -0.0000 fps = 18 mse_loss = 0.6389 
2022-05-01 05:17:48.887338 - gail/main.py:191 - [Discriminator] iter = 410000 loss = -1.4166 grad_norm = 2.4150 grad_penalty = 0.1235 regularization = 0.0000 true_logits = 0.0953 fake_logits = -1.4448 true_prob = 0.5182 fake_prob = 0.2494 
2022-05-01 05:17:58.630393 - gail/main.py:132 - [Evaluate] iter = 410000 episode={ returns = 196.8716 lengths = 76 } discounted_episode={ returns = 154.3998 lengths = 73 } 
2022-05-01 05:18:08.604424 - gail/main.py:164 - [TRPO] iter = 411000 dist_mean = 0.0786 dist_std = 0.2625 vf_loss = 0.2089 grad_norm = 1.3716 nat_grad_norm = 0.1584 cg_residual = 0.2205 step_size = 0.5114 reward = 0.0000 fps = 50 mse_loss = 0.6002 
2022-05-01 05:18:18.493909 - gail/main.py:164 - [TRPO] iter = 412000 dist_mean = 0.0631 dist_std = 0.2631 vf_loss = 0.1789 grad_norm = 1.1248 nat_grad_norm = 0.2145 cg_residual = 0.4103 step_size = 0.4309 reward = -0.0000 fps = 33 mse_loss = 0.6115 
2022-05-01 05:18:28.811134 - gail/main.py:164 - [TRPO] iter = 413000 dist_mean = 0.0766 dist_std = 0.2622 vf_loss = 0.3011 grad_norm = 1.4716 nat_grad_norm = 0.2018 cg_residual = 0.2905 step_size = 0.4382 reward = -0.0000 fps = 25 mse_loss = 0.5519 
2022-05-01 05:18:38.877858 - gail/main.py:164 - [TRPO] iter = 414000 dist_mean = 0.0362 dist_std = 0.2622 vf_loss = 0.1837 grad_norm = 1.8310 nat_grad_norm = 0.1641 cg_residual = 0.2392 step_size = 0.4620 reward = 0.0000 fps = 20 mse_loss = 0.5909 
2022-05-01 05:18:49.047908 - gail/main.py:164 - [TRPO] iter = 415000 dist_mean = 0.0789 dist_std = 0.2633 vf_loss = 0.4017 grad_norm = 1.6777 nat_grad_norm = 0.1560 cg_residual = 0.1763 step_size = 0.4828 reward = 0.0000 fps = 16 mse_loss = 0.5959 
2022-05-01 05:18:49.287630 - gail/main.py:191 - [Discriminator] iter = 415000 loss = -0.7702 grad_norm = 1.8609 grad_penalty = 0.0531 regularization = 0.0000 true_logits = 0.1082 fake_logits = -0.7151 true_prob = 0.5233 fake_prob = 0.3575 
2022-05-01 05:18:52.640388 - gail/main.py:132 - [Evaluate] iter = 415000 episode={ returns = 40.6382 lengths = 23 } discounted_episode={ returns = 39.1533 lengths = 22 } 
2022-05-01 05:19:03.257892 - gail/main.py:164 - [TRPO] iter = 416000 dist_mean = 0.0648 dist_std = 0.2633 vf_loss = 0.6124 grad_norm = 1.7386 nat_grad_norm = 0.1443 cg_residual = 0.2483 step_size = 0.4947 reward = 0.0000 fps = 71 mse_loss = 0.5408 
2022-05-01 05:19:13.162961 - gail/main.py:164 - [TRPO] iter = 417000 dist_mean = 0.0038 dist_std = 0.2649 vf_loss = 0.5015 grad_norm = 1.3578 nat_grad_norm = 0.1946 cg_residual = 0.1567 step_size = 0.4649 reward = 0.0000 fps = 41 mse_loss = 0.6050 
2022-05-01 05:19:23.006519 - gail/main.py:164 - [TRPO] iter = 418000 dist_mean = 0.0552 dist_std = 0.2655 vf_loss = 0.3640 grad_norm = 1.1976 nat_grad_norm = 0.2400 cg_residual = 0.6818 step_size = 0.3791 reward = 0.0000 fps = 29 mse_loss = 0.6665 
2022-05-01 05:19:33.151186 - gail/main.py:164 - [TRPO] iter = 419000 dist_mean = 0.1373 dist_std = 0.2659 vf_loss = 0.8280 grad_norm = 1.5572 nat_grad_norm = 0.1608 cg_residual = 0.2005 step_size = 0.4913 reward = 0.0000 fps = 22 mse_loss = 0.5628 
2022-05-01 05:19:43.636624 - gail/main.py:164 - [TRPO] iter = 420000 dist_mean = 0.1985 dist_std = 0.2661 vf_loss = 0.1723 grad_norm = 1.3935 nat_grad_norm = 0.1558 cg_residual = 0.1019 step_size = 0.5413 reward = -0.0000 fps = 18 mse_loss = 0.6298 
2022-05-01 05:19:43.854182 - gail/main.py:191 - [Discriminator] iter = 420000 loss = -1.4630 grad_norm = 2.3933 grad_penalty = 0.0849 regularization = 0.0000 true_logits = 0.0431 fake_logits = -1.5048 true_prob = 0.5109 fake_prob = 0.2708 
2022-05-01 05:19:47.376200 - gail/main.py:132 - [Evaluate] iter = 420000 episode={ returns = 39.4587 lengths = 22 } discounted_episode={ returns = 38.5035 lengths = 22 } 
2022-05-01 05:19:57.860074 - gail/main.py:164 - [TRPO] iter = 421000 dist_mean = 0.1331 dist_std = 0.2606 vf_loss = 0.8823 grad_norm = 1.8038 nat_grad_norm = 0.1432 cg_residual = 0.2093 step_size = 0.4976 reward = 0.0000 fps = 71 mse_loss = 0.6170 
2022-05-01 05:20:08.334826 - gail/main.py:164 - [TRPO] iter = 422000 dist_mean = 0.0947 dist_std = 0.2589 vf_loss = 0.7185 grad_norm = 0.9953 nat_grad_norm = 0.1220 cg_residual = 0.1258 step_size = 0.6390 reward = 0.0000 fps = 40 mse_loss = 0.5687 
2022-05-01 05:20:18.566312 - gail/main.py:164 - [TRPO] iter = 423000 dist_mean = 0.1067 dist_std = 0.2591 vf_loss = 0.3348 grad_norm = 1.3585 nat_grad_norm = 0.1566 cg_residual = 0.2604 step_size = 0.5189 reward = 0.0000 fps = 28 mse_loss = 0.5234 
2022-05-01 05:20:28.826353 - gail/main.py:164 - [TRPO] iter = 424000 dist_mean = 0.2653 dist_std = 0.2582 vf_loss = 0.1358 grad_norm = 2.3612 nat_grad_norm = 0.2363 cg_residual = 0.4549 step_size = 0.3075 reward = -0.0000 fps = 22 mse_loss = 0.5840 
2022-05-01 05:20:39.989877 - gail/main.py:164 - [TRPO] iter = 425000 dist_mean = 0.2580 dist_std = 0.2577 vf_loss = 0.1287 grad_norm = 2.0080 nat_grad_norm = 0.1363 cg_residual = 0.2454 step_size = 0.4560 reward = -0.0000 fps = 17 mse_loss = 0.5238 
2022-05-01 05:20:40.230508 - gail/main.py:191 - [Discriminator] iter = 425000 loss = -2.3536 grad_norm = 2.5408 grad_penalty = 0.1283 regularization = 0.0000 true_logits = 0.1345 fake_logits = -2.3473 true_prob = 0.5246 fake_prob = 0.1601 
2022-05-01 05:20:43.842277 - gail/main.py:132 - [Evaluate] iter = 425000 episode={ returns = 38.2055 lengths = 21 } discounted_episode={ returns = 37.6532 lengths = 21 } 
2022-05-01 05:20:55.394007 - gail/main.py:164 - [TRPO] iter = 426000 dist_mean = 0.2299 dist_std = 0.2559 vf_loss = 1.1399 grad_norm = 1.5434 nat_grad_norm = 0.1590 cg_residual = 0.2047 step_size = 0.5152 reward = -0.0000 fps = 66 mse_loss = 0.6105 
2022-05-01 05:21:07.709739 - gail/main.py:164 - [TRPO] iter = 427000 dist_mean = 0.4103 dist_std = 0.2537 vf_loss = 0.3171 grad_norm = 2.1064 nat_grad_norm = 0.0969 cg_residual = 0.2947 step_size = 0.6838 reward = 0.0000 fps = 36 mse_loss = 0.5742 
2022-05-01 05:21:19.838952 - gail/main.py:164 - [TRPO] iter = 428000 dist_mean = 0.1558 dist_std = 0.2542 vf_loss = 0.1757 grad_norm = 1.3846 nat_grad_norm = 0.1637 cg_residual = 0.2827 step_size = 0.5076 reward = -0.0000 fps = 25 mse_loss = 0.6621 
2022-05-01 05:21:31.383124 - gail/main.py:164 - [TRPO] iter = 429000 dist_mean = 0.0996 dist_std = 0.2534 vf_loss = 0.6412 grad_norm = 3.3402 nat_grad_norm = 0.1864 cg_residual = 0.2910 step_size = 0.3968 reward = -0.0000 fps = 19 mse_loss = 0.6991 
2022-05-01 05:21:42.789600 - gail/main.py:164 - [TRPO] iter = 430000 dist_mean = 0.1013 dist_std = 0.2511 vf_loss = 0.1438 grad_norm = 1.5431 nat_grad_norm = 0.2225 cg_residual = 0.3788 step_size = 0.3931 reward = 0.0000 fps = 15 mse_loss = 0.7057 
2022-05-01 05:21:43.040127 - gail/main.py:191 - [Discriminator] iter = 430000 loss = -1.1442 grad_norm = 2.0602 grad_penalty = 0.0828 regularization = 0.0000 true_logits = 0.2202 fake_logits = -1.0068 true_prob = 0.5418 fake_prob = 0.3176 
2022-05-01 05:21:46.643157 - gail/main.py:132 - [Evaluate] iter = 430000 episode={ returns = 38.6408 lengths = 22 } discounted_episode={ returns = 37.7542 lengths = 22 } 
2022-05-01 05:21:58.225370 - gail/main.py:164 - [TRPO] iter = 431000 dist_mean = 0.1798 dist_std = 0.2515 vf_loss = 0.0701 grad_norm = 1.7680 nat_grad_norm = 0.2082 cg_residual = 0.6991 step_size = 0.3641 reward = 0.0000 fps = 65 mse_loss = 0.6002 
2022-05-01 05:22:10.028861 - gail/main.py:164 - [TRPO] iter = 432000 dist_mean = 0.1052 dist_std = 0.2522 vf_loss = 0.1936 grad_norm = 1.4990 nat_grad_norm = 0.2336 cg_residual = 0.5981 step_size = 0.3858 reward = -0.0000 fps = 37 mse_loss = 0.6344 
2022-05-01 05:22:21.700569 - gail/main.py:164 - [TRPO] iter = 433000 dist_mean = 0.1900 dist_std = 0.2517 vf_loss = 0.7119 grad_norm = 1.1703 nat_grad_norm = 0.1154 cg_residual = 0.1001 step_size = 0.6814 reward = 0.0000 fps = 25 mse_loss = 0.6191 
2022-05-01 05:22:32.961806 - gail/main.py:164 - [TRPO] iter = 434000 dist_mean = 0.1103 dist_std = 0.2544 vf_loss = 0.0988 grad_norm = 1.2380 nat_grad_norm = 0.2135 cg_residual = 0.4560 step_size = 0.4468 reward = -0.0000 fps = 20 mse_loss = 0.7217 
2022-05-01 05:22:44.438237 - gail/main.py:164 - [TRPO] iter = 435000 dist_mean = 0.0926 dist_std = 0.2541 vf_loss = 0.3889 grad_norm = 1.3706 nat_grad_norm = 0.1363 cg_residual = 0.2921 step_size = 0.5851 reward = -0.0000 fps = 16 mse_loss = 0.6691 
2022-05-01 05:22:44.696663 - gail/main.py:191 - [Discriminator] iter = 435000 loss = -0.7261 grad_norm = 2.0429 grad_penalty = 0.0432 regularization = 0.0000 true_logits = 0.2371 fake_logits = -0.5322 true_prob = 0.5463 fake_prob = 0.4029 
2022-05-01 05:22:48.636550 - gail/main.py:132 - [Evaluate] iter = 435000 episode={ returns = 38.5014 lengths = 22 } discounted_episode={ returns = 38.4622 lengths = 22 } 
2022-05-01 05:23:00.211602 - gail/main.py:164 - [TRPO] iter = 436000 dist_mean = 0.0714 dist_std = 0.2543 vf_loss = 0.1520 grad_norm = 1.5644 nat_grad_norm = 0.2656 cg_residual = 0.5451 step_size = 0.3880 reward = 0.0000 fps = 64 mse_loss = 0.6541 
2022-05-01 05:23:11.033245 - gail/main.py:164 - [TRPO] iter = 437000 dist_mean = 0.1147 dist_std = 0.2529 vf_loss = 0.7567 grad_norm = 1.6655 nat_grad_norm = 0.1542 cg_residual = 0.3776 step_size = 0.4729 reward = -0.0000 fps = 37 mse_loss = 0.5958 
2022-05-01 05:23:21.089008 - gail/main.py:164 - [TRPO] iter = 438000 dist_mean = 0.1297 dist_std = 0.2521 vf_loss = 0.1352 grad_norm = 1.7048 nat_grad_norm = 0.1797 cg_residual = 0.3105 step_size = 0.4602 reward = 0.0000 fps = 27 mse_loss = 0.6343 
2022-05-01 05:23:31.216400 - gail/main.py:164 - [TRPO] iter = 439000 dist_mean = 0.1418 dist_std = 0.2533 vf_loss = 0.1358 grad_norm = 2.0885 nat_grad_norm = 0.1924 cg_residual = 0.2126 step_size = 0.4005 reward = 0.0000 fps = 21 mse_loss = 0.6079 
2022-05-01 05:23:41.243306 - gail/main.py:164 - [TRPO] iter = 440000 dist_mean = 0.1181 dist_std = 0.2545 vf_loss = 0.0887 grad_norm = 1.9963 nat_grad_norm = 0.2112 cg_residual = 0.9371 step_size = 0.3723 reward = -0.0000 fps = 17 mse_loss = 0.5212 
2022-05-01 05:23:41.461831 - gail/main.py:191 - [Discriminator] iter = 440000 loss = -0.6038 grad_norm = 1.8527 grad_penalty = 0.0487 regularization = 0.0000 true_logits = 0.0777 fake_logits = -0.5749 true_prob = 0.5181 fake_prob = 0.3971 
2022-05-01 05:23:44.709212 - gail/main.py:132 - [Evaluate] iter = 440000 episode={ returns = 38.3823 lengths = 22 } discounted_episode={ returns = 37.7600 lengths = 21 } 
2022-05-01 05:23:54.669163 - gail/main.py:164 - [TRPO] iter = 441000 dist_mean = 0.1212 dist_std = 0.2547 vf_loss = 0.1084 grad_norm = 1.4938 nat_grad_norm = 0.1802 cg_residual = 0.2498 step_size = 0.4736 reward = 0.0000 fps = 75 mse_loss = 0.5972 
2022-05-01 05:24:04.549889 - gail/main.py:164 - [TRPO] iter = 442000 dist_mean = 0.1506 dist_std = 0.2549 vf_loss = 0.1016 grad_norm = 2.2177 nat_grad_norm = 0.2120 cg_residual = 0.3346 step_size = 0.3648 reward = -0.0000 fps = 43 mse_loss = 0.6314 
2022-05-01 05:24:14.500392 - gail/main.py:164 - [TRPO] iter = 443000 dist_mean = 0.1691 dist_std = 0.2535 vf_loss = 0.4219 grad_norm = 1.5184 nat_grad_norm = 0.1603 cg_residual = 0.2937 step_size = 0.4565 reward = 0.0000 fps = 30 mse_loss = 0.5659 
2022-05-01 05:24:24.623358 - gail/main.py:164 - [TRPO] iter = 444000 dist_mean = 0.2200 dist_std = 0.2530 vf_loss = 0.0773 grad_norm = 0.9997 nat_grad_norm = 0.2266 cg_residual = 0.2918 step_size = 0.4611 reward = -0.0000 fps = 23 mse_loss = 0.5991 
2022-05-01 05:24:34.873996 - gail/main.py:164 - [TRPO] iter = 445000 dist_mean = 0.1520 dist_std = 0.2523 vf_loss = 0.0852 grad_norm = 1.7823 nat_grad_norm = 0.1560 cg_residual = 0.2325 step_size = 0.5294 reward = -0.0000 fps = 18 mse_loss = 0.5955 
2022-05-01 05:24:35.109553 - gail/main.py:191 - [Discriminator] iter = 445000 loss = -0.7570 grad_norm = 2.0586 grad_penalty = 0.0488 regularization = 0.0000 true_logits = 0.0121 fake_logits = -0.7938 true_prob = 0.5048 fake_prob = 0.3714 
2022-05-01 05:24:38.308281 - gail/main.py:132 - [Evaluate] iter = 445000 episode={ returns = 37.9240 lengths = 21 } discounted_episode={ returns = 37.9009 lengths = 22 } 
2022-05-01 05:24:48.481792 - gail/main.py:164 - [TRPO] iter = 446000 dist_mean = 0.3340 dist_std = 0.2532 vf_loss = 0.0715 grad_norm = 1.4805 nat_grad_norm = 0.2191 cg_residual = 0.2106 step_size = 0.4242 reward = -0.0000 fps = 74 mse_loss = 0.5219 
2022-05-01 05:24:58.651332 - gail/main.py:164 - [TRPO] iter = 447000 dist_mean = 0.2234 dist_std = 0.2535 vf_loss = 0.0881 grad_norm = 1.8554 nat_grad_norm = 0.2279 cg_residual = 0.5123 step_size = 0.4027 reward = -0.0000 fps = 42 mse_loss = 0.5533 
2022-05-01 05:25:08.894846 - gail/main.py:164 - [TRPO] iter = 448000 dist_mean = 0.2619 dist_std = 0.2531 vf_loss = 0.1073 grad_norm = 1.4184 nat_grad_norm = 0.1616 cg_residual = 0.6044 step_size = 0.4985 reward = 0.0000 fps = 29 mse_loss = 0.6019 
2022-05-01 05:25:18.923037 - gail/main.py:164 - [TRPO] iter = 449000 dist_mean = 0.2423 dist_std = 0.2527 vf_loss = 0.0794 grad_norm = 1.3497 nat_grad_norm = 0.2232 cg_residual = 0.4761 step_size = 0.4730 reward = -0.0000 fps = 22 mse_loss = 0.5515 
2022-05-01 05:25:29.448021 - gail/main.py:164 - [TRPO] iter = 450000 dist_mean = 0.2671 dist_std = 0.2549 vf_loss = 0.2069 grad_norm = 1.3891 nat_grad_norm = 0.1911 cg_residual = 0.3311 step_size = 0.4504 reward = 0.0000 fps = 18 mse_loss = 0.6059 
2022-05-01 05:25:29.702696 - gail/main.py:191 - [Discriminator] iter = 450000 loss = -2.0170 grad_norm = 2.3732 grad_penalty = 0.0990 regularization = 0.0000 true_logits = 0.0233 fake_logits = -2.0927 true_prob = 0.5068 fake_prob = 0.1929 
2022-05-01 05:25:33.083114 - gail/main.py:132 - [Evaluate] iter = 450000 episode={ returns = 37.6567 lengths = 21 } discounted_episode={ returns = 37.5984 lengths = 21 } 
2022-05-01 05:25:43.255533 - gail/main.py:164 - [TRPO] iter = 451000 dist_mean = 0.1892 dist_std = 0.2567 vf_loss = 0.1848 grad_norm = 1.3522 nat_grad_norm = 0.1490 cg_residual = 0.5397 step_size = 0.5298 reward = -0.0000 fps = 73 mse_loss = 0.6555 
2022-05-01 05:25:53.828819 - gail/main.py:164 - [TRPO] iter = 452000 dist_mean = 0.2070 dist_std = 0.2559 vf_loss = 0.1843 grad_norm = 1.6082 nat_grad_norm = 0.1811 cg_residual = 0.2165 step_size = 0.4562 reward = -0.0000 fps = 41 mse_loss = 0.6379 
2022-05-01 05:26:03.867311 - gail/main.py:164 - [TRPO] iter = 453000 dist_mean = 0.1247 dist_std = 0.2523 vf_loss = 0.2763 grad_norm = 1.4729 nat_grad_norm = 0.1609 cg_residual = 0.3116 step_size = 0.4811 reward = -0.0000 fps = 29 mse_loss = 0.6346 
2022-05-01 05:26:14.060082 - gail/main.py:164 - [TRPO] iter = 454000 dist_mean = 0.1279 dist_std = 0.2534 vf_loss = 1.3130 grad_norm = 0.9776 nat_grad_norm = 0.1203 cg_residual = 0.1718 step_size = 0.6932 reward = -0.0000 fps = 22 mse_loss = 0.5870 
2022-05-01 05:26:24.321813 - gail/main.py:164 - [TRPO] iter = 455000 dist_mean = 0.1705 dist_std = 0.2514 vf_loss = 1.4722 grad_norm = 2.0740 nat_grad_norm = 0.1214 cg_residual = 0.1621 step_size = 0.5073 reward = 0.0000 fps = 18 mse_loss = 0.7182 
2022-05-01 05:26:24.569149 - gail/main.py:191 - [Discriminator] iter = 455000 loss = -1.1111 grad_norm = 1.8772 grad_penalty = 0.0768 regularization = 0.0000 true_logits = 0.1053 fake_logits = -1.0826 true_prob = 0.5225 fake_prob = 0.3389 
2022-05-01 05:26:27.806871 - gail/main.py:132 - [Evaluate] iter = 455000 episode={ returns = 38.5107 lengths = 22 } discounted_episode={ returns = 37.7303 lengths = 21 } 
2022-05-01 05:26:37.981279 - gail/main.py:164 - [TRPO] iter = 456000 dist_mean = 0.1517 dist_std = 0.2505 vf_loss = 1.2480 grad_norm = 2.1406 nat_grad_norm = 0.1922 cg_residual = 0.2672 step_size = 0.3843 reward = -0.0000 fps = 74 mse_loss = 0.6486 
2022-05-01 05:26:48.220677 - gail/main.py:164 - [TRPO] iter = 457000 dist_mean = 0.1666 dist_std = 0.2505 vf_loss = 0.0586 grad_norm = 1.6529 nat_grad_norm = 0.1547 cg_residual = 0.3606 step_size = 0.5371 reward = -0.0000 fps = 42 mse_loss = 0.6890 
2022-05-01 05:26:58.018979 - gail/main.py:164 - [TRPO] iter = 458000 dist_mean = 0.1490 dist_std = 0.2516 vf_loss = 0.1007 grad_norm = 1.5027 nat_grad_norm = 0.1931 cg_residual = 0.1875 step_size = 0.4457 reward = -0.0000 fps = 29 mse_loss = 0.6502 
2022-05-01 05:27:08.381238 - gail/main.py:164 - [TRPO] iter = 459000 dist_mean = 0.0721 dist_std = 0.2474 vf_loss = 0.1071 grad_norm = 1.6499 nat_grad_norm = 0.2340 cg_residual = 0.5983 step_size = 0.3735 reward = -0.0000 fps = 22 mse_loss = 0.6672 
2022-05-01 05:27:18.293832 - gail/main.py:164 - [TRPO] iter = 460000 dist_mean = 0.0944 dist_std = 0.2483 vf_loss = 0.1442 grad_norm = 2.3991 nat_grad_norm = 0.1405 cg_residual = 0.3695 step_size = 0.5096 reward = -0.0000 fps = 18 mse_loss = 0.6545 
2022-05-01 05:27:18.515077 - gail/main.py:191 - [Discriminator] iter = 460000 loss = -0.5381 grad_norm = 1.7276 grad_penalty = 0.0404 regularization = 0.0000 true_logits = 0.0809 fake_logits = -0.4976 true_prob = 0.5143 fake_prob = 0.4059 
2022-05-01 05:27:34.903564 - gail/main.py:132 - [Evaluate] iter = 460000 episode={ returns = 364.4408 lengths = 120 } discounted_episode={ returns = 234.4072 lengths = 119 } 
2022-05-01 05:27:44.954475 - gail/main.py:164 - [TRPO] iter = 461000 dist_mean = 0.0999 dist_std = 0.2501 vf_loss = 0.0764 grad_norm = 1.8378 nat_grad_norm = 0.1589 cg_residual = 0.4582 step_size = 0.4155 reward = -0.0000 fps = 37 mse_loss = 0.7377 
2022-05-01 05:27:55.006384 - gail/main.py:164 - [TRPO] iter = 462000 dist_mean = 0.1752 dist_std = 0.2496 vf_loss = 0.0882 grad_norm = 0.9340 nat_grad_norm = 0.2281 cg_residual = 0.2534 step_size = 0.4589 reward = 0.0000 fps = 27 mse_loss = 0.6939 
2022-05-01 05:28:05.048671 - gail/main.py:164 - [TRPO] iter = 463000 dist_mean = 0.1179 dist_std = 0.2456 vf_loss = 0.1045 grad_norm = 1.8110 nat_grad_norm = 0.2111 cg_residual = 0.3371 step_size = 0.3376 reward = -0.0000 fps = 21 mse_loss = 0.6880 
2022-05-01 05:28:15.256105 - gail/main.py:164 - [TRPO] iter = 464000 dist_mean = 0.0522 dist_std = 0.2448 vf_loss = 0.5654 grad_norm = 1.0988 nat_grad_norm = 0.1427 cg_residual = 0.2280 step_size = 0.5266 reward = 0.0000 fps = 17 mse_loss = 0.6527 
2022-05-01 05:28:25.312648 - gail/main.py:164 - [TRPO] iter = 465000 dist_mean = 0.1783 dist_std = 0.2447 vf_loss = 0.8647 grad_norm = 2.3266 nat_grad_norm = 0.1268 cg_residual = 0.3632 step_size = 0.4626 reward = -0.0000 fps = 14 mse_loss = 0.7048 
2022-05-01 05:28:25.507783 - gail/main.py:191 - [Discriminator] iter = 465000 loss = -1.4410 grad_norm = 1.7794 grad_penalty = 0.0662 regularization = 0.0000 true_logits = -0.0011 fake_logits = -1.5083 true_prob = 0.5009 fake_prob = 0.2777 
2022-05-01 05:28:28.402833 - gail/main.py:132 - [Evaluate] iter = 465000 episode={ returns = 38.3383 lengths = 22 } discounted_episode={ returns = 38.3803 lengths = 22 } 
2022-05-01 05:28:38.322687 - gail/main.py:164 - [TRPO] iter = 466000 dist_mean = 0.1164 dist_std = 0.2450 vf_loss = 0.1221 grad_norm = 1.8201 nat_grad_norm = 0.1462 cg_residual = 0.2364 step_size = 0.4793 reward = 0.0000 fps = 78 mse_loss = 0.6609 
2022-05-01 05:28:47.809961 - gail/main.py:164 - [TRPO] iter = 467000 dist_mean = 0.1565 dist_std = 0.2443 vf_loss = 0.0975 grad_norm = 2.2938 nat_grad_norm = 0.1688 cg_residual = 0.5435 step_size = 0.4129 reward = -0.0000 fps = 44 mse_loss = 0.7131 
2022-05-01 05:28:57.610446 - gail/main.py:164 - [TRPO] iter = 468000 dist_mean = 0.1546 dist_std = 0.2439 vf_loss = 0.0611 grad_norm = 1.4152 nat_grad_norm = 0.1767 cg_residual = 0.3352 step_size = 0.4287 reward = -0.0000 fps = 31 mse_loss = 0.6674 
2022-05-01 05:29:07.661795 - gail/main.py:164 - [TRPO] iter = 469000 dist_mean = 0.2317 dist_std = 0.2451 vf_loss = 0.0627 grad_norm = 1.5160 nat_grad_norm = 0.1750 cg_residual = 0.2591 step_size = 0.4562 reward = -0.0000 fps = 23 mse_loss = 0.6720 
2022-05-01 05:29:17.733779 - gail/main.py:164 - [TRPO] iter = 470000 dist_mean = 0.1529 dist_std = 0.2439 vf_loss = 0.1340 grad_norm = 1.8757 nat_grad_norm = 0.2195 cg_residual = 0.4831 step_size = 0.3787 reward = 0.0000 fps = 19 mse_loss = 0.6822 
2022-05-01 05:29:17.971404 - gail/main.py:191 - [Discriminator] iter = 470000 loss = -1.4204 grad_norm = 2.2920 grad_penalty = 0.0814 regularization = 0.0000 true_logits = 0.1715 fake_logits = -1.3303 true_prob = 0.5328 fake_prob = 0.3104 
2022-05-01 05:29:21.296979 - gail/main.py:132 - [Evaluate] iter = 470000 episode={ returns = 38.2470 lengths = 22 } discounted_episode={ returns = 37.8841 lengths = 22 } 
2022-05-01 05:29:31.170981 - gail/main.py:164 - [TRPO] iter = 471000 dist_mean = 0.0708 dist_std = 0.2416 vf_loss = 0.5362 grad_norm = 1.3543 nat_grad_norm = 0.1913 cg_residual = 0.2754 step_size = 0.4212 reward = -0.0000 fps = 75 mse_loss = 0.7703 
2022-05-01 05:29:41.183671 - gail/main.py:164 - [TRPO] iter = 472000 dist_mean = 0.0646 dist_std = 0.2418 vf_loss = 0.0545 grad_norm = 1.6460 nat_grad_norm = 0.1529 cg_residual = 0.3658 step_size = 0.5146 reward = 0.0000 fps = 43 mse_loss = 0.7724 
2022-05-01 05:29:50.899056 - gail/main.py:164 - [TRPO] iter = 473000 dist_mean = 0.1163 dist_std = 0.2397 vf_loss = 0.4439 grad_norm = 2.6986 nat_grad_norm = 0.1550 cg_residual = 0.2945 step_size = 0.4196 reward = 0.0000 fps = 30 mse_loss = 0.7727 
2022-05-01 05:30:00.802974 - gail/main.py:164 - [TRPO] iter = 474000 dist_mean = 0.0906 dist_std = 0.2405 vf_loss = 0.4813 grad_norm = 1.6040 nat_grad_norm = 0.1340 cg_residual = 0.2431 step_size = 0.4680 reward = 0.0000 fps = 23 mse_loss = 0.6874 
2022-05-01 05:30:11.017411 - gail/main.py:164 - [TRPO] iter = 475000 dist_mean = 0.0706 dist_std = 0.2398 vf_loss = 0.0740 grad_norm = 1.4810 nat_grad_norm = 0.1389 cg_residual = 0.3325 step_size = 0.5669 reward = 0.0000 fps = 18 mse_loss = 0.7437 
2022-05-01 05:30:11.234039 - gail/main.py:191 - [Discriminator] iter = 475000 loss = -0.3250 grad_norm = 2.5449 grad_penalty = 0.0465 regularization = 0.0000 true_logits = 0.1010 fake_logits = -0.2705 true_prob = 0.5163 fake_prob = 0.4559 
2022-05-01 05:30:51.785697 - gail/main.py:132 - [Evaluate] iter = 475000 episode={ returns = 567.2757 lengths = 174 } discounted_episode={ returns = 859.6300 lengths = 413 } 
2022-05-01 05:31:01.737813 - gail/main.py:164 - [TRPO] iter = 476000 dist_mean = 0.0407 dist_std = 0.2384 vf_loss = 0.0823 grad_norm = 2.0280 nat_grad_norm = 0.2273 cg_residual = 0.7882 step_size = 0.3280 reward = 0.0000 fps = 19 mse_loss = 0.6981 
2022-05-01 05:31:11.874786 - gail/main.py:164 - [TRPO] iter = 477000 dist_mean = 0.0872 dist_std = 0.2375 vf_loss = 0.0822 grad_norm = 2.1172 nat_grad_norm = 0.1682 cg_residual = 0.3484 step_size = 0.3710 reward = -0.0000 fps = 16 mse_loss = 0.7426 
2022-05-01 05:31:21.971632 - gail/main.py:164 - [TRPO] iter = 478000 dist_mean = 0.0700 dist_std = 0.2378 vf_loss = 0.1010 grad_norm = 1.3770 nat_grad_norm = 0.1817 cg_residual = 0.4489 step_size = 0.4476 reward = 0.0000 fps = 14 mse_loss = 0.6719 
2022-05-01 05:31:31.898473 - gail/main.py:164 - [TRPO] iter = 479000 dist_mean = 0.0767 dist_std = 0.2368 vf_loss = 0.2045 grad_norm = 1.2729 nat_grad_norm = 0.2442 cg_residual = 0.7570 step_size = 0.3900 reward = 0.0000 fps = 12 mse_loss = 0.6907 
2022-05-01 05:31:41.731359 - gail/main.py:164 - [TRPO] iter = 480000 dist_mean = 0.0709 dist_std = 0.2369 vf_loss = 0.1904 grad_norm = 1.4912 nat_grad_norm = 0.1089 cg_residual = 0.1783 step_size = 0.5679 reward = 0.0000 fps = 11 mse_loss = 0.6418 
2022-05-01 05:31:41.951656 - gail/main.py:191 - [Discriminator] iter = 480000 loss = -0.4158 grad_norm = 2.0580 grad_penalty = 0.0386 regularization = 0.0000 true_logits = 0.0509 fake_logits = -0.4035 true_prob = 0.5093 fake_prob = 0.4329 
2022-05-01 05:31:45.033465 - gail/main.py:132 - [Evaluate] iter = 480000 episode={ returns = 38.1883 lengths = 21 } discounted_episode={ returns = 38.1875 lengths = 22 } 
2022-05-01 05:31:55.122809 - gail/main.py:164 - [TRPO] iter = 481000 dist_mean = 0.1314 dist_std = 0.2364 vf_loss = 0.0829 grad_norm = 1.4179 nat_grad_norm = 0.2673 cg_residual = 0.5213 step_size = 0.3626 reward = 0.0000 fps = 76 mse_loss = 0.7461 
2022-05-01 05:32:05.141378 - gail/main.py:164 - [TRPO] iter = 482000 dist_mean = 0.1079 dist_std = 0.2379 vf_loss = 0.0542 grad_norm = 1.2165 nat_grad_norm = 0.1549 cg_residual = 0.5210 step_size = 0.5534 reward = -0.0000 fps = 43 mse_loss = 0.6820 
2022-05-01 05:32:14.927899 - gail/main.py:164 - [TRPO] iter = 483000 dist_mean = 0.0155 dist_std = 0.2387 vf_loss = 0.3234 grad_norm = 2.0380 nat_grad_norm = 0.1325 cg_residual = 0.2877 step_size = 0.5140 reward = -0.0000 fps = 30 mse_loss = 0.6706 
2022-05-01 05:32:24.847762 - gail/main.py:164 - [TRPO] iter = 484000 dist_mean = 0.0270 dist_std = 0.2379 vf_loss = 0.2389 grad_norm = 2.5508 nat_grad_norm = 0.2366 cg_residual = 0.6396 step_size = 0.3428 reward = 0.0000 fps = 23 mse_loss = 0.7177 
2022-05-01 05:32:34.788243 - gail/main.py:164 - [TRPO] iter = 485000 dist_mean = 0.0398 dist_std = 0.2352 vf_loss = 0.0738 grad_norm = 1.5565 nat_grad_norm = 0.1576 cg_residual = 0.3476 step_size = 0.4648 reward = 0.0000 fps = 18 mse_loss = 0.6795 
2022-05-01 05:32:35.039364 - gail/main.py:191 - [Discriminator] iter = 485000 loss = -0.9090 grad_norm = 2.4163 grad_penalty = 0.0603 regularization = 0.0000 true_logits = -0.0758 fake_logits = -1.0451 true_prob = 0.4852 fake_prob = 0.3371 
2022-05-01 05:32:38.317815 - gail/main.py:132 - [Evaluate] iter = 485000 episode={ returns = 38.9493 lengths = 22 } discounted_episode={ returns = 38.7784 lengths = 22 } 
2022-05-01 05:32:48.198351 - gail/main.py:164 - [TRPO] iter = 486000 dist_mean = 0.0452 dist_std = 0.2361 vf_loss = 0.0853 grad_norm = 1.3256 nat_grad_norm = 0.1436 cg_residual = 0.3249 step_size = 0.4696 reward = -0.0000 fps = 76 mse_loss = 0.6160 
2022-05-01 05:32:58.237842 - gail/main.py:164 - [TRPO] iter = 487000 dist_mean = 0.2099 dist_std = 0.2336 vf_loss = 0.1011 grad_norm = 1.4153 nat_grad_norm = 0.2281 cg_residual = 0.5964 step_size = 0.3688 reward = -0.0000 fps = 43 mse_loss = 0.7309 
2022-05-01 05:33:08.271779 - gail/main.py:164 - [TRPO] iter = 488000 dist_mean = 0.0356 dist_std = 0.2327 vf_loss = 0.0839 grad_norm = 1.6168 nat_grad_norm = 0.1886 cg_residual = 0.5456 step_size = 0.3991 reward = -0.0000 fps = 30 mse_loss = 0.6417 
2022-05-01 05:33:18.207274 - gail/main.py:164 - [TRPO] iter = 489000 dist_mean = 0.1078 dist_std = 0.2323 vf_loss = 0.3353 grad_norm = 3.2858 nat_grad_norm = 0.2052 cg_residual = 0.4302 step_size = 0.3414 reward = 0.0000 fps = 23 mse_loss = 0.6997 
2022-05-01 05:33:28.270228 - gail/main.py:164 - [TRPO] iter = 490000 dist_mean = 0.0847 dist_std = 0.2319 vf_loss = 0.4879 grad_norm = 1.9912 nat_grad_norm = 0.1435 cg_residual = 0.2449 step_size = 0.4969 reward = 0.0000 fps = 18 mse_loss = 0.7247 
2022-05-01 05:33:28.665313 - gail/main.py:191 - [Discriminator] iter = 490000 loss = -0.9596 grad_norm = 1.9990 grad_penalty = 0.0703 regularization = 0.0000 true_logits = -0.0653 fake_logits = -1.0952 true_prob = 0.4879 fake_prob = 0.3278 
2022-05-01 05:33:32.065511 - gail/main.py:132 - [Evaluate] iter = 490000 episode={ returns = 39.8530 lengths = 23 } discounted_episode={ returns = 39.6117 lengths = 23 } 
2022-05-01 05:33:42.039345 - gail/main.py:164 - [TRPO] iter = 491000 dist_mean = 0.1279 dist_std = 0.2331 vf_loss = 0.0388 grad_norm = 1.2766 nat_grad_norm = 0.2128 cg_residual = 0.3681 step_size = 0.4238 reward = 0.0000 fps = 74 mse_loss = 0.7402 
2022-05-01 05:33:51.409998 - gail/main.py:164 - [TRPO] iter = 492000 dist_mean = 0.1075 dist_std = 0.2323 vf_loss = 0.0526 grad_norm = 1.8710 nat_grad_norm = 0.1992 cg_residual = 0.3874 step_size = 0.3620 reward = 0.0000 fps = 44 mse_loss = 0.6461 
2022-05-01 05:34:01.250903 - gail/main.py:164 - [TRPO] iter = 493000 dist_mean = 0.1576 dist_std = 0.2322 vf_loss = 0.1503 grad_norm = 1.7066 nat_grad_norm = 0.1883 cg_residual = 0.4244 step_size = 0.4586 reward = 0.0000 fps = 30 mse_loss = 0.7132 
2022-05-01 05:34:10.882605 - gail/main.py:164 - [TRPO] iter = 494000 dist_mean = 0.0700 dist_std = 0.2326 vf_loss = 0.1393 grad_norm = 1.4425 nat_grad_norm = 0.2069 cg_residual = 0.4907 step_size = 0.4163 reward = -0.0000 fps = 23 mse_loss = 0.6659 
2022-05-01 05:34:20.799942 - gail/main.py:164 - [TRPO] iter = 495000 dist_mean = 0.0305 dist_std = 0.2314 vf_loss = 0.1436 grad_norm = 2.2614 nat_grad_norm = 0.1602 cg_residual = 0.3731 step_size = 0.4548 reward = 0.0000 fps = 19 mse_loss = 0.7255 
2022-05-01 05:34:21.027997 - gail/main.py:191 - [Discriminator] iter = 495000 loss = -0.8490 grad_norm = 2.0622 grad_penalty = 0.0554 regularization = 0.0000 true_logits = 0.0367 fake_logits = -0.8676 true_prob = 0.5106 fake_prob = 0.3597 
2022-05-01 05:34:24.305394 - gail/main.py:132 - [Evaluate] iter = 495000 episode={ returns = 41.5058 lengths = 24 } discounted_episode={ returns = 40.8882 lengths = 24 } 
2022-05-01 05:34:33.986378 - gail/main.py:164 - [TRPO] iter = 496000 dist_mean = 0.0674 dist_std = 0.2321 vf_loss = 0.1103 grad_norm = 1.9063 nat_grad_norm = 0.1619 cg_residual = 0.4561 step_size = 0.4197 reward = 0.0000 fps = 77 mse_loss = 0.7242 
2022-05-01 05:34:43.770159 - gail/main.py:164 - [TRPO] iter = 497000 dist_mean = -0.0090 dist_std = 0.2309 vf_loss = 0.0991 grad_norm = 1.8219 nat_grad_norm = 0.2073 cg_residual = 0.5628 step_size = 0.3631 reward = -0.0000 fps = 44 mse_loss = 0.7390 
2022-05-01 05:34:53.552352 - gail/main.py:164 - [TRPO] iter = 498000 dist_mean = 0.0851 dist_std = 0.2302 vf_loss = 0.1042 grad_norm = 2.0260 nat_grad_norm = 0.1861 cg_residual = 0.5499 step_size = 0.4141 reward = -0.0000 fps = 30 mse_loss = 0.6453 
2022-05-01 05:35:03.677107 - gail/main.py:164 - [TRPO] iter = 499000 dist_mean = 0.0717 dist_std = 0.2310 vf_loss = 0.1598 grad_norm = 1.2812 nat_grad_norm = 0.1504 cg_residual = 0.3110 step_size = 0.5375 reward = 0.0000 fps = 23 mse_loss = 0.6494 
2022-05-01 05:35:13.640597 - gail/main.py:164 - [TRPO] iter = 500000 dist_mean = 0.0147 dist_std = 0.2309 vf_loss = 0.9480 grad_norm = 2.5686 nat_grad_norm = 0.1272 cg_residual = 0.2448 step_size = 0.4842 reward = -0.0000 fps = 19 mse_loss = 0.6675 
2022-05-01 05:35:13.850482 - gail/main.py:191 - [Discriminator] iter = 500000 loss = -0.6179 grad_norm = 2.0781 grad_penalty = 0.0458 regularization = 0.0000 true_logits = 0.0239 fake_logits = -0.6398 true_prob = 0.5096 fake_prob = 0.3865 
2022-05-01 05:35:23.166962 - gail/main.py:132 - [Evaluate] iter = 500000 episode={ returns = 42.2689 lengths = 24 } discounted_episode={ returns = 41.6120 lengths = 24 } 
2022-05-01 05:35:33.039932 - gail/main.py:164 - [TRPO] iter = 501000 dist_mean = 0.1670 dist_std = 0.2306 vf_loss = 1.2185 grad_norm = 2.1395 nat_grad_norm = 0.1183 cg_residual = 0.2507 step_size = 0.5352 reward = 0.0000 fps = 74 mse_loss = 0.7719 
2022-05-01 05:35:43.188725 - gail/main.py:164 - [TRPO] iter = 502000 dist_mean = 0.0798 dist_std = 0.2305 vf_loss = 0.1347 grad_norm = 2.5060 nat_grad_norm = 0.1864 cg_residual = 0.3178 step_size = 0.4277 reward = 0.0000 fps = 42 mse_loss = 0.7302 
2022-05-01 05:35:52.782685 - gail/main.py:164 - [TRPO] iter = 503000 dist_mean = 0.0014 dist_std = 0.2302 vf_loss = 0.1195 grad_norm = 1.2330 nat_grad_norm = 0.1378 cg_residual = 0.3247 step_size = 0.5174 reward = 0.0000 fps = 30 mse_loss = 0.7604 
2022-05-01 05:36:02.442239 - gail/main.py:164 - [TRPO] iter = 504000 dist_mean = 0.1513 dist_std = 0.2297 vf_loss = 1.3603 grad_norm = 1.8563 nat_grad_norm = 0.1466 cg_residual = 0.2695 step_size = 0.5029 reward = 0.0000 fps = 23 mse_loss = 0.7237 
2022-05-01 05:36:12.293143 - gail/main.py:164 - [TRPO] iter = 505000 dist_mean = 0.0310 dist_std = 0.2294 vf_loss = 0.1572 grad_norm = 2.1362 nat_grad_norm = 0.1828 cg_residual = 0.4292 step_size = 0.3431 reward = 0.0000 fps = 19 mse_loss = 0.6568 
2022-05-01 05:36:12.526337 - gail/main.py:191 - [Discriminator] iter = 505000 loss = -0.8887 grad_norm = 2.4661 grad_penalty = 0.0518 regularization = 0.0000 true_logits = 0.0267 fake_logits = -0.9138 true_prob = 0.5096 fake_prob = 0.3431 
2022-05-01 05:36:16.089766 - gail/main.py:132 - [Evaluate] iter = 505000 episode={ returns = 41.2535 lengths = 23 } discounted_episode={ returns = 40.9511 lengths = 24 } 
2022-05-01 05:36:26.112133 - gail/main.py:164 - [TRPO] iter = 506000 dist_mean = 0.1297 dist_std = 0.2295 vf_loss = 0.1600 grad_norm = 2.8521 nat_grad_norm = 0.1652 cg_residual = 0.3481 step_size = 0.4055 reward = -0.0000 fps = 73 mse_loss = 0.6983 
2022-05-01 05:36:36.418752 - gail/main.py:164 - [TRPO] iter = 507000 dist_mean = 0.2078 dist_std = 0.2307 vf_loss = 0.6578 grad_norm = 2.6556 nat_grad_norm = 0.1676 cg_residual = 0.1967 step_size = 0.3975 reward = 0.0000 fps = 41 mse_loss = 0.7322 
2022-05-01 05:36:46.545495 - gail/main.py:164 - [TRPO] iter = 508000 dist_mean = 0.0230 dist_std = 0.2307 vf_loss = 2.2900 grad_norm = 2.5088 nat_grad_norm = 0.1764 cg_residual = 0.3077 step_size = 0.4044 reward = 0.0000 fps = 29 mse_loss = 0.8176 
2022-05-01 05:36:57.149785 - gail/main.py:164 - [TRPO] iter = 509000 dist_mean = 0.0493 dist_std = 0.2304 vf_loss = 0.2914 grad_norm = 1.4345 nat_grad_norm = 0.1599 cg_residual = 0.2799 step_size = 0.5104 reward = 0.0000 fps = 22 mse_loss = 0.7539 
2022-05-01 05:37:07.397666 - gail/main.py:164 - [TRPO] iter = 510000 dist_mean = 0.0218 dist_std = 0.2280 vf_loss = 0.1646 grad_norm = 1.1135 nat_grad_norm = 0.1470 cg_residual = 0.3915 step_size = 0.5198 reward = 0.0000 fps = 18 mse_loss = 0.8132 
2022-05-01 05:37:07.636063 - gail/main.py:191 - [Discriminator] iter = 510000 loss = -0.8078 grad_norm = 2.3714 grad_penalty = 0.0502 regularization = 0.0000 true_logits = 0.0312 fake_logits = -0.8267 true_prob = 0.5111 fake_prob = 0.3648 
2022-05-01 05:37:11.128260 - gail/main.py:132 - [Evaluate] iter = 510000 episode={ returns = 43.2917 lengths = 25 } discounted_episode={ returns = 43.0736 lengths = 25 } 
2022-05-01 05:37:20.688449 - gail/main.py:164 - [TRPO] iter = 511000 dist_mean = 0.0314 dist_std = 0.2277 vf_loss = 0.1661 grad_norm = 1.5494 nat_grad_norm = 0.1703 cg_residual = 0.4131 step_size = 0.4854 reward = -0.0000 fps = 76 mse_loss = 0.7623 
2022-05-01 05:37:30.554642 - gail/main.py:164 - [TRPO] iter = 512000 dist_mean = 0.0273 dist_std = 0.2279 vf_loss = 0.1321 grad_norm = 1.4489 nat_grad_norm = 0.1493 cg_residual = 0.3657 step_size = 0.5430 reward = 0.0000 fps = 43 mse_loss = 0.8056 
2022-05-01 05:37:40.698117 - gail/main.py:164 - [TRPO] iter = 513000 dist_mean = 0.0172 dist_std = 0.2287 vf_loss = 0.2120 grad_norm = 2.3704 nat_grad_norm = 0.1373 cg_residual = 0.1951 step_size = 0.5204 reward = 0.0000 fps = 30 mse_loss = 0.7791 
2022-05-01 05:37:50.760055 - gail/main.py:164 - [TRPO] iter = 514000 dist_mean = 0.0131 dist_std = 0.2297 vf_loss = 0.1651 grad_norm = 1.5239 nat_grad_norm = 0.1550 cg_residual = 0.6482 step_size = 0.4722 reward = 0.0000 fps = 23 mse_loss = 0.8680 
2022-05-01 05:38:00.671907 - gail/main.py:164 - [TRPO] iter = 515000 dist_mean = 0.0162 dist_std = 0.2306 vf_loss = 0.3080 grad_norm = 1.8388 nat_grad_norm = 0.1030 cg_residual = 0.3117 step_size = 0.6039 reward = -0.0000 fps = 18 mse_loss = 0.7683 
2022-05-01 05:38:00.911609 - gail/main.py:191 - [Discriminator] iter = 515000 loss = -0.5720 grad_norm = 1.7126 grad_penalty = 0.0374 regularization = 0.0000 true_logits = 0.1030 fake_logits = -0.5064 true_prob = 0.5254 fake_prob = 0.4003 
2022-05-01 05:40:04.613589 - gail/main.py:132 - [Evaluate] iter = 515000 episode={ returns = 3058.5566 lengths = 926 } discounted_episode={ returns = 1916.7969 lengths = 944 } 
2022-05-01 05:40:14.512409 - gail/main.py:164 - [TRPO] iter = 516000 dist_mean = 0.0242 dist_std = 0.2305 vf_loss = 0.1152 grad_norm = 1.6590 nat_grad_norm = 0.1732 cg_residual = 0.3203 step_size = 0.4462 reward = 0.0000 fps = 7 mse_loss = 0.7643 
2022-05-01 05:40:24.065441 - gail/main.py:164 - [TRPO] iter = 517000 dist_mean = 0.0256 dist_std = 0.2311 vf_loss = 0.3345 grad_norm = 2.3033 nat_grad_norm = 0.1500 cg_residual = 0.4143 step_size = 0.4388 reward = -0.0000 fps = 6 mse_loss = 0.7345 
2022-05-01 05:40:34.013031 - gail/main.py:164 - [TRPO] iter = 518000 dist_mean = 0.0184 dist_std = 0.2313 vf_loss = 0.2237 grad_norm = 2.0500 nat_grad_norm = 0.1642 cg_residual = 0.5196 step_size = 0.4372 reward = -0.0000 fps = 6 mse_loss = 0.7329 
2022-05-01 05:40:43.779532 - gail/main.py:164 - [TRPO] iter = 519000 dist_mean = -0.0019 dist_std = 0.2301 vf_loss = 0.2184 grad_norm = 2.2475 nat_grad_norm = 0.1646 cg_residual = 0.6100 step_size = 0.3969 reward = -0.0000 fps = 6 mse_loss = 0.7244 
2022-05-01 05:40:53.447389 - gail/main.py:164 - [TRPO] iter = 520000 dist_mean = 0.0320 dist_std = 0.2314 vf_loss = 0.1874 grad_norm = 1.9695 nat_grad_norm = 0.1695 cg_residual = 0.8206 step_size = 0.4270 reward = 0.0000 fps = 5 mse_loss = 0.8061 
2022-05-01 05:40:53.659341 - gail/main.py:191 - [Discriminator] iter = 520000 loss = -0.7838 grad_norm = 2.1893 grad_penalty = 0.0557 regularization = 0.0000 true_logits = 0.0537 fake_logits = -0.7858 true_prob = 0.5151 fake_prob = 0.3640 
2022-05-01 05:40:57.146760 - gail/main.py:132 - [Evaluate] iter = 520000 episode={ returns = 42.1356 lengths = 24 } discounted_episode={ returns = 40.8805 lengths = 24 } 
2022-05-01 05:41:06.872045 - gail/main.py:164 - [TRPO] iter = 521000 dist_mean = 0.0467 dist_std = 0.2312 vf_loss = 0.1699 grad_norm = 1.7894 nat_grad_norm = 0.1918 cg_residual = 0.6285 step_size = 0.4121 reward = 0.0000 fps = 75 mse_loss = 0.6778 
2022-05-01 05:41:16.825682 - gail/main.py:164 - [TRPO] iter = 522000 dist_mean = -0.0074 dist_std = 0.2312 vf_loss = 0.1278 grad_norm = 1.2372 nat_grad_norm = 0.1612 cg_residual = 0.4794 step_size = 0.5103 reward = -0.0000 fps = 43 mse_loss = 0.7633 
2022-05-01 05:41:27.068184 - gail/main.py:164 - [TRPO] iter = 523000 dist_mean = 0.0868 dist_std = 0.2291 vf_loss = 0.1207 grad_norm = 1.9301 nat_grad_norm = 0.2154 cg_residual = 0.3588 step_size = 0.3689 reward = -0.0000 fps = 29 mse_loss = 0.7926 
2022-05-01 05:41:37.623556 - gail/main.py:164 - [TRPO] iter = 524000 dist_mean = 0.1406 dist_std = 0.2295 vf_loss = 0.0698 grad_norm = 2.3707 nat_grad_norm = 0.1990 cg_residual = 0.8157 step_size = 0.3846 reward = 0.0000 fps = 22 mse_loss = 0.6752 
2022-05-01 05:41:47.908722 - gail/main.py:164 - [TRPO] iter = 525000 dist_mean = 0.0584 dist_std = 0.2289 vf_loss = 0.1110 grad_norm = 2.1240 nat_grad_norm = 0.2010 cg_residual = 0.5998 step_size = 0.3114 reward = -0.0000 fps = 18 mse_loss = 0.7145 
2022-05-01 05:41:48.159256 - gail/main.py:191 - [Discriminator] iter = 525000 loss = -1.0932 grad_norm = 2.4071 grad_penalty = 0.0675 regularization = 0.0000 true_logits = 0.0061 fake_logits = -1.1545 true_prob = 0.5069 fake_prob = 0.3046 
2022-05-01 05:41:51.512412 - gail/main.py:132 - [Evaluate] iter = 525000 episode={ returns = 39.7799 lengths = 23 } discounted_episode={ returns = 39.6578 lengths = 23 } 
2022-05-01 05:42:01.284672 - gail/main.py:164 - [TRPO] iter = 526000 dist_mean = 0.0837 dist_std = 0.2276 vf_loss = 0.0933 grad_norm = 2.7114 nat_grad_norm = 0.1850 cg_residual = 0.6846 step_size = 0.3763 reward = 0.0000 fps = 76 mse_loss = 0.6562 
2022-05-01 05:42:11.617595 - gail/main.py:164 - [TRPO] iter = 527000 dist_mean = 0.0175 dist_std = 0.2278 vf_loss = 0.8865 grad_norm = 2.2865 nat_grad_norm = 0.1137 cg_residual = 0.3835 step_size = 0.5018 reward = -0.0000 fps = 42 mse_loss = 0.6836 
2022-05-01 05:42:21.528115 - gail/main.py:164 - [TRPO] iter = 528000 dist_mean = -0.0133 dist_std = 0.2282 vf_loss = 0.0915 grad_norm = 1.2647 nat_grad_norm = 0.1544 cg_residual = 0.2781 step_size = 0.4820 reward = -0.0000 fps = 29 mse_loss = 0.7074 
2022-05-01 05:42:31.687835 - gail/main.py:164 - [TRPO] iter = 529000 dist_mean = 0.0209 dist_std = 0.2275 vf_loss = 0.4767 grad_norm = 1.7170 nat_grad_norm = 0.1452 cg_residual = 0.2888 step_size = 0.4971 reward = -0.0000 fps = 22 mse_loss = 0.7162 
2022-05-01 05:42:42.075074 - gail/main.py:164 - [TRPO] iter = 530000 dist_mean = 0.0317 dist_std = 0.2282 vf_loss = 0.0734 grad_norm = 2.1142 nat_grad_norm = 0.1747 cg_residual = 0.2362 step_size = 0.4424 reward = 0.0000 fps = 18 mse_loss = 0.7305 
2022-05-01 05:42:42.358950 - gail/main.py:191 - [Discriminator] iter = 530000 loss = -1.1130 grad_norm = 2.3263 grad_penalty = 0.0716 regularization = 0.0000 true_logits = 0.0276 fake_logits = -1.1569 true_prob = 0.5118 fake_prob = 0.3249 
2022-05-01 05:42:45.817347 - gail/main.py:132 - [Evaluate] iter = 530000 episode={ returns = 39.5794 lengths = 23 } discounted_episode={ returns = 39.2921 lengths = 23 } 
2022-05-01 05:42:56.286463 - gail/main.py:164 - [TRPO] iter = 531000 dist_mean = 0.0734 dist_std = 0.2273 vf_loss = 0.1296 grad_norm = 1.8704 nat_grad_norm = 0.1361 cg_residual = 0.3900 step_size = 0.4706 reward = -0.0000 fps = 71 mse_loss = 0.7122 
2022-05-01 05:43:06.443375 - gail/main.py:164 - [TRPO] iter = 532000 dist_mean = 0.0070 dist_std = 0.2271 vf_loss = 0.7782 grad_norm = 1.0703 nat_grad_norm = 0.1030 cg_residual = 0.1899 step_size = 0.6860 reward = 0.0000 fps = 41 mse_loss = 0.6687 
2022-05-01 05:43:16.242986 - gail/main.py:164 - [TRPO] iter = 533000 dist_mean = 0.0621 dist_std = 0.2270 vf_loss = 0.0754 grad_norm = 3.2229 nat_grad_norm = 0.2157 cg_residual = 0.6610 step_size = 0.3022 reward = -0.0000 fps = 29 mse_loss = 0.7071 
2022-05-01 05:43:26.165967 - gail/main.py:164 - [TRPO] iter = 534000 dist_mean = 0.1314 dist_std = 0.2273 vf_loss = 0.1670 grad_norm = 2.7367 nat_grad_norm = 0.1541 cg_residual = 0.3072 step_size = 0.4498 reward = -0.0000 fps = 22 mse_loss = 0.6328 
2022-05-01 05:43:36.339658 - gail/main.py:164 - [TRPO] iter = 535000 dist_mean = 0.0557 dist_std = 0.2271 vf_loss = 0.1518 grad_norm = 2.2962 nat_grad_norm = 0.1529 cg_residual = 0.3677 step_size = 0.4084 reward = 0.0000 fps = 18 mse_loss = 0.5890 
2022-05-01 05:43:36.561695 - gail/main.py:191 - [Discriminator] iter = 535000 loss = -1.0392 grad_norm = 2.3221 grad_penalty = 0.0715 regularization = 0.0000 true_logits = 0.0711 fake_logits = -1.0396 true_prob = 0.5209 fake_prob = 0.3417 
2022-05-01 05:43:40.254793 - gail/main.py:132 - [Evaluate] iter = 535000 episode={ returns = 43.5928 lengths = 25 } discounted_episode={ returns = 43.2600 lengths = 25 } 
2022-05-01 05:43:49.964205 - gail/main.py:164 - [TRPO] iter = 536000 dist_mean = 0.0102 dist_std = 0.2280 vf_loss = 0.0818 grad_norm = 2.0776 nat_grad_norm = 0.2458 cg_residual = 0.9615 step_size = 0.2917 reward = 0.0000 fps = 74 mse_loss = 0.6382 
2022-05-01 05:43:59.837345 - gail/main.py:164 - [TRPO] iter = 537000 dist_mean = 0.0279 dist_std = 0.2275 vf_loss = 0.1013 grad_norm = 2.8711 nat_grad_norm = 0.2368 cg_residual = 0.4073 step_size = 0.3390 reward = 0.0000 fps = 42 mse_loss = 0.5827 
2022-05-01 05:44:09.848648 - gail/main.py:164 - [TRPO] iter = 538000 dist_mean = 0.0260 dist_std = 0.2269 vf_loss = 0.1457 grad_norm = 1.3984 nat_grad_norm = 0.1725 cg_residual = 0.4017 step_size = 0.4486 reward = 0.0000 fps = 30 mse_loss = 0.7414 
2022-05-01 05:44:20.187324 - gail/main.py:164 - [TRPO] iter = 539000 dist_mean = -0.0244 dist_std = 0.2258 vf_loss = 0.1470 grad_norm = 1.7547 nat_grad_norm = 0.1646 cg_residual = 0.5170 step_size = 0.4508 reward = 0.0000 fps = 22 mse_loss = 0.6581 
2022-05-01 05:44:30.040564 - gail/main.py:164 - [TRPO] iter = 540000 dist_mean = 0.0040 dist_std = 0.2242 vf_loss = 0.1649 grad_norm = 1.8834 nat_grad_norm = 0.1404 cg_residual = 0.3042 step_size = 0.4410 reward = 0.0000 fps = 18 mse_loss = 0.6655 
2022-05-01 05:44:30.242699 - gail/main.py:191 - [Discriminator] iter = 540000 loss = -0.7069 grad_norm = 2.9045 grad_penalty = 0.0625 regularization = 0.0000 true_logits = 0.0137 fake_logits = -0.7557 true_prob = 0.5073 fake_prob = 0.3676 
2022-05-01 05:45:33.217613 - gail/main.py:132 - [Evaluate] iter = 540000 episode={ returns = 1637.0302 lengths = 464 } discounted_episode={ returns = 1285.8681 lengths = 469 } 
2022-05-01 05:45:43.143073 - gail/main.py:164 - [TRPO] iter = 541000 dist_mean = -0.0143 dist_std = 0.2237 vf_loss = 0.6044 grad_norm = 2.5970 nat_grad_norm = 0.1110 cg_residual = 0.1998 step_size = 0.5424 reward = 0.0000 fps = 13 mse_loss = 0.6603 
2022-05-01 05:45:53.419372 - gail/main.py:164 - [TRPO] iter = 542000 dist_mean = -0.0213 dist_std = 0.2228 vf_loss = 0.0806 grad_norm = 1.5424 nat_grad_norm = 0.1358 cg_residual = 0.2208 step_size = 0.5465 reward = 0.0000 fps = 12 mse_loss = 0.6577 
2022-05-01 05:46:03.088741 - gail/main.py:164 - [TRPO] iter = 543000 dist_mean = 0.0188 dist_std = 0.2206 vf_loss = 0.3793 grad_norm = 2.7123 nat_grad_norm = 0.1466 cg_residual = 0.3370 step_size = 0.4622 reward = -0.0000 fps = 10 mse_loss = 0.6000 
2022-05-01 05:46:12.859981 - gail/main.py:164 - [TRPO] iter = 544000 dist_mean = 0.0248 dist_std = 0.2204 vf_loss = 0.3373 grad_norm = 1.9471 nat_grad_norm = 0.1225 cg_residual = 0.2658 step_size = 0.4671 reward = 0.0000 fps = 9 mse_loss = 0.6805 
2022-05-01 05:46:22.788331 - gail/main.py:164 - [TRPO] iter = 545000 dist_mean = 0.0344 dist_std = 0.2202 vf_loss = 0.1773 grad_norm = 2.4903 nat_grad_norm = 0.1692 cg_residual = 0.7794 step_size = 0.3710 reward = -0.0000 fps = 8 mse_loss = 0.6623 
2022-05-01 05:46:23.023507 - gail/main.py:191 - [Discriminator] iter = 545000 loss = -0.5106 grad_norm = 3.1105 grad_penalty = 0.0516 regularization = 0.0000 true_logits = -0.0197 fake_logits = -0.5819 true_prob = 0.5010 fake_prob = 0.3965 
2022-05-01 05:46:26.429671 - gail/main.py:132 - [Evaluate] iter = 545000 episode={ returns = 41.3569 lengths = 24 } discounted_episode={ returns = 41.1953 lengths = 24 } 
2022-05-01 05:46:36.612196 - gail/main.py:164 - [TRPO] iter = 546000 dist_mean = 0.0120 dist_std = 0.2209 vf_loss = 0.2797 grad_norm = 1.8675 nat_grad_norm = 0.1552 cg_residual = 0.3594 step_size = 0.4325 reward = -0.0000 fps = 73 mse_loss = 0.7116 
2022-05-01 05:46:46.346249 - gail/main.py:164 - [TRPO] iter = 547000 dist_mean = -0.0251 dist_std = 0.2211 vf_loss = 0.2552 grad_norm = 1.8346 nat_grad_norm = 0.1324 cg_residual = 0.2060 step_size = 0.5358 reward = -0.0000 fps = 42 mse_loss = 0.7274 
2022-05-01 05:46:56.037154 - gail/main.py:164 - [TRPO] iter = 548000 dist_mean = 0.0170 dist_std = 0.2218 vf_loss = 0.3952 grad_norm = 3.1328 nat_grad_norm = 0.1726 cg_residual = 0.5947 step_size = 0.3264 reward = 0.0000 fps = 30 mse_loss = 0.6739 
2022-05-01 05:47:06.082369 - gail/main.py:164 - [TRPO] iter = 549000 dist_mean = 0.0362 dist_std = 0.2222 vf_loss = 0.2775 grad_norm = 2.4341 nat_grad_norm = 0.2113 cg_residual = 1.1654 step_size = 0.3285 reward = 0.0000 fps = 23 mse_loss = 0.7117 
2022-05-01 05:47:16.196060 - gail/main.py:164 - [TRPO] iter = 550000 dist_mean = -0.0119 dist_std = 0.2224 vf_loss = 0.0885 grad_norm = 1.5029 nat_grad_norm = 0.1945 cg_residual = 0.6038 step_size = 0.3870 reward = 0.0000 fps = 18 mse_loss = 0.6827 
2022-05-01 05:47:16.453948 - gail/main.py:191 - [Discriminator] iter = 550000 loss = -0.4205 grad_norm = 2.9167 grad_penalty = 0.0471 regularization = 0.0000 true_logits = -0.0257 fake_logits = -0.4934 true_prob = 0.4985 fake_prob = 0.4057 
2022-05-01 05:47:19.686788 - gail/main.py:132 - [Evaluate] iter = 550000 episode={ returns = 40.1471 lengths = 23 } discounted_episode={ returns = 39.3205 lengths = 23 } 
2022-05-01 05:47:29.910723 - gail/main.py:164 - [TRPO] iter = 551000 dist_mean = 0.0642 dist_std = 0.2213 vf_loss = 0.8867 grad_norm = 2.5467 nat_grad_norm = 0.1525 cg_residual = 0.4000 step_size = 0.4636 reward = -0.0000 fps = 74 mse_loss = 0.7346 
2022-05-01 05:47:39.616115 - gail/main.py:164 - [TRPO] iter = 552000 dist_mean = 0.0527 dist_std = 0.2219 vf_loss = 0.2248 grad_norm = 2.4825 nat_grad_norm = 0.1663 cg_residual = 0.3519 step_size = 0.4049 reward = -0.0000 fps = 43 mse_loss = 0.6090 
2022-05-01 05:47:49.698160 - gail/main.py:164 - [TRPO] iter = 553000 dist_mean = 0.1053 dist_std = 0.2213 vf_loss = 0.8449 grad_norm = 1.8221 nat_grad_norm = 0.1329 cg_residual = 0.3968 step_size = 0.5047 reward = -0.0000 fps = 30 mse_loss = 0.6583 
2022-05-01 05:47:59.520598 - gail/main.py:164 - [TRPO] iter = 554000 dist_mean = -0.0202 dist_std = 0.2218 vf_loss = 0.4382 grad_norm = 2.0639 nat_grad_norm = 0.1408 cg_residual = 0.2224 step_size = 0.5051 reward = 0.0000 fps = 23 mse_loss = 0.5895 
2022-05-01 05:48:10.171327 - gail/main.py:164 - [TRPO] iter = 555000 dist_mean = 0.3636 dist_std = 0.2228 vf_loss = 0.2573 grad_norm = 2.6052 nat_grad_norm = 0.0763 cg_residual = 0.0430 step_size = 0.6661 reward = -0.0000 fps = 18 mse_loss = 0.5999 
2022-05-01 05:48:10.386740 - gail/main.py:191 - [Discriminator] iter = 555000 loss = -3.2138 grad_norm = 5.3117 grad_penalty = 0.2230 regularization = 0.0000 true_logits = 0.0175 fake_logits = -3.4193 true_prob = 0.5113 fake_prob = 0.0375 
2022-05-01 05:48:13.670602 - gail/main.py:132 - [Evaluate] iter = 555000 episode={ returns = 41.0002 lengths = 23 } discounted_episode={ returns = 39.7561 lengths = 23 } 
2022-05-01 05:48:23.760413 - gail/main.py:164 - [TRPO] iter = 556000 dist_mean = 0.1204 dist_std = 0.2203 vf_loss = 0.1186 grad_norm = 1.3841 nat_grad_norm = 0.1335 cg_residual = 0.4199 step_size = 0.5326 reward = 0.0000 fps = 74 mse_loss = 0.6585 
2022-05-01 05:48:34.355958 - gail/main.py:164 - [TRPO] iter = 557000 dist_mean = 0.3368 dist_std = 0.2211 vf_loss = 0.3492 grad_norm = 2.9807 nat_grad_norm = 0.0923 cg_residual = 0.1106 step_size = 0.5446 reward = -0.0000 fps = 41 mse_loss = 0.5938 
2022-05-01 05:48:44.187288 - gail/main.py:164 - [TRPO] iter = 558000 dist_mean = 0.1877 dist_std = 0.2210 vf_loss = 0.2548 grad_norm = 1.8400 nat_grad_norm = 0.1706 cg_residual = 0.4886 step_size = 0.4307 reward = 0.0000 fps = 29 mse_loss = 0.7060 
2022-05-01 05:48:54.220500 - gail/main.py:164 - [TRPO] iter = 559000 dist_mean = 0.2161 dist_std = 0.2219 vf_loss = 0.1044 grad_norm = 2.0402 nat_grad_norm = 0.1723 cg_residual = 0.3244 step_size = 0.4548 reward = -0.0000 fps = 22 mse_loss = 0.6821 
2022-05-01 05:49:04.230058 - gail/main.py:164 - [TRPO] iter = 560000 dist_mean = 0.1529 dist_std = 0.2218 vf_loss = 0.2183 grad_norm = 1.8297 nat_grad_norm = 0.1270 cg_residual = 0.2370 step_size = 0.5677 reward = 0.0000 fps = 18 mse_loss = 0.6857 
2022-05-01 05:49:04.443078 - gail/main.py:191 - [Discriminator] iter = 560000 loss = -1.3206 grad_norm = 2.9883 grad_penalty = 0.1052 regularization = 0.0000 true_logits = 0.1966 fake_logits = -1.2292 true_prob = 0.5426 fake_prob = 0.3264 
2022-05-01 05:49:08.342320 - gail/main.py:132 - [Evaluate] iter = 560000 episode={ returns = 47.4677 lengths = 27 } discounted_episode={ returns = 45.7634 lengths = 27 } 
2022-05-01 05:49:18.524392 - gail/main.py:164 - [TRPO] iter = 561000 dist_mean = 0.1589 dist_std = 0.2227 vf_loss = 1.5568 grad_norm = 3.2915 nat_grad_norm = 0.2307 cg_residual = 0.5226 step_size = 0.3000 reward = -0.0000 fps = 71 mse_loss = 0.6546 
2022-05-01 05:49:28.170936 - gail/main.py:164 - [TRPO] iter = 562000 dist_mean = 0.0745 dist_std = 0.2218 vf_loss = 1.5923 grad_norm = 2.0349 nat_grad_norm = 0.1133 cg_residual = 0.1718 step_size = 0.5704 reward = 0.0000 fps = 42 mse_loss = 0.7321 
2022-05-01 05:49:38.689811 - gail/main.py:164 - [TRPO] iter = 563000 dist_mean = 0.0620 dist_std = 0.2233 vf_loss = 1.2436 grad_norm = 1.2679 nat_grad_norm = 0.1209 cg_residual = 0.1936 step_size = 0.5886 reward = 0.0000 fps = 29 mse_loss = 0.6511 
2022-05-01 05:49:48.819341 - gail/main.py:164 - [TRPO] iter = 564000 dist_mean = 0.0752 dist_std = 0.2249 vf_loss = 0.7214 grad_norm = 2.8259 nat_grad_norm = 0.2245 cg_residual = 1.0951 step_size = 0.3164 reward = -0.0000 fps = 22 mse_loss = 0.6207 
2022-05-01 05:49:58.696176 - gail/main.py:164 - [TRPO] iter = 565000 dist_mean = 0.0687 dist_std = 0.2247 vf_loss = 0.0938 grad_norm = 1.9639 nat_grad_norm = 0.1348 cg_residual = 0.3058 step_size = 0.5115 reward = -0.0000 fps = 18 mse_loss = 0.6772 
2022-05-01 05:49:58.907428 - gail/main.py:191 - [Discriminator] iter = 565000 loss = -0.5049 grad_norm = 2.9156 grad_penalty = 0.0542 regularization = 0.0000 true_logits = 0.2885 fake_logits = -0.2705 true_prob = 0.5562 fake_prob = 0.4571 
2022-05-01 05:52:12.165375 - gail/main.py:132 - [Evaluate] iter = 565000 episode={ returns = 3491.3790 lengths = 1000 } discounted_episode={ returns = 2152.3537 lengths = 1000 } 
2022-05-01 05:52:22.167307 - gail/main.py:164 - [TRPO] iter = 566000 dist_mean = 0.0522 dist_std = 0.2247 vf_loss = 0.1782 grad_norm = 1.2982 nat_grad_norm = 0.0993 cg_residual = 0.2094 step_size = 0.6605 reward = -0.0000 fps = 6 mse_loss = 0.6586 
2022-05-01 05:52:31.966384 - gail/main.py:164 - [TRPO] iter = 567000 dist_mean = 0.0308 dist_std = 0.2248 vf_loss = 0.0755 grad_norm = 2.1599 nat_grad_norm = 0.1684 cg_residual = 0.8433 step_size = 0.3714 reward = -0.0000 fps = 6 mse_loss = 0.6951 
2022-05-01 05:52:41.983789 - gail/main.py:164 - [TRPO] iter = 568000 dist_mean = 0.0478 dist_std = 0.2252 vf_loss = 0.3357 grad_norm = 1.8544 nat_grad_norm = 0.1124 cg_residual = 0.2263 step_size = 0.5976 reward = 0.0000 fps = 6 mse_loss = 0.6444 
2022-05-01 05:52:52.158289 - gail/main.py:164 - [TRPO] iter = 569000 dist_mean = 0.0275 dist_std = 0.2257 vf_loss = 0.0969 grad_norm = 1.7813 nat_grad_norm = 0.1818 cg_residual = 0.8109 step_size = 0.3488 reward = 0.0000 fps = 5 mse_loss = 0.5920 
2022-05-01 05:53:02.105597 - gail/main.py:164 - [TRPO] iter = 570000 dist_mean = 0.0957 dist_std = 0.2261 vf_loss = 0.1446 grad_norm = 1.8371 nat_grad_norm = 0.1920 cg_residual = 0.3975 step_size = 0.3605 reward = -0.0000 fps = 5 mse_loss = 0.6919 
2022-05-01 05:53:02.341778 - gail/main.py:191 - [Discriminator] iter = 570000 loss = -0.5305 grad_norm = 2.5963 grad_penalty = 0.0515 regularization = 0.0000 true_logits = 0.0928 fake_logits = -0.4893 true_prob = 0.5205 fake_prob = 0.4150 
2022-05-01 05:55:16.160195 - gail/main.py:132 - [Evaluate] iter = 570000 episode={ returns = 3517.5139 lengths = 1000 } discounted_episode={ returns = 2157.0894 lengths = 1000 } 
2022-05-01 05:55:26.244096 - gail/main.py:164 - [TRPO] iter = 571000 dist_mean = 0.0855 dist_std = 0.2243 vf_loss = 0.1685 grad_norm = 1.8317 nat_grad_norm = 0.1303 cg_residual = 0.2553 step_size = 0.4896 reward = -0.0000 fps = 6 mse_loss = 0.6378 
2022-05-01 05:55:36.365855 - gail/main.py:164 - [TRPO] iter = 572000 dist_mean = 0.0606 dist_std = 0.2246 vf_loss = 0.2558 grad_norm = 1.3986 nat_grad_norm = 0.1209 cg_residual = 0.2916 step_size = 0.6151 reward = -0.0000 fps = 6 mse_loss = 0.6403 
2022-05-01 05:55:46.195320 - gail/main.py:164 - [TRPO] iter = 573000 dist_mean = 0.0630 dist_std = 0.2247 vf_loss = 0.2516 grad_norm = 1.8023 nat_grad_norm = 0.1177 cg_residual = 0.1933 step_size = 0.4778 reward = 0.0000 fps = 6 mse_loss = 0.6157 
2022-05-01 05:55:56.109027 - gail/main.py:164 - [TRPO] iter = 574000 dist_mean = 0.1012 dist_std = 0.2249 vf_loss = 0.2321 grad_norm = 2.3400 nat_grad_norm = 0.1249 cg_residual = 0.3529 step_size = 0.4898 reward = -0.0000 fps = 5 mse_loss = 0.6628 
2022-05-01 05:56:06.204537 - gail/main.py:164 - [TRPO] iter = 575000 dist_mean = 0.0471 dist_std = 0.2266 vf_loss = 0.0542 grad_norm = 1.4736 nat_grad_norm = 0.1545 cg_residual = 0.4858 step_size = 0.4403 reward = -0.0000 fps = 5 mse_loss = 0.6430 
2022-05-01 05:56:06.433347 - gail/main.py:191 - [Discriminator] iter = 575000 loss = -0.3635 grad_norm = 3.2117 grad_penalty = 0.0537 regularization = 0.0000 true_logits = 0.0870 fake_logits = -0.3301 true_prob = 0.5175 fake_prob = 0.4419 
2022-05-01 05:58:22.316245 - gail/main.py:132 - [Evaluate] iter = 575000 episode={ returns = 3571.8339 lengths = 1000 } discounted_episode={ returns = 2195.4295 lengths = 1000 } 
2022-05-01 05:58:32.138711 - gail/main.py:164 - [TRPO] iter = 576000 dist_mean = 0.0593 dist_std = 0.2262 vf_loss = 0.0520 grad_norm = 2.0530 nat_grad_norm = 0.1391 cg_residual = 0.6912 step_size = 0.4586 reward = -0.0000 fps = 6 mse_loss = 0.6510 
2022-05-01 05:58:42.107568 - gail/main.py:164 - [TRPO] iter = 577000 dist_mean = 0.0869 dist_std = 0.2249 vf_loss = 0.1360 grad_norm = 1.7307 nat_grad_norm = 0.1066 cg_residual = 0.1769 step_size = 0.6401 reward = -0.0000 fps = 6 mse_loss = 0.6916 
2022-05-01 05:58:52.142550 - gail/main.py:164 - [TRPO] iter = 578000 dist_mean = 0.0668 dist_std = 0.2251 vf_loss = 0.1325 grad_norm = 1.6020 nat_grad_norm = 0.1434 cg_residual = 0.5348 step_size = 0.4690 reward = 0.0000 fps = 6 mse_loss = 0.5792 
2022-05-01 05:59:02.137254 - gail/main.py:164 - [TRPO] iter = 579000 dist_mean = 0.0485 dist_std = 0.2248 vf_loss = 0.0394 grad_norm = 1.6568 nat_grad_norm = 0.1541 cg_residual = 0.3078 step_size = 0.4801 reward = 0.0000 fps = 5 mse_loss = 0.5688 
2022-05-01 05:59:12.215725 - gail/main.py:164 - [TRPO] iter = 580000 dist_mean = 0.0873 dist_std = 0.2251 vf_loss = 0.0816 grad_norm = 1.4222 nat_grad_norm = 0.1188 cg_residual = 0.2399 step_size = 0.5990 reward = -0.0000 fps = 5 mse_loss = 0.6383 
2022-05-01 05:59:12.475453 - gail/main.py:191 - [Discriminator] iter = 580000 loss = -0.3112 grad_norm = 2.6940 grad_penalty = 0.0507 regularization = 0.0000 true_logits = -0.0063 fake_logits = -0.3682 true_prob = 0.5011 fake_prob = 0.4292 
2022-05-01 06:01:27.083795 - gail/main.py:132 - [Evaluate] iter = 580000 episode={ returns = 3581.5190 lengths = 1000 } discounted_episode={ returns = 2207.4842 lengths = 1000 } 
2022-05-01 06:01:37.227251 - gail/main.py:164 - [TRPO] iter = 581000 dist_mean = 0.0757 dist_std = 0.2273 vf_loss = 0.1329 grad_norm = 1.9406 nat_grad_norm = 0.1934 cg_residual = 0.6485 step_size = 0.3942 reward = -0.0000 fps = 6 mse_loss = 0.5726 
2022-05-01 06:01:47.343629 - gail/main.py:164 - [TRPO] iter = 582000 dist_mean = 0.0933 dist_std = 0.2267 vf_loss = 0.1672 grad_norm = 2.7177 nat_grad_norm = 0.1759 cg_residual = 0.8001 step_size = 0.4050 reward = -0.0000 fps = 6 mse_loss = 0.6212 
2022-05-01 06:01:57.359902 - gail/main.py:164 - [TRPO] iter = 583000 dist_mean = 0.0932 dist_std = 0.2245 vf_loss = 0.0745 grad_norm = 1.9453 nat_grad_norm = 0.1464 cg_residual = 0.3895 step_size = 0.5047 reward = 0.0000 fps = 6 mse_loss = 0.6074 
2022-05-01 06:02:07.771011 - gail/main.py:164 - [TRPO] iter = 584000 dist_mean = 0.2050 dist_std = 0.2260 vf_loss = 0.3462 grad_norm = 1.8279 nat_grad_norm = 0.1520 cg_residual = 0.3697 step_size = 0.4924 reward = 0.0000 fps = 5 mse_loss = 0.5639 
2022-05-01 06:02:17.133238 - gail/main.py:164 - [TRPO] iter = 585000 dist_mean = 0.0722 dist_std = 0.2265 vf_loss = 0.5268 grad_norm = 1.5210 nat_grad_norm = 0.1116 cg_residual = 0.1428 step_size = 0.5789 reward = 0.0000 fps = 5 mse_loss = 0.6162 
2022-05-01 06:02:17.410549 - gail/main.py:191 - [Discriminator] iter = 585000 loss = -0.4542 grad_norm = 2.4086 grad_penalty = 0.0464 regularization = 0.0000 true_logits = 0.0186 fake_logits = -0.4820 true_prob = 0.5075 fake_prob = 0.4096 
2022-05-01 06:02:21.250205 - gail/main.py:132 - [Evaluate] iter = 585000 episode={ returns = 47.0749 lengths = 27 } discounted_episode={ returns = 46.9552 lengths = 27 } 
2022-05-01 06:02:30.898070 - gail/main.py:164 - [TRPO] iter = 586000 dist_mean = 0.0634 dist_std = 0.2269 vf_loss = 0.0680 grad_norm = 1.6263 nat_grad_norm = 0.1470 cg_residual = 0.5162 step_size = 0.4948 reward = 0.0000 fps = 74 mse_loss = 0.6308 
2022-05-01 06:02:40.960929 - gail/main.py:164 - [TRPO] iter = 587000 dist_mean = 0.2092 dist_std = 0.2261 vf_loss = 0.1926 grad_norm = 1.8577 nat_grad_norm = 0.2120 cg_residual = 0.3309 step_size = 0.3845 reward = 0.0000 fps = 42 mse_loss = 0.6556 
2022-05-01 06:02:50.806697 - gail/main.py:164 - [TRPO] iter = 588000 dist_mean = 0.1454 dist_std = 0.2281 vf_loss = 0.5868 grad_norm = 1.7015 nat_grad_norm = 0.1255 cg_residual = 0.3552 step_size = 0.4958 reward = -0.0000 fps = 29 mse_loss = 0.5526 
2022-05-01 06:03:00.557518 - gail/main.py:164 - [TRPO] iter = 589000 dist_mean = 0.0775 dist_std = 0.2277 vf_loss = 0.0855 grad_norm = 1.9098 nat_grad_norm = 0.1643 cg_residual = 0.5812 step_size = 0.4566 reward = -0.0000 fps = 23 mse_loss = 0.6320 
2022-05-01 06:03:10.865896 - gail/main.py:164 - [TRPO] iter = 590000 dist_mean = 0.0884 dist_std = 0.2268 vf_loss = 0.6570 grad_norm = 2.5552 nat_grad_norm = 0.1548 cg_residual = 0.6575 step_size = 0.4356 reward = 0.0000 fps = 18 mse_loss = 0.6054 
2022-05-01 06:03:11.091450 - gail/main.py:191 - [Discriminator] iter = 590000 loss = -0.5908 grad_norm = 2.4853 grad_penalty = 0.0466 regularization = 0.0000 true_logits = 0.0123 fake_logits = -0.6250 true_prob = 0.5063 fake_prob = 0.3866 
2022-05-01 06:03:15.253176 - gail/main.py:132 - [Evaluate] iter = 590000 episode={ returns = 49.4802 lengths = 28 } discounted_episode={ returns = 48.2594 lengths = 28 } 
2022-05-01 06:03:25.151942 - gail/main.py:164 - [TRPO] iter = 591000 dist_mean = 0.0087 dist_std = 0.2269 vf_loss = 0.1334 grad_norm = 1.7752 nat_grad_norm = 0.1885 cg_residual = 0.6599 step_size = 0.3916 reward = -0.0000 fps = 71 mse_loss = 0.6291 
2022-05-01 06:03:34.829750 - gail/main.py:164 - [TRPO] iter = 592000 dist_mean = 0.0826 dist_std = 0.2268 vf_loss = 0.0683 grad_norm = 2.0415 nat_grad_norm = 0.1582 cg_residual = 0.7153 step_size = 0.4929 reward = -0.0000 fps = 42 mse_loss = 0.6709 
2022-05-01 06:03:44.705136 - gail/main.py:164 - [TRPO] iter = 593000 dist_mean = 0.0435 dist_std = 0.2268 vf_loss = 0.4379 grad_norm = 2.0303 nat_grad_norm = 0.0916 cg_residual = 0.3560 step_size = 0.6448 reward = 0.0000 fps = 29 mse_loss = 0.5996 
2022-05-01 06:03:54.690377 - gail/main.py:164 - [TRPO] iter = 594000 dist_mean = 0.0752 dist_std = 0.2274 vf_loss = 0.0562 grad_norm = 1.9371 nat_grad_norm = 0.1502 cg_residual = 0.4518 step_size = 0.4466 reward = -0.0000 fps = 22 mse_loss = 0.6192 
2022-05-01 06:04:05.000623 - gail/main.py:164 - [TRPO] iter = 595000 dist_mean = 0.0601 dist_std = 0.2248 vf_loss = 0.0550 grad_norm = 1.8252 nat_grad_norm = 0.1522 cg_residual = 0.3079 step_size = 0.5417 reward = -0.0000 fps = 18 mse_loss = 0.6430 
2022-05-01 06:04:05.234286 - gail/main.py:191 - [Discriminator] iter = 595000 loss = -0.4584 grad_norm = 2.7176 grad_penalty = 0.0479 regularization = 0.0000 true_logits = -0.0177 fake_logits = -0.5240 true_prob = 0.4987 fake_prob = 0.4038 
2022-05-01 06:04:08.819995 - gail/main.py:132 - [Evaluate] iter = 595000 episode={ returns = 43.3126 lengths = 25 } discounted_episode={ returns = 42.3630 lengths = 25 } 
2022-05-01 06:04:18.788348 - gail/main.py:164 - [TRPO] iter = 596000 dist_mean = 0.0930 dist_std = 0.2252 vf_loss = 0.4465 grad_norm = 1.8973 nat_grad_norm = 0.1464 cg_residual = 0.3145 step_size = 0.5653 reward = 0.0000 fps = 73 mse_loss = 0.6285 
2022-05-01 06:04:28.459066 - gail/main.py:164 - [TRPO] iter = 597000 dist_mean = 0.1320 dist_std = 0.2258 vf_loss = 0.0953 grad_norm = 1.2698 nat_grad_norm = 0.1414 cg_residual = 0.2471 step_size = 0.5341 reward = 0.0000 fps = 43 mse_loss = 0.6926 
2022-05-01 06:04:38.203207 - gail/main.py:164 - [TRPO] iter = 598000 dist_mean = 0.0776 dist_std = 0.2269 vf_loss = 0.1120 grad_norm = 2.1901 nat_grad_norm = 0.1560 cg_residual = 0.3884 step_size = 0.4234 reward = -0.0000 fps = 30 mse_loss = 0.6557 
2022-05-01 06:04:47.971116 - gail/main.py:164 - [TRPO] iter = 599000 dist_mean = 0.0033 dist_std = 0.2267 vf_loss = 0.1315 grad_norm = 2.2755 nat_grad_norm = 0.1827 cg_residual = 0.5586 step_size = 0.3746 reward = 0.0000 fps = 23 mse_loss = 0.6913 
2022-05-01 06:04:57.733448 - gail/main.py:164 - [TRPO] iter = 600000 dist_mean = 0.0932 dist_std = 0.2272 vf_loss = 0.1536 grad_norm = 1.8632 nat_grad_norm = 0.1721 cg_residual = 0.4744 step_size = 0.4105 reward = -0.0000 fps = 19 mse_loss = 0.6697 
2022-05-01 06:04:57.969327 - gail/main.py:191 - [Discriminator] iter = 600000 loss = -1.2386 grad_norm = 2.8363 grad_penalty = 0.0718 regularization = 0.0000 true_logits = 0.0006 fake_logits = -1.3098 true_prob = 0.5030 fake_prob = 0.2997 
2022-05-01 06:05:01.642481 - gail/main.py:132 - [Evaluate] iter = 600000 episode={ returns = 44.6491 lengths = 26 } discounted_episode={ returns = 44.4611 lengths = 26 } 
2022-05-01 06:05:11.247728 - gail/main.py:164 - [TRPO] iter = 601000 dist_mean = 0.0265 dist_std = 0.2262 vf_loss = 0.0597 grad_norm = 1.7858 nat_grad_norm = 0.2120 cg_residual = 0.5914 step_size = 0.3643 reward = -0.0000 fps = 75 mse_loss = 0.6456 
2022-05-01 06:05:21.249812 - gail/main.py:164 - [TRPO] iter = 602000 dist_mean = 0.0156 dist_std = 0.2259 vf_loss = 0.0833 grad_norm = 2.1473 nat_grad_norm = 0.1558 cg_residual = 0.5101 step_size = 0.4240 reward = 0.0000 fps = 42 mse_loss = 0.6443 
2022-05-01 06:05:30.749309 - gail/main.py:164 - [TRPO] iter = 603000 dist_mean = 0.0053 dist_std = 0.2256 vf_loss = 0.0920 grad_norm = 1.6464 nat_grad_norm = 0.1818 cg_residual = 0.3837 step_size = 0.4248 reward = -0.0000 fps = 30 mse_loss = 0.6547 
2022-05-01 06:05:40.729572 - gail/main.py:164 - [TRPO] iter = 604000 dist_mean = 0.0237 dist_std = 0.2253 vf_loss = 0.5741 grad_norm = 2.0903 nat_grad_norm = 0.1328 cg_residual = 0.3449 step_size = 0.4805 reward = 0.0000 fps = 23 mse_loss = 0.6801 
2022-05-01 06:05:51.009006 - gail/main.py:164 - [TRPO] iter = 605000 dist_mean = 0.0276 dist_std = 0.2249 vf_loss = 0.5619 grad_norm = 1.6648 nat_grad_norm = 0.1052 cg_residual = 0.1930 step_size = 0.5762 reward = 0.0000 fps = 18 mse_loss = 0.7247 
2022-05-01 06:05:51.206747 - gail/main.py:191 - [Discriminator] iter = 605000 loss = -0.3154 grad_norm = 2.4342 grad_penalty = 0.0489 regularization = 0.0000 true_logits = 0.0286 fake_logits = -0.3357 true_prob = 0.5098 fake_prob = 0.4403 
2022-05-01 06:06:38.411406 - gail/main.py:132 - [Evaluate] iter = 605000 episode={ returns = 1042.5700 lengths = 291 } discounted_episode={ returns = 994.0021 lengths = 419 } 
2022-05-01 06:06:48.238539 - gail/main.py:164 - [TRPO] iter = 606000 dist_mean = 0.0525 dist_std = 0.2251 vf_loss = 0.5440 grad_norm = 1.6299 nat_grad_norm = 0.1039 cg_residual = 0.2398 step_size = 0.6086 reward = 0.0000 fps = 17 mse_loss = 0.6642 
2022-05-01 06:06:58.662982 - gail/main.py:164 - [TRPO] iter = 607000 dist_mean = 0.0427 dist_std = 0.2245 vf_loss = 0.0771 grad_norm = 1.5664 nat_grad_norm = 0.2123 cg_residual = 0.7776 step_size = 0.3956 reward = 0.0000 fps = 14 mse_loss = 0.6637 
2022-05-01 06:07:08.664136 - gail/main.py:164 - [TRPO] iter = 608000 dist_mean = 0.0178 dist_std = 0.2228 vf_loss = 0.3950 grad_norm = 1.2482 nat_grad_norm = 0.1091 cg_residual = 0.1989 step_size = 0.5930 reward = 0.0000 fps = 12 mse_loss = 0.6674 
2022-05-01 06:07:18.327392 - gail/main.py:164 - [TRPO] iter = 609000 dist_mean = 0.0328 dist_std = 0.2222 vf_loss = 0.0656 grad_norm = 2.0976 nat_grad_norm = 0.1669 cg_residual = 0.5241 step_size = 0.4331 reward = -0.0000 fps = 11 mse_loss = 0.6844 
2022-05-01 06:07:28.033226 - gail/main.py:164 - [TRPO] iter = 610000 dist_mean = -0.0012 dist_std = 0.2231 vf_loss = 0.3671 grad_norm = 1.5242 nat_grad_norm = 0.1643 cg_residual = 0.5294 step_size = 0.4821 reward = 0.0000 fps = 10 mse_loss = 0.6144 
2022-05-01 06:07:28.271853 - gail/main.py:191 - [Discriminator] iter = 610000 loss = -0.7191 grad_norm = 2.5848 grad_penalty = 0.0571 regularization = 0.0000 true_logits = 0.1166 fake_logits = -0.6596 true_prob = 0.5293 fake_prob = 0.3914 
2022-05-01 06:09:28.795789 - gail/main.py:132 - [Evaluate] iter = 610000 episode={ returns = 3323.7717 lengths = 919 } discounted_episode={ returns = 1993.9949 lengths = 902 } 
2022-05-01 06:09:38.740402 - gail/main.py:164 - [TRPO] iter = 611000 dist_mean = 0.0398 dist_std = 0.2226 vf_loss = 0.4146 grad_norm = 1.4735 nat_grad_norm = 0.1221 cg_residual = 0.3901 step_size = 0.5525 reward = 0.0000 fps = 7 mse_loss = 0.6800 
2022-05-01 06:09:48.451353 - gail/main.py:164 - [TRPO] iter = 612000 dist_mean = 0.0521 dist_std = 0.2221 vf_loss = 0.3277 grad_norm = 1.1136 nat_grad_norm = 0.1041 cg_residual = 0.2335 step_size = 0.5844 reward = 0.0000 fps = 7 mse_loss = 0.6456 
2022-05-01 06:09:58.157721 - gail/main.py:164 - [TRPO] iter = 613000 dist_mean = 0.0543 dist_std = 0.2216 vf_loss = 0.4932 grad_norm = 1.9712 nat_grad_norm = 0.0988 cg_residual = 0.2310 step_size = 0.6338 reward = -0.0000 fps = 6 mse_loss = 0.6671 
2022-05-01 06:10:08.252782 - gail/main.py:164 - [TRPO] iter = 614000 dist_mean = 0.0356 dist_std = 0.2209 vf_loss = 0.1304 grad_norm = 1.2333 nat_grad_norm = 0.1725 cg_residual = 0.6836 step_size = 0.4243 reward = -0.0000 fps = 6 mse_loss = 0.6723 
2022-05-01 06:10:18.514221 - gail/main.py:164 - [TRPO] iter = 615000 dist_mean = 0.0653 dist_std = 0.2204 vf_loss = 0.1373 grad_norm = 1.5429 nat_grad_norm = 0.1624 cg_residual = 0.6967 step_size = 0.4206 reward = 0.0000 fps = 5 mse_loss = 0.5910 
2022-05-01 06:10:18.761560 - gail/main.py:191 - [Discriminator] iter = 615000 loss = -0.7480 grad_norm = 2.9108 grad_penalty = 0.0650 regularization = 0.0000 true_logits = 0.0724 fake_logits = -0.7407 true_prob = 0.5178 fake_prob = 0.3825 
2022-05-01 06:10:22.017480 - gail/main.py:132 - [Evaluate] iter = 615000 episode={ returns = 41.0611 lengths = 23 } discounted_episode={ returns = 39.7429 lengths = 23 } 
2022-05-01 06:10:31.824075 - gail/main.py:164 - [TRPO] iter = 616000 dist_mean = 0.0941 dist_std = 0.2202 vf_loss = 0.0842 grad_norm = 1.6500 nat_grad_norm = 0.2026 cg_residual = 1.2520 step_size = 0.3747 reward = -0.0000 fps = 76 mse_loss = 0.6734 
2022-05-01 06:10:41.847807 - gail/main.py:164 - [TRPO] iter = 617000 dist_mean = 0.0200 dist_std = 0.2186 vf_loss = 0.4619 grad_norm = 1.2313 nat_grad_norm = 0.0922 cg_residual = 0.1412 step_size = 0.7385 reward = -0.0000 fps = 43 mse_loss = 0.6277 
2022-05-01 06:10:51.711137 - gail/main.py:164 - [TRPO] iter = 618000 dist_mean = 0.0996 dist_std = 0.2198 vf_loss = 0.0424 grad_norm = 1.7880 nat_grad_norm = 0.1441 cg_residual = 0.3727 step_size = 0.4719 reward = -0.0000 fps = 30 mse_loss = 0.6509 
2022-05-01 06:11:01.616105 - gail/main.py:164 - [TRPO] iter = 619000 dist_mean = 0.0255 dist_std = 0.2176 vf_loss = 0.2845 grad_norm = 1.5381 nat_grad_norm = 0.1389 cg_residual = 0.2177 step_size = 0.4778 reward = -0.0000 fps = 23 mse_loss = 0.6703 
2022-05-01 06:11:11.469961 - gail/main.py:164 - [TRPO] iter = 620000 dist_mean = 0.0559 dist_std = 0.2169 vf_loss = 0.0475 grad_norm = 2.5080 nat_grad_norm = 0.1674 cg_residual = 0.5545 step_size = 0.3934 reward = -0.0000 fps = 18 mse_loss = 0.6398 
2022-05-01 06:11:11.676388 - gail/main.py:191 - [Discriminator] iter = 620000 loss = -0.7855 grad_norm = 3.2713 grad_penalty = 0.0718 regularization = 0.0000 true_logits = 0.0618 fake_logits = -0.7954 true_prob = 0.5176 fake_prob = 0.3770 
2022-05-01 06:11:15.056288 - gail/main.py:132 - [Evaluate] iter = 620000 episode={ returns = 41.5087 lengths = 24 } discounted_episode={ returns = 40.8395 lengths = 24 } 
2022-05-01 06:11:25.390321 - gail/main.py:164 - [TRPO] iter = 621000 dist_mean = 0.2193 dist_std = 0.2157 vf_loss = 0.1986 grad_norm = 1.3267 nat_grad_norm = 0.1633 cg_residual = 0.2322 step_size = 0.4800 reward = 0.0000 fps = 73 mse_loss = 0.6754 
2022-05-01 06:11:35.223727 - gail/main.py:164 - [TRPO] iter = 622000 dist_mean = 0.0683 dist_std = 0.2152 vf_loss = 0.9071 grad_norm = 1.6244 nat_grad_norm = 0.1045 cg_residual = 0.3229 step_size = 0.5946 reward = -0.0000 fps = 42 mse_loss = 0.6575 
2022-05-01 06:11:45.367956 - gail/main.py:164 - [TRPO] iter = 623000 dist_mean = 0.0535 dist_std = 0.2154 vf_loss = 0.0840 grad_norm = 1.8493 nat_grad_norm = 0.2135 cg_residual = 0.9738 step_size = 0.3379 reward = -0.0000 fps = 29 mse_loss = 0.7132 
2022-05-01 06:11:55.204649 - gail/main.py:164 - [TRPO] iter = 624000 dist_mean = 0.1288 dist_std = 0.2152 vf_loss = 0.1078 grad_norm = 1.6791 nat_grad_norm = 0.1363 cg_residual = 0.2896 step_size = 0.5127 reward = -0.0000 fps = 22 mse_loss = 0.6312 
2022-05-01 06:12:05.093957 - gail/main.py:164 - [TRPO] iter = 625000 dist_mean = 0.1973 dist_std = 0.2169 vf_loss = 0.5485 grad_norm = 1.4599 nat_grad_norm = 0.1466 cg_residual = 0.3069 step_size = 0.4760 reward = -0.0000 fps = 18 mse_loss = 0.6106 
2022-05-01 06:12:05.348534 - gail/main.py:191 - [Discriminator] iter = 625000 loss = -2.5081 grad_norm = 3.3411 grad_penalty = 0.1692 regularization = 0.0000 true_logits = 0.1819 fake_logits = -2.4955 true_prob = 0.5365 fake_prob = 0.1518 
2022-05-01 06:12:08.888637 - gail/main.py:132 - [Evaluate] iter = 625000 episode={ returns = 43.1329 lengths = 25 } discounted_episode={ returns = 42.3333 lengths = 24 } 
2022-05-01 06:12:18.823987 - gail/main.py:164 - [TRPO] iter = 626000 dist_mean = 0.0366 dist_std = 0.2165 vf_loss = 1.2647 grad_norm = 1.9283 nat_grad_norm = 0.1245 cg_residual = 0.5133 step_size = 0.4471 reward = -0.0000 fps = 74 mse_loss = 0.6670 
2022-05-01 06:12:28.640230 - gail/main.py:164 - [TRPO] iter = 627000 dist_mean = 0.0059 dist_std = 0.2168 vf_loss = 1.1261 grad_norm = 1.4325 nat_grad_norm = 0.1178 cg_residual = 0.2142 step_size = 0.5295 reward = 0.0000 fps = 42 mse_loss = 0.6845 
2022-05-01 06:12:38.665094 - gail/main.py:164 - [TRPO] iter = 628000 dist_mean = 0.0235 dist_std = 0.2172 vf_loss = 0.2463 grad_norm = 1.6508 nat_grad_norm = 0.1595 cg_residual = 0.5801 step_size = 0.4583 reward = -0.0000 fps = 30 mse_loss = 0.7000 
2022-05-01 06:12:48.550768 - gail/main.py:164 - [TRPO] iter = 629000 dist_mean = 0.0227 dist_std = 0.2178 vf_loss = 0.2766 grad_norm = 1.9861 nat_grad_norm = 0.1546 cg_residual = 0.6045 step_size = 0.4441 reward = -0.0000 fps = 23 mse_loss = 0.6382 
2022-05-01 06:12:58.271933 - gail/main.py:164 - [TRPO] iter = 630000 dist_mean = 0.0052 dist_std = 0.2174 vf_loss = 0.1051 grad_norm = 1.9479 nat_grad_norm = 0.1806 cg_residual = 0.3449 step_size = 0.4706 reward = -0.0000 fps = 18 mse_loss = 0.7435 
2022-05-01 06:12:58.483926 - gail/main.py:191 - [Discriminator] iter = 630000 loss = -0.3798 grad_norm = 3.0828 grad_penalty = 0.0791 regularization = 0.0000 true_logits = 0.2820 fake_logits = -0.1769 true_prob = 0.5570 fake_prob = 0.4837 
2022-05-01 06:13:17.658639 - gail/main.py:132 - [Evaluate] iter = 630000 episode={ returns = 389.9094 lengths = 118 } discounted_episode={ returns = 438.5738 lengths = 163 } 
2022-05-01 06:13:27.345137 - gail/main.py:164 - [TRPO] iter = 631000 dist_mean = -0.0084 dist_std = 0.2165 vf_loss = 0.1319 grad_norm = 2.4698 nat_grad_norm = 0.1573 cg_residual = 0.5387 step_size = 0.4231 reward = 0.0000 fps = 34 mse_loss = 0.6244 
2022-05-01 06:13:37.400566 - gail/main.py:164 - [TRPO] iter = 632000 dist_mean = -0.0196 dist_std = 0.2169 vf_loss = 0.0823 grad_norm = 1.4253 nat_grad_norm = 0.1917 cg_residual = 1.0208 step_size = 0.4066 reward = -0.0000 fps = 25 mse_loss = 0.6358 
2022-05-01 06:13:47.680480 - gail/main.py:164 - [TRPO] iter = 633000 dist_mean = 0.0090 dist_std = 0.2163 vf_loss = 0.5270 grad_norm = 1.5362 nat_grad_norm = 0.1386 cg_residual = 0.4870 step_size = 0.5024 reward = -0.0000 fps = 20 mse_loss = 0.6324 
2022-05-01 06:13:57.344335 - gail/main.py:164 - [TRPO] iter = 634000 dist_mean = 0.0188 dist_std = 0.2151 vf_loss = 0.5383 grad_norm = 1.8640 nat_grad_norm = 0.1085 cg_residual = 0.2417 step_size = 0.5515 reward = -0.0000 fps = 16 mse_loss = 0.5981 
2022-05-01 06:14:07.462551 - gail/main.py:164 - [TRPO] iter = 635000 dist_mean = 0.0158 dist_std = 0.2155 vf_loss = 0.1200 grad_norm = 2.5555 nat_grad_norm = 0.1248 cg_residual = 0.5842 step_size = 0.4724 reward = -0.0000 fps = 14 mse_loss = 0.6633 
2022-05-01 06:14:07.691515 - gail/main.py:191 - [Discriminator] iter = 635000 loss = -0.6087 grad_norm = 2.4478 grad_penalty = 0.0568 regularization = 0.0000 true_logits = 0.2380 fake_logits = -0.4275 true_prob = 0.5467 fake_prob = 0.4428 
2022-05-01 06:15:07.052734 - gail/main.py:132 - [Evaluate] iter = 635000 episode={ returns = 1326.0627 lengths = 378 } discounted_episode={ returns = 1072.0848 lengths = 481 } 
2022-05-01 06:15:17.348507 - gail/main.py:164 - [TRPO] iter = 636000 dist_mean = 0.0045 dist_std = 0.2167 vf_loss = 0.2394 grad_norm = 1.1616 nat_grad_norm = 0.1481 cg_residual = 0.2985 step_size = 0.5252 reward = 0.0000 fps = 14 mse_loss = 0.6666 
2022-05-01 06:15:26.985016 - gail/main.py:164 - [TRPO] iter = 637000 dist_mean = 0.0139 dist_std = 0.2182 vf_loss = 0.2627 grad_norm = 1.4262 nat_grad_norm = 0.1178 cg_residual = 0.1616 step_size = 0.5461 reward = 0.0000 fps = 12 mse_loss = 0.5830 
2022-05-01 06:15:37.368644 - gail/main.py:164 - [TRPO] iter = 638000 dist_mean = 0.0102 dist_std = 0.2165 vf_loss = 0.3009 grad_norm = 1.8734 nat_grad_norm = 0.1216 cg_residual = 0.2305 step_size = 0.5346 reward = 0.0000 fps = 11 mse_loss = 0.6792 
2022-05-01 06:15:47.130846 - gail/main.py:164 - [TRPO] iter = 639000 dist_mean = 0.0212 dist_std = 0.2161 vf_loss = 0.2316 grad_norm = 1.7734 nat_grad_norm = 0.1014 cg_residual = 0.2469 step_size = 0.6163 reward = 0.0000 fps = 10 mse_loss = 0.6165 
2022-05-01 06:15:56.841626 - gail/main.py:164 - [TRPO] iter = 640000 dist_mean = 0.0160 dist_std = 0.2152 vf_loss = 0.1083 grad_norm = 1.1674 nat_grad_norm = 0.1294 cg_residual = 0.4855 step_size = 0.5435 reward = 0.0000 fps = 9 mse_loss = 0.6212 
2022-05-01 06:15:57.069488 - gail/main.py:191 - [Discriminator] iter = 640000 loss = -0.3452 grad_norm = 2.5627 grad_penalty = 0.0594 regularization = 0.0000 true_logits = 0.1176 fake_logits = -0.2869 true_prob = 0.5246 fake_prob = 0.4582 
2022-05-01 06:16:25.581826 - gail/main.py:132 - [Evaluate] iter = 640000 episode={ returns = 390.7971 lengths = 120 } discounted_episode={ returns = 691.2543 lengths = 315 } 
2022-05-01 06:16:35.743327 - gail/main.py:164 - [TRPO] iter = 641000 dist_mean = 0.0209 dist_std = 0.2144 vf_loss = 0.3962 grad_norm = 1.3749 nat_grad_norm = 0.1111 cg_residual = 0.2661 step_size = 0.6136 reward = 0.0000 fps = 25 mse_loss = 0.5549 
2022-05-01 06:16:46.125820 - gail/main.py:164 - [TRPO] iter = 642000 dist_mean = 0.0713 dist_std = 0.2144 vf_loss = 0.2506 grad_norm = 1.9760 nat_grad_norm = 0.1514 cg_residual = 0.3896 step_size = 0.4551 reward = -0.0000 fps = 20 mse_loss = 0.6109 
2022-05-01 06:16:57.141366 - gail/main.py:164 - [TRPO] iter = 643000 dist_mean = 0.0215 dist_std = 0.2117 vf_loss = 0.1639 grad_norm = 1.6594 nat_grad_norm = 0.1338 cg_residual = 0.5924 step_size = 0.4872 reward = -0.0000 fps = 16 mse_loss = 0.6468 
2022-05-01 06:17:08.228176 - gail/main.py:164 - [TRPO] iter = 644000 dist_mean = 0.0900 dist_std = 0.2120 vf_loss = 0.2044 grad_norm = 2.5308 nat_grad_norm = 0.1620 cg_residual = 0.3218 step_size = 0.4266 reward = 0.0000 fps = 14 mse_loss = 0.5692 
2022-05-01 06:17:19.638937 - gail/main.py:164 - [TRPO] iter = 645000 dist_mean = 0.2283 dist_std = 0.2107 vf_loss = 0.0821 grad_norm = 2.1500 nat_grad_norm = 0.1104 cg_residual = 0.1814 step_size = 0.5217 reward = 0.0000 fps = 12 mse_loss = 0.6650 
2022-05-01 06:17:19.889479 - gail/main.py:191 - [Discriminator] iter = 645000 loss = -1.7955 grad_norm = 3.1516 grad_penalty = 0.1093 regularization = 0.0000 true_logits = 0.0990 fake_logits = -1.8059 true_prob = 0.5234 fake_prob = 0.2577 
2022-05-01 06:17:23.698850 - gail/main.py:132 - [Evaluate] iter = 645000 episode={ returns = 40.0441 lengths = 22 } discounted_episode={ returns = 39.9903 lengths = 23 } 
2022-05-01 06:17:34.963008 - gail/main.py:164 - [TRPO] iter = 646000 dist_mean = 0.0454 dist_std = 0.2115 vf_loss = 0.5826 grad_norm = 1.5364 nat_grad_norm = 0.1409 cg_residual = 0.4661 step_size = 0.4392 reward = -0.0000 fps = 66 mse_loss = 0.6245 
2022-05-01 06:17:46.384398 - gail/main.py:164 - [TRPO] iter = 647000 dist_mean = 0.1430 dist_std = 0.2117 vf_loss = 0.0716 grad_norm = 1.9056 nat_grad_norm = 0.1359 cg_residual = 0.7356 step_size = 0.3914 reward = 0.0000 fps = 37 mse_loss = 0.5327 
2022-05-01 06:17:57.829717 - gail/main.py:164 - [TRPO] iter = 648000 dist_mean = 0.3050 dist_std = 0.2115 vf_loss = 1.9155 grad_norm = 3.1168 nat_grad_norm = 0.1690 cg_residual = 0.4833 step_size = 0.3466 reward = 0.0000 fps = 26 mse_loss = 0.5783 
2022-05-01 06:18:09.713136 - gail/main.py:164 - [TRPO] iter = 649000 dist_mean = 0.0913 dist_std = 0.2114 vf_loss = 0.2208 grad_norm = 2.2887 nat_grad_norm = 0.1456 cg_residual = 0.4196 step_size = 0.4263 reward = -0.0000 fps = 20 mse_loss = 0.5869 
2022-05-01 06:18:20.905763 - gail/main.py:164 - [TRPO] iter = 650000 dist_mean = 0.0324 dist_std = 0.2108 vf_loss = 0.1016 grad_norm = 1.7799 nat_grad_norm = 0.1781 cg_residual = 0.5985 step_size = 0.3950 reward = 0.0000 fps = 16 mse_loss = 0.5792 
2022-05-01 06:18:21.137062 - gail/main.py:191 - [Discriminator] iter = 650000 loss = -0.4313 grad_norm = 3.0556 grad_penalty = 0.0700 regularization = 0.0000 true_logits = 0.2376 fake_logits = -0.2638 true_prob = 0.5483 fake_prob = 0.4708 
2022-05-01 06:18:25.102526 - gail/main.py:132 - [Evaluate] iter = 650000 episode={ returns = 40.1295 lengths = 23 } discounted_episode={ returns = 38.9343 lengths = 22 } 
2022-05-01 06:18:36.485938 - gail/main.py:164 - [TRPO] iter = 651000 dist_mean = 0.0449 dist_std = 0.2109 vf_loss = 0.7074 grad_norm = 1.3939 nat_grad_norm = 0.1606 cg_residual = 0.5400 step_size = 0.5074 reward = 0.0000 fps = 65 mse_loss = 0.6106 
2022-05-01 06:18:48.291436 - gail/main.py:164 - [TRPO] iter = 652000 dist_mean = 0.0809 dist_std = 0.2109 vf_loss = 0.1371 grad_norm = 1.8986 nat_grad_norm = 0.1403 cg_residual = 0.5096 step_size = 0.4414 reward = 0.0000 fps = 36 mse_loss = 0.5649 
2022-05-01 06:18:59.587339 - gail/main.py:164 - [TRPO] iter = 653000 dist_mean = 0.1653 dist_std = 0.2109 vf_loss = 0.6967 grad_norm = 1.1460 nat_grad_norm = 0.1191 cg_residual = 0.2566 step_size = 0.5611 reward = -0.0000 fps = 26 mse_loss = 0.5947 
2022-05-01 06:19:10.810409 - gail/main.py:164 - [TRPO] iter = 654000 dist_mean = 0.0253 dist_std = 0.2113 vf_loss = 0.8150 grad_norm = 1.7614 nat_grad_norm = 0.1118 cg_residual = 0.3115 step_size = 0.5198 reward = -0.0000 fps = 20 mse_loss = 0.5829 
2022-05-01 06:19:21.758257 - gail/main.py:164 - [TRPO] iter = 655000 dist_mean = 0.0309 dist_std = 0.2111 vf_loss = 0.0826 grad_norm = 1.9702 nat_grad_norm = 0.1609 cg_residual = 0.5013 step_size = 0.3981 reward = -0.0000 fps = 16 mse_loss = 0.6087 
2022-05-01 06:19:21.975453 - gail/main.py:191 - [Discriminator] iter = 655000 loss = -0.3822 grad_norm = 3.6729 grad_penalty = 0.0717 regularization = 0.0000 true_logits = 0.1577 fake_logits = -0.2963 true_prob = 0.5319 fake_prob = 0.4592 
2022-05-01 06:19:34.562309 - gail/main.py:132 - [Evaluate] iter = 655000 episode={ returns = 280.3459 lengths = 87 } discounted_episode={ returns = 203.8503 lengths = 87 } 
2022-05-01 06:19:45.049868 - gail/main.py:164 - [TRPO] iter = 656000 dist_mean = -0.0001 dist_std = 0.2110 vf_loss = 0.1083 grad_norm = 2.6089 nat_grad_norm = 0.1587 cg_residual = 0.9133 step_size = 0.4232 reward = -0.0000 fps = 43 mse_loss = 0.5098 
2022-05-01 06:19:55.478965 - gail/main.py:164 - [TRPO] iter = 657000 dist_mean = 0.0869 dist_std = 0.2112 vf_loss = 0.0418 grad_norm = 1.5718 nat_grad_norm = 0.1780 cg_residual = 0.5889 step_size = 0.3939 reward = 0.0000 fps = 29 mse_loss = 0.4985 
2022-05-01 06:20:05.758153 - gail/main.py:164 - [TRPO] iter = 658000 dist_mean = 0.0319 dist_std = 0.2115 vf_loss = 0.4031 grad_norm = 3.9200 nat_grad_norm = 0.1548 cg_residual = 1.0459 step_size = 0.3368 reward = 0.0000 fps = 22 mse_loss = 0.5420 
2022-05-01 06:20:16.650312 - gail/main.py:164 - [TRPO] iter = 659000 dist_mean = 0.0454 dist_std = 0.2109 vf_loss = 0.0770 grad_norm = 1.7315 nat_grad_norm = 0.1507 cg_residual = 0.5957 step_size = 0.4145 reward = -0.0000 fps = 18 mse_loss = 0.5579 
2022-05-01 06:20:27.010644 - gail/main.py:164 - [TRPO] iter = 660000 dist_mean = 0.0298 dist_std = 0.2123 vf_loss = 0.0913 grad_norm = 1.6695 nat_grad_norm = 0.1373 cg_residual = 0.4948 step_size = 0.5020 reward = 0.0000 fps = 15 mse_loss = 0.6513 
2022-05-01 06:20:27.234628 - gail/main.py:191 - [Discriminator] iter = 660000 loss = -0.5998 grad_norm = 3.4071 grad_penalty = 0.0596 regularization = 0.0000 true_logits = 0.1375 fake_logits = -0.5219 true_prob = 0.5337 fake_prob = 0.4265 
2022-05-01 06:20:30.723977 - gail/main.py:132 - [Evaluate] iter = 660000 episode={ returns = 39.7901 lengths = 22 } discounted_episode={ returns = 39.0390 lengths = 22 } 
2022-05-01 06:20:40.923250 - gail/main.py:164 - [TRPO] iter = 661000 dist_mean = 0.0279 dist_std = 0.2129 vf_loss = 0.0923 grad_norm = 2.7661 nat_grad_norm = 0.1370 cg_residual = 0.4140 step_size = 0.4245 reward = -0.0000 fps = 73 mse_loss = 0.5710 
2022-05-01 06:20:50.549239 - gail/main.py:164 - [TRPO] iter = 662000 dist_mean = 0.0163 dist_std = 0.2119 vf_loss = 0.1038 grad_norm = 1.7623 nat_grad_norm = 0.2006 cg_residual = 1.2556 step_size = 0.3453 reward = 0.0000 fps = 42 mse_loss = 0.6785 
2022-05-01 06:21:00.556358 - gail/main.py:164 - [TRPO] iter = 663000 dist_mean = 0.0559 dist_std = 0.2108 vf_loss = 0.0516 grad_norm = 1.4934 nat_grad_norm = 0.1546 cg_residual = 0.7723 step_size = 0.4167 reward = -0.0000 fps = 30 mse_loss = 0.5643 
2022-05-01 06:21:10.898062 - gail/main.py:164 - [TRPO] iter = 664000 dist_mean = 0.2724 dist_std = 0.2101 vf_loss = 0.1402 grad_norm = 1.4713 nat_grad_norm = 0.1879 cg_residual = 0.3030 step_size = 0.4228 reward = 0.0000 fps = 22 mse_loss = 0.6901 
2022-05-01 06:21:20.913206 - gail/main.py:164 - [TRPO] iter = 665000 dist_mean = 0.1237 dist_std = 0.2101 vf_loss = 0.1258 grad_norm = 1.8437 nat_grad_norm = 0.1391 cg_residual = 0.6656 step_size = 0.4230 reward = -0.0000 fps = 18 mse_loss = 0.6403 
2022-05-01 06:21:21.139646 - gail/main.py:191 - [Discriminator] iter = 665000 loss = -1.1387 grad_norm = 2.7090 grad_penalty = 0.0911 regularization = 0.0000 true_logits = 0.1612 fake_logits = -1.0686 true_prob = 0.5363 fake_prob = 0.3590 
2022-05-01 06:21:24.527487 - gail/main.py:132 - [Evaluate] iter = 665000 episode={ returns = 39.6431 lengths = 22 } discounted_episode={ returns = 37.9538 lengths = 22 } 
2022-05-01 06:21:34.732020 - gail/main.py:164 - [TRPO] iter = 666000 dist_mean = 0.0554 dist_std = 0.2097 vf_loss = 0.6054 grad_norm = 1.4736 nat_grad_norm = 0.0696 cg_residual = 0.1588 step_size = 0.8837 reward = 0.0000 fps = 73 mse_loss = 0.5627 
2022-05-01 06:21:45.213319 - gail/main.py:164 - [TRPO] iter = 667000 dist_mean = 0.2970 dist_std = 0.2105 vf_loss = 0.3510 grad_norm = 1.8636 nat_grad_norm = 0.1348 cg_residual = 0.3580 step_size = 0.4727 reward = 0.0000 fps = 41 mse_loss = 0.5866 
2022-05-01 06:21:55.232024 - gail/main.py:164 - [TRPO] iter = 668000 dist_mean = 0.0695 dist_std = 0.2114 vf_loss = 1.4042 grad_norm = 1.4649 nat_grad_norm = 0.0897 cg_residual = 0.2470 step_size = 0.6519 reward = 0.0000 fps = 29 mse_loss = 0.5612 
2022-05-01 06:22:05.850248 - gail/main.py:164 - [TRPO] iter = 669000 dist_mean = 0.1631 dist_std = 0.2113 vf_loss = 0.2643 grad_norm = 1.8206 nat_grad_norm = 0.1473 cg_residual = 0.9078 step_size = 0.4402 reward = -0.0000 fps = 22 mse_loss = 0.6326 
2022-05-01 06:22:16.348522 - gail/main.py:164 - [TRPO] iter = 670000 dist_mean = 0.0078 dist_std = 0.2117 vf_loss = 0.9131 grad_norm = 1.8003 nat_grad_norm = 0.0986 cg_residual = 0.2800 step_size = 0.5332 reward = -0.0000 fps = 18 mse_loss = 0.5564 
2022-05-01 06:22:16.610044 - gail/main.py:191 - [Discriminator] iter = 670000 loss = -0.4174 grad_norm = 2.6469 grad_penalty = 0.0587 regularization = 0.0000 true_logits = 0.1623 fake_logits = -0.3138 true_prob = 0.5351 fake_prob = 0.4535 
2022-05-01 06:22:26.412796 - gail/main.py:132 - [Evaluate] iter = 670000 episode={ returns = 39.4099 lengths = 22 } discounted_episode={ returns = 258.2804 lengths = 120 } 
2022-05-01 06:22:36.547697 - gail/main.py:164 - [TRPO] iter = 671000 dist_mean = 0.0500 dist_std = 0.2129 vf_loss = 0.7283 grad_norm = 1.7762 nat_grad_norm = 0.1257 cg_residual = 0.6426 step_size = 0.5713 reward = 0.0000 fps = 50 mse_loss = 0.6507 
2022-05-01 06:22:46.550888 - gail/main.py:164 - [TRPO] iter = 672000 dist_mean = 0.0807 dist_std = 0.2130 vf_loss = 0.1420 grad_norm = 1.5845 nat_grad_norm = 0.1466 cg_residual = 0.3601 step_size = 0.4835 reward = 0.0000 fps = 33 mse_loss = 0.6456 
2022-05-01 06:22:56.668331 - gail/main.py:164 - [TRPO] iter = 673000 dist_mean = 0.0633 dist_std = 0.2142 vf_loss = 1.0321 grad_norm = 2.0005 nat_grad_norm = 0.1042 cg_residual = 0.2314 step_size = 0.5405 reward = 0.0000 fps = 24 mse_loss = 0.6111 
2022-05-01 06:23:07.120739 - gail/main.py:164 - [TRPO] iter = 674000 dist_mean = 0.0545 dist_std = 0.2135 vf_loss = 0.4864 grad_norm = 1.4830 nat_grad_norm = 0.1026 cg_residual = 0.2805 step_size = 0.6418 reward = 0.0000 fps = 19 mse_loss = 0.6689 
2022-05-01 06:23:16.915383 - gail/main.py:164 - [TRPO] iter = 675000 dist_mean = 0.0429 dist_std = 0.2133 vf_loss = 0.4814 grad_norm = 2.3590 nat_grad_norm = 0.1187 cg_residual = 0.5206 step_size = 0.5144 reward = -0.0000 fps = 16 mse_loss = 0.6188 
2022-05-01 06:23:17.158557 - gail/main.py:191 - [Discriminator] iter = 675000 loss = -0.4921 grad_norm = 2.8030 grad_penalty = 0.0573 regularization = 0.0000 true_logits = 0.1246 fake_logits = -0.4248 true_prob = 0.5260 fake_prob = 0.4362 
2022-05-01 06:25:12.022806 - gail/main.py:132 - [Evaluate] iter = 675000 episode={ returns = 2917.0147 lengths = 804 } discounted_episode={ returns = 2006.7144 lengths = 902 } 
2022-05-01 06:25:22.137707 - gail/main.py:164 - [TRPO] iter = 676000 dist_mean = 0.0251 dist_std = 0.2133 vf_loss = 0.3111 grad_norm = 2.7317 nat_grad_norm = 0.1456 cg_residual = 0.5488 step_size = 0.5139 reward = 0.0000 fps = 8 mse_loss = 0.6291 
2022-05-01 06:25:32.083661 - gail/main.py:164 - [TRPO] iter = 677000 dist_mean = 0.0686 dist_std = 0.2112 vf_loss = 0.2460 grad_norm = 2.2479 nat_grad_norm = 0.1317 cg_residual = 0.3320 step_size = 0.5263 reward = -0.0000 fps = 7 mse_loss = 0.6616 
2022-05-01 06:25:42.235686 - gail/main.py:164 - [TRPO] iter = 678000 dist_mean = 0.0492 dist_std = 0.2124 vf_loss = 0.0582 grad_norm = 2.4437 nat_grad_norm = 0.1511 cg_residual = 0.6749 step_size = 0.3767 reward = -0.0000 fps = 6 mse_loss = 0.6651 
2022-05-01 06:25:52.154251 - gail/main.py:164 - [TRPO] iter = 679000 dist_mean = 0.0523 dist_std = 0.2123 vf_loss = 0.0853 grad_norm = 2.0734 nat_grad_norm = 0.1391 cg_residual = 0.2331 step_size = 0.4452 reward = 0.0000 fps = 6 mse_loss = 0.5931 
2022-05-01 06:26:02.244926 - gail/main.py:164 - [TRPO] iter = 680000 dist_mean = 0.0348 dist_std = 0.2126 vf_loss = 0.1165 grad_norm = 1.8172 nat_grad_norm = 0.1299 cg_residual = 0.6630 step_size = 0.5181 reward = 0.0000 fps = 6 mse_loss = 0.6523 
2022-05-01 06:26:02.477402 - gail/main.py:191 - [Discriminator] iter = 680000 loss = -0.6034 grad_norm = 3.0724 grad_penalty = 0.0685 regularization = 0.0000 true_logits = -0.0144 fake_logits = -0.6863 true_prob = 0.5040 fake_prob = 0.3920 
2022-05-01 06:27:04.192654 - gail/main.py:132 - [Evaluate] iter = 680000 episode={ returns = 1831.6723 lengths = 511 } discounted_episode={ returns = 910.9556 lengths = 413 } 
2022-05-01 06:27:14.123534 - gail/main.py:164 - [TRPO] iter = 681000 dist_mean = 0.0686 dist_std = 0.2134 vf_loss = 0.1947 grad_norm = 2.5377 nat_grad_norm = 0.1383 cg_residual = 0.4878 step_size = 0.5101 reward = -0.0000 fps = 13 mse_loss = 0.5974 
2022-05-01 06:27:24.294480 - gail/main.py:164 - [TRPO] iter = 682000 dist_mean = 0.1126 dist_std = 0.2131 vf_loss = 0.0788 grad_norm = 1.7552 nat_grad_norm = 0.1051 cg_residual = 0.4813 step_size = 0.4970 reward = 0.0000 fps = 12 mse_loss = 0.5890 
2022-05-01 06:27:34.110238 - gail/main.py:164 - [TRPO] iter = 683000 dist_mean = 0.0936 dist_std = 0.2125 vf_loss = 0.0570 grad_norm = 2.4789 nat_grad_norm = 0.1286 cg_residual = 0.3529 step_size = 0.5122 reward = -0.0000 fps = 10 mse_loss = 0.4940 
2022-05-01 06:27:43.911643 - gail/main.py:164 - [TRPO] iter = 684000 dist_mean = 0.0448 dist_std = 0.2120 vf_loss = 0.3875 grad_norm = 1.8128 nat_grad_norm = 0.1171 cg_residual = 0.1746 step_size = 0.5601 reward = 0.0000 fps = 9 mse_loss = 0.5548 
2022-05-01 06:27:54.397848 - gail/main.py:164 - [TRPO] iter = 685000 dist_mean = 0.3056 dist_std = 0.2130 vf_loss = 0.7803 grad_norm = 1.7690 nat_grad_norm = 0.2571 cg_residual = 0.9458 step_size = 0.3067 reward = 0.0000 fps = 8 mse_loss = 0.5613 
2022-05-01 06:27:54.645379 - gail/main.py:191 - [Discriminator] iter = 685000 loss = -2.9069 grad_norm = 3.8116 grad_penalty = 0.2104 regularization = 0.0000 true_logits = 0.0807 fake_logits = -3.0367 true_prob = 0.5174 fake_prob = 0.1170 
2022-05-01 06:27:57.921591 - gail/main.py:132 - [Evaluate] iter = 685000 episode={ returns = 39.5203 lengths = 22 } discounted_episode={ returns = 38.7304 lengths = 22 } 
2022-05-01 06:28:08.392747 - gail/main.py:164 - [TRPO] iter = 686000 dist_mean = 0.0740 dist_std = 0.2131 vf_loss = 0.7967 grad_norm = 1.6480 nat_grad_norm = 0.1147 cg_residual = 0.3424 step_size = 0.5750 reward = 0.0000 fps = 72 mse_loss = 0.5724 
2022-05-01 06:28:18.784059 - gail/main.py:164 - [TRPO] iter = 687000 dist_mean = 0.4069 dist_std = 0.2129 vf_loss = 0.1507 grad_norm = 0.7504 nat_grad_norm = 0.0818 cg_residual = 0.0202 step_size = 1.0447 reward = -0.0000 fps = 41 mse_loss = 0.5288 
2022-05-01 06:28:28.523898 - gail/main.py:164 - [TRPO] iter = 688000 dist_mean = 0.0658 dist_std = 0.2161 vf_loss = 0.7774 grad_norm = 2.6425 nat_grad_norm = 0.1189 cg_residual = 0.3184 step_size = 0.4675 reward = 0.0000 fps = 29 mse_loss = 0.5843 
2022-05-01 06:28:39.307507 - gail/main.py:164 - [TRPO] iter = 689000 dist_mean = 0.4133 dist_std = 0.2153 vf_loss = 0.0707 grad_norm = 1.6221 nat_grad_norm = 0.0754 cg_residual = 0.0781 step_size = 0.8131 reward = 0.0000 fps = 22 mse_loss = 0.4910 
2022-05-01 06:28:49.913511 - gail/main.py:164 - [TRPO] iter = 690000 dist_mean = 0.3364 dist_std = 0.2182 vf_loss = 0.4130 grad_norm = 2.0242 nat_grad_norm = 0.1983 cg_residual = 0.4649 step_size = 0.3389 reward = 0.0000 fps = 18 mse_loss = 0.5310 
2022-05-01 06:28:50.129983 - gail/main.py:191 - [Discriminator] iter = 690000 loss = -3.2990 grad_norm = 3.4957 grad_penalty = 0.2553 regularization = 0.0000 true_logits = 0.3420 fake_logits = -3.2123 true_prob = 0.5576 fake_prob = 0.1169 
2022-05-01 06:28:53.506711 - gail/main.py:132 - [Evaluate] iter = 690000 episode={ returns = 40.1253 lengths = 23 } discounted_episode={ returns = 39.2622 lengths = 22 } 
2022-05-01 06:29:03.580100 - gail/main.py:164 - [TRPO] iter = 691000 dist_mean = 0.1648 dist_std = 0.2177 vf_loss = 0.7520 grad_norm = 2.1096 nat_grad_norm = 0.1376 cg_residual = 0.2869 step_size = 0.4519 reward = -0.0000 fps = 74 mse_loss = 0.5744 
2022-05-01 06:29:13.828935 - gail/main.py:164 - [TRPO] iter = 692000 dist_mean = 0.1144 dist_std = 0.2175 vf_loss = 0.1647 grad_norm = 2.3101 nat_grad_norm = 0.1720 cg_residual = 0.5189 step_size = 0.4214 reward = 0.0000 fps = 42 mse_loss = 0.5163 
2022-05-01 06:29:24.638106 - gail/main.py:164 - [TRPO] iter = 693000 dist_mean = 0.3630 dist_std = 0.2179 vf_loss = 1.9724 grad_norm = 1.2993 nat_grad_norm = 0.1502 cg_residual = 0.3182 step_size = 0.4404 reward = -0.0000 fps = 28 mse_loss = 0.5167 
2022-05-01 06:29:34.805365 - gail/main.py:164 - [TRPO] iter = 694000 dist_mean = 0.0852 dist_std = 0.2188 vf_loss = 0.2401 grad_norm = 1.5571 nat_grad_norm = 0.2144 cg_residual = 0.7012 step_size = 0.3858 reward = -0.0000 fps = 22 mse_loss = 0.5149 
2022-05-01 06:29:45.109974 - gail/main.py:164 - [TRPO] iter = 695000 dist_mean = 0.1130 dist_std = 0.2198 vf_loss = 1.1481 grad_norm = 1.2397 nat_grad_norm = 0.1602 cg_residual = 0.3556 step_size = 0.5079 reward = 0.0000 fps = 18 mse_loss = 0.5366 
2022-05-01 06:29:45.354349 - gail/main.py:191 - [Discriminator] iter = 695000 loss = -0.6674 grad_norm = 3.2255 grad_penalty = 0.1019 regularization = 0.0000 true_logits = 0.3941 fake_logits = -0.3752 true_prob = 0.5581 fake_prob = 0.4636 
2022-05-01 06:30:42.434996 - gail/main.py:132 - [Evaluate] iter = 695000 episode={ returns = 1647.8193 lengths = 511 } discounted_episode={ returns = 626.0782 lengths = 316 } 
2022-05-01 06:30:52.778538 - gail/main.py:164 - [TRPO] iter = 696000 dist_mean = 0.0561 dist_std = 0.2189 vf_loss = 0.3718 grad_norm = 1.6968 nat_grad_norm = 0.1587 cg_residual = 0.4018 step_size = 0.4259 reward = 0.0000 fps = 14 mse_loss = 0.5764 
2022-05-01 06:31:03.239754 - gail/main.py:164 - [TRPO] iter = 697000 dist_mean = 0.1080 dist_std = 0.2194 vf_loss = 1.0559 grad_norm = 1.8492 nat_grad_norm = 0.1026 cg_residual = 0.2767 step_size = 0.6306 reward = 0.0000 fps = 12 mse_loss = 0.4976 
2022-05-01 06:31:13.844051 - gail/main.py:164 - [TRPO] iter = 698000 dist_mean = 0.0953 dist_std = 0.2200 vf_loss = 0.6418 grad_norm = 2.5526 nat_grad_norm = 0.2679 cg_residual = 0.7493 step_size = 0.2508 reward = 0.0000 fps = 11 mse_loss = 0.5395 
2022-05-01 06:31:24.066122 - gail/main.py:164 - [TRPO] iter = 699000 dist_mean = 0.0712 dist_std = 0.2193 vf_loss = 0.5231 grad_norm = 1.8246 nat_grad_norm = 0.1233 cg_residual = 0.2671 step_size = 0.5352 reward = 0.0000 fps = 10 mse_loss = 0.5845 
2022-05-01 06:31:33.746917 - gail/main.py:164 - [TRPO] iter = 700000 dist_mean = 0.0988 dist_std = 0.2208 vf_loss = 0.2092 grad_norm = 2.2030 nat_grad_norm = 0.1814 cg_residual = 0.9007 step_size = 0.4204 reward = 0.0000 fps = 9 mse_loss = 0.5118 
2022-05-01 06:31:33.970472 - gail/main.py:191 - [Discriminator] iter = 700000 loss = -0.5191 grad_norm = 2.5700 grad_penalty = 0.0584 regularization = 0.0000 true_logits = 0.3038 fake_logits = -0.2738 true_prob = 0.5422 fake_prob = 0.4634 
2022-05-01 06:33:10.232974 - gail/main.py:132 - [Evaluate] iter = 700000 episode={ returns = 2424.3576 lengths = 706 } discounted_episode={ returns = 1484.8380 lengths = 706 } 
2022-05-01 06:33:20.086079 - gail/main.py:164 - [TRPO] iter = 701000 dist_mean = 0.0702 dist_std = 0.2189 vf_loss = 0.3141 grad_norm = 1.7711 nat_grad_norm = 0.1298 cg_residual = 0.4023 step_size = 0.4575 reward = 0.0000 fps = 9 mse_loss = 0.5219 
2022-05-01 06:33:29.988044 - gail/main.py:164 - [TRPO] iter = 702000 dist_mean = 0.0722 dist_std = 0.2200 vf_loss = 0.2316 grad_norm = 1.9771 nat_grad_norm = 0.1095 cg_residual = 0.2361 step_size = 0.5242 reward = -0.0000 fps = 8 mse_loss = 0.5150 
2022-05-01 06:33:39.749180 - gail/main.py:164 - [TRPO] iter = 703000 dist_mean = 0.0543 dist_std = 0.2205 vf_loss = 0.1568 grad_norm = 1.6301 nat_grad_norm = 0.1224 cg_residual = 0.2943 step_size = 0.5882 reward = -0.0000 fps = 7 mse_loss = 0.5268 
2022-05-01 06:33:49.581740 - gail/main.py:164 - [TRPO] iter = 704000 dist_mean = 0.0875 dist_std = 0.2219 vf_loss = 0.1491 grad_norm = 1.1406 nat_grad_norm = 0.1897 cg_residual = 0.4520 step_size = 0.4711 reward = 0.0000 fps = 7 mse_loss = 0.5254 
2022-05-01 06:33:59.209120 - gail/main.py:164 - [TRPO] iter = 705000 dist_mean = 0.0537 dist_std = 0.2220 vf_loss = 0.2002 grad_norm = 2.7440 nat_grad_norm = 0.1287 cg_residual = 0.5559 step_size = 0.4600 reward = -0.0000 fps = 6 mse_loss = 0.5861 
2022-05-01 06:33:59.416975 - gail/main.py:191 - [Discriminator] iter = 705000 loss = -0.3641 grad_norm = 2.7270 grad_penalty = 0.0438 regularization = 0.0000 true_logits = 0.2032 fake_logits = -0.2048 true_prob = 0.5311 fake_prob = 0.4781 
2022-05-01 06:36:11.352251 - gail/main.py:132 - [Evaluate] iter = 705000 episode={ returns = 3534.0326 lengths = 1000 } discounted_episode={ returns = 2155.1590 lengths = 1000 } 
2022-05-01 06:36:21.156484 - gail/main.py:164 - [TRPO] iter = 706000 dist_mean = 0.0684 dist_std = 0.2229 vf_loss = 0.0916 grad_norm = 1.7874 nat_grad_norm = 0.1773 cg_residual = 0.3521 step_size = 0.4102 reward = -0.0000 fps = 7 mse_loss = 0.5723 
2022-05-01 06:36:30.980051 - gail/main.py:164 - [TRPO] iter = 707000 dist_mean = 0.0497 dist_std = 0.2223 vf_loss = 0.1836 grad_norm = 1.6398 nat_grad_norm = 0.1620 cg_residual = 0.3634 step_size = 0.4396 reward = 0.0000 fps = 6 mse_loss = 0.5064 
2022-05-01 06:36:41.114709 - gail/main.py:164 - [TRPO] iter = 708000 dist_mean = 0.0606 dist_std = 0.2227 vf_loss = 0.2849 grad_norm = 2.4940 nat_grad_norm = 0.0950 cg_residual = 0.1841 step_size = 0.6231 reward = 0.0000 fps = 6 mse_loss = 0.5203 
2022-05-01 06:36:51.279114 - gail/main.py:164 - [TRPO] iter = 709000 dist_mean = 0.0480 dist_std = 0.2226 vf_loss = 0.1592 grad_norm = 1.6284 nat_grad_norm = 0.1432 cg_residual = 0.4102 step_size = 0.5446 reward = -0.0000 fps = 5 mse_loss = 0.5459 
2022-05-01 06:37:01.433724 - gail/main.py:164 - [TRPO] iter = 710000 dist_mean = 0.0639 dist_std = 0.2222 vf_loss = 0.2195 grad_norm = 1.4536 nat_grad_norm = 0.1597 cg_residual = 0.4742 step_size = 0.4307 reward = 0.0000 fps = 5 mse_loss = 0.5611 
2022-05-01 06:37:01.625800 - gail/main.py:191 - [Discriminator] iter = 710000 loss = -0.5689 grad_norm = 2.8692 grad_penalty = 0.0458 regularization = 0.0000 true_logits = 0.0434 fake_logits = -0.5713 true_prob = 0.5032 fake_prob = 0.4226 
2022-05-01 06:39:14.656383 - gail/main.py:132 - [Evaluate] iter = 710000 episode={ returns = 3573.6723 lengths = 1000 } discounted_episode={ returns = 2185.4098 lengths = 1000 } 
2022-05-01 06:39:24.395689 - gail/main.py:164 - [TRPO] iter = 711000 dist_mean = 0.0524 dist_std = 0.2231 vf_loss = 0.0882 grad_norm = 2.4274 nat_grad_norm = 0.1567 cg_residual = 0.5617 step_size = 0.4871 reward = -0.0000 fps = 7 mse_loss = 0.4937 
2022-05-01 06:39:33.850676 - gail/main.py:164 - [TRPO] iter = 712000 dist_mean = 0.0595 dist_std = 0.2241 vf_loss = 0.1401 grad_norm = 1.3592 nat_grad_norm = 0.0928 cg_residual = 0.1977 step_size = 0.7046 reward = -0.0000 fps = 6 mse_loss = 0.5186 
2022-05-01 06:39:44.091668 - gail/main.py:164 - [TRPO] iter = 713000 dist_mean = 0.0631 dist_std = 0.2243 vf_loss = 0.2000 grad_norm = 1.6725 nat_grad_norm = 0.1228 cg_residual = 0.6202 step_size = 0.4515 reward = -0.0000 fps = 6 mse_loss = 0.6426 
2022-05-01 06:39:53.561954 - gail/main.py:164 - [TRPO] iter = 714000 dist_mean = 0.0398 dist_std = 0.2246 vf_loss = 0.1941 grad_norm = 2.2947 nat_grad_norm = 0.1563 cg_residual = 0.5817 step_size = 0.4228 reward = -0.0000 fps = 5 mse_loss = 0.5917 
2022-05-01 06:40:03.457688 - gail/main.py:164 - [TRPO] iter = 715000 dist_mean = 0.0528 dist_std = 0.2251 vf_loss = 0.2289 grad_norm = 1.4637 nat_grad_norm = 0.1327 cg_residual = 0.2202 step_size = 0.4675 reward = 0.0000 fps = 5 mse_loss = 0.5027 
2022-05-01 06:40:03.675453 - gail/main.py:191 - [Discriminator] iter = 715000 loss = -0.5132 grad_norm = 3.1217 grad_penalty = 0.0538 regularization = 0.0000 true_logits = -0.1241 fake_logits = -0.6910 true_prob = 0.4735 fake_prob = 0.4053 
2022-05-01 06:40:06.946499 - gail/main.py:132 - [Evaluate] iter = 715000 episode={ returns = 39.1770 lengths = 22 } discounted_episode={ returns = 38.9987 lengths = 22 } 
2022-05-01 06:40:16.786701 - gail/main.py:164 - [TRPO] iter = 716000 dist_mean = 0.1192 dist_std = 0.2249 vf_loss = 0.0637 grad_norm = 2.4500 nat_grad_norm = 0.1575 cg_residual = 0.5550 step_size = 0.4469 reward = -0.0000 fps = 76 mse_loss = 0.5674 
2022-05-01 06:40:26.582075 - gail/main.py:164 - [TRPO] iter = 717000 dist_mean = 0.1826 dist_std = 0.2258 vf_loss = 0.0543 grad_norm = 1.5772 nat_grad_norm = 0.0925 cg_residual = 0.3539 step_size = 0.6144 reward = 0.0000 fps = 43 mse_loss = 0.5880 
2022-05-01 06:40:36.639171 - gail/main.py:164 - [TRPO] iter = 718000 dist_mean = 0.2024 dist_std = 0.2267 vf_loss = 0.3886 grad_norm = 1.3470 nat_grad_norm = 0.1201 cg_residual = 0.2673 step_size = 0.6159 reward = 0.0000 fps = 30 mse_loss = 0.5353 
2022-05-01 06:40:47.019267 - gail/main.py:164 - [TRPO] iter = 719000 dist_mean = 0.0475 dist_std = 0.2265 vf_loss = 0.0517 grad_norm = 1.8614 nat_grad_norm = 0.1547 cg_residual = 0.6279 step_size = 0.3939 reward = 0.0000 fps = 23 mse_loss = 0.5911 
2022-05-01 06:40:57.228036 - gail/main.py:164 - [TRPO] iter = 720000 dist_mean = 0.3072 dist_std = 0.2259 vf_loss = 0.9591 grad_norm = 2.4762 nat_grad_norm = 0.1319 cg_residual = 0.2382 step_size = 0.4632 reward = 0.0000 fps = 18 mse_loss = 0.4719 
2022-05-01 06:40:57.431472 - gail/main.py:191 - [Discriminator] iter = 720000 loss = -2.5549 grad_norm = 3.5460 grad_penalty = 0.1542 regularization = 0.0000 true_logits = -0.0418 fake_logits = -2.7508 true_prob = 0.4928 fake_prob = 0.1885 
2022-05-01 06:41:00.628624 - gail/main.py:132 - [Evaluate] iter = 720000 episode={ returns = 39.1534 lengths = 22 } discounted_episode={ returns = 38.6759 lengths = 22 } 
2022-05-01 06:41:10.802729 - gail/main.py:164 - [TRPO] iter = 721000 dist_mean = 0.4624 dist_std = 0.2270 vf_loss = 0.4515 grad_norm = 1.4325 nat_grad_norm = 0.0962 cg_residual = 0.0969 step_size = 0.9227 reward = 0.0000 fps = 74 mse_loss = 0.5122 
2022-05-01 06:41:21.077480 - gail/main.py:164 - [TRPO] iter = 722000 dist_mean = 0.0966 dist_std = 0.2247 vf_loss = 0.6421 grad_norm = 1.8309 nat_grad_norm = 0.1152 cg_residual = 0.3340 step_size = 0.5534 reward = -0.0000 fps = 42 mse_loss = 0.5189 
2022-05-01 06:41:30.818165 - gail/main.py:164 - [TRPO] iter = 723000 dist_mean = 0.0825 dist_std = 0.2252 vf_loss = 0.8574 grad_norm = 1.0890 nat_grad_norm = 0.1073 cg_residual = 0.1172 step_size = 0.5838 reward = 0.0000 fps = 29 mse_loss = 0.4951 
2022-05-01 06:41:40.949003 - gail/main.py:164 - [TRPO] iter = 724000 dist_mean = 0.0872 dist_std = 0.2256 vf_loss = 0.0845 grad_norm = 2.1662 nat_grad_norm = 0.1190 cg_residual = 0.4595 step_size = 0.5352 reward = -0.0000 fps = 22 mse_loss = 0.4929 
2022-05-01 06:41:50.912404 - gail/main.py:164 - [TRPO] iter = 725000 dist_mean = 0.2924 dist_std = 0.2261 vf_loss = 0.4288 grad_norm = 2.2218 nat_grad_norm = 0.2487 cg_residual = 0.4300 step_size = 0.3173 reward = 0.0000 fps = 18 mse_loss = 0.5249 
2022-05-01 06:41:51.168897 - gail/main.py:191 - [Discriminator] iter = 725000 loss = -2.5173 grad_norm = 3.0684 grad_penalty = 0.1847 regularization = 0.0000 true_logits = 0.1475 fake_logits = -2.5545 true_prob = 0.5186 fake_prob = 0.2215 
2022-05-01 06:41:54.027120 - gail/main.py:132 - [Evaluate] iter = 725000 episode={ returns = 39.3691 lengths = 22 } discounted_episode={ returns = 38.1594 lengths = 22 } 
2022-05-01 06:42:04.222188 - gail/main.py:164 - [TRPO] iter = 726000 dist_mean = 0.1867 dist_std = 0.2266 vf_loss = 0.6304 grad_norm = 2.0996 nat_grad_norm = 0.1213 cg_residual = 0.3464 step_size = 0.5021 reward = -0.0000 fps = 76 mse_loss = 0.5408 
2022-05-01 06:42:14.357526 - gail/main.py:164 - [TRPO] iter = 727000 dist_mean = 0.1752 dist_std = 0.2278 vf_loss = 1.0475 grad_norm = 1.1595 nat_grad_norm = 0.1047 cg_residual = 0.1919 step_size = 0.6665 reward = -0.0000 fps = 43 mse_loss = 0.6037 
2022-05-01 06:42:23.874961 - gail/main.py:164 - [TRPO] iter = 728000 dist_mean = 0.1242 dist_std = 0.2277 vf_loss = 0.0793 grad_norm = 1.8181 nat_grad_norm = 0.1675 cg_residual = 0.4668 step_size = 0.4078 reward = 0.0000 fps = 30 mse_loss = 0.5258 
2022-05-01 06:42:33.803055 - gail/main.py:164 - [TRPO] iter = 729000 dist_mean = 0.1022 dist_std = 0.2278 vf_loss = 0.6817 grad_norm = 1.5989 nat_grad_norm = 0.0974 cg_residual = 0.3850 step_size = 0.6409 reward = 0.0000 fps = 23 mse_loss = 0.5868 
2022-05-01 06:42:43.767394 - gail/main.py:164 - [TRPO] iter = 730000 dist_mean = 0.1051 dist_std = 0.2273 vf_loss = 0.5506 grad_norm = 2.1636 nat_grad_norm = 0.1515 cg_residual = 0.7724 step_size = 0.4464 reward = 0.0000 fps = 19 mse_loss = 0.5397 
2022-05-01 06:42:43.941445 - gail/main.py:191 - [Discriminator] iter = 730000 loss = -0.4137 grad_norm = 2.5874 grad_penalty = 0.0738 regularization = 0.0000 true_logits = 0.2044 fake_logits = -0.2831 true_prob = 0.5262 fake_prob = 0.4857 
2022-05-01 06:43:06.700824 - gail/main.py:132 - [Evaluate] iter = 730000 episode={ returns = 746.3294 lengths = 218 } discounted_episode={ returns = 255.2308 lengths = 120 } 
2022-05-01 06:43:16.620717 - gail/main.py:164 - [TRPO] iter = 731000 dist_mean = 0.0733 dist_std = 0.2283 vf_loss = 0.0794 grad_norm = 1.9655 nat_grad_norm = 0.1386 cg_residual = 0.3846 step_size = 0.5006 reward = 0.0000 fps = 30 mse_loss = 0.5343 
2022-05-01 06:43:26.249291 - gail/main.py:164 - [TRPO] iter = 732000 dist_mean = 0.0859 dist_std = 0.2279 vf_loss = 0.3951 grad_norm = 1.5119 nat_grad_norm = 0.1138 cg_residual = 0.1935 step_size = 0.5643 reward = 0.0000 fps = 23 mse_loss = 0.5133 
2022-05-01 06:43:36.169810 - gail/main.py:164 - [TRPO] iter = 733000 dist_mean = 0.1090 dist_std = 0.2284 vf_loss = 0.3420 grad_norm = 1.4457 nat_grad_norm = 0.1342 cg_residual = 0.4118 step_size = 0.5246 reward = -0.0000 fps = 19 mse_loss = 0.5558 
2022-05-01 06:43:45.856818 - gail/main.py:164 - [TRPO] iter = 734000 dist_mean = 0.0438 dist_std = 0.2295 vf_loss = 0.1544 grad_norm = 2.0924 nat_grad_norm = 0.1315 cg_residual = 0.3669 step_size = 0.5125 reward = -0.0000 fps = 16 mse_loss = 0.6402 
2022-05-01 06:43:55.312834 - gail/main.py:164 - [TRPO] iter = 735000 dist_mean = 0.0549 dist_std = 0.2299 vf_loss = 0.1576 grad_norm = 1.9205 nat_grad_norm = 0.1207 cg_residual = 0.4879 step_size = 0.5628 reward = 0.0000 fps = 14 mse_loss = 0.5279 
2022-05-01 06:43:55.523011 - gail/main.py:191 - [Discriminator] iter = 735000 loss = -0.4114 grad_norm = 2.8630 grad_penalty = 0.0569 regularization = 0.0000 true_logits = 0.0921 fake_logits = -0.3763 true_prob = 0.5120 fake_prob = 0.4690 
2022-05-01 06:44:58.011527 - gail/main.py:132 - [Evaluate] iter = 735000 episode={ returns = 1442.3318 lengths = 413 } discounted_episode={ returns = 1108.4872 lengths = 511 } 
2022-05-01 06:45:08.111206 - gail/main.py:164 - [TRPO] iter = 736000 dist_mean = 0.0567 dist_std = 0.2285 vf_loss = 0.3024 grad_norm = 1.0634 nat_grad_norm = 0.1220 cg_residual = 0.1610 step_size = 0.6198 reward = 0.0000 fps = 13 mse_loss = 0.5665 
2022-05-01 06:45:17.854499 - gail/main.py:164 - [TRPO] iter = 737000 dist_mean = 0.0656 dist_std = 0.2289 vf_loss = 0.1110 grad_norm = 1.4503 nat_grad_norm = 0.1228 cg_residual = 0.5071 step_size = 0.5552 reward = -0.0000 fps = 12 mse_loss = 0.6085 
2022-05-01 06:45:27.595010 - gail/main.py:164 - [TRPO] iter = 738000 dist_mean = 0.0897 dist_std = 0.2292 vf_loss = 0.2338 grad_norm = 1.4366 nat_grad_norm = 0.1377 cg_residual = 0.3822 step_size = 0.5132 reward = -0.0000 fps = 10 mse_loss = 0.6460 
2022-05-01 06:45:37.374501 - gail/main.py:164 - [TRPO] iter = 739000 dist_mean = 0.0712 dist_std = 0.2297 vf_loss = 0.1180 grad_norm = 1.5250 nat_grad_norm = 0.1050 cg_residual = 0.1274 step_size = 0.5886 reward = 0.0000 fps = 9 mse_loss = 0.5829 
2022-05-01 06:45:47.195903 - gail/main.py:164 - [TRPO] iter = 740000 dist_mean = 0.0575 dist_std = 0.2294 vf_loss = 0.0628 grad_norm = 2.1004 nat_grad_norm = 0.2478 cg_residual = 0.8789 step_size = 0.2866 reward = -0.0000 fps = 8 mse_loss = 0.5528 
2022-05-01 06:45:47.373806 - gail/main.py:191 - [Discriminator] iter = 740000 loss = -0.5594 grad_norm = 2.7715 grad_penalty = 0.0662 regularization = 0.0000 true_logits = -0.1182 fake_logits = -0.7439 true_prob = 0.4835 fake_prob = 0.4182 
2022-05-01 06:45:50.520544 - gail/main.py:132 - [Evaluate] iter = 740000 episode={ returns = 39.5833 lengths = 22 } discounted_episode={ returns = 39.0917 lengths = 22 } 
2022-05-01 06:45:59.912535 - gail/main.py:164 - [TRPO] iter = 741000 dist_mean = 0.0468 dist_std = 0.2294 vf_loss = 0.0527 grad_norm = 1.8214 nat_grad_norm = 0.1409 cg_residual = 0.4944 step_size = 0.5044 reward = -0.0000 fps = 79 mse_loss = 0.5541 
2022-05-01 06:46:09.718220 - gail/main.py:164 - [TRPO] iter = 742000 dist_mean = 0.0623 dist_std = 0.2291 vf_loss = 0.0342 grad_norm = 1.7064 nat_grad_norm = 0.1610 cg_residual = 0.5624 step_size = 0.4658 reward = 0.0000 fps = 44 mse_loss = 0.5303 
2022-05-01 06:46:19.486888 - gail/main.py:164 - [TRPO] iter = 743000 dist_mean = 0.1104 dist_std = 0.2284 vf_loss = 0.2130 grad_norm = 1.2694 nat_grad_norm = 0.1331 cg_residual = 0.1931 step_size = 0.5785 reward = 0.0000 fps = 31 mse_loss = 0.5851 
2022-05-01 06:46:29.431085 - gail/main.py:164 - [TRPO] iter = 744000 dist_mean = 0.1936 dist_std = 0.2283 vf_loss = 0.0375 grad_norm = 2.5216 nat_grad_norm = 0.1957 cg_residual = 1.7286 step_size = 0.3614 reward = 0.0000 fps = 23 mse_loss = 0.5301 
2022-05-01 06:46:39.834606 - gail/main.py:164 - [TRPO] iter = 745000 dist_mean = 0.2792 dist_std = 0.2283 vf_loss = 0.1383 grad_norm = 1.2369 nat_grad_norm = 0.1481 cg_residual = 0.3375 step_size = 0.5082 reward = 0.0000 fps = 19 mse_loss = 0.5453 
2022-05-01 06:46:40.091850 - gail/main.py:191 - [Discriminator] iter = 745000 loss = -2.4269 grad_norm = 4.0618 grad_penalty = 0.1598 regularization = 0.0000 true_logits = -0.1704 fake_logits = -2.7571 true_prob = 0.4764 fake_prob = 0.1969 
2022-05-01 06:46:43.279509 - gail/main.py:132 - [Evaluate] iter = 745000 episode={ returns = 39.0925 lengths = 22 } discounted_episode={ returns = 38.8650 lengths = 22 } 
2022-05-01 06:46:53.422027 - gail/main.py:164 - [TRPO] iter = 746000 dist_mean = 0.0864 dist_std = 0.2266 vf_loss = 0.0958 grad_norm = 1.8263 nat_grad_norm = 0.1516 cg_residual = 0.5671 step_size = 0.4326 reward = -0.0000 fps = 75 mse_loss = 0.5756 
2022-05-01 06:47:03.247051 - gail/main.py:164 - [TRPO] iter = 747000 dist_mean = 0.0493 dist_std = 0.2268 vf_loss = 0.3857 grad_norm = 1.4144 nat_grad_norm = 0.1359 cg_residual = 0.4364 step_size = 0.5240 reward = 0.0000 fps = 43 mse_loss = 0.5291 
2022-05-01 06:47:13.136396 - gail/main.py:164 - [TRPO] iter = 748000 dist_mean = 0.0380 dist_std = 0.2278 vf_loss = 0.0391 grad_norm = 1.6569 nat_grad_norm = 0.1560 cg_residual = 0.8337 step_size = 0.4202 reward = 0.0000 fps = 30 mse_loss = 0.5738 
2022-05-01 06:47:22.539066 - gail/main.py:164 - [TRPO] iter = 749000 dist_mean = 0.0136 dist_std = 0.2271 vf_loss = 0.0379 grad_norm = 2.2581 nat_grad_norm = 0.1505 cg_residual = 0.3794 step_size = 0.4207 reward = 0.0000 fps = 23 mse_loss = 0.5607 
2022-05-01 06:47:32.140825 - gail/main.py:164 - [TRPO] iter = 750000 dist_mean = -0.0012 dist_std = 0.2266 vf_loss = 0.0306 grad_norm = 1.8199 nat_grad_norm = 0.1849 cg_residual = 0.5488 step_size = 0.3454 reward = 0.0000 fps = 19 mse_loss = 0.4985 
2022-05-01 06:47:32.331195 - gail/main.py:191 - [Discriminator] iter = 750000 loss = -0.4258 grad_norm = 3.1538 grad_penalty = 0.0828 regularization = 0.0000 true_logits = 0.0418 fake_logits = -0.4668 true_prob = 0.5091 fake_prob = 0.4569 
2022-05-01 06:47:54.797250 - gail/main.py:132 - [Evaluate] iter = 750000 episode={ returns = 395.1674 lengths = 120 } discounted_episode={ returns = 466.5748 lengths = 218 } 
2022-05-01 06:48:04.788139 - gail/main.py:164 - [TRPO] iter = 751000 dist_mean = 0.0274 dist_std = 0.2267 vf_loss = 0.0536 grad_norm = 2.4111 nat_grad_norm = 0.1640 cg_residual = 0.5383 step_size = 0.3948 reward = 0.0000 fps = 30 mse_loss = 0.5322 
2022-05-01 06:48:14.974293 - gail/main.py:164 - [TRPO] iter = 752000 dist_mean = 0.0156 dist_std = 0.2253 vf_loss = 0.0271 grad_norm = 2.3914 nat_grad_norm = 0.1535 cg_residual = 0.6167 step_size = 0.3974 reward = 0.0000 fps = 23 mse_loss = 0.5910 
2022-05-01 06:48:25.172824 - gail/main.py:164 - [TRPO] iter = 753000 dist_mean = 0.0659 dist_std = 0.2243 vf_loss = 0.0444 grad_norm = 1.6244 nat_grad_norm = 0.1457 cg_residual = 0.5463 step_size = 0.4626 reward = -0.0000 fps = 18 mse_loss = 0.5865 
2022-05-01 06:48:35.483999 - gail/main.py:164 - [TRPO] iter = 754000 dist_mean = 0.0987 dist_std = 0.2238 vf_loss = 0.0488 grad_norm = 2.1622 nat_grad_norm = 0.1829 cg_residual = 0.6909 step_size = 0.3861 reward = -0.0000 fps = 15 mse_loss = 0.6310 
2022-05-01 06:48:45.262531 - gail/main.py:164 - [TRPO] iter = 755000 dist_mean = 0.0721 dist_std = 0.2233 vf_loss = 0.3476 grad_norm = 1.7364 nat_grad_norm = 0.1008 cg_residual = 0.1779 step_size = 0.5611 reward = 0.0000 fps = 13 mse_loss = 0.5752 
2022-05-01 06:48:45.456752 - gail/main.py:191 - [Discriminator] iter = 755000 loss = -0.4160 grad_norm = 3.9875 grad_penalty = 0.0607 regularization = 0.0000 true_logits = -0.1646 fake_logits = -0.6413 true_prob = 0.4792 fake_prob = 0.4282 
2022-05-01 06:48:55.609323 - gail/main.py:132 - [Evaluate] iter = 755000 episode={ returns = 39.6584 lengths = 22 } discounted_episode={ returns = 249.3839 lengths = 120 } 
2022-05-01 06:49:05.674230 - gail/main.py:164 - [TRPO] iter = 756000 dist_mean = 0.0613 dist_std = 0.2229 vf_loss = 0.1457 grad_norm = 2.2409 nat_grad_norm = 0.1086 cg_residual = 0.4272 step_size = 0.5718 reward = -0.0000 fps = 49 mse_loss = 0.6158 
2022-05-01 06:49:15.607998 - gail/main.py:164 - [TRPO] iter = 757000 dist_mean = 0.0376 dist_std = 0.2218 vf_loss = 0.0420 grad_norm = 2.5194 nat_grad_norm = 0.1606 cg_residual = 0.2129 step_size = 0.4651 reward = 0.0000 fps = 33 mse_loss = 0.5319 
2022-05-01 06:49:25.507396 - gail/main.py:164 - [TRPO] iter = 758000 dist_mean = 0.1154 dist_std = 0.2210 vf_loss = 0.0437 grad_norm = 2.0577 nat_grad_norm = 0.1463 cg_residual = 0.5545 step_size = 0.4204 reward = -0.0000 fps = 24 mse_loss = 0.5549 
2022-05-01 06:49:35.568447 - gail/main.py:164 - [TRPO] iter = 759000 dist_mean = 0.0554 dist_std = 0.2211 vf_loss = 0.2751 grad_norm = 2.8547 nat_grad_norm = 0.1284 cg_residual = 0.4152 step_size = 0.5055 reward = 0.0000 fps = 19 mse_loss = 0.5970 
2022-05-01 06:49:45.732277 - gail/main.py:164 - [TRPO] iter = 760000 dist_mean = 0.1274 dist_std = 0.2199 vf_loss = 0.0527 grad_norm = 2.0262 nat_grad_norm = 0.1415 cg_residual = 0.3405 step_size = 0.4301 reward = -0.0000 fps = 16 mse_loss = 0.5815 
2022-05-01 06:49:45.953645 - gail/main.py:191 - [Discriminator] iter = 760000 loss = -1.1027 grad_norm = 3.8853 grad_penalty = 0.0963 regularization = 0.0000 true_logits = -0.1563 fake_logits = -1.3553 true_prob = 0.4781 fake_prob = 0.3301 
2022-05-01 06:49:49.268751 - gail/main.py:132 - [Evaluate] iter = 760000 episode={ returns = 39.8869 lengths = 22 } discounted_episode={ returns = 39.0889 lengths = 22 } 
2022-05-01 06:49:59.214246 - gail/main.py:164 - [TRPO] iter = 761000 dist_mean = 0.0706 dist_std = 0.2190 vf_loss = 0.1225 grad_norm = 1.5645 nat_grad_norm = 0.1284 cg_residual = 0.2934 step_size = 0.5045 reward = 0.0000 fps = 75 mse_loss = 0.5286 
2022-05-01 06:50:09.479908 - gail/main.py:164 - [TRPO] iter = 762000 dist_mean = 0.0570 dist_std = 0.2186 vf_loss = 0.2664 grad_norm = 1.5293 nat_grad_norm = 0.1290 cg_residual = 0.4632 step_size = 0.4676 reward = -0.0000 fps = 42 mse_loss = 0.5467 
2022-05-01 06:50:19.443160 - gail/main.py:164 - [TRPO] iter = 763000 dist_mean = 0.0467 dist_std = 0.2183 vf_loss = 0.0347 grad_norm = 1.4991 nat_grad_norm = 0.1736 cg_residual = 0.4826 step_size = 0.4204 reward = 0.0000 fps = 29 mse_loss = 0.5540 
2022-05-01 06:50:29.522848 - gail/main.py:164 - [TRPO] iter = 764000 dist_mean = 0.2429 dist_std = 0.2171 vf_loss = 0.0834 grad_norm = 2.3247 nat_grad_norm = 0.1505 cg_residual = 0.4660 step_size = 0.4216 reward = -0.0000 fps = 22 mse_loss = 0.5455 
2022-05-01 06:50:39.872065 - gail/main.py:164 - [TRPO] iter = 765000 dist_mean = 0.1479 dist_std = 0.2177 vf_loss = 0.6762 grad_norm = 0.9886 nat_grad_norm = 0.0788 cg_residual = 0.1430 step_size = 0.7727 reward = -0.0000 fps = 18 mse_loss = 0.5430 
2022-05-01 06:50:40.106952 - gail/main.py:191 - [Discriminator] iter = 765000 loss = -1.1163 grad_norm = 3.1111 grad_penalty = 0.0704 regularization = 0.0000 true_logits = -0.0775 fake_logits = -1.2642 true_prob = 0.4931 fake_prob = 0.3589 
2022-05-01 06:50:43.414632 - gail/main.py:132 - [Evaluate] iter = 765000 episode={ returns = 39.7434 lengths = 22 } discounted_episode={ returns = 39.3879 lengths = 22 } 
2022-05-01 06:50:53.872269 - gail/main.py:164 - [TRPO] iter = 766000 dist_mean = 0.3144 dist_std = 0.2177 vf_loss = 0.1930 grad_norm = 1.8806 nat_grad_norm = 0.1236 cg_residual = 0.5775 step_size = 0.5182 reward = 0.0000 fps = 72 mse_loss = 0.5027 
2022-05-01 06:51:03.451148 - gail/main.py:164 - [TRPO] iter = 767000 dist_mean = 0.0559 dist_std = 0.2184 vf_loss = 0.0985 grad_norm = 2.3278 nat_grad_norm = 0.1545 cg_residual = 0.4948 step_size = 0.4118 reward = -0.0000 fps = 42 mse_loss = 0.5981 
2022-05-01 06:51:13.468258 - gail/main.py:164 - [TRPO] iter = 768000 dist_mean = 0.1267 dist_std = 0.2191 vf_loss = 0.1700 grad_norm = 2.6066 nat_grad_norm = 0.1852 cg_residual = 0.4826 step_size = 0.3462 reward = 0.0000 fps = 30 mse_loss = 0.5404 
2022-05-01 06:51:23.395141 - gail/main.py:164 - [TRPO] iter = 769000 dist_mean = 0.1812 dist_std = 0.2184 vf_loss = 0.2230 grad_norm = 1.7549 nat_grad_norm = 0.1261 cg_residual = 0.2877 step_size = 0.5315 reward = -0.0000 fps = 23 mse_loss = 0.5183 
2022-05-01 06:51:33.147929 - gail/main.py:164 - [TRPO] iter = 770000 dist_mean = 0.1099 dist_std = 0.2192 vf_loss = 0.2149 grad_norm = 1.7176 nat_grad_norm = 0.1756 cg_residual = 0.3845 step_size = 0.4182 reward = -0.0000 fps = 18 mse_loss = 0.5440 
2022-05-01 06:51:33.364589 - gail/main.py:191 - [Discriminator] iter = 770000 loss = -1.0536 grad_norm = 2.4651 grad_penalty = 0.0907 regularization = 0.0000 true_logits = -0.0634 fake_logits = -1.2077 true_prob = 0.4972 fake_prob = 0.3447 
2022-05-01 06:51:52.300634 - gail/main.py:132 - [Evaluate] iter = 770000 episode={ returns = 39.5375 lengths = 22 } discounted_episode={ returns = 597.6502 lengths = 265 } 
2022-05-01 06:52:02.172036 - gail/main.py:164 - [TRPO] iter = 771000 dist_mean = 0.0635 dist_std = 0.2200 vf_loss = 0.1291 grad_norm = 2.3995 nat_grad_norm = 0.1444 cg_residual = 0.3685 step_size = 0.4265 reward = -0.0000 fps = 34 mse_loss = 0.5059 
2022-05-01 06:52:12.312793 - gail/main.py:164 - [TRPO] iter = 772000 dist_mean = 0.0303 dist_std = 0.2205 vf_loss = 0.2005 grad_norm = 4.2457 nat_grad_norm = 0.1868 cg_residual = 0.8710 step_size = 0.2939 reward = 0.0000 fps = 25 mse_loss = 0.5271 
2022-05-01 06:52:22.233145 - gail/main.py:164 - [TRPO] iter = 773000 dist_mean = 0.0287 dist_std = 0.2200 vf_loss = 0.0605 grad_norm = 2.0088 nat_grad_norm = 0.1737 cg_residual = 0.5888 step_size = 0.3713 reward = -0.0000 fps = 20 mse_loss = 0.5385 
2022-05-01 06:52:31.757766 - gail/main.py:164 - [TRPO] iter = 774000 dist_mean = 0.0298 dist_std = 0.2186 vf_loss = 0.0499 grad_norm = 2.5890 nat_grad_norm = 0.1889 cg_residual = 0.6745 step_size = 0.3475 reward = -0.0000 fps = 17 mse_loss = 0.4716 
2022-05-01 06:52:41.235273 - gail/main.py:164 - [TRPO] iter = 775000 dist_mean = 0.0410 dist_std = 0.2180 vf_loss = 0.4022 grad_norm = 1.7987 nat_grad_norm = 0.0648 cg_residual = 0.1039 step_size = 0.8210 reward = -0.0000 fps = 14 mse_loss = 0.5757 
2022-05-01 06:52:41.457875 - gail/main.py:191 - [Discriminator] iter = 775000 loss = -0.3439 grad_norm = 2.7930 grad_penalty = 0.0548 regularization = 0.0000 true_logits = -0.1737 fake_logits = -0.5725 true_prob = 0.4743 fake_prob = 0.4283 
2022-05-01 06:54:32.417856 - gail/main.py:132 - [Evaluate] iter = 775000 episode={ returns = 3058.3601 lengths = 852 } discounted_episode={ returns = 1834.0381 lengths = 805 } 
2022-05-01 06:54:42.107151 - gail/main.py:164 - [TRPO] iter = 776000 dist_mean = 0.0415 dist_std = 0.2177 vf_loss = 0.3398 grad_norm = 1.2812 nat_grad_norm = 0.1133 cg_residual = 0.3109 step_size = 0.6761 reward = -0.0000 fps = 8 mse_loss = 0.5719 
2022-05-01 06:54:51.978671 - gail/main.py:164 - [TRPO] iter = 777000 dist_mean = 0.0296 dist_std = 0.2187 vf_loss = 0.0992 grad_norm = 2.0865 nat_grad_norm = 0.1273 cg_residual = 0.7171 step_size = 0.4944 reward = 0.0000 fps = 7 mse_loss = 0.4919 
2022-05-01 06:55:02.008704 - gail/main.py:164 - [TRPO] iter = 778000 dist_mean = 0.0555 dist_std = 0.2187 vf_loss = 0.0507 grad_norm = 2.5785 nat_grad_norm = 0.1568 cg_residual = 0.8417 step_size = 0.3785 reward = -0.0000 fps = 7 mse_loss = 0.5107 
2022-05-01 06:55:11.797541 - gail/main.py:164 - [TRPO] iter = 779000 dist_mean = 0.0350 dist_std = 0.2188 vf_loss = 0.3164 grad_norm = 1.7839 nat_grad_norm = 0.1013 cg_residual = 0.2577 step_size = 0.5206 reward = -0.0000 fps = 6 mse_loss = 0.4881 
2022-05-01 06:55:21.989720 - gail/main.py:164 - [TRPO] iter = 780000 dist_mean = 0.0551 dist_std = 0.2190 vf_loss = 0.1309 grad_norm = 1.7169 nat_grad_norm = 0.1032 cg_residual = 0.2295 step_size = 0.5691 reward = -0.0000 fps = 6 mse_loss = 0.5254 
2022-05-01 06:55:22.188454 - gail/main.py:191 - [Discriminator] iter = 780000 loss = -0.5938 grad_norm = 3.1769 grad_penalty = 0.0533 regularization = 0.0000 true_logits = -0.2433 fake_logits = -0.8904 true_prob = 0.4648 fake_prob = 0.3843 
2022-05-01 06:55:25.385458 - gail/main.py:132 - [Evaluate] iter = 780000 episode={ returns = 39.3630 lengths = 22 } discounted_episode={ returns = 38.8342 lengths = 22 } 
2022-05-01 06:55:35.498776 - gail/main.py:164 - [TRPO] iter = 781000 dist_mean = 0.0655 dist_std = 0.2191 vf_loss = 0.2045 grad_norm = 1.6960 nat_grad_norm = 0.0949 cg_residual = 0.1835 step_size = 0.5701 reward = 0.0000 fps = 75 mse_loss = 0.4756 
2022-05-01 06:55:45.594733 - gail/main.py:164 - [TRPO] iter = 782000 dist_mean = 0.0953 dist_std = 0.2195 vf_loss = 0.2597 grad_norm = 1.5936 nat_grad_norm = 0.0993 cg_residual = 0.1803 step_size = 0.6377 reward = 0.0000 fps = 42 mse_loss = 0.5105 
2022-05-01 06:55:55.661120 - gail/main.py:164 - [TRPO] iter = 783000 dist_mean = 0.0595 dist_std = 0.2193 vf_loss = 0.0430 grad_norm = 1.7050 nat_grad_norm = 0.1444 cg_residual = 0.4804 step_size = 0.4802 reward = -0.0000 fps = 29 mse_loss = 0.4787 
2022-05-01 06:56:06.236897 - gail/main.py:164 - [TRPO] iter = 784000 dist_mean = 0.1334 dist_std = 0.2198 vf_loss = 0.3063 grad_norm = 1.3616 nat_grad_norm = 0.1060 cg_residual = 0.1538 step_size = 0.5824 reward = -0.0000 fps = 22 mse_loss = 0.5295 
2022-05-01 06:56:16.109456 - gail/main.py:164 - [TRPO] iter = 785000 dist_mean = 0.1019 dist_std = 0.2190 vf_loss = 0.5025 grad_norm = 2.1280 nat_grad_norm = 0.1247 cg_residual = 0.2680 step_size = 0.4629 reward = 0.0000 fps = 18 mse_loss = 0.4891 
2022-05-01 06:56:16.351313 - gail/main.py:191 - [Discriminator] iter = 785000 loss = -0.8906 grad_norm = 2.7041 grad_penalty = 0.0703 regularization = 0.0000 true_logits = -0.4182 fake_logits = -1.3792 true_prob = 0.4352 fake_prob = 0.3285 
2022-05-01 06:56:19.657731 - gail/main.py:132 - [Evaluate] iter = 785000 episode={ returns = 39.1938 lengths = 22 } discounted_episode={ returns = 38.9785 lengths = 22 } 
2022-05-01 06:56:30.072204 - gail/main.py:164 - [TRPO] iter = 786000 dist_mean = 0.4832 dist_std = 0.2189 vf_loss = 0.0709 grad_norm = 1.8952 nat_grad_norm = 0.0529 cg_residual = 0.1114 step_size = 1.0500 reward = -0.0000 fps = 72 mse_loss = 0.4877 
2022-05-01 06:56:40.353150 - gail/main.py:164 - [TRPO] iter = 787000 dist_mean = 0.0493 dist_std = 0.2188 vf_loss = 0.0433 grad_norm = 2.2543 nat_grad_norm = 0.1176 cg_residual = 0.3446 step_size = 0.4272 reward = 0.0000 fps = 41 mse_loss = 0.4292 
2022-05-01 06:56:50.813971 - gail/main.py:164 - [TRPO] iter = 788000 dist_mean = 0.3735 dist_std = 0.2190 vf_loss = 0.6162 grad_norm = 1.8418 nat_grad_norm = 0.2255 cg_residual = 0.9040 step_size = 0.2896 reward = -0.0000 fps = 29 mse_loss = 0.4422 
2022-05-01 06:57:00.927315 - gail/main.py:164 - [TRPO] iter = 789000 dist_mean = 0.2105 dist_std = 0.2191 vf_loss = 0.2096 grad_norm = 2.1217 nat_grad_norm = 0.1145 cg_residual = 0.2388 step_size = 0.5066 reward = 0.0000 fps = 22 mse_loss = 0.4645 
2022-05-01 06:57:10.678787 - gail/main.py:164 - [TRPO] iter = 790000 dist_mean = 0.1390 dist_std = 0.2204 vf_loss = 1.3234 grad_norm = 1.6309 nat_grad_norm = 0.1585 cg_residual = 0.7132 step_size = 0.4717 reward = -0.0000 fps = 18 mse_loss = 0.4617 
2022-05-01 06:57:10.904798 - gail/main.py:191 - [Discriminator] iter = 790000 loss = -1.1667 grad_norm = 2.8165 grad_penalty = 0.0880 regularization = 0.0000 true_logits = -0.3436 fake_logits = -1.5983 true_prob = 0.4459 fake_prob = 0.3059 
2022-05-01 06:57:14.183913 - gail/main.py:132 - [Evaluate] iter = 790000 episode={ returns = 39.0420 lengths = 22 } discounted_episode={ returns = 38.8072 lengths = 22 } 
2022-05-01 06:57:23.986089 - gail/main.py:164 - [TRPO] iter = 791000 dist_mean = 0.0645 dist_std = 0.2207 vf_loss = 0.8755 grad_norm = 1.6991 nat_grad_norm = 0.1456 cg_residual = 0.3735 step_size = 0.4605 reward = 0.0000 fps = 76 mse_loss = 0.4651 
2022-05-01 06:57:33.648650 - gail/main.py:164 - [TRPO] iter = 792000 dist_mean = 0.0586 dist_std = 0.2191 vf_loss = 0.0651 grad_norm = 1.8125 nat_grad_norm = 0.1638 cg_residual = 0.6050 step_size = 0.4172 reward = -0.0000 fps = 44 mse_loss = 0.5014 
2022-05-01 06:57:44.252496 - gail/main.py:164 - [TRPO] iter = 793000 dist_mean = 0.3914 dist_std = 0.2194 vf_loss = 0.8261 grad_norm = 2.4667 nat_grad_norm = 0.2012 cg_residual = 2.2888 step_size = 0.2933 reward = 0.0000 fps = 30 mse_loss = 0.4744 
2022-05-01 06:57:54.381592 - gail/main.py:164 - [TRPO] iter = 794000 dist_mean = 0.0577 dist_std = 0.2199 vf_loss = 0.2008 grad_norm = 1.7233 nat_grad_norm = 0.1164 cg_residual = 0.3889 step_size = 0.4857 reward = -0.0000 fps = 23 mse_loss = 0.4905 
2022-05-01 06:58:04.606510 - gail/main.py:164 - [TRPO] iter = 795000 dist_mean = 0.0575 dist_std = 0.2197 vf_loss = 0.1391 grad_norm = 1.5205 nat_grad_norm = 0.1579 cg_residual = 0.2777 step_size = 0.4526 reward = 0.0000 fps = 18 mse_loss = 0.4972 
2022-05-01 06:58:04.863452 - gail/main.py:191 - [Discriminator] iter = 795000 loss = -0.4428 grad_norm = 3.5190 grad_penalty = 0.0646 regularization = 0.0000 true_logits = -0.3468 fake_logits = -0.8542 true_prob = 0.4436 fake_prob = 0.3873 
2022-05-01 06:58:14.782878 - gail/main.py:132 - [Evaluate] iter = 795000 episode={ returns = 39.3415 lengths = 22 } discounted_episode={ returns = 255.7296 lengths = 120 } 
2022-05-01 06:58:24.449366 - gail/main.py:164 - [TRPO] iter = 796000 dist_mean = 0.0145 dist_std = 0.2192 vf_loss = 0.2063 grad_norm = 0.8586 nat_grad_norm = 0.1175 cg_residual = 0.4312 step_size = 0.5744 reward = -0.0000 fps = 51 mse_loss = 0.5538 
2022-05-01 06:58:34.337876 - gail/main.py:164 - [TRPO] iter = 797000 dist_mean = 0.0798 dist_std = 0.2180 vf_loss = 0.0907 grad_norm = 2.5045 nat_grad_norm = 0.1228 cg_residual = 0.5195 step_size = 0.4698 reward = -0.0000 fps = 33 mse_loss = 0.5257 
2022-05-01 06:58:43.895089 - gail/main.py:164 - [TRPO] iter = 798000 dist_mean = 0.0290 dist_std = 0.2194 vf_loss = 0.1619 grad_norm = 1.9567 nat_grad_norm = 0.1271 cg_residual = 0.2630 step_size = 0.4599 reward = 0.0000 fps = 25 mse_loss = 0.4777 
2022-05-01 06:58:53.561765 - gail/main.py:164 - [TRPO] iter = 799000 dist_mean = 0.0356 dist_std = 0.2199 vf_loss = 0.0563 grad_norm = 2.0338 nat_grad_norm = 0.1389 cg_residual = 0.4333 step_size = 0.5170 reward = -0.0000 fps = 20 mse_loss = 0.4957 
2022-05-01 06:59:03.513660 - gail/main.py:164 - [TRPO] iter = 800000 dist_mean = 0.0577 dist_std = 0.2191 vf_loss = 0.0664 grad_norm = 1.3711 nat_grad_norm = 0.1312 cg_residual = 0.4109 step_size = 0.4536 reward = -0.0000 fps = 17 mse_loss = 0.4385 
2022-05-01 06:59:03.705127 - gail/main.py:191 - [Discriminator] iter = 800000 loss = -0.5617 grad_norm = 3.0312 grad_penalty = 0.0703 regularization = 0.0000 true_logits = -0.4008 fake_logits = -1.0327 true_prob = 0.4395 fake_prob = 0.3620 
2022-05-01 07:00:04.501285 - gail/main.py:132 - [Evaluate] iter = 800000 episode={ returns = 1800.1712 lengths = 511 } discounted_episode={ returns = 898.8677 lengths = 413 } 
2022-05-01 07:00:14.510049 - gail/main.py:164 - [TRPO] iter = 801000 dist_mean = 0.0365 dist_std = 0.2188 vf_loss = 0.0969 grad_norm = 3.0664 nat_grad_norm = 0.1418 cg_residual = 0.3808 step_size = 0.3734 reward = 0.0000 fps = 14 mse_loss = 0.4375 
2022-05-01 07:00:24.083443 - gail/main.py:164 - [TRPO] iter = 802000 dist_mean = 0.0608 dist_std = 0.2184 vf_loss = 0.1078 grad_norm = 2.0252 nat_grad_norm = 0.1282 cg_residual = 0.3552 step_size = 0.5060 reward = 0.0000 fps = 12 mse_loss = 0.4764 
2022-05-01 07:00:34.024697 - gail/main.py:164 - [TRPO] iter = 803000 dist_mean = 0.0914 dist_std = 0.2175 vf_loss = 0.1961 grad_norm = 1.9511 nat_grad_norm = 0.1011 cg_residual = 0.3483 step_size = 0.5853 reward = -0.0000 fps = 11 mse_loss = 0.4969 
2022-05-01 07:00:43.747893 - gail/main.py:164 - [TRPO] iter = 804000 dist_mean = 0.0546 dist_std = 0.2173 vf_loss = 0.0773 grad_norm = 2.3103 nat_grad_norm = 0.1692 cg_residual = 0.5060 step_size = 0.3610 reward = 0.0000 fps = 9 mse_loss = 0.5116 
2022-05-01 07:00:53.477846 - gail/main.py:164 - [TRPO] iter = 805000 dist_mean = 0.0414 dist_std = 0.2169 vf_loss = 0.0667 grad_norm = 2.4847 nat_grad_norm = 0.1521 cg_residual = 0.4474 step_size = 0.3467 reward = 0.0000 fps = 9 mse_loss = 0.4226 
2022-05-01 07:00:53.692609 - gail/main.py:191 - [Discriminator] iter = 805000 loss = -0.5306 grad_norm = 3.0105 grad_penalty = 0.0644 regularization = 0.0000 true_logits = -0.4472 fake_logits = -1.0422 true_prob = 0.4271 fake_prob = 0.3465 
2022-05-01 07:00:56.792813 - gail/main.py:132 - [Evaluate] iter = 805000 episode={ returns = 39.3151 lengths = 22 } discounted_episode={ returns = 38.4713 lengths = 22 } 
2022-05-01 07:01:06.910173 - gail/main.py:164 - [TRPO] iter = 806000 dist_mean = 0.1053 dist_std = 0.2165 vf_loss = 0.1966 grad_norm = 2.7921 nat_grad_norm = 0.1028 cg_residual = 0.3639 step_size = 0.5180 reward = 0.0000 fps = 75 mse_loss = 0.4603 
2022-05-01 07:01:17.126909 - gail/main.py:164 - [TRPO] iter = 807000 dist_mean = 0.1822 dist_std = 0.2158 vf_loss = 0.0432 grad_norm = 2.3022 nat_grad_norm = 0.1440 cg_residual = 0.5514 step_size = 0.4386 reward = 0.0000 fps = 42 mse_loss = 0.4608 
2022-05-01 07:01:26.999524 - gail/main.py:164 - [TRPO] iter = 808000 dist_mean = 0.0738 dist_std = 0.2148 vf_loss = 0.0656 grad_norm = 1.4569 nat_grad_norm = 0.1325 cg_residual = 0.3320 step_size = 0.4983 reward = 0.0000 fps = 30 mse_loss = 0.4815 
2022-05-01 07:01:37.047688 - gail/main.py:164 - [TRPO] iter = 809000 dist_mean = 0.1590 dist_std = 0.2150 vf_loss = 0.0429 grad_norm = 1.8494 nat_grad_norm = 0.1218 cg_residual = 0.3639 step_size = 0.5103 reward = -0.0000 fps = 23 mse_loss = 0.4514 
2022-05-01 07:01:46.968437 - gail/main.py:164 - [TRPO] iter = 810000 dist_mean = 0.0822 dist_std = 0.2134 vf_loss = 0.3560 grad_norm = 1.1847 nat_grad_norm = 0.1217 cg_residual = 0.2521 step_size = 0.6539 reward = -0.0000 fps = 18 mse_loss = 0.4933 
2022-05-01 07:01:47.193509 - gail/main.py:191 - [Discriminator] iter = 810000 loss = -0.3046 grad_norm = 3.1435 grad_penalty = 0.0618 regularization = 0.0000 true_logits = -0.4850 fake_logits = -0.8514 true_prob = 0.4145 fake_prob = 0.3647 
2022-05-01 07:01:50.373663 - gail/main.py:132 - [Evaluate] iter = 810000 episode={ returns = 38.6403 lengths = 22 } discounted_episode={ returns = 38.1527 lengths = 22 } 
2022-05-01 07:02:00.436613 - gail/main.py:164 - [TRPO] iter = 811000 dist_mean = 0.2427 dist_std = 0.2126 vf_loss = 0.5555 grad_norm = 1.7248 nat_grad_norm = 0.1137 cg_residual = 0.2756 step_size = 0.5777 reward = -0.0000 fps = 75 mse_loss = 0.4270 
2022-05-01 07:02:10.497433 - gail/main.py:164 - [TRPO] iter = 812000 dist_mean = 0.1885 dist_std = 0.2147 vf_loss = 0.1328 grad_norm = 1.9744 nat_grad_norm = 0.1419 cg_residual = 0.4133 step_size = 0.4626 reward = 0.0000 fps = 42 mse_loss = 0.4698 
2022-05-01 07:02:20.652643 - gail/main.py:164 - [TRPO] iter = 813000 dist_mean = 0.2336 dist_std = 0.2132 vf_loss = 0.0734 grad_norm = 1.7792 nat_grad_norm = 0.1610 cg_residual = 0.5035 step_size = 0.3720 reward = 0.0000 fps = 29 mse_loss = 0.4129 
2022-05-01 07:02:30.081552 - gail/main.py:164 - [TRPO] iter = 814000 dist_mean = 0.2897 dist_std = 0.2134 vf_loss = 0.1829 grad_norm = 1.7952 nat_grad_norm = 0.1079 cg_residual = 0.4575 step_size = 0.5662 reward = 0.0000 fps = 23 mse_loss = 0.4999 
2022-05-01 07:02:39.941095 - gail/main.py:164 - [TRPO] iter = 815000 dist_mean = 0.2627 dist_std = 0.2128 vf_loss = 1.1645 grad_norm = 2.0573 nat_grad_norm = 0.1312 cg_residual = 0.6721 step_size = 0.4627 reward = -0.0000 fps = 18 mse_loss = 0.4192 
2022-05-01 07:02:40.152103 - gail/main.py:191 - [Discriminator] iter = 815000 loss = -1.8656 grad_norm = 3.4571 grad_penalty = 0.1130 regularization = 0.0000 true_logits = -0.4375 fake_logits = -2.4161 true_prob = 0.4208 fake_prob = 0.2153 
2022-05-01 07:02:43.253070 - gail/main.py:132 - [Evaluate] iter = 815000 episode={ returns = 39.2381 lengths = 22 } discounted_episode={ returns = 38.3301 lengths = 22 } 
2022-05-01 07:02:53.386602 - gail/main.py:164 - [TRPO] iter = 816000 dist_mean = 0.5079 dist_std = 0.2118 vf_loss = 0.0837 grad_norm = 2.3885 nat_grad_norm = 0.0504 cg_residual = 0.1166 step_size = 0.8284 reward = 0.0000 fps = 75 mse_loss = 0.4342 
2022-05-01 07:03:03.138697 - gail/main.py:164 - [TRPO] iter = 817000 dist_mean = 0.1840 dist_std = 0.2110 vf_loss = 0.2173 grad_norm = 1.7994 nat_grad_norm = 0.1190 cg_residual = 0.3542 step_size = 0.5198 reward = -0.0000 fps = 43 mse_loss = 0.4186 
2022-05-01 07:03:12.900759 - gail/main.py:164 - [TRPO] iter = 818000 dist_mean = 0.0980 dist_std = 0.2114 vf_loss = 1.2937 grad_norm = 1.5834 nat_grad_norm = 0.1060 cg_residual = 0.4516 step_size = 0.5912 reward = 0.0000 fps = 30 mse_loss = 0.4475 
2022-05-01 07:03:22.794819 - gail/main.py:164 - [TRPO] iter = 819000 dist_mean = 0.2180 dist_std = 0.2101 vf_loss = 0.2334 grad_norm = 1.8342 nat_grad_norm = 0.1526 cg_residual = 0.4783 step_size = 0.4282 reward = -0.0000 fps = 23 mse_loss = 0.4771 
2022-05-01 07:03:32.503933 - gail/main.py:164 - [TRPO] iter = 820000 dist_mean = 0.1834 dist_std = 0.2101 vf_loss = 0.2635 grad_norm = 1.3752 nat_grad_norm = 0.1084 cg_residual = 0.5823 step_size = 0.5620 reward = 0.0000 fps = 19 mse_loss = 0.4702 
2022-05-01 07:03:32.733439 - gail/main.py:191 - [Discriminator] iter = 820000 loss = -1.4858 grad_norm = 3.7000 grad_penalty = 0.1370 regularization = 0.0000 true_logits = -0.2024 fake_logits = -1.8251 true_prob = 0.4657 fake_prob = 0.2934 
2022-05-01 07:03:35.754699 - gail/main.py:132 - [Evaluate] iter = 820000 episode={ returns = 39.4174 lengths = 22 } discounted_episode={ returns = 37.9950 lengths = 22 } 
2022-05-01 07:03:45.594137 - gail/main.py:164 - [TRPO] iter = 821000 dist_mean = 0.2469 dist_std = 0.2104 vf_loss = 0.4162 grad_norm = 1.5137 nat_grad_norm = 0.1225 cg_residual = 0.2736 step_size = 0.5561 reward = -0.0000 fps = 77 mse_loss = 0.4727 
2022-05-01 07:03:55.400825 - gail/main.py:164 - [TRPO] iter = 822000 dist_mean = 0.1877 dist_std = 0.2100 vf_loss = 2.9078 grad_norm = 3.2192 nat_grad_norm = 0.1432 cg_residual = 0.4391 step_size = 0.4098 reward = 0.0000 fps = 44 mse_loss = 0.4891 
2022-05-01 07:04:05.593344 - gail/main.py:164 - [TRPO] iter = 823000 dist_mean = 0.0713 dist_std = 0.2107 vf_loss = 0.1981 grad_norm = 1.5382 nat_grad_norm = 0.1318 cg_residual = 0.4240 step_size = 0.4908 reward = 0.0000 fps = 30 mse_loss = 0.4675 
2022-05-01 07:04:15.720121 - gail/main.py:164 - [TRPO] iter = 824000 dist_mean = 0.1785 dist_std = 0.2106 vf_loss = 0.2556 grad_norm = 2.1342 nat_grad_norm = 0.1191 cg_residual = 0.5239 step_size = 0.4625 reward = -0.0000 fps = 23 mse_loss = 0.4690 
2022-05-01 07:04:25.415890 - gail/main.py:164 - [TRPO] iter = 825000 dist_mean = 0.1158 dist_std = 0.2106 vf_loss = 0.2436 grad_norm = 1.6651 nat_grad_norm = 0.1392 cg_residual = 0.4231 step_size = 0.4777 reward = -0.0000 fps = 18 mse_loss = 0.4528 
2022-05-01 07:04:25.678763 - gail/main.py:191 - [Discriminator] iter = 825000 loss = -1.0577 grad_norm = 3.1294 grad_penalty = 0.0911 regularization = 0.0000 true_logits = -0.0530 fake_logits = -1.2018 true_prob = 0.4915 fake_prob = 0.3633 
2022-05-01 07:04:54.867877 - gail/main.py:132 - [Evaluate] iter = 825000 episode={ returns = 390.1637 lengths = 120 } discounted_episode={ returns = 687.2518 lengths = 315 } 
2022-05-01 07:05:04.458654 - gail/main.py:164 - [TRPO] iter = 826000 dist_mean = 0.0430 dist_std = 0.2115 vf_loss = 0.7764 grad_norm = 1.5856 nat_grad_norm = 0.1552 cg_residual = 0.5367 step_size = 0.4479 reward = 0.0000 fps = 25 mse_loss = 0.4155 
2022-05-01 07:05:14.392710 - gail/main.py:164 - [TRPO] iter = 827000 dist_mean = 0.0354 dist_std = 0.2128 vf_loss = 0.1087 grad_norm = 1.6573 nat_grad_norm = 0.2143 cg_residual = 0.7300 step_size = 0.3191 reward = -0.0000 fps = 20 mse_loss = 0.4330 
2022-05-01 07:05:23.891155 - gail/main.py:164 - [TRPO] iter = 828000 dist_mean = 0.0531 dist_std = 0.2137 vf_loss = 0.4367 grad_norm = 1.8486 nat_grad_norm = 0.1285 cg_residual = 0.3342 step_size = 0.5422 reward = 0.0000 fps = 17 mse_loss = 0.4120 
2022-05-01 07:05:33.510655 - gail/main.py:164 - [TRPO] iter = 829000 dist_mean = 0.0498 dist_std = 0.2149 vf_loss = 0.0685 grad_norm = 1.7598 nat_grad_norm = 0.1762 cg_residual = 0.2943 step_size = 0.4171 reward = 0.0000 fps = 14 mse_loss = 0.4577 
2022-05-01 07:05:43.894934 - gail/main.py:164 - [TRPO] iter = 830000 dist_mean = 0.0389 dist_std = 0.2145 vf_loss = 0.1209 grad_norm = 1.7608 nat_grad_norm = 0.1422 cg_residual = 0.7963 step_size = 0.4571 reward = -0.0000 fps = 12 mse_loss = 0.4536 
2022-05-01 07:05:44.158676 - gail/main.py:191 - [Discriminator] iter = 830000 loss = -0.6647 grad_norm = 3.6547 grad_penalty = 0.0798 regularization = 0.0000 true_logits = -0.0420 fake_logits = -0.7864 true_prob = 0.4999 fake_prob = 0.3984 
2022-05-01 07:06:59.632383 - gail/main.py:132 - [Evaluate] iter = 830000 episode={ returns = 1446.8289 lengths = 413 } discounted_episode={ returns = 1541.3805 lengths = 706 } 
2022-05-01 07:07:09.140314 - gail/main.py:164 - [TRPO] iter = 831000 dist_mean = 0.0487 dist_std = 0.2144 vf_loss = 0.0435 grad_norm = 1.9900 nat_grad_norm = 0.1483 cg_residual = 0.6451 step_size = 0.3983 reward = -0.0000 fps = 11 mse_loss = 0.4819 
2022-05-01 07:07:19.053975 - gail/main.py:164 - [TRPO] iter = 832000 dist_mean = 0.0375 dist_std = 0.2139 vf_loss = 0.1666 grad_norm = 2.0226 nat_grad_norm = 0.1483 cg_residual = 0.4157 step_size = 0.4396 reward = -0.0000 fps = 10 mse_loss = 0.4462 
2022-05-01 07:07:28.776236 - gail/main.py:164 - [TRPO] iter = 833000 dist_mean = 0.0438 dist_std = 0.2141 vf_loss = 0.0773 grad_norm = 1.6502 nat_grad_norm = 0.1566 cg_residual = 0.5991 step_size = 0.4831 reward = -0.0000 fps = 9 mse_loss = 0.4527 
2022-05-01 07:07:38.240743 - gail/main.py:164 - [TRPO] iter = 834000 dist_mean = 0.0615 dist_std = 0.2117 vf_loss = 0.2578 grad_norm = 2.1569 nat_grad_norm = 0.1173 cg_residual = 0.3049 step_size = 0.5219 reward = -0.0000 fps = 8 mse_loss = 0.4056 
2022-05-01 07:07:48.024968 - gail/main.py:164 - [TRPO] iter = 835000 dist_mean = 0.0469 dist_std = 0.2110 vf_loss = 0.0889 grad_norm = 2.0282 nat_grad_norm = 0.1323 cg_residual = 0.4240 step_size = 0.4356 reward = -0.0000 fps = 8 mse_loss = 0.4354 
2022-05-01 07:07:48.256815 - gail/main.py:191 - [Discriminator] iter = 835000 loss = -0.3397 grad_norm = 4.4738 grad_penalty = 0.0648 regularization = 0.0000 true_logits = -0.0927 fake_logits = -0.4973 true_prob = 0.4863 fake_prob = 0.4340 
2022-05-01 07:08:37.161608 - gail/main.py:132 - [Evaluate] iter = 835000 episode={ returns = 738.7530 lengths = 217 } discounted_episode={ returns = 1108.5239 lengths = 511 } 
2022-05-01 07:08:47.120425 - gail/main.py:164 - [TRPO] iter = 836000 dist_mean = 0.0558 dist_std = 0.2107 vf_loss = 0.0430 grad_norm = 2.0169 nat_grad_norm = 0.1403 cg_residual = 1.3977 step_size = 0.4772 reward = -0.0000 fps = 16 mse_loss = 0.4305 
2022-05-01 07:08:56.903338 - gail/main.py:164 - [TRPO] iter = 837000 dist_mean = 0.0923 dist_std = 0.2113 vf_loss = 0.1996 grad_norm = 2.0586 nat_grad_norm = 0.1134 cg_residual = 0.3129 step_size = 0.5198 reward = 0.0000 fps = 14 mse_loss = 0.5074 
2022-05-01 07:09:06.804167 - gail/main.py:164 - [TRPO] iter = 838000 dist_mean = 0.0825 dist_std = 0.2116 vf_loss = 0.1420 grad_norm = 2.2601 nat_grad_norm = 0.1151 cg_residual = 0.3245 step_size = 0.4413 reward = -0.0000 fps = 12 mse_loss = 0.4483 
2022-05-01 07:09:16.561655 - gail/main.py:164 - [TRPO] iter = 839000 dist_mean = 0.0472 dist_std = 0.2111 vf_loss = 0.0884 grad_norm = 3.0600 nat_grad_norm = 0.1382 cg_residual = 0.6376 step_size = 0.3639 reward = 0.0000 fps = 11 mse_loss = 0.4230 
2022-05-01 07:09:26.465830 - gail/main.py:164 - [TRPO] iter = 840000 dist_mean = 0.0710 dist_std = 0.2113 vf_loss = 0.2064 grad_norm = 3.3922 nat_grad_norm = 0.1214 cg_residual = 1.9380 step_size = 0.4903 reward = 0.0000 fps = 10 mse_loss = 0.4583 
2022-05-01 07:09:26.661913 - gail/main.py:191 - [Discriminator] iter = 840000 loss = -0.3282 grad_norm = 3.7344 grad_penalty = 0.0617 regularization = 0.0000 true_logits = -0.1887 fake_logits = -0.5785 true_prob = 0.4694 fake_prob = 0.4162 
2022-05-01 07:09:36.647226 - gail/main.py:132 - [Evaluate] iter = 840000 episode={ returns = 38.5059 lengths = 22 } discounted_episode={ returns = 252.4008 lengths = 120 } 
2022-05-01 07:09:46.731878 - gail/main.py:164 - [TRPO] iter = 841000 dist_mean = 0.1933 dist_std = 0.2108 vf_loss = 0.1972 grad_norm = 2.5433 nat_grad_norm = 0.1012 cg_residual = 0.4714 step_size = 0.4855 reward = -0.0000 fps = 49 mse_loss = 0.4159 
2022-05-01 07:09:57.044130 - gail/main.py:164 - [TRPO] iter = 842000 dist_mean = 0.2329 dist_std = 0.2097 vf_loss = 0.5298 grad_norm = 2.1007 nat_grad_norm = 0.1479 cg_residual = 0.3319 step_size = 0.4726 reward = -0.0000 fps = 32 mse_loss = 0.4997 
2022-05-01 07:10:07.247820 - gail/main.py:164 - [TRPO] iter = 843000 dist_mean = 0.4694 dist_std = 0.2086 vf_loss = 0.0896 grad_norm = 1.8142 nat_grad_norm = 0.0373 cg_residual = 1.0813 step_size = 1.0266 reward = -0.0000 fps = 24 mse_loss = 0.5150 
2022-05-01 07:10:16.724215 - gail/main.py:164 - [TRPO] iter = 844000 dist_mean = 0.1242 dist_std = 0.2083 vf_loss = 0.0578 grad_norm = 2.3704 nat_grad_norm = 0.1554 cg_residual = 0.4485 step_size = 0.3892 reward = -0.0000 fps = 19 mse_loss = 0.4170 
2022-05-01 07:10:26.546481 - gail/main.py:164 - [TRPO] iter = 845000 dist_mean = 0.1424 dist_std = 0.2083 vf_loss = 0.4465 grad_norm = 1.9506 nat_grad_norm = 0.1360 cg_residual = 0.5861 step_size = 0.4154 reward = 0.0000 fps = 16 mse_loss = 0.4769 
2022-05-01 07:10:26.752670 - gail/main.py:191 - [Discriminator] iter = 845000 loss = -1.1080 grad_norm = 3.4831 grad_penalty = 0.0827 regularization = 0.0000 true_logits = -0.1888 fake_logits = -1.3795 true_prob = 0.4649 fake_prob = 0.3227 
2022-05-01 07:10:30.024231 - gail/main.py:132 - [Evaluate] iter = 845000 episode={ returns = 39.0114 lengths = 22 } discounted_episode={ returns = 38.2162 lengths = 22 } 
2022-05-01 07:10:39.999722 - gail/main.py:164 - [TRPO] iter = 846000 dist_mean = 0.0907 dist_std = 0.2076 vf_loss = 0.2600 grad_norm = 1.5907 nat_grad_norm = 0.1203 cg_residual = 0.2611 step_size = 0.5684 reward = -0.0000 fps = 75 mse_loss = 0.4601 
2022-05-01 07:10:49.907985 - gail/main.py:164 - [TRPO] iter = 847000 dist_mean = 0.0618 dist_std = 0.2094 vf_loss = 0.1738 grad_norm = 2.7271 nat_grad_norm = 0.1171 cg_residual = 0.4851 step_size = 0.4555 reward = 0.0000 fps = 43 mse_loss = 0.4621 
2022-05-01 07:11:00.028743 - gail/main.py:164 - [TRPO] iter = 848000 dist_mean = 0.1423 dist_std = 0.2090 vf_loss = 0.2558 grad_norm = 2.2058 nat_grad_norm = 0.1153 cg_residual = 0.5103 step_size = 0.4942 reward = 0.0000 fps = 30 mse_loss = 0.4538 
2022-05-01 07:11:10.602045 - gail/main.py:164 - [TRPO] iter = 849000 dist_mean = 0.1676 dist_std = 0.2096 vf_loss = 0.3310 grad_norm = 2.2891 nat_grad_norm = 0.0948 cg_residual = 0.2222 step_size = 0.5869 reward = 0.0000 fps = 22 mse_loss = 0.4288 
2022-05-01 07:11:20.639833 - gail/main.py:164 - [TRPO] iter = 850000 dist_mean = 0.1334 dist_std = 0.2105 vf_loss = 0.3428 grad_norm = 2.1562 nat_grad_norm = 0.1618 cg_residual = 0.2707 step_size = 0.4535 reward = -0.0000 fps = 18 mse_loss = 0.4418 
2022-05-01 07:11:20.896745 - gail/main.py:191 - [Discriminator] iter = 850000 loss = -0.7965 grad_norm = 3.4358 grad_penalty = 0.0785 regularization = 0.0000 true_logits = -0.1274 fake_logits = -1.0024 true_prob = 0.4749 fake_prob = 0.3768 
2022-05-01 07:11:24.191838 - gail/main.py:132 - [Evaluate] iter = 850000 episode={ returns = 38.4358 lengths = 22 } discounted_episode={ returns = 38.4301 lengths = 22 } 
2022-05-01 07:11:34.619955 - gail/main.py:164 - [TRPO] iter = 851000 dist_mean = 0.1005 dist_std = 0.2106 vf_loss = 0.0423 grad_norm = 2.4732 nat_grad_norm = 0.1308 cg_residual = 0.6608 step_size = 0.4674 reward = 0.0000 fps = 72 mse_loss = 0.5185 
2022-05-01 07:11:45.500031 - gail/main.py:164 - [TRPO] iter = 852000 dist_mean = 0.4513 dist_std = 0.2101 vf_loss = 0.2051 grad_norm = 2.4999 nat_grad_norm = 0.1188 cg_residual = 3.0338 step_size = 0.4539 reward = -0.0000 fps = 40 mse_loss = 0.4659 
2022-05-01 07:11:55.381569 - gail/main.py:164 - [TRPO] iter = 853000 dist_mean = 0.1040 dist_std = 0.2099 vf_loss = 0.0773 grad_norm = 1.6552 nat_grad_norm = 0.0972 cg_residual = 0.3694 step_size = 0.5917 reward = -0.0000 fps = 29 mse_loss = 0.5086 
2022-05-01 07:12:05.818528 - gail/main.py:164 - [TRPO] iter = 854000 dist_mean = 0.1915 dist_std = 0.2101 vf_loss = 0.3297 grad_norm = 2.4371 nat_grad_norm = 0.1946 cg_residual = 1.1891 step_size = 0.3562 reward = 0.0000 fps = 22 mse_loss = 0.4326 
2022-05-01 07:12:15.929291 - gail/main.py:164 - [TRPO] iter = 855000 dist_mean = 0.1486 dist_std = 0.2106 vf_loss = 0.4223 grad_norm = 1.7255 nat_grad_norm = 0.1317 cg_residual = 0.2206 step_size = 0.5372 reward = -0.0000 fps = 18 mse_loss = 0.4843 
2022-05-01 07:12:16.208068 - gail/main.py:191 - [Discriminator] iter = 855000 loss = -0.7638 grad_norm = 3.5941 grad_penalty = 0.0786 regularization = 0.0000 true_logits = -0.0832 fake_logits = -0.9256 true_prob = 0.4822 fake_prob = 0.3858 
2022-05-01 07:12:19.219061 - gail/main.py:132 - [Evaluate] iter = 855000 episode={ returns = 38.0843 lengths = 21 } discounted_episode={ returns = 37.4637 lengths = 21 } 
2022-05-01 07:12:29.081330 - gail/main.py:164 - [TRPO] iter = 856000 dist_mean = 0.1285 dist_std = 0.2092 vf_loss = 0.3752 grad_norm = 3.8204 nat_grad_norm = 0.1607 cg_residual = 0.6772 step_size = 0.3518 reward = -0.0000 fps = 77 mse_loss = 0.5344 
2022-05-01 07:12:39.576591 - gail/main.py:164 - [TRPO] iter = 857000 dist_mean = 0.4596 dist_std = 0.2089 vf_loss = 0.7152 grad_norm = 1.9361 nat_grad_norm = 0.1758 cg_residual = 0.5546 step_size = 0.3651 reward = -0.0000 fps = 42 mse_loss = 0.4382 
2022-05-01 07:12:49.668609 - gail/main.py:164 - [TRPO] iter = 858000 dist_mean = 0.1180 dist_std = 0.2093 vf_loss = 0.8736 grad_norm = 1.6498 nat_grad_norm = 0.0966 cg_residual = 0.2444 step_size = 0.5572 reward = -0.0000 fps = 29 mse_loss = 0.4694 
2022-05-01 07:12:59.421656 - gail/main.py:164 - [TRPO] iter = 859000 dist_mean = 0.1231 dist_std = 0.2092 vf_loss = 0.1937 grad_norm = 2.4212 nat_grad_norm = 0.2102 cg_residual = 0.9170 step_size = 0.2659 reward = 0.0000 fps = 23 mse_loss = 0.5133 
2022-05-01 07:13:09.629809 - gail/main.py:164 - [TRPO] iter = 860000 dist_mean = 0.3382 dist_std = 0.2092 vf_loss = 1.1190 grad_norm = 1.6063 nat_grad_norm = 0.1213 cg_residual = 0.3090 step_size = 0.5647 reward = 0.0000 fps = 18 mse_loss = 0.4385 
2022-05-01 07:13:09.867678 - gail/main.py:191 - [Discriminator] iter = 860000 loss = -2.6490 grad_norm = 3.5981 grad_penalty = 0.1964 regularization = 0.0000 true_logits = 0.0036 fake_logits = -2.8419 true_prob = 0.4969 fake_prob = 0.1803 
2022-05-01 07:13:13.252073 - gail/main.py:132 - [Evaluate] iter = 860000 episode={ returns = 38.7613 lengths = 22 } discounted_episode={ returns = 38.2533 lengths = 22 } 
2022-05-01 07:13:23.267238 - gail/main.py:164 - [TRPO] iter = 861000 dist_mean = 0.1985 dist_std = 0.2102 vf_loss = 0.9741 grad_norm = 2.4709 nat_grad_norm = 0.1143 cg_residual = 0.4767 step_size = 0.4858 reward = -0.0000 fps = 74 mse_loss = 0.5346 
2022-05-01 07:13:33.446086 - gail/main.py:164 - [TRPO] iter = 862000 dist_mean = 0.2654 dist_std = 0.2085 vf_loss = 0.4947 grad_norm = 2.1230 nat_grad_norm = 0.0922 cg_residual = 0.2141 step_size = 0.6117 reward = -0.0000 fps = 42 mse_loss = 0.4922 
2022-05-01 07:13:43.531341 - gail/main.py:164 - [TRPO] iter = 863000 dist_mean = 0.0994 dist_std = 0.2088 vf_loss = 1.1851 grad_norm = 2.1268 nat_grad_norm = 0.1210 cg_residual = 0.5101 step_size = 0.4786 reward = -0.0000 fps = 29 mse_loss = 0.5643 
2022-05-01 07:13:53.880487 - gail/main.py:164 - [TRPO] iter = 864000 dist_mean = 0.0883 dist_std = 0.2085 vf_loss = 0.1457 grad_norm = 1.8646 nat_grad_norm = 0.1945 cg_residual = 1.4141 step_size = 0.3211 reward = 0.0000 fps = 22 mse_loss = 0.5051 
2022-05-01 07:14:03.980050 - gail/main.py:164 - [TRPO] iter = 865000 dist_mean = 0.0775 dist_std = 0.2090 vf_loss = 0.3686 grad_norm = 2.4642 nat_grad_norm = 0.1932 cg_residual = 0.5743 step_size = 0.3513 reward = -0.0000 fps = 18 mse_loss = 0.5376 
2022-05-01 07:14:04.210535 - gail/main.py:191 - [Discriminator] iter = 865000 loss = -0.2112 grad_norm = 3.8862 grad_penalty = 0.0756 regularization = 0.0000 true_logits = 0.1194 fake_logits = -0.1673 true_prob = 0.5106 fake_prob = 0.4940 
2022-05-01 07:14:34.681007 - gail/main.py:132 - [Evaluate] iter = 865000 episode={ returns = 376.4015 lengths = 120 } discounted_episode={ returns = 675.3156 lengths = 315 } 
2022-05-01 07:14:44.891049 - gail/main.py:164 - [TRPO] iter = 866000 dist_mean = 0.1123 dist_std = 0.2078 vf_loss = 0.6059 grad_norm = 1.2195 nat_grad_norm = 0.0804 cg_residual = 0.2470 step_size = 0.6901 reward = -0.0000 fps = 24 mse_loss = 0.4602 
2022-05-01 07:14:55.276676 - gail/main.py:164 - [TRPO] iter = 867000 dist_mean = 0.1022 dist_std = 0.2087 vf_loss = 0.5035 grad_norm = 1.2014 nat_grad_norm = 0.0863 cg_residual = 0.1377 step_size = 0.6653 reward = -0.0000 fps = 19 mse_loss = 0.5141 
2022-05-01 07:15:05.269795 - gail/main.py:164 - [TRPO] iter = 868000 dist_mean = 0.1120 dist_std = 0.2083 vf_loss = 0.3890 grad_norm = 1.6186 nat_grad_norm = 0.1353 cg_residual = 0.4904 step_size = 0.4765 reward = 0.0000 fps = 16 mse_loss = 0.5879 
2022-05-01 07:15:15.490581 - gail/main.py:164 - [TRPO] iter = 869000 dist_mean = 0.1002 dist_std = 0.2079 vf_loss = 0.3406 grad_norm = 2.3239 nat_grad_norm = 0.0989 cg_residual = 1.2306 step_size = 0.6379 reward = 0.0000 fps = 14 mse_loss = 0.5162 
2022-05-01 07:15:25.467032 - gail/main.py:164 - [TRPO] iter = 870000 dist_mean = 0.0875 dist_std = 0.2094 vf_loss = 0.2365 grad_norm = 1.5270 nat_grad_norm = 0.0776 cg_residual = 0.1450 step_size = 0.7991 reward = 0.0000 fps = 12 mse_loss = 0.4891 
2022-05-01 07:15:25.673527 - gail/main.py:191 - [Discriminator] iter = 870000 loss = -0.3100 grad_norm = 3.3698 grad_penalty = 0.0549 regularization = 0.0000 true_logits = 0.1126 fake_logits = -0.2523 true_prob = 0.5184 fake_prob = 0.4752 
2022-05-01 07:17:19.941089 - gail/main.py:132 - [Evaluate] iter = 870000 episode={ returns = 2653.2646 lengths = 760 } discounted_episode={ returns = 1910.2682 lengths = 902 } 
2022-05-01 07:17:29.952144 - gail/main.py:164 - [TRPO] iter = 871000 dist_mean = 0.1136 dist_std = 0.2107 vf_loss = 0.2709 grad_norm = 1.5908 nat_grad_norm = 0.1384 cg_residual = 0.3638 step_size = 0.4266 reward = -0.0000 fps = 8 mse_loss = 0.4787 
2022-05-01 07:17:39.780738 - gail/main.py:164 - [TRPO] iter = 872000 dist_mean = 0.0771 dist_std = 0.2104 vf_loss = 0.0525 grad_norm = 1.9336 nat_grad_norm = 0.1635 cg_residual = 0.6431 step_size = 0.3678 reward = 0.0000 fps = 7 mse_loss = 0.5764 
2022-05-01 07:17:49.807247 - gail/main.py:164 - [TRPO] iter = 873000 dist_mean = 0.0750 dist_std = 0.2102 vf_loss = 0.0369 grad_norm = 2.4409 nat_grad_norm = 0.1493 cg_residual = 0.7498 step_size = 0.4009 reward = 0.0000 fps = 6 mse_loss = 0.5784 
2022-05-01 07:17:59.678099 - gail/main.py:164 - [TRPO] iter = 874000 dist_mean = 0.0584 dist_std = 0.2089 vf_loss = 0.0495 grad_norm = 1.6638 nat_grad_norm = 0.1369 cg_residual = 0.5620 step_size = 0.4876 reward = -0.0000 fps = 6 mse_loss = 0.6003 
2022-05-01 07:18:09.728145 - gail/main.py:164 - [TRPO] iter = 875000 dist_mean = 0.1123 dist_std = 0.2084 vf_loss = 0.0454 grad_norm = 2.4166 nat_grad_norm = 0.1728 cg_residual = 0.7426 step_size = 0.3541 reward = 0.0000 fps = 6 mse_loss = 0.5281 
2022-05-01 07:18:09.952696 - gail/main.py:191 - [Discriminator] iter = 875000 loss = -0.7807 grad_norm = 2.7517 grad_penalty = 0.0573 regularization = 0.0000 true_logits = 0.0615 fake_logits = -0.7765 true_prob = 0.5099 fake_prob = 0.4068 
2022-05-01 07:18:47.496021 - gail/main.py:132 - [Evaluate] iter = 875000 episode={ returns = 980.3647 lengths = 283 } discounted_episode={ returns = 620.3065 lengths = 280 } 
2022-05-01 07:18:57.293232 - gail/main.py:164 - [TRPO] iter = 876000 dist_mean = 0.0855 dist_std = 0.2089 vf_loss = 0.0515 grad_norm = 1.8336 nat_grad_norm = 0.1437 cg_residual = 0.3578 step_size = 0.4621 reward = 0.0000 fps = 21 mse_loss = 0.5091 
2022-05-01 07:19:06.644350 - gail/main.py:164 - [TRPO] iter = 877000 dist_mean = 0.0448 dist_std = 0.2087 vf_loss = 0.0260 grad_norm = 1.8127 nat_grad_norm = 0.1253 cg_residual = 0.3621 step_size = 0.5049 reward = -0.0000 fps = 17 mse_loss = 0.4963 
2022-05-01 07:19:16.475909 - gail/main.py:164 - [TRPO] iter = 878000 dist_mean = 0.1897 dist_std = 0.2088 vf_loss = 0.1899 grad_norm = 1.5276 nat_grad_norm = 0.1321 cg_residual = 0.5479 step_size = 0.4548 reward = -0.0000 fps = 15 mse_loss = 0.4887 
2022-05-01 07:19:26.529891 - gail/main.py:164 - [TRPO] iter = 879000 dist_mean = 0.0970 dist_std = 0.2097 vf_loss = 0.1058 grad_norm = 1.8623 nat_grad_norm = 0.1931 cg_residual = 0.9866 step_size = 0.3841 reward = -0.0000 fps = 13 mse_loss = 0.5635 
2022-05-01 07:19:36.659166 - gail/main.py:164 - [TRPO] iter = 880000 dist_mean = 0.1923 dist_std = 0.2096 vf_loss = 0.0721 grad_norm = 2.0752 nat_grad_norm = 0.1301 cg_residual = 0.4416 step_size = 0.4940 reward = -0.0000 fps = 11 mse_loss = 0.5709 
2022-05-01 07:19:36.883686 - gail/main.py:191 - [Discriminator] iter = 880000 loss = -1.3800 grad_norm = 3.4978 grad_penalty = 0.0958 regularization = 0.0000 true_logits = 0.0310 fake_logits = -1.4448 true_prob = 0.5067 fake_prob = 0.3287 
2022-05-01 07:19:56.222754 - gail/main.py:132 - [Evaluate] iter = 880000 episode={ returns = 202.9833 lengths = 68 } discounted_episode={ returns = 542.2342 lengths = 206 } 
2022-05-01 07:20:06.869214 - gail/main.py:164 - [TRPO] iter = 881000 dist_mean = 0.1054 dist_std = 0.2085 vf_loss = 0.0170 grad_norm = 2.2493 nat_grad_norm = 0.1342 cg_residual = 0.3928 step_size = 0.4792 reward = -0.0000 fps = 33 mse_loss = 0.4773 
2022-05-01 07:20:16.893119 - gail/main.py:164 - [TRPO] iter = 882000 dist_mean = 0.0611 dist_std = 0.2084 vf_loss = 0.1316 grad_norm = 1.5301 nat_grad_norm = 0.1243 cg_residual = 0.5109 step_size = 0.5119 reward = 0.0000 fps = 25 mse_loss = 0.5245 
2022-05-01 07:20:26.801381 - gail/main.py:164 - [TRPO] iter = 883000 dist_mean = 0.1043 dist_std = 0.2091 vf_loss = 0.0434 grad_norm = 2.1298 nat_grad_norm = 0.2036 cg_residual = 1.1886 step_size = 0.3314 reward = -0.0000 fps = 20 mse_loss = 0.5240 
2022-05-01 07:20:37.174758 - gail/main.py:164 - [TRPO] iter = 884000 dist_mean = 0.0765 dist_std = 0.2086 vf_loss = 0.0818 grad_norm = 2.4831 nat_grad_norm = 0.1320 cg_residual = 0.5329 step_size = 0.4828 reward = 0.0000 fps = 16 mse_loss = 0.5830 
2022-05-01 07:20:47.415464 - gail/main.py:164 - [TRPO] iter = 885000 dist_mean = 0.1357 dist_std = 0.2079 vf_loss = 0.0398 grad_norm = 2.0027 nat_grad_norm = 0.1660 cg_residual = 0.4545 step_size = 0.3987 reward = 0.0000 fps = 14 mse_loss = 0.5873 
2022-05-01 07:20:47.676110 - gail/main.py:191 - [Discriminator] iter = 885000 loss = -1.0218 grad_norm = 3.1729 grad_penalty = 0.0988 regularization = 0.0000 true_logits = 0.0268 fake_logits = -1.0938 true_prob = 0.5052 fake_prob = 0.3776 
2022-05-01 07:20:54.775065 - gail/main.py:132 - [Evaluate] iter = 885000 episode={ returns = 39.2468 lengths = 22 } discounted_episode={ returns = 179.9222 lengths = 76 } 
2022-05-01 07:21:05.151191 - gail/main.py:164 - [TRPO] iter = 886000 dist_mean = 0.1665 dist_std = 0.2087 vf_loss = 0.0335 grad_norm = 2.1114 nat_grad_norm = 0.1612 cg_residual = 0.6619 step_size = 0.4037 reward = 0.0000 fps = 57 mse_loss = 0.5401 
2022-05-01 07:21:15.268085 - gail/main.py:164 - [TRPO] iter = 887000 dist_mean = 0.1057 dist_std = 0.2105 vf_loss = 0.0307 grad_norm = 1.9594 nat_grad_norm = 0.1624 cg_residual = 0.7049 step_size = 0.4068 reward = -0.0000 fps = 36 mse_loss = 0.5034 
2022-05-01 07:21:25.577136 - gail/main.py:164 - [TRPO] iter = 888000 dist_mean = 0.1509 dist_std = 0.2107 vf_loss = 0.1290 grad_norm = 2.0912 nat_grad_norm = 0.2094 cg_residual = 1.3236 step_size = 0.3378 reward = 0.0000 fps = 26 mse_loss = 0.5304 
2022-05-01 07:21:35.831638 - gail/main.py:164 - [TRPO] iter = 889000 dist_mean = 0.0805 dist_std = 0.2106 vf_loss = 0.0416 grad_norm = 2.3341 nat_grad_norm = 0.1449 cg_residual = 0.7453 step_size = 0.3979 reward = 0.0000 fps = 20 mse_loss = 0.5626 
2022-05-01 07:21:46.104380 - gail/main.py:164 - [TRPO] iter = 890000 dist_mean = 0.1071 dist_std = 0.2108 vf_loss = 0.0528 grad_norm = 1.9999 nat_grad_norm = 0.1474 cg_residual = 0.8104 step_size = 0.4227 reward = -0.0000 fps = 17 mse_loss = 0.5097 
2022-05-01 07:21:46.305115 - gail/main.py:191 - [Discriminator] iter = 890000 loss = -0.8406 grad_norm = 2.9994 grad_penalty = 0.0719 regularization = 0.0000 true_logits = 0.0736 fake_logits = -0.8389 true_prob = 0.5139 fake_prob = 0.3874 
2022-05-01 07:22:02.181409 - gail/main.py:132 - [Evaluate] iter = 890000 episode={ returns = 532.1904 lengths = 157 } discounted_episode={ returns = 164.5302 lengths = 68 } 
2022-05-01 07:22:12.308956 - gail/main.py:164 - [TRPO] iter = 891000 dist_mean = 0.0952 dist_std = 0.2112 vf_loss = 0.0420 grad_norm = 2.3226 nat_grad_norm = 0.1553 cg_residual = 0.3968 step_size = 0.4062 reward = -0.0000 fps = 38 mse_loss = 0.5546 
2022-05-01 07:22:22.544947 - gail/main.py:164 - [TRPO] iter = 892000 dist_mean = 0.0895 dist_std = 0.2124 vf_loss = 0.0772 grad_norm = 1.6629 nat_grad_norm = 0.1416 cg_residual = 0.6146 step_size = 0.4986 reward = -0.0000 fps = 27 mse_loss = 0.4982 
2022-05-01 07:22:33.007380 - gail/main.py:164 - [TRPO] iter = 893000 dist_mean = 0.0828 dist_std = 0.2125 vf_loss = 0.0384 grad_norm = 1.7662 nat_grad_norm = 0.1908 cg_residual = 1.0798 step_size = 0.3630 reward = -0.0000 fps = 21 mse_loss = 0.5032 
2022-05-01 07:22:43.373121 - gail/main.py:164 - [TRPO] iter = 894000 dist_mean = 0.0679 dist_std = 0.2126 vf_loss = 0.0265 grad_norm = 2.3021 nat_grad_norm = 0.1648 cg_residual = 0.8188 step_size = 0.4116 reward = -0.0000 fps = 17 mse_loss = 0.4597 
2022-05-01 07:22:53.900025 - gail/main.py:164 - [TRPO] iter = 895000 dist_mean = 0.0496 dist_std = 0.2123 vf_loss = 0.0533 grad_norm = 2.8983 nat_grad_norm = 0.1945 cg_residual = 0.6092 step_size = 0.3396 reward = -0.0000 fps = 14 mse_loss = 0.4607 
2022-05-01 07:22:54.111394 - gail/main.py:191 - [Discriminator] iter = 895000 loss = -0.4664 grad_norm = 3.2338 grad_penalty = 0.0707 regularization = 0.0000 true_logits = 0.0341 fake_logits = -0.5029 true_prob = 0.5107 fake_prob = 0.4349 
2022-05-01 07:24:12.623526 - gail/main.py:132 - [Evaluate] iter = 895000 episode={ returns = 2265.2788 lengths = 633 } discounted_episode={ returns = 1106.9039 lengths = 502 } 
2022-05-01 07:24:22.592462 - gail/main.py:164 - [TRPO] iter = 896000 dist_mean = 0.0375 dist_std = 0.2109 vf_loss = 0.0222 grad_norm = 1.7254 nat_grad_norm = 0.1937 cg_residual = 1.0689 step_size = 0.3996 reward = -0.0000 fps = 11 mse_loss = 0.5590 
2022-05-01 07:24:32.728846 - gail/main.py:164 - [TRPO] iter = 897000 dist_mean = 0.1322 dist_std = 0.2102 vf_loss = 0.1093 grad_norm = 2.0687 nat_grad_norm = 0.1218 cg_residual = 0.3202 step_size = 0.4928 reward = -0.0000 fps = 10 mse_loss = 0.5247 
2022-05-01 07:24:42.677448 - gail/main.py:164 - [TRPO] iter = 898000 dist_mean = 0.0833 dist_std = 0.2096 vf_loss = 0.0489 grad_norm = 2.4675 nat_grad_norm = 0.1650 cg_residual = 0.8163 step_size = 0.3599 reward = 0.0000 fps = 9 mse_loss = 0.5162 
2022-05-01 07:24:52.853817 - gail/main.py:164 - [TRPO] iter = 899000 dist_mean = 0.0864 dist_std = 0.2090 vf_loss = 0.0469 grad_norm = 2.1719 nat_grad_norm = 0.1278 cg_residual = 0.4389 step_size = 0.4906 reward = -0.0000 fps = 8 mse_loss = 0.5231 
2022-05-01 07:25:03.191064 - gail/main.py:164 - [TRPO] iter = 900000 dist_mean = 0.0788 dist_std = 0.2097 vf_loss = 0.0983 grad_norm = 3.3297 nat_grad_norm = 0.2346 cg_residual = 1.2037 step_size = 0.2886 reward = 0.0000 fps = 7 mse_loss = 0.5076 
2022-05-01 07:25:03.370622 - gail/main.py:191 - [Discriminator] iter = 900000 loss = -0.6223 grad_norm = 3.1213 grad_penalty = 0.0618 regularization = 0.0000 true_logits = 0.0331 fake_logits = -0.6511 true_prob = 0.5112 fake_prob = 0.4095 
2022-05-01 07:25:31.701502 - gail/main.py:132 - [Evaluate] iter = 900000 episode={ returns = 965.5350 lengths = 275 } discounted_episode={ returns = 328.3766 lengths = 129 } 
2022-05-01 07:25:42.226160 - gail/main.py:164 - [TRPO] iter = 901000 dist_mean = 0.0599 dist_std = 0.2093 vf_loss = 0.0494 grad_norm = 1.9962 nat_grad_norm = 0.1882 cg_residual = 0.5565 step_size = 0.3711 reward = 0.0000 fps = 25 mse_loss = 0.4909 
2022-05-01 07:25:52.654717 - gail/main.py:164 - [TRPO] iter = 902000 dist_mean = 0.1087 dist_std = 0.2089 vf_loss = 0.0521 grad_norm = 1.8891 nat_grad_norm = 0.1441 cg_residual = 0.8972 step_size = 0.4277 reward = -0.0000 fps = 20 mse_loss = 0.4695 
2022-05-01 07:26:03.219969 - gail/main.py:164 - [TRPO] iter = 903000 dist_mean = 0.1220 dist_std = 0.2084 vf_loss = 0.0494 grad_norm = 2.4621 nat_grad_norm = 0.1501 cg_residual = 0.6786 step_size = 0.4442 reward = 0.0000 fps = 16 mse_loss = 0.4522 
2022-05-01 07:26:13.110949 - gail/main.py:164 - [TRPO] iter = 904000 dist_mean = 0.0877 dist_std = 0.2090 vf_loss = 0.1735 grad_norm = 1.7812 nat_grad_norm = 0.1101 cg_residual = 0.4715 step_size = 0.5672 reward = -0.0000 fps = 14 mse_loss = 0.5125 
2022-05-01 07:26:23.150023 - gail/main.py:164 - [TRPO] iter = 905000 dist_mean = 0.0959 dist_std = 0.2091 vf_loss = 0.0688 grad_norm = 2.3388 nat_grad_norm = 0.1365 cg_residual = 0.5547 step_size = 0.3778 reward = -0.0000 fps = 12 mse_loss = 0.4602 
2022-05-01 07:26:23.353149 - gail/main.py:191 - [Discriminator] iter = 905000 loss = -0.7383 grad_norm = 2.5653 grad_penalty = 0.0699 regularization = 0.0000 true_logits = -0.0210 fake_logits = -0.8291 true_prob = 0.5009 fake_prob = 0.3875 
2022-05-01 07:26:33.596945 - gail/main.py:132 - [Evaluate] iter = 905000 episode={ returns = 39.5043 lengths = 22 } discounted_episode={ returns = 251.1698 lengths = 120 } 
2022-05-01 07:26:44.034523 - gail/main.py:164 - [TRPO] iter = 906000 dist_mean = 0.0940 dist_std = 0.2090 vf_loss = 0.1587 grad_norm = 2.1271 nat_grad_norm = 0.1172 cg_residual = 0.3860 step_size = 0.4664 reward = 0.0000 fps = 48 mse_loss = 0.4626 
2022-05-01 07:26:54.849220 - gail/main.py:164 - [TRPO] iter = 907000 dist_mean = 0.1633 dist_std = 0.2085 vf_loss = 0.0479 grad_norm = 3.0955 nat_grad_norm = 0.1605 cg_residual = 0.5027 step_size = 0.3570 reward = -0.0000 fps = 31 mse_loss = 0.4711 
2022-05-01 07:27:05.152054 - gail/main.py:164 - [TRPO] iter = 908000 dist_mean = 0.0593 dist_std = 0.2082 vf_loss = 0.1801 grad_norm = 1.5816 nat_grad_norm = 0.1049 cg_residual = 0.3274 step_size = 0.5752 reward = -0.0000 fps = 23 mse_loss = 0.5115 
2022-05-01 07:27:15.874189 - gail/main.py:164 - [TRPO] iter = 909000 dist_mean = 0.3848 dist_std = 0.2091 vf_loss = 0.0902 grad_norm = 1.7824 nat_grad_norm = 0.1661 cg_residual = 3.1821 step_size = 0.3709 reward = 0.0000 fps = 19 mse_loss = 0.4447 
2022-05-01 07:27:25.990706 - gail/main.py:164 - [TRPO] iter = 910000 dist_mean = 0.1415 dist_std = 0.2109 vf_loss = 0.0338 grad_norm = 2.2311 nat_grad_norm = 0.0972 cg_residual = 0.1615 step_size = 0.6016 reward = -0.0000 fps = 15 mse_loss = 0.5019 
2022-05-01 07:27:26.252379 - gail/main.py:191 - [Discriminator] iter = 910000 loss = -1.2478 grad_norm = 3.4043 grad_penalty = 0.1032 regularization = 0.0000 true_logits = -0.0829 fake_logits = -1.4339 true_prob = 0.4916 fake_prob = 0.3216 
2022-05-01 07:27:34.051550 - gail/main.py:132 - [Evaluate] iter = 910000 episode={ returns = 39.3106 lengths = 22 } discounted_episode={ returns = 200.8987 lengths = 85 } 
2022-05-01 07:27:45.208204 - gail/main.py:164 - [TRPO] iter = 911000 dist_mean = 0.4888 dist_std = 0.2110 vf_loss = 0.4447 grad_norm = 2.0588 nat_grad_norm = 0.1137 cg_residual = 0.9131 step_size = 0.5018 reward = -0.0000 fps = 52 mse_loss = 0.5050 
2022-05-01 07:27:55.537553 - gail/main.py:164 - [TRPO] iter = 912000 dist_mean = 0.1952 dist_std = 0.2109 vf_loss = 0.2606 grad_norm = 2.4702 nat_grad_norm = 0.1351 cg_residual = 0.4224 step_size = 0.4091 reward = 0.0000 fps = 34 mse_loss = 0.4633 
2022-05-01 07:28:06.240556 - gail/main.py:164 - [TRPO] iter = 913000 dist_mean = 0.1153 dist_std = 0.2110 vf_loss = 0.5096 grad_norm = 1.1868 nat_grad_norm = 0.0974 cg_residual = 0.3124 step_size = 0.7150 reward = -0.0000 fps = 25 mse_loss = 0.5289 
2022-05-01 07:28:16.856575 - gail/main.py:164 - [TRPO] iter = 914000 dist_mean = 0.2322 dist_std = 0.2120 vf_loss = 0.2957 grad_norm = 1.6062 nat_grad_norm = 0.1319 cg_residual = 0.3922 step_size = 0.5249 reward = -0.0000 fps = 19 mse_loss = 0.5111 
2022-05-01 07:28:27.455506 - gail/main.py:164 - [TRPO] iter = 915000 dist_mean = 0.1538 dist_std = 0.2127 vf_loss = 0.5465 grad_norm = 2.3737 nat_grad_norm = 0.1542 cg_residual = 0.5285 step_size = 0.3945 reward = -0.0000 fps = 16 mse_loss = 0.5678 
2022-05-01 07:28:27.659963 - gail/main.py:191 - [Discriminator] iter = 915000 loss = -1.0075 grad_norm = 2.9073 grad_penalty = 0.0997 regularization = 0.0000 true_logits = -0.1422 fake_logits = -1.2494 true_prob = 0.4832 fake_prob = 0.3416 
2022-05-01 07:28:42.672698 - gail/main.py:132 - [Evaluate] iter = 915000 episode={ returns = 622.9797 lengths = 181 } discounted_episode={ returns = 39.1503 lengths = 22 } 
2022-05-01 07:28:52.987296 - gail/main.py:164 - [TRPO] iter = 916000 dist_mean = 0.1161 dist_std = 0.2125 vf_loss = 0.2101 grad_norm = 2.7329 nat_grad_norm = 0.1569 cg_residual = 0.5795 step_size = 0.3960 reward = 0.0000 fps = 39 mse_loss = 0.5774 
2022-05-01 07:29:03.352846 - gail/main.py:164 - [TRPO] iter = 917000 dist_mean = 0.0638 dist_std = 0.2130 vf_loss = 0.1018 grad_norm = 2.4080 nat_grad_norm = 0.1618 cg_residual = 0.7307 step_size = 0.3678 reward = -0.0000 fps = 28 mse_loss = 0.5402 
2022-05-01 07:29:13.770556 - gail/main.py:164 - [TRPO] iter = 918000 dist_mean = 0.0668 dist_std = 0.2122 vf_loss = 0.0495 grad_norm = 1.6749 nat_grad_norm = 0.1356 cg_residual = 0.4633 step_size = 0.4683 reward = -0.0000 fps = 21 mse_loss = 0.5172 
2022-05-01 07:29:24.361194 - gail/main.py:164 - [TRPO] iter = 919000 dist_mean = 0.0470 dist_std = 0.2111 vf_loss = 0.0715 grad_norm = 2.1246 nat_grad_norm = 0.1291 cg_residual = 0.7892 step_size = 0.4688 reward = -0.0000 fps = 17 mse_loss = 0.5374 
2022-05-01 07:29:34.636255 - gail/main.py:164 - [TRPO] iter = 920000 dist_mean = 0.0658 dist_std = 0.2117 vf_loss = 0.0574 grad_norm = 1.8617 nat_grad_norm = 0.1266 cg_residual = 0.4903 step_size = 0.4793 reward = -0.0000 fps = 14 mse_loss = 0.5800 
2022-05-01 07:29:34.846017 - gail/main.py:191 - [Discriminator] iter = 920000 loss = -0.4011 grad_norm = 2.9702 grad_penalty = 0.0730 regularization = 0.0000 true_logits = -0.1339 fake_logits = -0.6080 true_prob = 0.4818 fake_prob = 0.4127 
2022-05-01 07:30:13.265852 - gail/main.py:132 - [Evaluate] iter = 920000 episode={ returns = 1087.0578 lengths = 315 } discounted_episode={ returns = 467.0182 lengths = 218 } 
2022-05-01 07:30:23.985248 - gail/main.py:164 - [TRPO] iter = 921000 dist_mean = 0.1601 dist_std = 0.2115 vf_loss = 0.1055 grad_norm = 2.2841 nat_grad_norm = 0.1386 cg_residual = 0.5003 step_size = 0.4102 reward = -0.0000 fps = 20 mse_loss = 0.5041 
2022-05-01 07:30:34.330047 - gail/main.py:164 - [TRPO] iter = 922000 dist_mean = 0.0530 dist_std = 0.2122 vf_loss = 0.0434 grad_norm = 1.7928 nat_grad_norm = 0.1166 cg_residual = 0.4454 step_size = 0.4957 reward = -0.0000 fps = 16 mse_loss = 0.5821 
2022-05-01 07:30:44.969810 - gail/main.py:164 - [TRPO] iter = 923000 dist_mean = 0.0483 dist_std = 0.2104 vf_loss = 0.0541 grad_norm = 2.6260 nat_grad_norm = 0.1479 cg_residual = 0.4252 step_size = 0.3890 reward = 0.0000 fps = 14 mse_loss = 0.5166 
2022-05-01 07:30:55.144061 - gail/main.py:164 - [TRPO] iter = 924000 dist_mean = 0.0304 dist_std = 0.2103 vf_loss = 0.0279 grad_norm = 1.6873 nat_grad_norm = 0.1530 cg_residual = 0.9373 step_size = 0.4359 reward = -0.0000 fps = 12 mse_loss = 0.4979 
2022-05-01 07:31:05.757450 - gail/main.py:164 - [TRPO] iter = 925000 dist_mean = 0.0755 dist_std = 0.2104 vf_loss = 0.1280 grad_norm = 2.4322 nat_grad_norm = 0.1030 cg_residual = 0.2884 step_size = 0.5129 reward = -0.0000 fps = 11 mse_loss = 0.5184 
2022-05-01 07:31:05.946579 - gail/main.py:191 - [Discriminator] iter = 925000 loss = -0.3847 grad_norm = 3.1168 grad_penalty = 0.0623 regularization = 0.0000 true_logits = -0.1041 fake_logits = -0.5510 true_prob = 0.4869 fake_prob = 0.4119 
2022-05-01 07:31:56.683435 - gail/main.py:132 - [Evaluate] iter = 925000 episode={ returns = 1435.5055 lengths = 413 } discounted_episode={ returns = 679.8419 lengths = 315 } 
2022-05-01 07:32:06.681670 - gail/main.py:164 - [TRPO] iter = 926000 dist_mean = 0.0970 dist_std = 0.2097 vf_loss = 0.0388 grad_norm = 4.2890 nat_grad_norm = 0.1408 cg_residual = 1.7396 step_size = 0.3569 reward = -0.0000 fps = 16 mse_loss = 0.5194 
2022-05-01 07:32:16.656353 - gail/main.py:164 - [TRPO] iter = 927000 dist_mean = 0.0349 dist_std = 0.2094 vf_loss = 0.0217 grad_norm = 2.0588 nat_grad_norm = 0.1401 cg_residual = 0.6153 step_size = 0.4748 reward = 0.0000 fps = 14 mse_loss = 0.4710 
2022-05-01 07:32:26.973198 - gail/main.py:164 - [TRPO] iter = 928000 dist_mean = 0.1264 dist_std = 0.2080 vf_loss = 0.1288 grad_norm = 2.2427 nat_grad_norm = 0.1135 cg_residual = 0.5339 step_size = 0.5061 reward = 0.0000 fps = 12 mse_loss = 0.5724 
2022-05-01 07:32:36.893574 - gail/main.py:164 - [TRPO] iter = 929000 dist_mean = 0.0347 dist_std = 0.2082 vf_loss = 0.0242 grad_norm = 1.5436 nat_grad_norm = 0.1408 cg_residual = 0.8834 step_size = 0.4995 reward = -0.0000 fps = 10 mse_loss = 0.5315 
2022-05-01 07:32:47.231611 - gail/main.py:164 - [TRPO] iter = 930000 dist_mean = 0.2757 dist_std = 0.2069 vf_loss = 0.3013 grad_norm = 1.6632 nat_grad_norm = 0.1412 cg_residual = 0.5869 step_size = 0.4750 reward = 0.0000 fps = 9 mse_loss = 0.5091 
2022-05-01 07:32:47.485829 - gail/main.py:191 - [Discriminator] iter = 930000 loss = -1.9629 grad_norm = 3.8676 grad_penalty = 0.1457 regularization = 0.0000 true_logits = -0.2655 fake_logits = -2.3741 true_prob = 0.4569 fake_prob = 0.2224 
2022-05-01 07:32:58.889123 - gail/main.py:132 - [Evaluate] iter = 930000 episode={ returns = 260.5604 lengths = 82 } discounted_episode={ returns = 187.3567 lengths = 78 } 
2022-05-01 07:33:09.438458 - gail/main.py:164 - [TRPO] iter = 931000 dist_mean = 0.0906 dist_std = 0.2078 vf_loss = 0.0546 grad_norm = 2.0840 nat_grad_norm = 0.1808 cg_residual = 0.5400 step_size = 0.4210 reward = 0.0000 fps = 45 mse_loss = 0.5635 
2022-05-01 07:33:19.931206 - gail/main.py:164 - [TRPO] iter = 932000 dist_mean = 0.1254 dist_std = 0.2078 vf_loss = 0.0314 grad_norm = 1.7061 nat_grad_norm = 0.1312 cg_residual = 0.5773 step_size = 0.4815 reward = 0.0000 fps = 30 mse_loss = 0.5757 
2022-05-01 07:33:29.559157 - gail/main.py:164 - [TRPO] iter = 933000 dist_mean = 0.0729 dist_std = 0.2079 vf_loss = 0.1927 grad_norm = 1.3140 nat_grad_norm = 0.0872 cg_residual = 0.2095 step_size = 0.7262 reward = 0.0000 fps = 23 mse_loss = 0.5560 
2022-05-01 07:33:40.194572 - gail/main.py:164 - [TRPO] iter = 934000 dist_mean = 0.0894 dist_std = 0.2062 vf_loss = 0.2186 grad_norm = 1.8021 nat_grad_norm = 0.1176 cg_residual = 0.3359 step_size = 0.4730 reward = 0.0000 fps = 18 mse_loss = 0.5520 
2022-05-01 07:33:50.476806 - gail/main.py:164 - [TRPO] iter = 935000 dist_mean = 0.0778 dist_std = 0.2065 vf_loss = 0.1917 grad_norm = 2.2433 nat_grad_norm = 0.0904 cg_residual = 0.4072 step_size = 0.5652 reward = 0.0000 fps = 15 mse_loss = 0.5198 
2022-05-01 07:33:50.699712 - gail/main.py:191 - [Discriminator] iter = 935000 loss = -0.5804 grad_norm = 3.1088 grad_penalty = 0.0818 regularization = 0.0000 true_logits = -0.0946 fake_logits = -0.7568 true_prob = 0.4876 fake_prob = 0.3977 
2022-05-01 07:34:00.548598 - gail/main.py:132 - [Evaluate] iter = 935000 episode={ returns = 39.2925 lengths = 22 } discounted_episode={ returns = 253.6123 lengths = 120 } 
2022-05-01 07:34:10.429504 - gail/main.py:164 - [TRPO] iter = 936000 dist_mean = 0.0335 dist_std = 0.2075 vf_loss = 0.0192 grad_norm = 1.7675 nat_grad_norm = 0.1766 cg_residual = 0.8751 step_size = 0.3836 reward = -0.0000 fps = 50 mse_loss = 0.5606 
2022-05-01 07:34:20.559175 - gail/main.py:164 - [TRPO] iter = 937000 dist_mean = 0.0977 dist_std = 0.2074 vf_loss = 0.0164 grad_norm = 3.0500 nat_grad_norm = 0.1145 cg_residual = 0.3267 step_size = 0.4976 reward = -0.0000 fps = 33 mse_loss = 0.5399 
2022-05-01 07:34:30.839105 - gail/main.py:164 - [TRPO] iter = 938000 dist_mean = 0.0248 dist_std = 0.2072 vf_loss = 0.0280 grad_norm = 1.8314 nat_grad_norm = 0.1171 cg_residual = 0.2155 step_size = 0.4825 reward = 0.0000 fps = 24 mse_loss = 0.5087 
2022-05-01 07:34:41.056710 - gail/main.py:164 - [TRPO] iter = 939000 dist_mean = 0.0415 dist_std = 0.2075 vf_loss = 0.0297 grad_norm = 1.5471 nat_grad_norm = 0.1155 cg_residual = 0.3657 step_size = 0.4916 reward = -0.0000 fps = 19 mse_loss = 0.5242 
2022-05-01 07:34:51.419698 - gail/main.py:164 - [TRPO] iter = 940000 dist_mean = 0.0577 dist_std = 0.2077 vf_loss = 0.1082 grad_norm = 1.4764 nat_grad_norm = 0.1272 cg_residual = 0.2620 step_size = 0.4624 reward = -0.0000 fps = 16 mse_loss = 0.5733 
2022-05-01 07:34:51.668983 - gail/main.py:191 - [Discriminator] iter = 940000 loss = -0.6549 grad_norm = 3.2769 grad_penalty = 0.0691 regularization = 0.0000 true_logits = -0.1224 fake_logits = -0.8464 true_prob = 0.4834 fake_prob = 0.3838 
2022-05-01 07:35:22.242354 - gail/main.py:132 - [Evaluate] iter = 940000 episode={ returns = 1171.1030 lengths = 332 } discounted_episode={ returns = 222.7875 lengths = 97 } 
2022-05-01 07:35:32.243778 - gail/main.py:164 - [TRPO] iter = 941000 dist_mean = 0.1214 dist_std = 0.2085 vf_loss = 0.0499 grad_norm = 2.4517 nat_grad_norm = 0.1740 cg_residual = 0.9458 step_size = 0.4020 reward = 0.0000 fps = 24 mse_loss = 0.5370 
2022-05-01 07:35:42.758989 - gail/main.py:164 - [TRPO] iter = 942000 dist_mean = 0.0779 dist_std = 0.2090 vf_loss = 0.0306 grad_norm = 2.0844 nat_grad_norm = 0.1570 cg_residual = 0.4896 step_size = 0.4482 reward = -0.0000 fps = 19 mse_loss = 0.4990 
2022-05-01 07:35:52.400639 - gail/main.py:164 - [TRPO] iter = 943000 dist_mean = 0.0201 dist_std = 0.2097 vf_loss = 0.0174 grad_norm = 2.0155 nat_grad_norm = 0.1671 cg_residual = 1.5630 step_size = 0.3966 reward = 0.0000 fps = 16 mse_loss = 0.5566 
2022-05-01 07:36:02.219143 - gail/main.py:164 - [TRPO] iter = 944000 dist_mean = 0.0765 dist_std = 0.2090 vf_loss = 0.2656 grad_norm = 1.1367 nat_grad_norm = 0.1042 cg_residual = 0.2525 step_size = 0.6091 reward = 0.0000 fps = 14 mse_loss = 0.5361 
2022-05-01 07:36:11.958610 - gail/main.py:164 - [TRPO] iter = 945000 dist_mean = 0.0830 dist_std = 0.2092 vf_loss = 0.0252 grad_norm = 2.3515 nat_grad_norm = 0.1479 cg_residual = 0.5479 step_size = 0.4535 reward = 0.0000 fps = 12 mse_loss = 0.5715 
2022-05-01 07:36:12.237715 - gail/main.py:191 - [Discriminator] iter = 945000 loss = -1.0281 grad_norm = 3.1776 grad_penalty = 0.0863 regularization = 0.0000 true_logits = -0.1523 fake_logits = -1.2666 true_prob = 0.4804 fake_prob = 0.3331 
2022-05-01 07:36:31.771730 - gail/main.py:132 - [Evaluate] iter = 945000 episode={ returns = 273.2272 lengths = 86 } discounted_episode={ returns = 428.7789 lengths = 191 } 
2022-05-01 07:36:41.882302 - gail/main.py:164 - [TRPO] iter = 946000 dist_mean = 0.0502 dist_std = 0.2076 vf_loss = 0.1734 grad_norm = 2.0046 nat_grad_norm = 0.1251 cg_residual = 0.4556 step_size = 0.4888 reward = 0.0000 fps = 33 mse_loss = 0.4908 
2022-05-01 07:36:52.025981 - gail/main.py:164 - [TRPO] iter = 947000 dist_mean = 0.0645 dist_std = 0.2077 vf_loss = 0.0312 grad_norm = 1.8784 nat_grad_norm = 0.1632 cg_residual = 0.7543 step_size = 0.3985 reward = -0.0000 fps = 25 mse_loss = 0.4819 
2022-05-01 07:37:02.542548 - gail/main.py:164 - [TRPO] iter = 948000 dist_mean = 0.0929 dist_std = 0.2073 vf_loss = 0.0240 grad_norm = 2.0947 nat_grad_norm = 0.1144 cg_residual = 0.3026 step_size = 0.5209 reward = -0.0000 fps = 19 mse_loss = 0.5187 
2022-05-01 07:37:12.881416 - gail/main.py:164 - [TRPO] iter = 949000 dist_mean = 0.0985 dist_std = 0.2070 vf_loss = 0.0454 grad_norm = 1.9754 nat_grad_norm = 0.2376 cg_residual = 1.1310 step_size = 0.3012 reward = 0.0000 fps = 16 mse_loss = 0.5471 
2022-05-01 07:37:23.205517 - gail/main.py:164 - [TRPO] iter = 950000 dist_mean = 0.1651 dist_std = 0.2074 vf_loss = 0.0295 grad_norm = 2.2528 nat_grad_norm = 0.1411 cg_residual = 0.4078 step_size = 0.4213 reward = -0.0000 fps = 14 mse_loss = 0.5516 
2022-05-01 07:37:23.445043 - gail/main.py:191 - [Discriminator] iter = 950000 loss = -1.4290 grad_norm = 3.4305 grad_penalty = 0.1100 regularization = 0.0000 true_logits = -0.2248 fake_logits = -1.7637 true_prob = 0.4700 fake_prob = 0.2888 
2022-05-01 07:37:26.628526 - gail/main.py:132 - [Evaluate] iter = 950000 episode={ returns = 38.5729 lengths = 22 } discounted_episode={ returns = 37.6995 lengths = 21 } 
2022-05-01 07:37:36.988501 - gail/main.py:164 - [TRPO] iter = 951000 dist_mean = 0.0749 dist_std = 0.2070 vf_loss = 0.2192 grad_norm = 1.9992 nat_grad_norm = 0.1164 cg_residual = 0.4337 step_size = 0.5236 reward = 0.0000 fps = 73 mse_loss = 0.5604 
2022-05-01 07:37:47.343497 - gail/main.py:164 - [TRPO] iter = 952000 dist_mean = 0.1525 dist_std = 0.2061 vf_loss = 0.6102 grad_norm = 3.0184 nat_grad_norm = 0.1166 cg_residual = 1.2671 step_size = 0.4627 reward = -0.0000 fps = 41 mse_loss = 0.5783 
2022-05-01 07:37:57.122881 - gail/main.py:164 - [TRPO] iter = 953000 dist_mean = 0.0597 dist_std = 0.2067 vf_loss = 0.0378 grad_norm = 2.0039 nat_grad_norm = 0.1196 cg_residual = 0.8918 step_size = 0.4688 reward = 0.0000 fps = 29 mse_loss = 0.5680 
2022-05-01 07:38:06.657005 - gail/main.py:164 - [TRPO] iter = 954000 dist_mean = 0.0715 dist_std = 0.2080 vf_loss = 0.2540 grad_norm = 2.3622 nat_grad_norm = 0.1093 cg_residual = 0.5411 step_size = 0.4790 reward = -0.0000 fps = 23 mse_loss = 0.5762 
2022-05-01 07:38:16.602533 - gail/main.py:164 - [TRPO] iter = 955000 dist_mean = 0.1261 dist_std = 0.2080 vf_loss = 0.4376 grad_norm = 1.3654 nat_grad_norm = 0.1051 cg_residual = 0.3224 step_size = 0.5988 reward = -0.0000 fps = 18 mse_loss = 0.5489 
2022-05-01 07:38:16.842787 - gail/main.py:191 - [Discriminator] iter = 955000 loss = -0.6688 grad_norm = 3.1023 grad_penalty = 0.0876 regularization = 0.0000 true_logits = -0.2450 fake_logits = -1.0015 true_prob = 0.4710 fake_prob = 0.3725 
2022-05-01 07:38:39.783546 - gail/main.py:132 - [Evaluate] iter = 955000 episode={ returns = 372.9728 lengths = 119 } discounted_episode={ returns = 449.8320 lengths = 218 } 
2022-05-01 07:38:50.083510 - gail/main.py:164 - [TRPO] iter = 956000 dist_mean = 0.1033 dist_std = 0.2097 vf_loss = 0.4790 grad_norm = 1.8907 nat_grad_norm = 0.1001 cg_residual = 0.2409 step_size = 0.6104 reward = -0.0000 fps = 30 mse_loss = 0.6084 
2022-05-01 07:39:00.109137 - gail/main.py:164 - [TRPO] iter = 957000 dist_mean = 0.0333 dist_std = 0.2111 vf_loss = 0.0194 grad_norm = 2.2954 nat_grad_norm = 0.1490 cg_residual = 0.5632 step_size = 0.3617 reward = 0.0000 fps = 23 mse_loss = 0.5635 
2022-05-01 07:39:10.225788 - gail/main.py:164 - [TRPO] iter = 958000 dist_mean = 0.0786 dist_std = 0.2116 vf_loss = 0.0296 grad_norm = 2.7984 nat_grad_norm = 0.1493 cg_residual = 0.9152 step_size = 0.3663 reward = -0.0000 fps = 18 mse_loss = 0.4906 
2022-05-01 07:39:20.515115 - gail/main.py:164 - [TRPO] iter = 959000 dist_mean = 0.0817 dist_std = 0.2110 vf_loss = 0.4326 grad_norm = 2.4793 nat_grad_norm = 0.1384 cg_residual = 0.5630 step_size = 0.4546 reward = -0.0000 fps = 15 mse_loss = 0.5198 
2022-05-01 07:39:30.442239 - gail/main.py:164 - [TRPO] iter = 960000 dist_mean = 0.0339 dist_std = 0.2108 vf_loss = 0.0380 grad_norm = 3.0692 nat_grad_norm = 0.1166 cg_residual = 0.4546 step_size = 0.4666 reward = 0.0000 fps = 13 mse_loss = 0.5277 
2022-05-01 07:39:30.679355 - gail/main.py:191 - [Discriminator] iter = 960000 loss = -0.3525 grad_norm = 3.2005 grad_penalty = 0.0617 regularization = 0.0000 true_logits = -0.2371 fake_logits = -0.6513 true_prob = 0.4704 fake_prob = 0.4034 
2022-05-01 07:39:33.831832 - gail/main.py:132 - [Evaluate] iter = 960000 episode={ returns = 38.1353 lengths = 22 } discounted_episode={ returns = 37.9144 lengths = 22 } 
2022-05-01 07:39:43.989905 - gail/main.py:164 - [TRPO] iter = 961000 dist_mean = 0.1467 dist_std = 0.2101 vf_loss = 0.1639 grad_norm = 1.6418 nat_grad_norm = 0.1652 cg_residual = 0.5592 step_size = 0.4091 reward = -0.0000 fps = 75 mse_loss = 0.5586 
2022-05-01 07:39:53.886340 - gail/main.py:164 - [TRPO] iter = 962000 dist_mean = 0.0343 dist_std = 0.2109 vf_loss = 0.0388 grad_norm = 1.8959 nat_grad_norm = 0.1251 cg_residual = 0.3653 step_size = 0.4849 reward = 0.0000 fps = 43 mse_loss = 0.5009 
2022-05-01 07:40:04.150756 - gail/main.py:164 - [TRPO] iter = 963000 dist_mean = 0.1633 dist_std = 0.2110 vf_loss = 0.0571 grad_norm = 2.1370 nat_grad_norm = 0.2073 cg_residual = 0.9361 step_size = 0.3545 reward = -0.0000 fps = 29 mse_loss = 0.6322 
2022-05-01 07:40:14.265049 - gail/main.py:164 - [TRPO] iter = 964000 dist_mean = 0.0112 dist_std = 0.2110 vf_loss = 0.2949 grad_norm = 1.9321 nat_grad_norm = 0.1018 cg_residual = 0.2938 step_size = 0.5266 reward = -0.0000 fps = 22 mse_loss = 0.5216 
2022-05-01 07:40:23.920353 - gail/main.py:164 - [TRPO] iter = 965000 dist_mean = 0.0603 dist_std = 0.2111 vf_loss = 0.0219 grad_norm = 1.7041 nat_grad_norm = 0.1626 cg_residual = 0.5677 step_size = 0.4202 reward = -0.0000 fps = 18 mse_loss = 0.5400 
2022-05-01 07:40:24.155169 - gail/main.py:191 - [Discriminator] iter = 965000 loss = -0.7034 grad_norm = 2.8304 grad_penalty = 0.0684 regularization = 0.0000 true_logits = -0.4175 fake_logits = -1.1893 true_prob = 0.4460 fake_prob = 0.3479 
2022-05-01 07:40:50.818234 - gail/main.py:132 - [Evaluate] iter = 965000 episode={ returns = 37.4506 lengths = 21 } discounted_episode={ returns = 838.9047 lengths = 379 } 
2022-05-01 07:41:00.643452 - gail/main.py:164 - [TRPO] iter = 966000 dist_mean = 0.0306 dist_std = 0.2109 vf_loss = 0.0164 grad_norm = 2.0685 nat_grad_norm = 0.1257 cg_residual = 0.4375 step_size = 0.4488 reward = -0.0000 fps = 27 mse_loss = 0.6055 
2022-05-01 07:41:10.682377 - gail/main.py:164 - [TRPO] iter = 967000 dist_mean = 0.1390 dist_std = 0.2105 vf_loss = 0.3125 grad_norm = 1.4820 nat_grad_norm = 0.1345 cg_residual = 0.3714 step_size = 0.5151 reward = -0.0000 fps = 21 mse_loss = 0.5894 
2022-05-01 07:41:20.567457 - gail/main.py:164 - [TRPO] iter = 968000 dist_mean = 0.0522 dist_std = 0.2104 vf_loss = 0.4002 grad_norm = 1.4462 nat_grad_norm = 0.0936 cg_residual = 0.3460 step_size = 0.6658 reward = -0.0000 fps = 17 mse_loss = 0.6478 
2022-05-01 07:41:30.136398 - gail/main.py:164 - [TRPO] iter = 969000 dist_mean = 0.0733 dist_std = 0.2106 vf_loss = 0.0237 grad_norm = 1.7840 nat_grad_norm = 0.1871 cg_residual = 0.8003 step_size = 0.3508 reward = -0.0000 fps = 15 mse_loss = 0.6178 
2022-05-01 07:41:40.287609 - gail/main.py:164 - [TRPO] iter = 970000 dist_mean = 0.0391 dist_std = 0.2097 vf_loss = 0.0266 grad_norm = 2.6103 nat_grad_norm = 0.1289 cg_residual = 0.4814 step_size = 0.4594 reward = -0.0000 fps = 13 mse_loss = 0.5711 
2022-05-01 07:41:40.516562 - gail/main.py:191 - [Discriminator] iter = 970000 loss = -0.6333 grad_norm = 2.8616 grad_penalty = 0.0680 regularization = 0.0000 true_logits = -0.3550 fake_logits = -1.0563 true_prob = 0.4543 fake_prob = 0.3627 
2022-05-01 07:41:56.428348 - gail/main.py:132 - [Evaluate] iter = 970000 episode={ returns = 391.4594 lengths = 119 } discounted_episode={ returns = 248.9968 lengths = 119 } 
2022-05-01 07:42:06.397902 - gail/main.py:164 - [TRPO] iter = 971000 dist_mean = 0.0166 dist_std = 0.2100 vf_loss = 0.1417 grad_norm = 2.0133 nat_grad_norm = 0.0927 cg_residual = 0.4056 step_size = 0.5376 reward = 0.0000 fps = 38 mse_loss = 0.7005 
2022-05-01 07:42:16.370362 - gail/main.py:164 - [TRPO] iter = 972000 dist_mean = 0.0962 dist_std = 0.2099 vf_loss = 0.0243 grad_norm = 2.3011 nat_grad_norm = 0.1759 cg_residual = 0.8272 step_size = 0.3278 reward = 0.0000 fps = 27 mse_loss = 0.5624 
2022-05-01 07:42:26.437176 - gail/main.py:164 - [TRPO] iter = 973000 dist_mean = 0.0666 dist_std = 0.2094 vf_loss = 0.0221 grad_norm = 1.8635 nat_grad_norm = 0.1948 cg_residual = 0.8269 step_size = 0.3704 reward = 0.0000 fps = 21 mse_loss = 0.6260 
2022-05-01 07:42:36.522492 - gail/main.py:164 - [TRPO] iter = 974000 dist_mean = 0.0535 dist_std = 0.2089 vf_loss = 0.4379 grad_norm = 1.6510 nat_grad_norm = 0.1208 cg_residual = 0.3475 step_size = 0.5254 reward = -0.0000 fps = 17 mse_loss = 0.6070 
2022-05-01 07:42:46.548706 - gail/main.py:164 - [TRPO] iter = 975000 dist_mean = 0.0469 dist_std = 0.2080 vf_loss = 0.0203 grad_norm = 1.3983 nat_grad_norm = 0.1849 cg_residual = 0.6870 step_size = 0.4079 reward = 0.0000 fps = 15 mse_loss = 0.6215 
2022-05-01 07:42:46.758774 - gail/main.py:191 - [Discriminator] iter = 975000 loss = -0.7067 grad_norm = 2.8687 grad_penalty = 0.0675 regularization = 0.0000 true_logits = -0.4694 fake_logits = -1.2436 true_prob = 0.4380 fake_prob = 0.3432 
2022-05-01 07:42:56.610053 - gail/main.py:132 - [Evaluate] iter = 975000 episode={ returns = 382.6559 lengths = 119 } discounted_episode={ returns = 38.1475 lengths = 22 } 
2022-05-01 07:43:06.544700 - gail/main.py:164 - [TRPO] iter = 976000 dist_mean = 0.0482 dist_std = 0.2077 vf_loss = 0.1068 grad_norm = 1.7485 nat_grad_norm = 0.0935 cg_residual = 0.3084 step_size = 0.5597 reward = -0.0000 fps = 50 mse_loss = 0.5893 
2022-05-01 07:43:16.629024 - gail/main.py:164 - [TRPO] iter = 977000 dist_mean = 0.0527 dist_std = 0.2073 vf_loss = 0.1711 grad_norm = 3.1143 nat_grad_norm = 0.1266 cg_residual = 0.5801 step_size = 0.4066 reward = 0.0000 fps = 33 mse_loss = 0.6710 
2022-05-01 07:43:26.798903 - gail/main.py:164 - [TRPO] iter = 978000 dist_mean = 0.0650 dist_std = 0.2073 vf_loss = 0.0204 grad_norm = 2.6700 nat_grad_norm = 0.1541 cg_residual = 0.6214 step_size = 0.4211 reward = -0.0000 fps = 24 mse_loss = 0.6204 
2022-05-01 07:43:36.613848 - gail/main.py:164 - [TRPO] iter = 979000 dist_mean = 0.0772 dist_std = 0.2080 vf_loss = 0.0511 grad_norm = 1.6595 nat_grad_norm = 0.1429 cg_residual = 0.4610 step_size = 0.5245 reward = 0.0000 fps = 20 mse_loss = 0.6091 
2022-05-01 07:43:46.352809 - gail/main.py:164 - [TRPO] iter = 980000 dist_mean = 0.0429 dist_std = 0.2088 vf_loss = 0.3135 grad_norm = 1.7478 nat_grad_norm = 0.1036 cg_residual = 0.5681 step_size = 0.5981 reward = 0.0000 fps = 16 mse_loss = 0.6590 
2022-05-01 07:43:46.560214 - gail/main.py:191 - [Discriminator] iter = 980000 loss = -0.5541 grad_norm = 3.0905 grad_penalty = 0.0708 regularization = 0.0000 true_logits = -0.5055 fake_logits = -1.1304 true_prob = 0.4321 fake_prob = 0.3504 
2022-05-01 07:43:56.207205 - gail/main.py:132 - [Evaluate] iter = 980000 episode={ returns = 37.9292 lengths = 21 } discounted_episode={ returns = 249.6663 lengths = 119 } 
2022-05-01 07:44:05.898211 - gail/main.py:164 - [TRPO] iter = 981000 dist_mean = 0.0276 dist_std = 0.2078 vf_loss = 0.0330 grad_norm = 2.7816 nat_grad_norm = 0.1676 cg_residual = 0.9093 step_size = 0.3279 reward = -0.0000 fps = 51 mse_loss = 0.7124 
2022-05-01 07:44:15.195773 - gail/main.py:164 - [TRPO] iter = 982000 dist_mean = 0.0473 dist_std = 0.2079 vf_loss = 0.1014 grad_norm = 2.8704 nat_grad_norm = 0.1212 cg_residual = 0.3125 step_size = 0.4159 reward = -0.0000 fps = 34 mse_loss = 0.6148 
2022-05-01 07:44:25.167693 - gail/main.py:164 - [TRPO] iter = 983000 dist_mean = 0.1810 dist_std = 0.2077 vf_loss = 0.0685 grad_norm = 2.0616 nat_grad_norm = 0.2139 cg_residual = 1.3722 step_size = 0.3239 reward = -0.0000 fps = 25 mse_loss = 0.6582 
2022-05-01 07:44:34.826734 - gail/main.py:164 - [TRPO] iter = 984000 dist_mean = 0.0346 dist_std = 0.2071 vf_loss = 0.0223 grad_norm = 2.4706 nat_grad_norm = 0.2088 cg_residual = 1.3965 step_size = 0.3138 reward = 0.0000 fps = 20 mse_loss = 0.6364 
2022-05-01 07:44:44.778840 - gail/main.py:164 - [TRPO] iter = 985000 dist_mean = 0.0654 dist_std = 0.2066 vf_loss = 0.2414 grad_norm = 1.7449 nat_grad_norm = 0.1563 cg_residual = 0.3920 step_size = 0.4615 reward = -0.0000 fps = 17 mse_loss = 0.6013 
2022-05-01 07:44:45.074859 - gail/main.py:191 - [Discriminator] iter = 985000 loss = -0.7339 grad_norm = 2.9229 grad_penalty = 0.0781 regularization = 0.0000 true_logits = -0.5618 fake_logits = -1.3737 true_prob = 0.4222 fake_prob = 0.3308 
2022-05-01 07:45:00.385404 - gail/main.py:132 - [Evaluate] iter = 985000 episode={ returns = 386.8247 lengths = 119 } discounted_episode={ returns = 250.8099 lengths = 119 } 
2022-05-01 07:45:10.592378 - gail/main.py:164 - [TRPO] iter = 986000 dist_mean = 0.0236 dist_std = 0.2057 vf_loss = 0.0157 grad_norm = 1.8568 nat_grad_norm = 0.1950 cg_residual = 1.9934 step_size = 0.3383 reward = 0.0000 fps = 39 mse_loss = 0.7237 
2022-05-01 07:45:21.334361 - gail/main.py:164 - [TRPO] iter = 987000 dist_mean = 0.2927 dist_std = 0.2056 vf_loss = 0.1752 grad_norm = 1.9049 nat_grad_norm = 0.1282 cg_residual = 0.5087 step_size = 0.4574 reward = -0.0000 fps = 27 mse_loss = 0.6204 
2022-05-01 07:45:31.443742 - gail/main.py:164 - [TRPO] iter = 988000 dist_mean = 0.0213 dist_std = 0.2054 vf_loss = 0.1911 grad_norm = 2.7107 nat_grad_norm = 0.0987 cg_residual = 0.6842 step_size = 0.4931 reward = -0.0000 fps = 21 mse_loss = 0.6917 
2022-05-01 07:45:41.564380 - gail/main.py:164 - [TRPO] iter = 989000 dist_mean = 0.0501 dist_std = 0.2052 vf_loss = 0.1000 grad_norm = 1.7595 nat_grad_norm = 0.2864 cg_residual = 3.2571 step_size = 0.2886 reward = 0.0000 fps = 17 mse_loss = 0.6151 
2022-05-01 07:45:51.591872 - gail/main.py:164 - [TRPO] iter = 990000 dist_mean = 0.0935 dist_std = 0.2050 vf_loss = 0.1406 grad_norm = 1.8096 nat_grad_norm = 0.0922 cg_residual = 0.2689 step_size = 0.6185 reward = -0.0000 fps = 15 mse_loss = 0.6281 
2022-05-01 07:45:51.820626 - gail/main.py:191 - [Discriminator] iter = 990000 loss = -1.0936 grad_norm = 2.9393 grad_penalty = 0.0841 regularization = 0.0000 true_logits = -0.3709 fake_logits = -1.5487 true_prob = 0.4548 fake_prob = 0.3204 
2022-05-01 07:45:55.003911 - gail/main.py:132 - [Evaluate] iter = 990000 episode={ returns = 39.1193 lengths = 22 } discounted_episode={ returns = 37.9713 lengths = 22 } 
2022-05-01 07:46:05.064545 - gail/main.py:164 - [TRPO] iter = 991000 dist_mean = 0.1727 dist_std = 0.2046 vf_loss = 0.0800 grad_norm = 3.1092 nat_grad_norm = 0.2300 cg_residual = 1.5433 step_size = 0.3017 reward = 0.0000 fps = 75 mse_loss = 0.6615 
2022-05-01 07:46:15.202993 - gail/main.py:164 - [TRPO] iter = 992000 dist_mean = 0.0777 dist_std = 0.2048 vf_loss = 0.0964 grad_norm = 1.8093 nat_grad_norm = 0.1152 cg_residual = 0.2346 step_size = 0.5185 reward = 0.0000 fps = 42 mse_loss = 0.6386 
2022-05-01 07:46:25.365326 - gail/main.py:164 - [TRPO] iter = 993000 dist_mean = 0.1135 dist_std = 0.2047 vf_loss = 0.0200 grad_norm = 2.0488 nat_grad_norm = 0.1703 cg_residual = 0.6854 step_size = 0.3876 reward = -0.0000 fps = 29 mse_loss = 0.6697 
2022-05-01 07:46:35.415947 - gail/main.py:164 - [TRPO] iter = 994000 dist_mean = 0.1139 dist_std = 0.2046 vf_loss = 0.1111 grad_norm = 1.5628 nat_grad_norm = 0.1177 cg_residual = 0.3330 step_size = 0.5035 reward = 0.0000 fps = 22 mse_loss = 0.6614 
2022-05-01 07:46:45.412768 - gail/main.py:164 - [TRPO] iter = 995000 dist_mean = 0.0780 dist_std = 0.2051 vf_loss = 0.0582 grad_norm = 2.1692 nat_grad_norm = 0.1628 cg_residual = 0.7694 step_size = 0.3369 reward = 0.0000 fps = 18 mse_loss = 0.6452 
2022-05-01 07:46:45.639712 - gail/main.py:191 - [Discriminator] iter = 995000 loss = -0.8867 grad_norm = 3.1693 grad_penalty = 0.0895 regularization = 0.0000 true_logits = -0.2926 fake_logits = -1.2688 true_prob = 0.4703 fake_prob = 0.3607 
2022-05-01 07:47:14.611702 - gail/main.py:132 - [Evaluate] iter = 995000 episode={ returns = 388.6499 lengths = 120 } discounted_episode={ returns = 680.7024 lengths = 315 } 
2022-05-01 07:47:24.616772 - gail/main.py:164 - [TRPO] iter = 996000 dist_mean = 0.0483 dist_std = 0.2050 vf_loss = 0.0751 grad_norm = 2.6753 nat_grad_norm = 0.1745 cg_residual = 0.8294 step_size = 0.3634 reward = 0.0000 fps = 25 mse_loss = 0.6842 
2022-05-01 07:47:34.691050 - gail/main.py:164 - [TRPO] iter = 997000 dist_mean = 0.0650 dist_std = 0.2050 vf_loss = 0.0527 grad_norm = 2.3596 nat_grad_norm = 0.1004 cg_residual = 1.9066 step_size = 0.5644 reward = -0.0000 fps = 20 mse_loss = 0.5856 
2022-05-01 07:47:44.729491 - gail/main.py:164 - [TRPO] iter = 998000 dist_mean = 0.0511 dist_std = 0.2047 vf_loss = 0.0426 grad_norm = 1.9660 nat_grad_norm = 0.1230 cg_residual = 0.7385 step_size = 0.4230 reward = -0.0000 fps = 16 mse_loss = 0.6984 
2022-05-01 07:47:54.903144 - gail/main.py:164 - [TRPO] iter = 999000 dist_mean = 0.0901 dist_std = 0.2050 vf_loss = 0.3918 grad_norm = 1.5852 nat_grad_norm = 0.1108 cg_residual = 0.3298 step_size = 0.5737 reward = 0.0000 fps = 14 mse_loss = 0.7250 
2022-05-01 07:48:04.835061 - gail/main.py:164 - [TRPO] iter = 1000000 dist_mean = 0.0338 dist_std = 0.2057 vf_loss = 0.0375 grad_norm = 2.4576 nat_grad_norm = 0.1670 cg_residual = 0.5213 step_size = 0.3979 reward = 0.0000 fps = 12 mse_loss = 0.6921 
2022-05-01 07:48:05.046079 - gail/main.py:191 - [Discriminator] iter = 1000000 loss = -0.4063 grad_norm = 3.3416 grad_penalty = 0.0719 regularization = 0.0000 true_logits = -0.3408 fake_logits = -0.8190 true_prob = 0.4667 fake_prob = 0.4048 
2022-05-01 07:49:00.627349 - gail/main.py:132 - [Evaluate] iter = 1000000 episode={ returns = 1441.9725 lengths = 413 } discounted_episode={ returns = 897.5617 lengths = 413 } 
2022-05-01 07:49:10.447446 - gail/main.py:164 - [TRPO] iter = 1001000 dist_mean = 0.0273 dist_std = 0.2042 vf_loss = 0.0766 grad_norm = 3.7247 nat_grad_norm = 0.1267 cg_residual = 0.9792 step_size = 0.4519 reward = 0.0000 fps = 15 mse_loss = 0.5519 
2022-05-01 07:49:20.307634 - gail/main.py:164 - [TRPO] iter = 1002000 dist_mean = 0.0485 dist_std = 0.2046 vf_loss = 0.0204 grad_norm = 2.2584 nat_grad_norm = 0.1473 cg_residual = 1.5391 step_size = 0.4058 reward = 0.0000 fps = 13 mse_loss = 0.7256 
2022-05-01 07:49:30.134854 - gail/main.py:164 - [TRPO] iter = 1003000 dist_mean = 0.0735 dist_std = 0.2034 vf_loss = 0.0239 grad_norm = 1.6348 nat_grad_norm = 0.1579 cg_residual = 1.0208 step_size = 0.4192 reward = 0.0000 fps = 11 mse_loss = 0.6872 
2022-05-01 07:49:40.266550 - gail/main.py:164 - [TRPO] iter = 1004000 dist_mean = 0.0338 dist_std = 0.2031 vf_loss = 0.0446 grad_norm = 2.3553 nat_grad_norm = 0.0965 cg_residual = 0.3006 step_size = 0.5208 reward = 0.0000 fps = 10 mse_loss = 0.5835 
2022-05-01 07:49:50.687609 - gail/main.py:164 - [TRPO] iter = 1005000 dist_mean = 0.0387 dist_std = 0.2023 vf_loss = 0.0316 grad_norm = 2.9302 nat_grad_norm = 0.1705 cg_residual = 0.7732 step_size = 0.3993 reward = -0.0000 fps = 9 mse_loss = 0.7003 
2022-05-01 07:49:50.913937 - gail/main.py:191 - [Discriminator] iter = 1005000 loss = -0.5391 grad_norm = 3.3066 grad_penalty = 0.0672 regularization = 0.0000 true_logits = -0.3878 fake_logits = -0.9941 true_prob = 0.4614 fake_prob = 0.3769 
2022-05-01 07:50:27.312774 - gail/main.py:132 - [Evaluate] iter = 1005000 episode={ returns = 1433.7235 lengths = 413 } discounted_episode={ returns = 248.1262 lengths = 119 } 
2022-05-01 07:50:36.897381 - gail/main.py:164 - [TRPO] iter = 1006000 dist_mean = 0.0656 dist_std = 0.2015 vf_loss = 0.0432 grad_norm = 2.0988 nat_grad_norm = 0.1336 cg_residual = 0.4945 step_size = 0.4815 reward = 0.0000 fps = 21 mse_loss = 0.6421 
2022-05-01 07:50:46.925128 - gail/main.py:164 - [TRPO] iter = 1007000 dist_mean = 0.0849 dist_std = 0.2007 vf_loss = 0.0220 grad_norm = 2.1339 nat_grad_norm = 0.1927 cg_residual = 1.1398 step_size = 0.3300 reward = 0.0000 fps = 17 mse_loss = 0.5994 
2022-05-01 07:50:56.872242 - gail/main.py:164 - [TRPO] iter = 1008000 dist_mean = 0.0510 dist_std = 0.2000 vf_loss = 0.0424 grad_norm = 2.5648 nat_grad_norm = 0.1177 cg_residual = 0.3986 step_size = 0.4473 reward = 0.0000 fps = 15 mse_loss = 0.6059 
2022-05-01 07:51:06.570768 - gail/main.py:164 - [TRPO] iter = 1009000 dist_mean = 0.1135 dist_std = 0.2005 vf_loss = 0.0411 grad_norm = 2.1521 nat_grad_norm = 0.1211 cg_residual = 0.5282 step_size = 0.4495 reward = 0.0000 fps = 13 mse_loss = 0.6606 
2022-05-01 07:51:16.689732 - gail/main.py:164 - [TRPO] iter = 1010000 dist_mean = 0.1557 dist_std = 0.2004 vf_loss = 0.3191 grad_norm = 2.2240 nat_grad_norm = 0.1406 cg_residual = 0.4197 step_size = 0.4468 reward = 0.0000 fps = 11 mse_loss = 0.6792 
2022-05-01 07:51:16.935765 - gail/main.py:191 - [Discriminator] iter = 1010000 loss = -1.4091 grad_norm = 3.2126 grad_penalty = 0.1102 regularization = 0.0000 true_logits = -0.3923 fake_logits = -1.9117 true_prob = 0.4607 fake_prob = 0.2920 
2022-05-01 07:51:52.315728 - gail/main.py:132 - [Evaluate] iter = 1010000 episode={ returns = 1433.6143 lengths = 413 } discounted_episode={ returns = 251.7554 lengths = 119 } 
2022-05-01 07:52:02.317882 - gail/main.py:164 - [TRPO] iter = 1011000 dist_mean = 0.0466 dist_std = 0.2013 vf_loss = 0.0238 grad_norm = 2.1809 nat_grad_norm = 0.1303 cg_residual = 1.0407 step_size = 0.4678 reward = -0.0000 fps = 22 mse_loss = 0.6830 
2022-05-01 07:52:12.330032 - gail/main.py:164 - [TRPO] iter = 1012000 dist_mean = 0.0651 dist_std = 0.2004 vf_loss = 0.1874 grad_norm = 2.3512 nat_grad_norm = 0.1252 cg_residual = 0.6898 step_size = 0.4248 reward = 0.0000 fps = 18 mse_loss = 0.6518 
2022-05-01 07:52:22.407169 - gail/main.py:164 - [TRPO] iter = 1013000 dist_mean = 0.0938 dist_std = 0.2007 vf_loss = 0.0634 grad_norm = 1.9824 nat_grad_norm = 0.1016 cg_residual = 0.4285 step_size = 0.5004 reward = 0.0000 fps = 15 mse_loss = 0.7104 
2022-05-01 07:52:32.241107 - gail/main.py:164 - [TRPO] iter = 1014000 dist_mean = 0.0645 dist_std = 0.2007 vf_loss = 0.1835 grad_norm = 1.9875 nat_grad_norm = 0.1086 cg_residual = 0.3709 step_size = 0.5509 reward = 0.0000 fps = 13 mse_loss = 0.6446 
2022-05-01 07:52:42.137685 - gail/main.py:164 - [TRPO] iter = 1015000 dist_mean = 0.0761 dist_std = 0.2005 vf_loss = 0.0230 grad_norm = 1.8430 nat_grad_norm = 0.1175 cg_residual = 0.6237 step_size = 0.4555 reward = -0.0000 fps = 11 mse_loss = 0.6886 
2022-05-01 07:52:42.353777 - gail/main.py:191 - [Discriminator] iter = 1015000 loss = -0.5641 grad_norm = 3.0371 grad_penalty = 0.0950 regularization = 0.0000 true_logits = -0.5425 fake_logits = -1.2016 true_prob = 0.4371 fake_prob = 0.3631 
2022-05-01 07:52:51.976415 - gail/main.py:132 - [Evaluate] iter = 1015000 episode={ returns = 388.4229 lengths = 119 } discounted_episode={ returns = 37.9564 lengths = 22 } 
2022-05-01 07:53:02.206280 - gail/main.py:164 - [TRPO] iter = 1016000 dist_mean = 0.0446 dist_std = 0.1998 vf_loss = 0.0654 grad_norm = 2.6296 nat_grad_norm = 0.1179 cg_residual = 0.8463 step_size = 0.4496 reward = 0.0000 fps = 50 mse_loss = 0.6624 
2022-05-01 07:53:11.982655 - gail/main.py:164 - [TRPO] iter = 1017000 dist_mean = 0.0312 dist_std = 0.1990 vf_loss = 0.1039 grad_norm = 3.2875 nat_grad_norm = 0.1005 cg_residual = 1.1510 step_size = 0.3959 reward = 0.0000 fps = 33 mse_loss = 0.6377 
2022-05-01 07:53:21.835136 - gail/main.py:164 - [TRPO] iter = 1018000 dist_mean = 0.0419 dist_std = 0.1990 vf_loss = 0.0427 grad_norm = 2.6302 nat_grad_norm = 0.1493 cg_residual = 0.4442 step_size = 0.3549 reward = -0.0000 fps = 25 mse_loss = 0.6441 
2022-05-01 07:53:31.534398 - gail/main.py:164 - [TRPO] iter = 1019000 dist_mean = 0.0392 dist_std = 0.1988 vf_loss = 0.0406 grad_norm = 1.9638 nat_grad_norm = 0.1668 cg_residual = 0.7282 step_size = 0.3556 reward = -0.0000 fps = 20 mse_loss = 0.6157 
2022-05-01 07:53:41.692685 - gail/main.py:164 - [TRPO] iter = 1020000 dist_mean = 0.1600 dist_std = 0.1982 vf_loss = 0.1273 grad_norm = 2.5707 nat_grad_norm = 0.1247 cg_residual = 0.5776 step_size = 0.3948 reward = -0.0000 fps = 16 mse_loss = 0.6481 
2022-05-01 07:53:41.989681 - gail/main.py:191 - [Discriminator] iter = 1020000 loss = -1.6307 grad_norm = 3.8690 grad_penalty = 0.1107 regularization = 0.0000 true_logits = -0.4230 fake_logits = -2.1644 true_prob = 0.4558 fake_prob = 0.2627 
2022-05-01 07:54:25.656251 - gail/main.py:132 - [Evaluate] iter = 1020000 episode={ returns = 388.9041 lengths = 119 } discounted_episode={ returns = 1108.4040 lengths = 511 } 
2022-05-01 07:54:35.507275 - gail/main.py:164 - [TRPO] iter = 1021000 dist_mean = 0.0585 dist_std = 0.1982 vf_loss = 0.0682 grad_norm = 2.8882 nat_grad_norm = 0.0964 cg_residual = 0.3878 step_size = 0.5102 reward = -0.0000 fps = 18 mse_loss = 0.6206 
2022-05-01 07:54:45.572996 - gail/main.py:164 - [TRPO] iter = 1022000 dist_mean = 0.0513 dist_std = 0.1982 vf_loss = 0.2674 grad_norm = 4.6337 nat_grad_norm = 0.1060 cg_residual = 4.5780 step_size = 0.3900 reward = 0.0000 fps = 15 mse_loss = 0.5995 
2022-05-01 07:54:55.205451 - gail/main.py:164 - [TRPO] iter = 1023000 dist_mean = 0.0422 dist_std = 0.1980 vf_loss = 0.1623 grad_norm = 1.7863 nat_grad_norm = 0.0977 cg_residual = 0.4393 step_size = 0.5774 reward = -0.0000 fps = 13 mse_loss = 0.6991 
2022-05-01 07:55:05.251815 - gail/main.py:164 - [TRPO] iter = 1024000 dist_mean = 0.0490 dist_std = 0.1987 vf_loss = 0.2167 grad_norm = 1.8815 nat_grad_norm = 0.0801 cg_residual = 0.3142 step_size = 0.6060 reward = 0.0000 fps = 12 mse_loss = 0.5941 
2022-05-01 07:55:15.485268 - gail/main.py:164 - [TRPO] iter = 1025000 dist_mean = 0.0954 dist_std = 0.1989 vf_loss = 0.2547 grad_norm = 1.3843 nat_grad_norm = 0.0896 cg_residual = 0.5612 step_size = 0.5594 reward = 0.0000 fps = 10 mse_loss = 0.5692 
2022-05-01 07:55:15.714296 - gail/main.py:191 - [Discriminator] iter = 1025000 loss = -0.6390 grad_norm = 3.5655 grad_penalty = 0.0901 regularization = 0.0000 true_logits = -0.4219 fake_logits = -1.1511 true_prob = 0.4594 fake_prob = 0.3748 
2022-05-01 07:55:32.041969 - gail/main.py:132 - [Evaluate] iter = 1025000 episode={ returns = 38.1733 lengths = 22 } discounted_episode={ returns = 459.9023 lengths = 217 } 
2022-05-01 07:55:42.085689 - gail/main.py:164 - [TRPO] iter = 1026000 dist_mean = 0.0929 dist_std = 0.1995 vf_loss = 0.2552 grad_norm = 1.9223 nat_grad_norm = 0.1058 cg_residual = 0.6593 step_size = 0.4840 reward = 0.0000 fps = 37 mse_loss = 0.6526 
2022-05-01 07:55:52.420593 - gail/main.py:164 - [TRPO] iter = 1027000 dist_mean = 0.0684 dist_std = 0.1995 vf_loss = 0.1689 grad_norm = 1.9817 nat_grad_norm = 0.1087 cg_residual = 0.4183 step_size = 0.4924 reward = -0.0000 fps = 27 mse_loss = 0.6469 
2022-05-01 07:56:02.355011 - gail/main.py:164 - [TRPO] iter = 1028000 dist_mean = 0.0410 dist_std = 0.1994 vf_loss = 0.1927 grad_norm = 2.7459 nat_grad_norm = 0.0977 cg_residual = 1.1930 step_size = 0.4991 reward = -0.0000 fps = 21 mse_loss = 0.6943 
2022-05-01 07:56:12.162911 - gail/main.py:164 - [TRPO] iter = 1029000 dist_mean = 0.0900 dist_std = 0.1990 vf_loss = 0.0240 grad_norm = 2.7084 nat_grad_norm = 0.0916 cg_residual = 0.3324 step_size = 0.4926 reward = -0.0000 fps = 17 mse_loss = 0.6467 
2022-05-01 07:56:22.263075 - gail/main.py:164 - [TRPO] iter = 1030000 dist_mean = 0.0840 dist_std = 0.1984 vf_loss = 0.1082 grad_norm = 2.6807 nat_grad_norm = 0.0963 cg_residual = 0.4145 step_size = 0.4763 reward = 0.0000 fps = 15 mse_loss = 0.6030 
2022-05-01 07:56:22.515358 - gail/main.py:191 - [Discriminator] iter = 1030000 loss = -0.7145 grad_norm = 4.1570 grad_penalty = 0.0713 regularization = 0.0000 true_logits = -0.3416 fake_logits = -1.1274 true_prob = 0.4687 fake_prob = 0.3805 
2022-05-01 07:56:45.126785 - gail/main.py:132 - [Evaluate] iter = 1030000 episode={ returns = 733.3650 lengths = 217 } discounted_episode={ returns = 251.8008 lengths = 120 } 
2022-05-01 07:56:55.297690 - gail/main.py:164 - [TRPO] iter = 1031000 dist_mean = 0.0932 dist_std = 0.1983 vf_loss = 0.0666 grad_norm = 2.2855 nat_grad_norm = 0.1179 cg_residual = 0.4491 step_size = 0.4169 reward = -0.0000 fps = 30 mse_loss = 0.6062 
2022-05-01 07:57:05.774847 - gail/main.py:164 - [TRPO] iter = 1032000 dist_mean = 0.1624 dist_std = 0.1978 vf_loss = 0.0294 grad_norm = 2.1326 nat_grad_norm = 0.1499 cg_residual = 0.3964 step_size = 0.4530 reward = 0.0000 fps = 23 mse_loss = 0.7744 
2022-05-01 07:57:15.659143 - gail/main.py:164 - [TRPO] iter = 1033000 dist_mean = 0.0523 dist_std = 0.1978 vf_loss = 0.0564 grad_norm = 2.9228 nat_grad_norm = 0.1281 cg_residual = 2.1764 step_size = 0.4523 reward = 0.0000 fps = 18 mse_loss = 0.6076 
2022-05-01 07:57:25.566154 - gail/main.py:164 - [TRPO] iter = 1034000 dist_mean = 0.0933 dist_std = 0.1969 vf_loss = 0.3301 grad_norm = 1.2058 nat_grad_norm = 0.0901 cg_residual = 0.5172 step_size = 0.6284 reward = -0.0000 fps = 15 mse_loss = 0.5404 
2022-05-01 07:57:35.441761 - gail/main.py:164 - [TRPO] iter = 1035000 dist_mean = 0.0477 dist_std = 0.1974 vf_loss = 0.1058 grad_norm = 2.5933 nat_grad_norm = 0.1024 cg_residual = 0.4667 step_size = 0.4191 reward = -0.0000 fps = 13 mse_loss = 0.5471 
2022-05-01 07:57:35.655174 - gail/main.py:191 - [Discriminator] iter = 1035000 loss = -0.3611 grad_norm = 3.6302 grad_penalty = 0.0597 regularization = 0.0000 true_logits = -0.5056 fake_logits = -0.9263 true_prob = 0.4459 fake_prob = 0.3968 
2022-05-01 07:57:38.848151 - gail/main.py:132 - [Evaluate] iter = 1035000 episode={ returns = 38.3892 lengths = 22 } discounted_episode={ returns = 37.7768 lengths = 22 } 
2022-05-01 07:57:48.745106 - gail/main.py:164 - [TRPO] iter = 1036000 dist_mean = 0.0516 dist_std = 0.1970 vf_loss = 0.0815 grad_norm = 1.8153 nat_grad_norm = 0.0946 cg_residual = 0.4317 step_size = 0.5407 reward = -0.0000 fps = 76 mse_loss = 0.5990 
2022-05-01 07:57:58.375608 - gail/main.py:164 - [TRPO] iter = 1037000 dist_mean = 0.0499 dist_std = 0.1967 vf_loss = 0.0261 grad_norm = 3.3499 nat_grad_norm = 0.1317 cg_residual = 2.3955 step_size = 0.3747 reward = 0.0000 fps = 44 mse_loss = 0.6047 
2022-05-01 07:58:08.576400 - gail/main.py:164 - [TRPO] iter = 1038000 dist_mean = 0.1551 dist_std = 0.1964 vf_loss = 0.3167 grad_norm = 2.1129 nat_grad_norm = 0.1220 cg_residual = 0.5103 step_size = 0.4546 reward = 0.0000 fps = 30 mse_loss = 0.5803 
2022-05-01 07:58:18.731560 - gail/main.py:164 - [TRPO] iter = 1039000 dist_mean = 0.4003 dist_std = 0.1960 vf_loss = 0.0886 grad_norm = 2.8474 nat_grad_norm = 0.0520 cg_residual = 0.1081 step_size = 0.7596 reward = -0.0000 fps = 23 mse_loss = 0.6003 
2022-05-01 07:58:29.080522 - gail/main.py:164 - [TRPO] iter = 1040000 dist_mean = 0.3920 dist_std = 0.1967 vf_loss = 0.0697 grad_norm = 2.3475 nat_grad_norm = 0.0701 cg_residual = 0.2091 step_size = 0.7442 reward = -0.0000 fps = 18 mse_loss = 0.6547 
2022-05-01 07:58:29.316751 - gail/main.py:191 - [Discriminator] iter = 1040000 loss = -4.2139 grad_norm = 5.0780 grad_penalty = 0.3474 regularization = 0.0000 true_logits = -0.4301 fake_logits = -4.9914 true_prob = 0.4596 fake_prob = 0.0201 
2022-05-01 07:58:32.510983 - gail/main.py:132 - [Evaluate] iter = 1040000 episode={ returns = 38.9700 lengths = 22 } discounted_episode={ returns = 38.6268 lengths = 22 } 
2022-05-01 07:58:42.905548 - gail/main.py:164 - [TRPO] iter = 1041000 dist_mean = 0.3916 dist_std = 0.1987 vf_loss = 0.0945 grad_norm = 4.8510 nat_grad_norm = 0.0671 cg_residual = 0.3278 step_size = 0.5318 reward = 0.0000 fps = 73 mse_loss = 0.6108 
2022-05-01 07:58:53.056159 - gail/main.py:164 - [TRPO] iter = 1042000 dist_mean = 0.3728 dist_std = 0.1990 vf_loss = 0.1117 grad_norm = 5.4051 nat_grad_norm = 0.0706 cg_residual = 0.0523 step_size = 0.5573 reward = 0.0000 fps = 42 mse_loss = 0.6378 
2022-05-01 07:59:03.118390 - gail/main.py:164 - [TRPO] iter = 1043000 dist_mean = 0.1006 dist_std = 0.2009 vf_loss = 0.0577 grad_norm = 2.6955 nat_grad_norm = 0.1137 cg_residual = 0.2614 step_size = 0.5211 reward = -0.0000 fps = 29 mse_loss = 0.6218 
2022-05-01 07:59:13.065107 - gail/main.py:164 - [TRPO] iter = 1044000 dist_mean = 0.1945 dist_std = 0.2008 vf_loss = 0.0525 grad_norm = 1.9189 nat_grad_norm = 0.1161 cg_residual = 0.6494 step_size = 0.4799 reward = -0.0000 fps = 22 mse_loss = 0.5866 
2022-05-01 07:59:23.212247 - gail/main.py:164 - [TRPO] iter = 1045000 dist_mean = 0.2379 dist_std = 0.2017 vf_loss = 0.2136 grad_norm = 2.1306 nat_grad_norm = 0.1473 cg_residual = 0.6222 step_size = 0.4422 reward = 0.0000 fps = 18 mse_loss = 0.6167 
2022-05-01 07:59:23.422526 - gail/main.py:191 - [Discriminator] iter = 1045000 loss = -3.2024 grad_norm = 4.0015 grad_penalty = 0.2661 regularization = 0.0000 true_logits = -0.1152 fake_logits = -3.5836 true_prob = 0.5072 fake_prob = 0.1544 
2022-05-01 07:59:26.821763 - gail/main.py:132 - [Evaluate] iter = 1045000 episode={ returns = 43.0528 lengths = 24 } discounted_episode={ returns = 41.7328 lengths = 24 } 
2022-05-01 07:59:36.492415 - gail/main.py:164 - [TRPO] iter = 1046000 dist_mean = 0.0675 dist_std = 0.2018 vf_loss = 0.1690 grad_norm = 2.2734 nat_grad_norm = 0.1186 cg_residual = 0.3666 step_size = 0.4201 reward = 0.0000 fps = 76 mse_loss = 0.6201 
2022-05-01 07:59:46.316080 - gail/main.py:164 - [TRPO] iter = 1047000 dist_mean = 0.0369 dist_std = 0.2011 vf_loss = 0.1012 grad_norm = 1.9217 nat_grad_norm = 0.1405 cg_residual = 0.5193 step_size = 0.3845 reward = -0.0000 fps = 43 mse_loss = 0.6530 
2022-05-01 07:59:56.311202 - gail/main.py:164 - [TRPO] iter = 1048000 dist_mean = 0.0075 dist_std = 0.2005 vf_loss = 0.2968 grad_norm = 2.0984 nat_grad_norm = 0.1085 cg_residual = 0.6825 step_size = 0.5327 reward = -0.0000 fps = 30 mse_loss = 0.5426 
2022-05-01 08:00:06.153566 - gail/main.py:164 - [TRPO] iter = 1049000 dist_mean = 0.0243 dist_std = 0.2015 vf_loss = 0.1549 grad_norm = 2.3188 nat_grad_norm = 0.0988 cg_residual = 0.7235 step_size = 0.5103 reward = -0.0000 fps = 23 mse_loss = 0.6312 
2022-05-01 08:00:16.111551 - gail/main.py:164 - [TRPO] iter = 1050000 dist_mean = 0.0425 dist_std = 0.2013 vf_loss = 0.0454 grad_norm = 1.8908 nat_grad_norm = 0.1649 cg_residual = 0.8663 step_size = 0.3644 reward = 0.0000 fps = 18 mse_loss = 0.6753 
2022-05-01 08:00:16.316306 - gail/main.py:191 - [Discriminator] iter = 1050000 loss = -0.3969 grad_norm = 3.7072 grad_penalty = 0.1026 regularization = 0.0000 true_logits = 0.0328 fake_logits = -0.4667 true_prob = 0.5246 fake_prob = 0.4842 
2022-05-01 08:00:19.950982 - gail/main.py:132 - [Evaluate] iter = 1050000 episode={ returns = 44.9863 lengths = 25 } discounted_episode={ returns = 44.3579 lengths = 25 } 
2022-05-01 08:00:30.005946 - gail/main.py:164 - [TRPO] iter = 1051000 dist_mean = 0.0349 dist_std = 0.2012 vf_loss = 0.0288 grad_norm = 1.6883 nat_grad_norm = 0.1804 cg_residual = 1.0189 step_size = 0.3647 reward = 0.0000 fps = 73 mse_loss = 0.6240 
2022-05-01 08:00:40.129033 - gail/main.py:164 - [TRPO] iter = 1052000 dist_mean = 0.0737 dist_std = 0.2012 vf_loss = 0.0385 grad_norm = 2.6371 nat_grad_norm = 0.1376 cg_residual = 1.0291 step_size = 0.4121 reward = 0.0000 fps = 42 mse_loss = 0.6629 
2022-05-01 08:00:50.124574 - gail/main.py:164 - [TRPO] iter = 1053000 dist_mean = 0.0306 dist_std = 0.2007 vf_loss = 0.0177 grad_norm = 1.6635 nat_grad_norm = 0.1479 cg_residual = 1.0743 step_size = 0.4198 reward = -0.0000 fps = 29 mse_loss = 0.6979 
2022-05-01 08:00:59.967056 - gail/main.py:164 - [TRPO] iter = 1054000 dist_mean = 0.0090 dist_std = 0.2005 vf_loss = 0.0356 grad_norm = 2.3500 nat_grad_norm = 0.1078 cg_residual = 0.4593 step_size = 0.4932 reward = 0.0000 fps = 22 mse_loss = 0.7140 
2022-05-01 08:01:09.983360 - gail/main.py:164 - [TRPO] iter = 1055000 dist_mean = 0.1446 dist_std = 0.1997 vf_loss = 0.1968 grad_norm = 1.8847 nat_grad_norm = 0.1200 cg_residual = 0.3744 step_size = 0.5009 reward = -0.0000 fps = 18 mse_loss = 0.6019 
2022-05-01 08:01:10.275601 - gail/main.py:191 - [Discriminator] iter = 1055000 loss = -0.6698 grad_norm = 3.9472 grad_penalty = 0.0795 regularization = 0.0000 true_logits = -0.2335 fake_logits = -0.9829 true_prob = 0.4969 fake_prob = 0.4071 
2022-05-01 08:02:58.652487 - gail/main.py:132 - [Evaluate] iter = 1055000 episode={ returns = 2798.1956 lengths = 799 } discounted_episode={ returns = 1876.1156 lengths = 812 } 
2022-05-01 08:03:08.805426 - gail/main.py:164 - [TRPO] iter = 1056000 dist_mean = 0.0486 dist_std = 0.1996 vf_loss = 0.0269 grad_norm = 2.7319 nat_grad_norm = 0.1255 cg_residual = 0.7245 step_size = 0.4267 reward = 0.0000 fps = 8 mse_loss = 0.6567 
2022-05-01 08:03:18.811968 - gail/main.py:164 - [TRPO] iter = 1057000 dist_mean = 0.0265 dist_std = 0.1990 vf_loss = 0.0271 grad_norm = 2.0670 nat_grad_norm = 0.1559 cg_residual = 1.3262 step_size = 0.4078 reward = -0.0000 fps = 7 mse_loss = 0.6893 
2022-05-01 08:03:28.519320 - gail/main.py:164 - [TRPO] iter = 1058000 dist_mean = 0.0392 dist_std = 0.1989 vf_loss = 0.0355 grad_norm = 2.0961 nat_grad_norm = 0.1285 cg_residual = 1.3285 step_size = 0.4316 reward = -0.0000 fps = 7 mse_loss = 0.6085 
2022-05-01 08:03:38.839920 - gail/main.py:164 - [TRPO] iter = 1059000 dist_mean = 0.0937 dist_std = 0.1991 vf_loss = 0.1004 grad_norm = 3.3601 nat_grad_norm = 0.2006 cg_residual = 1.2735 step_size = 0.2853 reward = 0.0000 fps = 6 mse_loss = 0.8092 
2022-05-01 08:03:48.787761 - gail/main.py:164 - [TRPO] iter = 1060000 dist_mean = 0.0715 dist_std = 0.1984 vf_loss = 0.0605 grad_norm = 1.9406 nat_grad_norm = 0.1455 cg_residual = 0.5867 step_size = 0.3648 reward = 0.0000 fps = 6 mse_loss = 0.7418 
2022-05-01 08:03:49.102458 - gail/main.py:191 - [Discriminator] iter = 1060000 loss = -0.4777 grad_norm = 3.8969 grad_penalty = 0.0805 regularization = 0.0000 true_logits = -0.1814 fake_logits = -0.7397 true_prob = 0.4993 fake_prob = 0.4333 
2022-05-01 08:05:50.456636 - gail/main.py:132 - [Evaluate] iter = 1060000 episode={ returns = 3228.9058 lengths = 918 } discounted_episode={ returns = 1988.0834 lengths = 883 } 
2022-05-01 08:06:00.686056 - gail/main.py:164 - [TRPO] iter = 1061000 dist_mean = 0.0367 dist_std = 0.1982 vf_loss = 0.0452 grad_norm = 1.5104 nat_grad_norm = 0.1679 cg_residual = 0.9105 step_size = 0.4181 reward = 0.0000 fps = 7 mse_loss = 0.6645 
2022-05-01 08:06:10.727154 - gail/main.py:164 - [TRPO] iter = 1062000 dist_mean = 0.0284 dist_std = 0.1972 vf_loss = 0.0208 grad_norm = 2.0784 nat_grad_norm = 0.1554 cg_residual = 1.1297 step_size = 0.3467 reward = 0.0000 fps = 7 mse_loss = 0.7515 
2022-05-01 08:06:20.699985 - gail/main.py:164 - [TRPO] iter = 1063000 dist_mean = 0.1560 dist_std = 0.1970 vf_loss = 0.1343 grad_norm = 1.9686 nat_grad_norm = 0.1498 cg_residual = 0.7544 step_size = 0.4457 reward = 0.0000 fps = 6 mse_loss = 0.6799 
2022-05-01 08:06:30.597346 - gail/main.py:164 - [TRPO] iter = 1064000 dist_mean = 0.0381 dist_std = 0.1966 vf_loss = 0.0458 grad_norm = 1.7262 nat_grad_norm = 0.1139 cg_residual = 0.4607 step_size = 0.5329 reward = -0.0000 fps = 6 mse_loss = 0.6723 
2022-05-01 08:06:40.472084 - gail/main.py:164 - [TRPO] iter = 1065000 dist_mean = 0.0412 dist_std = 0.1969 vf_loss = 0.0371 grad_norm = 1.6892 nat_grad_norm = 0.1521 cg_residual = 1.0453 step_size = 0.3932 reward = 0.0000 fps = 5 mse_loss = 0.6535 
2022-05-01 08:06:40.695381 - gail/main.py:191 - [Discriminator] iter = 1065000 loss = -0.5890 grad_norm = 3.0526 grad_penalty = 0.0598 regularization = 0.0000 true_logits = -0.1565 fake_logits = -0.8053 true_prob = 0.5038 fake_prob = 0.4164 
2022-05-01 08:08:27.504247 - gail/main.py:132 - [Evaluate] iter = 1065000 episode={ returns = 2663.9297 lengths = 779 } discounted_episode={ returns = 1810.9005 lengths = 832 } 
2022-05-01 08:08:37.520513 - gail/main.py:164 - [TRPO] iter = 1066000 dist_mean = 0.1512 dist_std = 0.1956 vf_loss = 0.1203 grad_norm = 2.2058 nat_grad_norm = 0.1437 cg_residual = 0.6708 step_size = 0.4277 reward = -0.0000 fps = 8 mse_loss = 0.6156 
2022-05-01 08:08:47.443208 - gail/main.py:164 - [TRPO] iter = 1067000 dist_mean = 0.0108 dist_std = 0.1957 vf_loss = 0.0378 grad_norm = 2.0477 nat_grad_norm = 0.1051 cg_residual = 1.5005 step_size = 0.4923 reward = -0.0000 fps = 7 mse_loss = 0.6635 
2022-05-01 08:08:57.218224 - gail/main.py:164 - [TRPO] iter = 1068000 dist_mean = 0.0084 dist_std = 0.1949 vf_loss = 0.0223 grad_norm = 1.9433 nat_grad_norm = 0.1249 cg_residual = 0.4884 step_size = 0.4847 reward = 0.0000 fps = 7 mse_loss = 0.6712 
2022-05-01 08:09:06.970049 - gail/main.py:164 - [TRPO] iter = 1069000 dist_mean = 0.0298 dist_std = 0.1951 vf_loss = 0.0200 grad_norm = 1.8310 nat_grad_norm = 0.1681 cg_residual = 1.8902 step_size = 0.4238 reward = -0.0000 fps = 6 mse_loss = 0.6406 
2022-05-01 08:09:16.570146 - gail/main.py:164 - [TRPO] iter = 1070000 dist_mean = 0.0131 dist_std = 0.1949 vf_loss = 0.0156 grad_norm = 1.9526 nat_grad_norm = 0.1356 cg_residual = 1.0553 step_size = 0.4164 reward = -0.0000 fps = 6 mse_loss = 0.7799 
2022-05-01 08:09:16.777983 - gail/main.py:191 - [Discriminator] iter = 1070000 loss = -0.1912 grad_norm = 2.8742 grad_penalty = 0.0589 regularization = 0.0000 true_logits = -0.3881 fake_logits = -0.6382 true_prob = 0.4677 fake_prob = 0.4340 
2022-05-01 08:11:15.266530 - gail/main.py:132 - [Evaluate] iter = 1070000 episode={ returns = 2901.2443 lengths = 826 } discounted_episode={ returns = 2049.3746 lengths = 938 } 
2022-05-01 08:11:25.622182 - gail/main.py:164 - [TRPO] iter = 1071000 dist_mean = 0.0578 dist_std = 0.1942 vf_loss = 0.0337 grad_norm = 2.3772 nat_grad_norm = 0.1412 cg_residual = 0.6691 step_size = 0.3897 reward = 0.0000 fps = 7 mse_loss = 0.6541 
2022-05-01 08:11:35.495364 - gail/main.py:164 - [TRPO] iter = 1072000 dist_mean = 0.0413 dist_std = 0.1944 vf_loss = 0.0230 grad_norm = 2.0615 nat_grad_norm = 0.1330 cg_residual = 0.6311 step_size = 0.4286 reward = 0.0000 fps = 7 mse_loss = 0.6238 
2022-05-01 08:11:45.436191 - gail/main.py:164 - [TRPO] iter = 1073000 dist_mean = 0.0269 dist_std = 0.1941 vf_loss = 0.0156 grad_norm = 2.2908 nat_grad_norm = 0.1606 cg_residual = 1.8620 step_size = 0.3739 reward = -0.0000 fps = 6 mse_loss = 0.7091 
2022-05-01 08:11:55.302241 - gail/main.py:164 - [TRPO] iter = 1074000 dist_mean = 0.0618 dist_std = 0.1939 vf_loss = 0.0321 grad_norm = 1.7380 nat_grad_norm = 0.1245 cg_residual = 0.8718 step_size = 0.4652 reward = 0.0000 fps = 6 mse_loss = 0.6002 
2022-05-01 08:12:05.765164 - gail/main.py:164 - [TRPO] iter = 1075000 dist_mean = 0.0215 dist_std = 0.1938 vf_loss = 0.0130 grad_norm = 2.8334 nat_grad_norm = 0.1489 cg_residual = 0.8558 step_size = 0.3849 reward = -0.0000 fps = 5 mse_loss = 0.7169 
2022-05-01 08:12:05.975477 - gail/main.py:191 - [Discriminator] iter = 1075000 loss = -0.2354 grad_norm = 3.9537 grad_penalty = 0.0727 regularization = 0.0000 true_logits = -0.3777 fake_logits = -0.6858 true_prob = 0.4635 fake_prob = 0.4253 
2022-05-01 08:14:09.463767 - gail/main.py:132 - [Evaluate] iter = 1075000 episode={ returns = 3400.8155 lengths = 965 } discounted_episode={ returns = 1847.3260 lengths = 829 } 
2022-05-01 08:14:19.714698 - gail/main.py:164 - [TRPO] iter = 1076000 dist_mean = 0.0285 dist_std = 0.1932 vf_loss = 0.0179 grad_norm = 2.1118 nat_grad_norm = 0.1768 cg_residual = 2.4947 step_size = 0.3166 reward = -0.0000 fps = 7 mse_loss = 0.6050 
2022-05-01 08:14:29.111540 - gail/main.py:164 - [TRPO] iter = 1077000 dist_mean = 0.0240 dist_std = 0.1936 vf_loss = 0.0183 grad_norm = 3.0213 nat_grad_norm = 0.1761 cg_residual = 2.6997 step_size = 0.3076 reward = 0.0000 fps = 6 mse_loss = 0.6263 
2022-05-01 08:14:39.149440 - gail/main.py:164 - [TRPO] iter = 1078000 dist_mean = 0.0256 dist_std = 0.1938 vf_loss = 0.0172 grad_norm = 1.0981 nat_grad_norm = 0.1337 cg_residual = 0.8772 step_size = 0.4582 reward = 0.0000 fps = 6 mse_loss = 0.5998 
2022-05-01 08:14:49.057903 - gail/main.py:164 - [TRPO] iter = 1079000 dist_mean = 0.0520 dist_std = 0.1944 vf_loss = 0.2051 grad_norm = 1.7702 nat_grad_norm = 0.1149 cg_residual = 0.3386 step_size = 0.5125 reward = 0.0000 fps = 6 mse_loss = 0.6357 
2022-05-01 08:14:58.817657 - gail/main.py:164 - [TRPO] iter = 1080000 dist_mean = 0.0254 dist_std = 0.1947 vf_loss = 0.0158 grad_norm = 3.0558 nat_grad_norm = 0.1125 cg_residual = 0.5340 step_size = 0.4764 reward = 0.0000 fps = 5 mse_loss = 0.6831 
2022-05-01 08:14:59.040639 - gail/main.py:191 - [Discriminator] iter = 1080000 loss = -0.3789 grad_norm = 3.3299 grad_penalty = 0.0678 regularization = 0.0000 true_logits = -0.2909 fake_logits = -0.7377 true_prob = 0.4746 fake_prob = 0.4174 
2022-05-01 08:16:20.291839 - gail/main.py:132 - [Evaluate] iter = 1080000 episode={ returns = 2175.6299 lengths = 618 } discounted_episode={ returns = 1520.6486 lengths = 599 } 
2022-05-01 08:16:30.150500 - gail/main.py:164 - [TRPO] iter = 1081000 dist_mean = 0.0787 dist_std = 0.1940 vf_loss = 0.0270 grad_norm = 2.1922 nat_grad_norm = 0.1558 cg_residual = 0.8434 step_size = 0.3570 reward = 0.0000 fps = 10 mse_loss = 0.6038 
2022-05-01 08:16:40.215240 - gail/main.py:164 - [TRPO] iter = 1082000 dist_mean = 0.0208 dist_std = 0.1941 vf_loss = 0.0162 grad_norm = 1.7910 nat_grad_norm = 0.1166 cg_residual = 1.1066 step_size = 0.5092 reward = 0.0000 fps = 9 mse_loss = 0.6206 
2022-05-01 08:16:50.096618 - gail/main.py:164 - [TRPO] iter = 1083000 dist_mean = 0.0333 dist_std = 0.1940 vf_loss = 0.0127 grad_norm = 2.1249 nat_grad_norm = 0.1030 cg_residual = 0.5631 step_size = 0.4949 reward = -0.0000 fps = 9 mse_loss = 0.7055 
2022-05-01 08:16:59.310691 - gail/main.py:164 - [TRPO] iter = 1084000 dist_mean = 0.0741 dist_std = 0.1938 vf_loss = 0.0231 grad_norm = 2.4896 nat_grad_norm = 0.1444 cg_residual = 0.8503 step_size = 0.4248 reward = 0.0000 fps = 8 mse_loss = 0.7201 
2022-05-01 08:17:09.487931 - gail/main.py:164 - [TRPO] iter = 1085000 dist_mean = 0.0195 dist_std = 0.1942 vf_loss = 0.0130 grad_norm = 2.0879 nat_grad_norm = 0.1035 cg_residual = 0.6239 step_size = 0.5085 reward = 0.0000 fps = 7 mse_loss = 0.6011 
2022-05-01 08:17:09.720899 - gail/main.py:191 - [Discriminator] iter = 1085000 loss = -0.3651 grad_norm = 3.7722 grad_penalty = 0.0641 regularization = 0.0000 true_logits = -0.3566 fake_logits = -0.7858 true_prob = 0.4609 fake_prob = 0.4010 
2022-05-01 08:19:16.258100 - gail/main.py:132 - [Evaluate] iter = 1085000 episode={ returns = 3506.7121 lengths = 988 } discounted_episode={ returns = 2023.3424 lengths = 896 } 
2022-05-01 08:19:26.202165 - gail/main.py:164 - [TRPO] iter = 1086000 dist_mean = 0.0419 dist_std = 0.1936 vf_loss = 0.0193 grad_norm = 2.0828 nat_grad_norm = 0.1162 cg_residual = 0.5812 step_size = 0.4453 reward = -0.0000 fps = 7 mse_loss = 0.5918 
2022-05-01 08:19:35.686170 - gail/main.py:164 - [TRPO] iter = 1087000 dist_mean = 0.0364 dist_std = 0.1932 vf_loss = 0.0129 grad_norm = 2.2043 nat_grad_norm = 0.1133 cg_residual = 0.8122 step_size = 0.4768 reward = 0.0000 fps = 6 mse_loss = 0.5845 
2022-05-01 08:19:45.333531 - gail/main.py:164 - [TRPO] iter = 1088000 dist_mean = 0.0139 dist_std = 0.1938 vf_loss = 0.0211 grad_norm = 2.4140 nat_grad_norm = 0.1628 cg_residual = 0.8091 step_size = 0.4313 reward = 0.0000 fps = 6 mse_loss = 0.6721 
2022-05-01 08:19:55.437795 - gail/main.py:164 - [TRPO] iter = 1089000 dist_mean = 0.0434 dist_std = 0.1932 vf_loss = 0.0478 grad_norm = 2.1222 nat_grad_norm = 0.1341 cg_residual = 0.8105 step_size = 0.4545 reward = 0.0000 fps = 6 mse_loss = 0.7030 
2022-05-01 08:20:05.412007 - gail/main.py:164 - [TRPO] iter = 1090000 dist_mean = 0.0555 dist_std = 0.1935 vf_loss = 0.0239 grad_norm = 2.2334 nat_grad_norm = 0.2030 cg_residual = 1.2745 step_size = 0.3205 reward = 0.0000 fps = 5 mse_loss = 0.6864 
2022-05-01 08:20:05.654108 - gail/main.py:191 - [Discriminator] iter = 1090000 loss = -0.5442 grad_norm = 3.8644 grad_penalty = 0.0658 regularization = 0.0000 true_logits = -0.3681 fake_logits = -0.9782 true_prob = 0.4558 fake_prob = 0.3656 
2022-05-01 08:22:18.031785 - gail/main.py:132 - [Evaluate] iter = 1090000 episode={ returns = 3468.8362 lengths = 971 } discounted_episode={ returns = 2199.9657 lengths = 1000 } 
2022-05-01 08:22:27.656369 - gail/main.py:164 - [TRPO] iter = 1091000 dist_mean = 0.0454 dist_std = 0.1938 vf_loss = 0.0153 grad_norm = 2.3704 nat_grad_norm = 0.1498 cg_residual = 0.9067 step_size = 0.3844 reward = 0.0000 fps = 7 mse_loss = 0.6831 
2022-05-01 08:22:37.907537 - gail/main.py:164 - [TRPO] iter = 1092000 dist_mean = 0.0581 dist_std = 0.1943 vf_loss = 0.0280 grad_norm = 2.3127 nat_grad_norm = 0.1313 cg_residual = 0.4521 step_size = 0.4335 reward = -0.0000 fps = 6 mse_loss = 0.6755 
2022-05-01 08:22:47.688308 - gail/main.py:164 - [TRPO] iter = 1093000 dist_mean = 0.0278 dist_std = 0.1939 vf_loss = 0.0141 grad_norm = 2.0293 nat_grad_norm = 0.1062 cg_residual = 0.7373 step_size = 0.4549 reward = -0.0000 fps = 6 mse_loss = 0.6784 
2022-05-01 08:22:57.780624 - gail/main.py:164 - [TRPO] iter = 1094000 dist_mean = 0.0218 dist_std = 0.1939 vf_loss = 0.0244 grad_norm = 2.3577 nat_grad_norm = 0.1006 cg_residual = 0.4409 step_size = 0.4691 reward = 0.0000 fps = 5 mse_loss = 0.6282 
2022-05-01 08:23:07.849023 - gail/main.py:164 - [TRPO] iter = 1095000 dist_mean = 0.1339 dist_std = 0.1935 vf_loss = 0.0568 grad_norm = 1.7732 nat_grad_norm = 0.1194 cg_residual = 0.6222 step_size = 0.4682 reward = -0.0000 fps = 5 mse_loss = 0.6647 
2022-05-01 08:23:08.084800 - gail/main.py:191 - [Discriminator] iter = 1095000 loss = -0.7688 grad_norm = 3.5865 grad_penalty = 0.0735 regularization = 0.0000 true_logits = -0.5060 fake_logits = -1.3483 true_prob = 0.4365 fake_prob = 0.3024 
2022-05-01 08:24:42.079825 - gail/main.py:132 - [Evaluate] iter = 1095000 episode={ returns = 2825.0417 lengths = 828 } discounted_episode={ returns = 1260.4255 lengths = 574 } 
2022-05-01 08:24:51.979486 - gail/main.py:164 - [TRPO] iter = 1096000 dist_mean = 0.0563 dist_std = 0.1933 vf_loss = 0.0195 grad_norm = 1.6645 nat_grad_norm = 0.1627 cg_residual = 0.7265 step_size = 0.3645 reward = 0.0000 fps = 9 mse_loss = 0.6765 
2022-05-01 08:25:01.977155 - gail/main.py:164 - [TRPO] iter = 1097000 dist_mean = 0.0403 dist_std = 0.1936 vf_loss = 0.0273 grad_norm = 2.6372 nat_grad_norm = 0.1489 cg_residual = 0.5894 step_size = 0.4083 reward = -0.0000 fps = 8 mse_loss = 0.6942 
2022-05-01 08:25:11.810463 - gail/main.py:164 - [TRPO] iter = 1098000 dist_mean = 0.0662 dist_std = 0.1940 vf_loss = 0.0337 grad_norm = 1.8971 nat_grad_norm = 0.1178 cg_residual = 0.4763 step_size = 0.4803 reward = 0.0000 fps = 8 mse_loss = 0.6922 
2022-05-01 08:25:21.510920 - gail/main.py:164 - [TRPO] iter = 1099000 dist_mean = 0.0673 dist_std = 0.1942 vf_loss = 0.3522 grad_norm = 2.7780 nat_grad_norm = 0.1177 cg_residual = 1.5095 step_size = 0.4337 reward = -0.0000 fps = 7 mse_loss = 0.6340 
2022-05-01 08:25:31.146224 - gail/main.py:164 - [TRPO] iter = 1100000 dist_mean = 0.0528 dist_std = 0.1937 vf_loss = 0.0456 grad_norm = 2.9746 nat_grad_norm = 0.1336 cg_residual = 1.1046 step_size = 0.4364 reward = 0.0000 fps = 6 mse_loss = 0.6685 
2022-05-01 08:25:31.348079 - gail/main.py:191 - [Discriminator] iter = 1100000 loss = -0.5331 grad_norm = 3.1605 grad_penalty = 0.0739 regularization = 0.0000 true_logits = -0.4391 fake_logits = -1.0461 true_prob = 0.4433 fake_prob = 0.3463 
2022-05-01 08:27:45.612575 - gail/main.py:132 - [Evaluate] iter = 1100000 episode={ returns = 3536.3604 lengths = 1000 } discounted_episode={ returns = 2181.3634 lengths = 1000 } 
2022-05-01 08:27:55.459774 - gail/main.py:164 - [TRPO] iter = 1101000 dist_mean = 0.0206 dist_std = 0.1946 vf_loss = 0.0324 grad_norm = 1.5476 nat_grad_norm = 0.1299 cg_residual = 0.6780 step_size = 0.5133 reward = -0.0000 fps = 6 mse_loss = 0.6965 
2022-05-01 08:28:05.626749 - gail/main.py:164 - [TRPO] iter = 1102000 dist_mean = 0.0185 dist_std = 0.1939 vf_loss = 0.1137 grad_norm = 2.9945 nat_grad_norm = 0.0944 cg_residual = 1.9037 step_size = 0.5373 reward = 0.0000 fps = 6 mse_loss = 0.6906 
2022-05-01 08:28:15.589382 - gail/main.py:164 - [TRPO] iter = 1103000 dist_mean = 0.0540 dist_std = 0.1940 vf_loss = 0.0281 grad_norm = 2.1556 nat_grad_norm = 0.1136 cg_residual = 0.6834 step_size = 0.4933 reward = -0.0000 fps = 6 mse_loss = 0.7974 
2022-05-01 08:28:25.578066 - gail/main.py:164 - [TRPO] iter = 1104000 dist_mean = 0.0221 dist_std = 0.1939 vf_loss = 0.0334 grad_norm = 1.9904 nat_grad_norm = 0.1361 cg_residual = 1.0270 step_size = 0.4533 reward = 0.0000 fps = 5 mse_loss = 0.7116 
2022-05-01 08:28:35.543188 - gail/main.py:164 - [TRPO] iter = 1105000 dist_mean = 0.0214 dist_std = 0.1934 vf_loss = 0.0159 grad_norm = 2.9623 nat_grad_norm = 0.1392 cg_residual = 0.5428 step_size = 0.3825 reward = -0.0000 fps = 5 mse_loss = 0.6797 
2022-05-01 08:28:35.770470 - gail/main.py:191 - [Discriminator] iter = 1105000 loss = -0.2977 grad_norm = 3.6223 grad_penalty = 0.0601 regularization = 0.0000 true_logits = -0.3873 fake_logits = -0.7451 true_prob = 0.4485 fake_prob = 0.3860 
2022-05-01 08:30:51.418824 - gail/main.py:132 - [Evaluate] iter = 1105000 episode={ returns = 3581.9133 lengths = 1000 } discounted_episode={ returns = 2210.5976 lengths = 1000 } 
2022-05-01 08:31:01.282684 - gail/main.py:164 - [TRPO] iter = 1106000 dist_mean = 0.0188 dist_std = 0.1924 vf_loss = 0.0193 grad_norm = 2.6838 nat_grad_norm = 0.1175 cg_residual = 0.4724 step_size = 0.4866 reward = 0.0000 fps = 6 mse_loss = 0.6370 
2022-05-01 08:31:11.368673 - gail/main.py:164 - [TRPO] iter = 1107000 dist_mean = 0.0184 dist_std = 0.1919 vf_loss = 0.0885 grad_norm = 1.9052 nat_grad_norm = 0.0959 cg_residual = 0.4879 step_size = 0.5148 reward = 0.0000 fps = 6 mse_loss = 0.7092 
2022-05-01 08:31:21.177877 - gail/main.py:164 - [TRPO] iter = 1108000 dist_mean = 0.0181 dist_std = 0.1912 vf_loss = 0.0532 grad_norm = 2.3900 nat_grad_norm = 0.0904 cg_residual = 0.4586 step_size = 0.5094 reward = -0.0000 fps = 6 mse_loss = 0.6720 
2022-05-01 08:31:30.684279 - gail/main.py:164 - [TRPO] iter = 1109000 dist_mean = 0.0435 dist_std = 0.1909 vf_loss = 0.0946 grad_norm = 2.7825 nat_grad_norm = 0.1028 cg_residual = 1.0233 step_size = 0.4541 reward = -0.0000 fps = 5 mse_loss = 0.7099 
2022-05-01 08:31:40.335702 - gail/main.py:164 - [TRPO] iter = 1110000 dist_mean = 0.0347 dist_std = 0.1903 vf_loss = 0.0773 grad_norm = 2.4354 nat_grad_norm = 0.0891 cg_residual = 0.3554 step_size = 0.4853 reward = -0.0000 fps = 5 mse_loss = 0.6562 
2022-05-01 08:31:40.543684 - gail/main.py:191 - [Discriminator] iter = 1110000 loss = -0.2858 grad_norm = 3.7505 grad_penalty = 0.0568 regularization = 0.0000 true_logits = -0.4846 fake_logits = -0.8273 true_prob = 0.4275 fake_prob = 0.3700 
2022-05-01 08:33:52.130319 - gail/main.py:132 - [Evaluate] iter = 1110000 episode={ returns = 3564.2426 lengths = 1000 } discounted_episode={ returns = 2201.9234 lengths = 1000 } 
2022-05-01 08:34:01.709704 - gail/main.py:164 - [TRPO] iter = 1111000 dist_mean = 0.0183 dist_std = 0.1904 vf_loss = 0.0765 grad_norm = 2.3511 nat_grad_norm = 0.1157 cg_residual = 0.5014 step_size = 0.4561 reward = 0.0000 fps = 7 mse_loss = 0.8221 
2022-05-01 08:34:11.303976 - gail/main.py:164 - [TRPO] iter = 1112000 dist_mean = 0.0286 dist_std = 0.1908 vf_loss = 0.0371 grad_norm = 1.8157 nat_grad_norm = 0.0936 cg_residual = 0.4917 step_size = 0.5817 reward = -0.0000 fps = 6 mse_loss = 0.7032 
2022-05-01 08:34:21.143947 - gail/main.py:164 - [TRPO] iter = 1113000 dist_mean = 0.0861 dist_std = 0.1907 vf_loss = 0.0870 grad_norm = 1.7723 nat_grad_norm = 0.1153 cg_residual = 0.9051 step_size = 0.4620 reward = 0.0000 fps = 6 mse_loss = 0.7428 
2022-05-01 08:34:31.039965 - gail/main.py:164 - [TRPO] iter = 1114000 dist_mean = 0.0319 dist_std = 0.1914 vf_loss = 0.1150 grad_norm = 1.6908 nat_grad_norm = 0.1008 cg_residual = 0.4491 step_size = 0.6206 reward = -0.0000 fps = 5 mse_loss = 0.6603 
2022-05-01 08:34:41.083025 - gail/main.py:164 - [TRPO] iter = 1115000 dist_mean = 0.0558 dist_std = 0.1919 vf_loss = 0.0874 grad_norm = 2.9974 nat_grad_norm = 0.1293 cg_residual = 1.0935 step_size = 0.3954 reward = 0.0000 fps = 5 mse_loss = 0.6007 
2022-05-01 08:34:41.331689 - gail/main.py:191 - [Discriminator] iter = 1115000 loss = -0.3201 grad_norm = 2.9362 grad_penalty = 0.0594 regularization = 0.0000 true_logits = -0.5670 fake_logits = -0.9465 true_prob = 0.4139 fake_prob = 0.3440 
2022-05-01 08:36:47.847319 - gail/main.py:132 - [Evaluate] iter = 1115000 episode={ returns = 3234.2969 lengths = 925 } discounted_episode={ returns = 2167.1177 lengths = 1000 } 
2022-05-01 08:36:57.782823 - gail/main.py:164 - [TRPO] iter = 1116000 dist_mean = 0.1049 dist_std = 0.1912 vf_loss = 0.3273 grad_norm = 1.7097 nat_grad_norm = 0.1886 cg_residual = 1.1958 step_size = 0.3583 reward = 0.0000 fps = 7 mse_loss = 0.7084 
2022-05-01 08:37:07.739373 - gail/main.py:164 - [TRPO] iter = 1117000 dist_mean = 0.0160 dist_std = 0.1907 vf_loss = 0.0888 grad_norm = 2.3999 nat_grad_norm = 0.1085 cg_residual = 0.8101 step_size = 0.4391 reward = 0.0000 fps = 6 mse_loss = 0.7125 
2022-05-01 08:37:17.308555 - gail/main.py:164 - [TRPO] iter = 1118000 dist_mean = 0.0422 dist_std = 0.1911 vf_loss = 0.1246 grad_norm = 2.2432 nat_grad_norm = 0.1052 cg_residual = 2.7075 step_size = 0.5357 reward = 0.0000 fps = 6 mse_loss = 0.6272 
2022-05-01 08:37:26.948275 - gail/main.py:164 - [TRPO] iter = 1119000 dist_mean = 0.0162 dist_std = 0.1909 vf_loss = 0.0229 grad_norm = 2.1703 nat_grad_norm = 0.1170 cg_residual = 0.7398 step_size = 0.4856 reward = -0.0000 fps = 6 mse_loss = 0.7307 
2022-05-01 08:37:36.593212 - gail/main.py:164 - [TRPO] iter = 1120000 dist_mean = 0.0240 dist_std = 0.1900 vf_loss = 0.0134 grad_norm = 2.4132 nat_grad_norm = 0.1211 cg_residual = 0.5152 step_size = 0.4365 reward = -0.0000 fps = 5 mse_loss = 0.7469 
2022-05-01 08:37:36.803618 - gail/main.py:191 - [Discriminator] iter = 1120000 loss = -0.5208 grad_norm = 3.1997 grad_penalty = 0.0598 regularization = 0.0000 true_logits = -0.5691 fake_logits = -1.1497 true_prob = 0.4096 fake_prob = 0.3160 
2022-05-01 08:39:48.391426 - gail/main.py:132 - [Evaluate] iter = 1120000 episode={ returns = 3565.1664 lengths = 1000 } discounted_episode={ returns = 2194.5199 lengths = 1000 } 
2022-05-01 08:39:58.273675 - gail/main.py:164 - [TRPO] iter = 1121000 dist_mean = 0.0175 dist_std = 0.1895 vf_loss = 0.1038 grad_norm = 1.9330 nat_grad_norm = 0.1239 cg_residual = 0.4539 step_size = 0.4407 reward = -0.0000 fps = 7 mse_loss = 0.7851 
2022-05-01 08:40:07.963954 - gail/main.py:164 - [TRPO] iter = 1122000 dist_mean = 0.0269 dist_std = 0.1889 vf_loss = 0.0800 grad_norm = 2.6789 nat_grad_norm = 0.1126 cg_residual = 1.1283 step_size = 0.4536 reward = 0.0000 fps = 6 mse_loss = 0.7290 
2022-05-01 08:40:17.524717 - gail/main.py:164 - [TRPO] iter = 1123000 dist_mean = 0.0622 dist_std = 0.1892 vf_loss = 0.0693 grad_norm = 2.6946 nat_grad_norm = 0.0797 cg_residual = 1.9420 step_size = 0.5720 reward = 0.0000 fps = 6 mse_loss = 0.7074 
2022-05-01 08:40:27.228970 - gail/main.py:164 - [TRPO] iter = 1124000 dist_mean = 0.0501 dist_std = 0.1885 vf_loss = 0.0133 grad_norm = 2.9563 nat_grad_norm = 0.1154 cg_residual = 3.6426 step_size = 0.3992 reward = -0.0000 fps = 5 mse_loss = 0.6499 
2022-05-01 08:40:37.005365 - gail/main.py:164 - [TRPO] iter = 1125000 dist_mean = 0.0402 dist_std = 0.1885 vf_loss = 0.1191 grad_norm = 2.1877 nat_grad_norm = 0.0977 cg_residual = 0.3777 step_size = 0.4855 reward = 0.0000 fps = 5 mse_loss = 0.6297 
2022-05-01 08:40:37.221525 - gail/main.py:191 - [Discriminator] iter = 1125000 loss = -0.4271 grad_norm = 2.9875 grad_penalty = 0.0592 regularization = 0.0000 true_logits = -0.7712 fake_logits = -1.2575 true_prob = 0.3792 fake_prob = 0.2948 
2022-05-01 08:42:44.314735 - gail/main.py:132 - [Evaluate] iter = 1125000 episode={ returns = 3284.1036 lengths = 927 } discounted_episode={ returns = 2176.1948 lengths = 1000 } 
2022-05-01 08:42:54.266712 - gail/main.py:164 - [TRPO] iter = 1126000 dist_mean = -0.0066 dist_std = 0.1887 vf_loss = 0.0565 grad_norm = 2.8868 nat_grad_norm = 0.0792 cg_residual = 0.2981 step_size = 0.5527 reward = -0.0000 fps = 7 mse_loss = 0.6768 
2022-05-01 08:43:04.040413 - gail/main.py:164 - [TRPO] iter = 1127000 dist_mean = -0.0021 dist_std = 0.1892 vf_loss = 0.0123 grad_norm = 2.2677 nat_grad_norm = 0.1505 cg_residual = 2.3160 step_size = 0.3720 reward = -0.0000 fps = 6 mse_loss = 0.7474 
2022-05-01 08:43:14.102804 - gail/main.py:164 - [TRPO] iter = 1128000 dist_mean = 0.0128 dist_std = 0.1887 vf_loss = 0.0786 grad_norm = 4.2444 nat_grad_norm = 0.1228 cg_residual = 1.0948 step_size = 0.4079 reward = 0.0000 fps = 6 mse_loss = 0.7222 
2022-05-01 08:43:24.174624 - gail/main.py:164 - [TRPO] iter = 1129000 dist_mean = -0.0034 dist_std = 0.1887 vf_loss = 0.0157 grad_norm = 2.4474 nat_grad_norm = 0.1130 cg_residual = 0.7921 step_size = 0.4614 reward = 0.0000 fps = 5 mse_loss = 0.7132 
2022-05-01 08:43:33.939968 - gail/main.py:164 - [TRPO] iter = 1130000 dist_mean = 0.0100 dist_std = 0.1879 vf_loss = 0.0660 grad_norm = 1.9749 nat_grad_norm = 0.1159 cg_residual = 0.6534 step_size = 0.4747 reward = -0.0000 fps = 5 mse_loss = 0.7092 
2022-05-01 08:43:34.176566 - gail/main.py:191 - [Discriminator] iter = 1130000 loss = -0.5035 grad_norm = 3.1912 grad_penalty = 0.0626 regularization = 0.0000 true_logits = -0.5895 fake_logits = -1.1556 true_prob = 0.4022 fake_prob = 0.3066 
2022-05-01 08:45:13.548742 - gail/main.py:132 - [Evaluate] iter = 1130000 episode={ returns = 2464.3195 lengths = 716 } discounted_episode={ returns = 1758.8013 lengths = 773 } 
2022-05-01 08:45:23.367704 - gail/main.py:164 - [TRPO] iter = 1131000 dist_mean = 0.0092 dist_std = 0.1870 vf_loss = 0.0216 grad_norm = 2.0045 nat_grad_norm = 0.1328 cg_residual = 0.8908 step_size = 0.4269 reward = -0.0000 fps = 9 mse_loss = 0.7155 
2022-05-01 08:45:33.212976 - gail/main.py:164 - [TRPO] iter = 1132000 dist_mean = 0.0099 dist_std = 0.1864 vf_loss = 0.0179 grad_norm = 2.0217 nat_grad_norm = 0.1036 cg_residual = 0.7197 step_size = 0.4984 reward = 0.0000 fps = 8 mse_loss = 0.7644 
2022-05-01 08:45:42.976397 - gail/main.py:164 - [TRPO] iter = 1133000 dist_mean = 0.0388 dist_std = 0.1865 vf_loss = 0.0165 grad_norm = 3.6581 nat_grad_norm = 0.1263 cg_residual = 1.5073 step_size = 0.3403 reward = -0.0000 fps = 7 mse_loss = 0.6735 
2022-05-01 08:45:53.266628 - gail/main.py:164 - [TRPO] iter = 1134000 dist_mean = 0.0318 dist_std = 0.1863 vf_loss = 0.1145 grad_norm = 2.6262 nat_grad_norm = 0.1323 cg_residual = 0.7244 step_size = 0.3842 reward = -0.0000 fps = 7 mse_loss = 0.7140 
2022-05-01 08:46:02.971118 - gail/main.py:164 - [TRPO] iter = 1135000 dist_mean = 0.0173 dist_std = 0.1865 vf_loss = 0.0202 grad_norm = 2.3252 nat_grad_norm = 0.1341 cg_residual = 0.8402 step_size = 0.4173 reward = 0.0000 fps = 6 mse_loss = 0.7010 
2022-05-01 08:46:03.215930 - gail/main.py:191 - [Discriminator] iter = 1135000 loss = -0.6266 grad_norm = 3.0266 grad_penalty = 0.0666 regularization = 0.0000 true_logits = -0.6628 fake_logits = -1.3559 true_prob = 0.3922 fake_prob = 0.2790 
2022-05-01 08:47:36.357496 - gail/main.py:132 - [Evaluate] iter = 1135000 episode={ returns = 2557.1241 lengths = 828 } discounted_episode={ returns = 999.8973 lengths = 575 } 
2022-05-01 08:47:46.056799 - gail/main.py:164 - [TRPO] iter = 1136000 dist_mean = 0.0318 dist_std = 0.1871 vf_loss = 0.0175 grad_norm = 2.4115 nat_grad_norm = 0.0921 cg_residual = 1.0676 step_size = 0.5007 reward = -0.0000 fps = 9 mse_loss = 0.6923 
2022-05-01 08:47:55.505449 - gail/main.py:164 - [TRPO] iter = 1137000 dist_mean = 0.1201 dist_std = 0.1872 vf_loss = 0.1665 grad_norm = 2.7706 nat_grad_norm = 0.0890 cg_residual = 0.7227 step_size = 0.5792 reward = 0.0000 fps = 8 mse_loss = 0.6453 
2022-05-01 08:48:05.070773 - gail/main.py:164 - [TRPO] iter = 1138000 dist_mean = 0.0705 dist_std = 0.1869 vf_loss = 0.0213 grad_norm = 2.1982 nat_grad_norm = 0.1502 cg_residual = 1.0225 step_size = 0.3833 reward = -0.0000 fps = 8 mse_loss = 0.6595 
2022-05-01 08:48:14.863553 - gail/main.py:164 - [TRPO] iter = 1139000 dist_mean = 0.0738 dist_std = 0.1860 vf_loss = 0.3075 grad_norm = 2.3157 nat_grad_norm = 0.0986 cg_residual = 0.5748 step_size = 0.4883 reward = -0.0000 fps = 7 mse_loss = 0.7099 
2022-05-01 08:48:24.632842 - gail/main.py:164 - [TRPO] iter = 1140000 dist_mean = 0.0304 dist_std = 0.1858 vf_loss = 0.1545 grad_norm = 2.2280 nat_grad_norm = 0.1338 cg_residual = 1.0084 step_size = 0.4378 reward = 0.0000 fps = 7 mse_loss = 0.7023 
2022-05-01 08:48:24.861783 - gail/main.py:191 - [Discriminator] iter = 1140000 loss = -0.5172 grad_norm = 3.6094 grad_penalty = 0.0661 regularization = 0.0000 true_logits = -0.5717 fake_logits = -1.1551 true_prob = 0.4062 fake_prob = 0.3064 
2022-05-01 08:50:30.859256 - gail/main.py:132 - [Evaluate] iter = 1140000 episode={ returns = 3066.8216 lengths = 920 } discounted_episode={ returns = 2020.8398 lengths = 1000 } 
2022-05-01 08:50:40.874134 - gail/main.py:164 - [TRPO] iter = 1141000 dist_mean = 0.1042 dist_std = 0.1865 vf_loss = 0.0527 grad_norm = 1.8168 nat_grad_norm = 0.1406 cg_residual = 1.1491 step_size = 0.3913 reward = 0.0000 fps = 7 mse_loss = 0.6995 
2022-05-01 08:50:50.710146 - gail/main.py:164 - [TRPO] iter = 1142000 dist_mean = 0.0281 dist_std = 0.1857 vf_loss = 0.1109 grad_norm = 2.1937 nat_grad_norm = 0.1093 cg_residual = 0.9656 step_size = 0.5279 reward = 0.0000 fps = 6 mse_loss = 0.7210 
2022-05-01 08:51:00.601423 - gail/main.py:164 - [TRPO] iter = 1143000 dist_mean = -0.0056 dist_std = 0.1857 vf_loss = 0.1826 grad_norm = 2.3551 nat_grad_norm = 0.0963 cg_residual = 0.4413 step_size = 0.4973 reward = -0.0000 fps = 6 mse_loss = 0.7239 
2022-05-01 08:51:10.246711 - gail/main.py:164 - [TRPO] iter = 1144000 dist_mean = 0.0199 dist_std = 0.1858 vf_loss = 0.1204 grad_norm = 2.2724 nat_grad_norm = 0.1009 cg_residual = 0.4713 step_size = 0.4779 reward = -0.0000 fps = 6 mse_loss = 0.6861 
2022-05-01 08:51:20.106008 - gail/main.py:164 - [TRPO] iter = 1145000 dist_mean = 0.0159 dist_std = 0.1846 vf_loss = 0.2279 grad_norm = 3.4242 nat_grad_norm = 0.1140 cg_residual = 1.2707 step_size = 0.3669 reward = -0.0000 fps = 5 mse_loss = 0.7000 
2022-05-01 08:51:20.336011 - gail/main.py:191 - [Discriminator] iter = 1145000 loss = -0.6067 grad_norm = 3.2870 grad_penalty = 0.0665 regularization = 0.0000 true_logits = -0.4591 fake_logits = -1.1323 true_prob = 0.4271 fake_prob = 0.3098 
2022-05-01 08:53:11.086165 - gail/main.py:132 - [Evaluate] iter = 1145000 episode={ returns = 2964.1013 lengths = 843 } discounted_episode={ returns = 1879.9199 lengths = 850 } 
2022-05-01 08:53:21.008358 - gail/main.py:164 - [TRPO] iter = 1146000 dist_mean = 0.0661 dist_std = 0.1840 vf_loss = 0.1728 grad_norm = 1.7380 nat_grad_norm = 0.0797 cg_residual = 0.5062 step_size = 0.5588 reward = -0.0000 fps = 8 mse_loss = 0.6932 
2022-05-01 08:53:30.687123 - gail/main.py:164 - [TRPO] iter = 1147000 dist_mean = 0.0486 dist_std = 0.1835 vf_loss = 0.0213 grad_norm = 2.0147 nat_grad_norm = 0.1084 cg_residual = 0.8442 step_size = 0.4691 reward = 0.0000 fps = 7 mse_loss = 0.6776 
2022-05-01 08:53:40.571796 - gail/main.py:164 - [TRPO] iter = 1148000 dist_mean = 0.0499 dist_std = 0.1827 vf_loss = 0.0183 grad_norm = 3.3873 nat_grad_norm = 0.1186 cg_residual = 0.7146 step_size = 0.4055 reward = 0.0000 fps = 7 mse_loss = 0.6913 
2022-05-01 08:53:50.563676 - gail/main.py:164 - [TRPO] iter = 1149000 dist_mean = 0.0121 dist_std = 0.1824 vf_loss = 0.1452 grad_norm = 2.1858 nat_grad_norm = 0.0792 cg_residual = 0.7339 step_size = 0.5728 reward = -0.0000 fps = 6 mse_loss = 0.6059 
2022-05-01 08:54:00.409866 - gail/main.py:164 - [TRPO] iter = 1150000 dist_mean = 0.0501 dist_std = 0.1820 vf_loss = 0.1035 grad_norm = 2.4481 nat_grad_norm = 0.1116 cg_residual = 1.2478 step_size = 0.4749 reward = -0.0000 fps = 6 mse_loss = 0.6961 
2022-05-01 08:54:00.642472 - gail/main.py:191 - [Discriminator] iter = 1150000 loss = -0.3201 grad_norm = 2.7511 grad_penalty = 0.0664 regularization = 0.0000 true_logits = -0.5823 fake_logits = -0.9687 true_prob = 0.4038 fake_prob = 0.3336 
2022-05-01 08:56:12.035286 - gail/main.py:132 - [Evaluate] iter = 1150000 episode={ returns = 3610.4509 lengths = 1000 } discounted_episode={ returns = 2227.5791 lengths = 1000 } 
2022-05-01 08:56:21.999069 - gail/main.py:164 - [TRPO] iter = 1151000 dist_mean = 0.0454 dist_std = 0.1809 vf_loss = 0.0124 grad_norm = 2.4034 nat_grad_norm = 0.0889 cg_residual = 1.1779 step_size = 0.4662 reward = -0.0000 fps = 7 mse_loss = 0.6447 
2022-05-01 08:56:31.856821 - gail/main.py:164 - [TRPO] iter = 1152000 dist_mean = 0.0340 dist_std = 0.1812 vf_loss = 0.1214 grad_norm = 1.7960 nat_grad_norm = 0.0982 cg_residual = 0.4409 step_size = 0.6015 reward = -0.0000 fps = 6 mse_loss = 0.6529 
2022-05-01 08:56:41.407836 - gail/main.py:164 - [TRPO] iter = 1153000 dist_mean = 0.0381 dist_std = 0.1814 vf_loss = 0.0593 grad_norm = 1.9104 nat_grad_norm = 0.1021 cg_residual = 0.6611 step_size = 0.5879 reward = 0.0000 fps = 6 mse_loss = 0.6365 
2022-05-01 08:56:51.275569 - gail/main.py:164 - [TRPO] iter = 1154000 dist_mean = 0.0322 dist_std = 0.1806 vf_loss = 0.1377 grad_norm = 2.9580 nat_grad_norm = 0.1001 cg_residual = 0.9049 step_size = 0.5186 reward = -0.0000 fps = 5 mse_loss = 0.6824 
2022-05-01 08:57:00.786235 - gail/main.py:164 - [TRPO] iter = 1155000 dist_mean = 0.0560 dist_std = 0.1809 vf_loss = 0.0153 grad_norm = 1.8617 nat_grad_norm = 0.1159 cg_residual = 0.4351 step_size = 0.4581 reward = -0.0000 fps = 5 mse_loss = 0.5893 
2022-05-01 08:57:01.059655 - gail/main.py:191 - [Discriminator] iter = 1155000 loss = -0.3703 grad_norm = 2.9651 grad_penalty = 0.0627 regularization = 0.0000 true_logits = -0.6357 fake_logits = -1.0687 true_prob = 0.3919 fake_prob = 0.3132 
2022-05-01 08:59:12.881177 - gail/main.py:132 - [Evaluate] iter = 1155000 episode={ returns = 3612.9834 lengths = 1000 } discounted_episode={ returns = 2229.6060 lengths = 1000 } 
2022-05-01 08:59:22.651774 - gail/main.py:164 - [TRPO] iter = 1156000 dist_mean = 0.0616 dist_std = 0.1810 vf_loss = 0.0133 grad_norm = 3.4305 nat_grad_norm = 0.1036 cg_residual = 3.1590 step_size = 0.4423 reward = -0.0000 fps = 7 mse_loss = 0.6671 
2022-05-01 08:59:32.075617 - gail/main.py:164 - [TRPO] iter = 1157000 dist_mean = 0.0804 dist_std = 0.1808 vf_loss = 0.0675 grad_norm = 2.2291 nat_grad_norm = 0.0892 cg_residual = 0.4108 step_size = 0.6332 reward = -0.0000 fps = 6 mse_loss = 0.6468 
2022-05-01 08:59:41.859329 - gail/main.py:164 - [TRPO] iter = 1158000 dist_mean = 0.0113 dist_std = 0.1814 vf_loss = 0.0141 grad_norm = 1.6771 nat_grad_norm = 0.0717 cg_residual = 0.6283 step_size = 0.6305 reward = -0.0000 fps = 6 mse_loss = 0.6345 
2022-05-01 08:59:51.530448 - gail/main.py:164 - [TRPO] iter = 1159000 dist_mean = 0.0134 dist_std = 0.1807 vf_loss = 0.0473 grad_norm = 2.3805 nat_grad_norm = 0.0827 cg_residual = 0.9000 step_size = 0.5267 reward = 0.0000 fps = 5 mse_loss = 0.6179 
2022-05-01 09:00:01.759333 - gail/main.py:164 - [TRPO] iter = 1160000 dist_mean = 0.0169 dist_std = 0.1802 vf_loss = 0.0506 grad_norm = 2.8249 nat_grad_norm = 0.1174 cg_residual = 0.8270 step_size = 0.4515 reward = -0.0000 fps = 5 mse_loss = 0.7288 
2022-05-01 09:00:01.965386 - gail/main.py:191 - [Discriminator] iter = 1160000 loss = -0.5237 grad_norm = 3.2013 grad_penalty = 0.0643 regularization = 0.0000 true_logits = -0.6481 fake_logits = -1.2361 true_prob = 0.3909 fake_prob = 0.2877 
2022-05-01 09:02:13.327257 - gail/main.py:132 - [Evaluate] iter = 1160000 episode={ returns = 3615.4651 lengths = 1000 } discounted_episode={ returns = 2229.7956 lengths = 1000 } 
2022-05-01 09:02:22.927483 - gail/main.py:164 - [TRPO] iter = 1161000 dist_mean = 0.0123 dist_std = 0.1800 vf_loss = 0.0196 grad_norm = 3.3705 nat_grad_norm = 0.1182 cg_residual = 1.8080 step_size = 0.4378 reward = 0.0000 fps = 7 mse_loss = 0.7123 
2022-05-01 09:02:32.499877 - gail/main.py:164 - [TRPO] iter = 1162000 dist_mean = 0.0148 dist_std = 0.1796 vf_loss = 0.0175 grad_norm = 3.1092 nat_grad_norm = 0.1284 cg_residual = 1.1056 step_size = 0.4125 reward = 0.0000 fps = 6 mse_loss = 0.6499 
2022-05-01 09:02:42.386434 - gail/main.py:164 - [TRPO] iter = 1163000 dist_mean = 0.0204 dist_std = 0.1788 vf_loss = 0.0123 grad_norm = 2.7256 nat_grad_norm = 0.1156 cg_residual = 0.6846 step_size = 0.4406 reward = -0.0000 fps = 6 mse_loss = 0.6585 
2022-05-01 09:02:51.825101 - gail/main.py:164 - [TRPO] iter = 1164000 dist_mean = 0.0210 dist_std = 0.1784 vf_loss = 0.0773 grad_norm = 2.0423 nat_grad_norm = 0.0723 cg_residual = 0.5091 step_size = 0.5942 reward = -0.0000 fps = 5 mse_loss = 0.7402 
2022-05-01 09:03:01.591488 - gail/main.py:164 - [TRPO] iter = 1165000 dist_mean = 0.0348 dist_std = 0.1780 vf_loss = 0.0800 grad_norm = 1.9812 nat_grad_norm = 0.0701 cg_residual = 0.8251 step_size = 0.6892 reward = -0.0000 fps = 5 mse_loss = 0.6485 
2022-05-01 09:03:01.807459 - gail/main.py:191 - [Discriminator] iter = 1165000 loss = -0.3745 grad_norm = 4.4970 grad_penalty = 0.0630 regularization = 0.0000 true_logits = -0.5939 fake_logits = -1.0314 true_prob = 0.4005 fake_prob = 0.3182 
2022-05-01 09:05:11.874254 - gail/main.py:132 - [Evaluate] iter = 1165000 episode={ returns = 3612.1094 lengths = 1000 } discounted_episode={ returns = 2227.7624 lengths = 1000 } 
2022-05-01 09:05:21.484676 - gail/main.py:164 - [TRPO] iter = 1166000 dist_mean = 0.0116 dist_std = 0.1786 vf_loss = 0.0664 grad_norm = 2.2895 nat_grad_norm = 0.0781 cg_residual = 0.5029 step_size = 0.5793 reward = -0.0000 fps = 7 mse_loss = 0.6175 
2022-05-01 09:05:31.065682 - gail/main.py:164 - [TRPO] iter = 1167000 dist_mean = 0.0516 dist_std = 0.1788 vf_loss = 0.1397 grad_norm = 1.7781 nat_grad_norm = 0.1120 cg_residual = 0.5326 step_size = 0.4859 reward = 0.0000 fps = 6 mse_loss = 0.5864 
2022-05-01 09:05:40.895572 - gail/main.py:164 - [TRPO] iter = 1168000 dist_mean = 0.0202 dist_std = 0.1793 vf_loss = 0.0201 grad_norm = 2.3175 nat_grad_norm = 0.0929 cg_residual = 0.5145 step_size = 0.5095 reward = 0.0000 fps = 6 mse_loss = 0.7458 
2022-05-01 09:05:51.054957 - gail/main.py:164 - [TRPO] iter = 1169000 dist_mean = 0.0398 dist_std = 0.1789 vf_loss = 0.0112 grad_norm = 3.1234 nat_grad_norm = 0.2704 cg_residual = 4.0685 step_size = 0.2330 reward = -0.0000 fps = 5 mse_loss = 0.6753 
2022-05-01 09:06:01.143797 - gail/main.py:164 - [TRPO] iter = 1170000 dist_mean = 0.0411 dist_std = 0.1787 vf_loss = 0.0939 grad_norm = 1.5799 nat_grad_norm = 0.0854 cg_residual = 0.2784 step_size = 0.5828 reward = -0.0000 fps = 5 mse_loss = 0.6846 
2022-05-01 09:06:01.360035 - gail/main.py:191 - [Discriminator] iter = 1170000 loss = -0.4505 grad_norm = 4.4058 grad_penalty = 0.0772 regularization = 0.0000 true_logits = -0.4539 fake_logits = -0.9816 true_prob = 0.4269 fake_prob = 0.3277 
2022-05-01 09:08:07.936199 - gail/main.py:132 - [Evaluate] iter = 1170000 episode={ returns = 3507.3831 lengths = 969 } discounted_episode={ returns = 2228.2171 lengths = 1000 } 
2022-05-01 09:08:17.693098 - gail/main.py:164 - [TRPO] iter = 1171000 dist_mean = 0.0109 dist_std = 0.1785 vf_loss = 0.0515 grad_norm = 1.7239 nat_grad_norm = 0.0697 cg_residual = 0.5775 step_size = 0.6482 reward = 0.0000 fps = 7 mse_loss = 0.5935 
2022-05-01 09:08:27.420255 - gail/main.py:164 - [TRPO] iter = 1172000 dist_mean = 0.0327 dist_std = 0.1781 vf_loss = 0.0159 grad_norm = 3.0484 nat_grad_norm = 0.1209 cg_residual = 0.7198 step_size = 0.4582 reward = 0.0000 fps = 6 mse_loss = 0.6141 
2022-05-01 09:08:37.390842 - gail/main.py:164 - [TRPO] iter = 1173000 dist_mean = 0.0826 dist_std = 0.1783 vf_loss = 0.0317 grad_norm = 2.3068 nat_grad_norm = 0.1211 cg_residual = 1.1745 step_size = 0.4113 reward = 0.0000 fps = 6 mse_loss = 0.6126 
2022-05-01 09:08:46.987747 - gail/main.py:164 - [TRPO] iter = 1174000 dist_mean = 0.0348 dist_std = 0.1781 vf_loss = 0.0170 grad_norm = 1.5230 nat_grad_norm = 0.1368 cg_residual = 1.1747 step_size = 0.4583 reward = -0.0000 fps = 6 mse_loss = 0.6340 
2022-05-01 09:08:56.709383 - gail/main.py:164 - [TRPO] iter = 1175000 dist_mean = 0.0489 dist_std = 0.1783 vf_loss = 0.0127 grad_norm = 3.4745 nat_grad_norm = 0.1079 cg_residual = 0.3631 step_size = 0.4088 reward = 0.0000 fps = 5 mse_loss = 0.5994 
2022-05-01 09:08:56.954382 - gail/main.py:191 - [Discriminator] iter = 1175000 loss = -0.6237 grad_norm = 3.1216 grad_penalty = 0.0650 regularization = 0.0000 true_logits = -0.3819 fake_logits = -1.0707 true_prob = 0.4339 fake_prob = 0.3171 
2022-05-01 09:11:08.662184 - gail/main.py:132 - [Evaluate] iter = 1175000 episode={ returns = 3605.2300 lengths = 1000 } discounted_episode={ returns = 2224.7423 lengths = 1000 } 
2022-05-01 09:11:18.548772 - gail/main.py:164 - [TRPO] iter = 1176000 dist_mean = 0.0285 dist_std = 0.1787 vf_loss = 0.0190 grad_norm = 2.2770 nat_grad_norm = 0.1155 cg_residual = 2.6727 step_size = 0.4390 reward = 0.0000 fps = 7 mse_loss = 0.6861 
2022-05-01 09:11:28.203023 - gail/main.py:164 - [TRPO] iter = 1177000 dist_mean = 0.0427 dist_std = 0.1790 vf_loss = 0.1011 grad_norm = 1.1156 nat_grad_norm = 0.0790 cg_residual = 1.4827 step_size = 0.6909 reward = -0.0000 fps = 6 mse_loss = 0.5834 
2022-05-01 09:11:38.132485 - gail/main.py:164 - [TRPO] iter = 1178000 dist_mean = 0.0534 dist_std = 0.1781 vf_loss = 0.1435 grad_norm = 4.0461 nat_grad_norm = 0.0709 cg_residual = 2.2678 step_size = 0.4337 reward = -0.0000 fps = 6 mse_loss = 0.6443 
2022-05-01 09:11:47.948330 - gail/main.py:164 - [TRPO] iter = 1179000 dist_mean = 0.0548 dist_std = 0.1779 vf_loss = 0.1570 grad_norm = 2.7668 nat_grad_norm = 0.0741 cg_residual = 0.6546 step_size = 0.5505 reward = -0.0000 fps = 5 mse_loss = 0.7278 
2022-05-01 09:11:57.956548 - gail/main.py:164 - [TRPO] iter = 1180000 dist_mean = 0.0429 dist_std = 0.1780 vf_loss = 0.1082 grad_norm = 1.7925 nat_grad_norm = 0.0665 cg_residual = 0.3348 step_size = 0.7182 reward = 0.0000 fps = 5 mse_loss = 0.5735 
2022-05-01 09:11:58.154883 - gail/main.py:191 - [Discriminator] iter = 1180000 loss = -0.4453 grad_norm = 3.5713 grad_penalty = 0.0648 regularization = 0.0000 true_logits = -0.3196 fake_logits = -0.8297 true_prob = 0.4455 fake_prob = 0.3557 
2022-05-01 09:14:12.036699 - gail/main.py:132 - [Evaluate] iter = 1180000 episode={ returns = 3612.1723 lengths = 1000 } discounted_episode={ returns = 2226.7817 lengths = 1000 } 
2022-05-01 09:14:21.818800 - gail/main.py:164 - [TRPO] iter = 1181000 dist_mean = 0.0472 dist_std = 0.1787 vf_loss = 0.0853 grad_norm = 3.4559 nat_grad_norm = 0.0790 cg_residual = 0.2828 step_size = 0.5951 reward = -0.0000 fps = 6 mse_loss = 0.5943 
2022-05-01 09:14:31.598381 - gail/main.py:164 - [TRPO] iter = 1182000 dist_mean = 0.0265 dist_std = 0.1791 vf_loss = 0.0567 grad_norm = 2.6127 nat_grad_norm = 0.1336 cg_residual = 1.3565 step_size = 0.4015 reward = -0.0000 fps = 6 mse_loss = 0.6634 
2022-05-01 09:14:41.739832 - gail/main.py:164 - [TRPO] iter = 1183000 dist_mean = 0.0527 dist_std = 0.1794 vf_loss = 0.0791 grad_norm = 1.5951 nat_grad_norm = 0.0669 cg_residual = 0.4279 step_size = 0.8092 reward = -0.0000 fps = 6 mse_loss = 0.6399 
2022-05-01 09:14:51.203737 - gail/main.py:164 - [TRPO] iter = 1184000 dist_mean = 0.0501 dist_std = 0.1795 vf_loss = 0.0613 grad_norm = 2.0833 nat_grad_norm = 0.0780 cg_residual = 0.4901 step_size = 0.5871 reward = -0.0000 fps = 5 mse_loss = 0.6428 
2022-05-01 09:15:01.135679 - gail/main.py:164 - [TRPO] iter = 1185000 dist_mean = 0.0510 dist_std = 0.1789 vf_loss = 0.0870 grad_norm = 2.2044 nat_grad_norm = 0.0732 cg_residual = 0.3976 step_size = 0.6307 reward = 0.0000 fps = 5 mse_loss = 0.6262 
2022-05-01 09:15:01.388035 - gail/main.py:191 - [Discriminator] iter = 1185000 loss = -0.4004 grad_norm = 3.2481 grad_penalty = 0.0727 regularization = 0.0000 true_logits = -0.3231 fake_logits = -0.7962 true_prob = 0.4497 fake_prob = 0.3603 
2022-05-01 09:17:11.969520 - gail/main.py:132 - [Evaluate] iter = 1185000 episode={ returns = 3566.9838 lengths = 1000 } discounted_episode={ returns = 2196.3489 lengths = 1000 } 
2022-05-01 09:17:21.585401 - gail/main.py:164 - [TRPO] iter = 1186000 dist_mean = 0.0664 dist_std = 0.1799 vf_loss = 0.0920 grad_norm = 1.2769 nat_grad_norm = 0.0655 cg_residual = 0.4217 step_size = 0.7713 reward = 0.0000 fps = 7 mse_loss = 0.6211 
2022-05-01 09:17:31.114048 - gail/main.py:164 - [TRPO] iter = 1187000 dist_mean = 0.0414 dist_std = 0.1809 vf_loss = 0.0908 grad_norm = 3.3435 nat_grad_norm = 0.0447 cg_residual = 0.6797 step_size = 0.7288 reward = -0.0000 fps = 6 mse_loss = 0.7026 
2022-05-01 09:17:40.888059 - gail/main.py:164 - [TRPO] iter = 1188000 dist_mean = 0.0733 dist_std = 0.1806 vf_loss = 0.0939 grad_norm = 2.3564 nat_grad_norm = 0.0996 cg_residual = 1.7433 step_size = 0.5050 reward = -0.0000 fps = 6 mse_loss = 0.6414 
2022-05-01 09:17:51.099989 - gail/main.py:164 - [TRPO] iter = 1189000 dist_mean = 0.0643 dist_std = 0.1812 vf_loss = 0.1075 grad_norm = 3.2754 nat_grad_norm = 0.0636 cg_residual = 0.5013 step_size = 0.6249 reward = -0.0000 fps = 5 mse_loss = 0.6602 
2022-05-01 09:18:00.863956 - gail/main.py:164 - [TRPO] iter = 1190000 dist_mean = 0.0803 dist_std = 0.1819 vf_loss = 0.1050 grad_norm = 3.6501 nat_grad_norm = 0.0774 cg_residual = 1.4705 step_size = 0.6143 reward = -0.0000 fps = 5 mse_loss = 0.7046 
2022-05-01 09:18:01.120079 - gail/main.py:191 - [Discriminator] iter = 1190000 loss = -0.3578 grad_norm = 3.7026 grad_penalty = 0.0727 regularization = 0.0000 true_logits = -0.3213 fake_logits = -0.7518 true_prob = 0.4449 fake_prob = 0.3672 
2022-05-01 09:20:11.664438 - gail/main.py:132 - [Evaluate] iter = 1190000 episode={ returns = 3514.8675 lengths = 1000 } discounted_episode={ returns = 2175.5914 lengths = 1000 } 
2022-05-01 09:20:21.319592 - gail/main.py:164 - [TRPO] iter = 1191000 dist_mean = 0.0655 dist_std = 0.1824 vf_loss = 0.0975 grad_norm = 1.5997 nat_grad_norm = 0.0732 cg_residual = 0.3694 step_size = 0.6799 reward = 0.0000 fps = 7 mse_loss = 0.6602 
2022-05-01 09:20:31.289481 - gail/main.py:164 - [TRPO] iter = 1192000 dist_mean = 0.0783 dist_std = 0.1810 vf_loss = 0.0935 grad_norm = 3.8490 nat_grad_norm = 0.1187 cg_residual = 2.5040 step_size = 0.3659 reward = 0.0000 fps = 6 mse_loss = 0.7360 
2022-05-01 09:20:40.915734 - gail/main.py:164 - [TRPO] iter = 1193000 dist_mean = 0.0708 dist_std = 0.1806 vf_loss = 0.0978 grad_norm = 3.1666 nat_grad_norm = 0.1086 cg_residual = 0.7229 step_size = 0.5160 reward = -0.0000 fps = 6 mse_loss = 0.7921 
2022-05-01 09:20:50.651897 - gail/main.py:164 - [TRPO] iter = 1194000 dist_mean = 0.0492 dist_std = 0.1803 vf_loss = 0.0716 grad_norm = 2.3332 nat_grad_norm = 0.0917 cg_residual = 0.4887 step_size = 0.4899 reward = -0.0000 fps = 5 mse_loss = 0.6502 
2022-05-01 09:21:00.395401 - gail/main.py:164 - [TRPO] iter = 1195000 dist_mean = 0.0788 dist_std = 0.1806 vf_loss = 0.0192 grad_norm = 3.3169 nat_grad_norm = 0.1722 cg_residual = 1.2005 step_size = 0.3833 reward = 0.0000 fps = 5 mse_loss = 0.6376 
2022-05-01 09:21:00.606040 - gail/main.py:191 - [Discriminator] iter = 1195000 loss = -0.3053 grad_norm = 3.5427 grad_penalty = 0.0687 regularization = 0.0000 true_logits = -0.4478 fake_logits = -0.8218 true_prob = 0.4208 fake_prob = 0.3494 
2022-05-01 09:23:12.835267 - gail/main.py:132 - [Evaluate] iter = 1195000 episode={ returns = 3518.4150 lengths = 1000 } discounted_episode={ returns = 2175.8886 lengths = 1000 } 
2022-05-01 09:23:22.910400 - gail/main.py:164 - [TRPO] iter = 1196000 dist_mean = 0.0896 dist_std = 0.1809 vf_loss = 0.0158 grad_norm = 3.6767 nat_grad_norm = 0.0814 cg_residual = 0.3260 step_size = 0.5035 reward = -0.0000 fps = 7 mse_loss = 0.6903 
2022-05-01 09:23:32.794275 - gail/main.py:164 - [TRPO] iter = 1197000 dist_mean = 0.0741 dist_std = 0.1809 vf_loss = 0.0151 grad_norm = 2.1594 nat_grad_norm = 0.1176 cg_residual = 0.6389 step_size = 0.5194 reward = 0.0000 fps = 6 mse_loss = 0.6735 
2022-05-01 09:23:42.556975 - gail/main.py:164 - [TRPO] iter = 1198000 dist_mean = 0.0440 dist_std = 0.1806 vf_loss = 0.0882 grad_norm = 2.4579 nat_grad_norm = 0.0777 cg_residual = 1.5373 step_size = 0.5685 reward = -0.0000 fps = 6 mse_loss = 0.6463 
2022-05-01 09:23:52.029632 - gail/main.py:164 - [TRPO] iter = 1199000 dist_mean = 0.1240 dist_std = 0.1806 vf_loss = 0.0186 grad_norm = 3.0291 nat_grad_norm = 0.0954 cg_residual = 0.5259 step_size = 0.4591 reward = -0.0000 fps = 5 mse_loss = 0.6357 
2022-05-01 09:24:02.020479 - gail/main.py:164 - [TRPO] iter = 1200000 dist_mean = 0.0892 dist_std = 0.1806 vf_loss = 0.0390 grad_norm = 2.6376 nat_grad_norm = 0.1107 cg_residual = 0.5375 step_size = 0.4207 reward = -0.0000 fps = 5 mse_loss = 0.7402 
2022-05-01 09:24:02.247735 - gail/main.py:191 - [Discriminator] iter = 1200000 loss = -0.4672 grad_norm = 3.5041 grad_penalty = 0.0661 regularization = 0.0000 true_logits = -0.3808 fake_logits = -0.9140 true_prob = 0.4299 fake_prob = 0.3333 
2022-05-01 09:26:14.887375 - gail/main.py:132 - [Evaluate] iter = 1200000 episode={ returns = 3531.2804 lengths = 1000 } discounted_episode={ returns = 2184.3007 lengths = 1000 } 
2022-05-01 09:26:25.046905 - gail/main.py:164 - [TRPO] iter = 1201000 dist_mean = 0.0639 dist_std = 0.1801 vf_loss = 0.0672 grad_norm = 3.6235 nat_grad_norm = 0.1200 cg_residual = 0.7133 step_size = 0.4300 reward = -0.0000 fps = 7 mse_loss = 0.6831 
2022-05-01 09:26:35.190639 - gail/main.py:164 - [TRPO] iter = 1202000 dist_mean = 0.0792 dist_std = 0.1795 vf_loss = 0.0115 grad_norm = 2.8166 nat_grad_norm = 0.1546 cg_residual = 1.7332 step_size = 0.3631 reward = 0.0000 fps = 6 mse_loss = 0.6425 
2022-05-01 09:26:45.115762 - gail/main.py:164 - [TRPO] iter = 1203000 dist_mean = 0.0814 dist_std = 0.1790 vf_loss = 0.0186 grad_norm = 2.2861 nat_grad_norm = 0.1037 cg_residual = 0.7443 step_size = 0.5462 reward = -0.0000 fps = 6 mse_loss = 0.7044 
2022-05-01 09:26:54.866813 - gail/main.py:164 - [TRPO] iter = 1204000 dist_mean = 0.0856 dist_std = 0.1793 vf_loss = 0.0404 grad_norm = 4.7943 nat_grad_norm = 0.1164 cg_residual = 1.6053 step_size = 0.3351 reward = -0.0000 fps = 5 mse_loss = 0.7266 
2022-05-01 09:27:04.555319 - gail/main.py:164 - [TRPO] iter = 1205000 dist_mean = 0.0524 dist_std = 0.1791 vf_loss = 0.0622 grad_norm = 4.1250 nat_grad_norm = 0.0966 cg_residual = 2.9855 step_size = 0.4250 reward = -0.0000 fps = 5 mse_loss = 0.6431 
2022-05-01 09:27:04.770323 - gail/main.py:191 - [Discriminator] iter = 1205000 loss = -0.3994 grad_norm = 4.3294 grad_penalty = 0.0643 regularization = 0.0000 true_logits = -0.4167 fake_logits = -0.8803 true_prob = 0.4250 fake_prob = 0.3337 
2022-05-01 09:29:14.121651 - gail/main.py:132 - [Evaluate] iter = 1205000 episode={ returns = 3554.7492 lengths = 1000 } discounted_episode={ returns = 2200.5484 lengths = 1000 } 
2022-05-01 09:29:23.682483 - gail/main.py:164 - [TRPO] iter = 1206000 dist_mean = 0.0824 dist_std = 0.1789 vf_loss = 0.0946 grad_norm = 1.8576 nat_grad_norm = 0.0799 cg_residual = 0.4725 step_size = 0.5674 reward = -0.0000 fps = 7 mse_loss = 0.6481 
2022-05-01 09:29:33.219126 - gail/main.py:164 - [TRPO] iter = 1207000 dist_mean = 0.0674 dist_std = 0.1789 vf_loss = 0.0697 grad_norm = 3.3797 nat_grad_norm = 0.0840 cg_residual = 0.7569 step_size = 0.4426 reward = 0.0000 fps = 6 mse_loss = 0.6681 
2022-05-01 09:29:42.534482 - gail/main.py:164 - [TRPO] iter = 1208000 dist_mean = 0.0656 dist_std = 0.1786 vf_loss = 0.0921 grad_norm = 2.8827 nat_grad_norm = 0.0742 cg_residual = 0.4186 step_size = 0.5784 reward = -0.0000 fps = 6 mse_loss = 0.6410 
2022-05-01 09:29:52.225702 - gail/main.py:164 - [TRPO] iter = 1209000 dist_mean = 0.0345 dist_std = 0.1787 vf_loss = 0.0613 grad_norm = 2.0250 nat_grad_norm = 0.0853 cg_residual = 0.6179 step_size = 0.6052 reward = 0.0000 fps = 5 mse_loss = 0.5748 
2022-05-01 09:30:01.991598 - gail/main.py:164 - [TRPO] iter = 1210000 dist_mean = 0.0295 dist_std = 0.1782 vf_loss = 0.0716 grad_norm = 1.8381 nat_grad_norm = 0.1036 cg_residual = 0.8982 step_size = 0.5210 reward = 0.0000 fps = 5 mse_loss = 0.5916 
2022-05-01 09:30:02.230778 - gail/main.py:191 - [Discriminator] iter = 1210000 loss = -0.5422 grad_norm = 3.7640 grad_penalty = 0.0747 regularization = 0.0000 true_logits = -0.4278 fake_logits = -1.0447 true_prob = 0.4173 fake_prob = 0.3097 
2022-05-01 09:32:11.579309 - gail/main.py:132 - [Evaluate] iter = 1210000 episode={ returns = 3631.9980 lengths = 1000 } discounted_episode={ returns = 2244.1122 lengths = 1000 } 
2022-05-01 09:32:21.153583 - gail/main.py:164 - [TRPO] iter = 1211000 dist_mean = 0.0210 dist_std = 0.1785 vf_loss = 0.0703 grad_norm = 2.0677 nat_grad_norm = 0.0867 cg_residual = 0.5674 step_size = 0.5474 reward = 0.0000 fps = 7 mse_loss = 0.6438 
2022-05-01 09:32:30.962963 - gail/main.py:164 - [TRPO] iter = 1212000 dist_mean = 0.0348 dist_std = 0.1784 vf_loss = 0.0499 grad_norm = 3.6652 nat_grad_norm = 0.0993 cg_residual = 0.8948 step_size = 0.4133 reward = -0.0000 fps = 6 mse_loss = 0.5972 
2022-05-01 09:32:40.308059 - gail/main.py:164 - [TRPO] iter = 1213000 dist_mean = 0.0402 dist_std = 0.1785 vf_loss = 0.0639 grad_norm = 1.8270 nat_grad_norm = 0.0768 cg_residual = 1.3313 step_size = 0.6192 reward = 0.0000 fps = 6 mse_loss = 0.6297 
2022-05-01 09:32:50.051724 - gail/main.py:164 - [TRPO] iter = 1214000 dist_mean = 0.0128 dist_std = 0.1785 vf_loss = 0.0109 grad_norm = 2.5284 nat_grad_norm = 0.1454 cg_residual = 0.8809 step_size = 0.4008 reward = 0.0000 fps = 5 mse_loss = 0.5803 
2022-05-01 09:32:59.782816 - gail/main.py:164 - [TRPO] iter = 1215000 dist_mean = 0.0009 dist_std = 0.1784 vf_loss = 0.0909 grad_norm = 3.5541 nat_grad_norm = 0.0985 cg_residual = 0.7896 step_size = 0.4338 reward = 0.0000 fps = 5 mse_loss = 0.6172 
2022-05-01 09:33:00.006115 - gail/main.py:191 - [Discriminator] iter = 1215000 loss = -0.3488 grad_norm = 4.1365 grad_penalty = 0.0686 regularization = 0.0000 true_logits = -0.3429 fake_logits = -0.7603 true_prob = 0.4319 fake_prob = 0.3503 
2022-05-01 09:35:00.667636 - gail/main.py:132 - [Evaluate] iter = 1215000 episode={ returns = 3609.1214 lengths = 1000 } discounted_episode={ returns = 2006.3933 lengths = 882 } 
2022-05-01 09:35:10.448465 - gail/main.py:164 - [TRPO] iter = 1216000 dist_mean = 0.0104 dist_std = 0.1782 vf_loss = 0.0187 grad_norm = 2.6907 nat_grad_norm = 0.1092 cg_residual = 0.6396 step_size = 0.4315 reward = -0.0000 fps = 7 mse_loss = 0.6121 
2022-05-01 09:35:20.054883 - gail/main.py:164 - [TRPO] iter = 1217000 dist_mean = -0.0086 dist_std = 0.1778 vf_loss = 0.0443 grad_norm = 2.4282 nat_grad_norm = 0.0821 cg_residual = 0.7479 step_size = 0.5365 reward = 0.0000 fps = 7 mse_loss = 0.6146 
2022-05-01 09:35:29.860600 - gail/main.py:164 - [TRPO] iter = 1218000 dist_mean = 0.0017 dist_std = 0.1779 vf_loss = 0.0307 grad_norm = 3.9005 nat_grad_norm = 0.1188 cg_residual = 1.0688 step_size = 0.4007 reward = -0.0000 fps = 6 mse_loss = 0.6443 
2022-05-01 09:35:39.735953 - gail/main.py:164 - [TRPO] iter = 1219000 dist_mean = -0.0130 dist_std = 0.1779 vf_loss = 0.0632 grad_norm = 1.5479 nat_grad_norm = 0.0863 cg_residual = 0.2981 step_size = 0.5960 reward = 0.0000 fps = 6 mse_loss = 0.5333 
2022-05-01 09:35:49.389647 - gail/main.py:164 - [TRPO] iter = 1220000 dist_mean = -0.0079 dist_std = 0.1782 vf_loss = 0.0114 grad_norm = 3.1934 nat_grad_norm = 0.1151 cg_residual = 1.8886 step_size = 0.4262 reward = -0.0000 fps = 5 mse_loss = 0.6450 
2022-05-01 09:35:49.654543 - gail/main.py:191 - [Discriminator] iter = 1220000 loss = -0.4707 grad_norm = 3.2458 grad_penalty = 0.0824 regularization = 0.0000 true_logits = -0.2394 fake_logits = -0.7926 true_prob = 0.4476 fake_prob = 0.3449 
2022-05-01 09:36:58.565010 - gail/main.py:132 - [Evaluate] iter = 1220000 episode={ returns = 1978.9268 lengths = 557 } discounted_episode={ returns = 1282.4558 lengths = 494 } 
2022-05-01 09:37:07.877953 - gail/main.py:164 - [TRPO] iter = 1221000 dist_mean = -0.0135 dist_std = 0.1778 vf_loss = 0.0247 grad_norm = 1.7829 nat_grad_norm = 0.1028 cg_residual = 0.6721 step_size = 0.5150 reward = -0.0000 fps = 12 mse_loss = 0.6348 
2022-05-01 09:37:17.650479 - gail/main.py:164 - [TRPO] iter = 1222000 dist_mean = 0.0109 dist_std = 0.1779 vf_loss = 0.0186 grad_norm = 2.1800 nat_grad_norm = 0.1152 cg_residual = 0.7470 step_size = 0.4292 reward = -0.0000 fps = 11 mse_loss = 0.5718 
2022-05-01 09:37:27.262515 - gail/main.py:164 - [TRPO] iter = 1223000 dist_mean = -0.0157 dist_std = 0.1776 vf_loss = 0.0108 grad_norm = 3.7452 nat_grad_norm = 0.0846 cg_residual = 0.7608 step_size = 0.5119 reward = -0.0000 fps = 10 mse_loss = 0.6127 
2022-05-01 09:37:37.025388 - gail/main.py:164 - [TRPO] iter = 1224000 dist_mean = -0.0124 dist_std = 0.1781 vf_loss = 0.0262 grad_norm = 2.2102 nat_grad_norm = 0.0929 cg_residual = 1.1883 step_size = 0.5423 reward = 0.0000 fps = 9 mse_loss = 0.6238 
2022-05-01 09:37:46.403325 - gail/main.py:164 - [TRPO] iter = 1225000 dist_mean = 0.0151 dist_std = 0.1787 vf_loss = 0.0237 grad_norm = 2.5814 nat_grad_norm = 0.1030 cg_residual = 2.6944 step_size = 0.4486 reward = -0.0000 fps = 8 mse_loss = 0.5761 
2022-05-01 09:37:46.655469 - gail/main.py:191 - [Discriminator] iter = 1225000 loss = -0.5316 grad_norm = 3.2002 grad_penalty = 0.0728 regularization = 0.0000 true_logits = -0.1196 fake_logits = -0.7240 true_prob = 0.4723 fake_prob = 0.3580 
2022-05-01 09:39:56.549822 - gail/main.py:132 - [Evaluate] iter = 1225000 episode={ returns = 3620.1665 lengths = 1000 } discounted_episode={ returns = 2232.0666 lengths = 1000 } 
2022-05-01 09:40:06.191932 - gail/main.py:164 - [TRPO] iter = 1226000 dist_mean = 0.0095 dist_std = 0.1787 vf_loss = 0.0478 grad_norm = 2.0844 nat_grad_norm = 0.1333 cg_residual = 2.7348 step_size = 0.4525 reward = -0.0000 fps = 7 mse_loss = 0.6746 
2022-05-01 09:40:16.050209 - gail/main.py:164 - [TRPO] iter = 1227000 dist_mean = -0.0032 dist_std = 0.1778 vf_loss = 0.0160 grad_norm = 3.3325 nat_grad_norm = 0.0899 cg_residual = 0.5476 step_size = 0.5069 reward = -0.0000 fps = 6 mse_loss = 0.6234 
2022-05-01 09:40:25.789361 - gail/main.py:164 - [TRPO] iter = 1228000 dist_mean = -0.0199 dist_std = 0.1765 vf_loss = 0.0202 grad_norm = 3.9445 nat_grad_norm = 0.0797 cg_residual = 0.3701 step_size = 0.4811 reward = -0.0000 fps = 6 mse_loss = 0.5511 
2022-05-01 09:40:35.750932 - gail/main.py:164 - [TRPO] iter = 1229000 dist_mean = 0.0350 dist_std = 0.1760 vf_loss = 0.0359 grad_norm = 3.1858 nat_grad_norm = 0.0954 cg_residual = 0.6388 step_size = 0.4816 reward = 0.0000 fps = 5 mse_loss = 0.5781 
2022-05-01 09:40:45.626213 - gail/main.py:164 - [TRPO] iter = 1230000 dist_mean = 0.0204 dist_std = 0.1758 vf_loss = 0.1135 grad_norm = 2.1587 nat_grad_norm = 0.0819 cg_residual = 0.6935 step_size = 0.6854 reward = -0.0000 fps = 5 mse_loss = 0.6700 
2022-05-01 09:40:45.856255 - gail/main.py:191 - [Discriminator] iter = 1230000 loss = -0.4109 grad_norm = 3.1158 grad_penalty = 0.0714 regularization = 0.0000 true_logits = -0.1456 fake_logits = -0.6280 true_prob = 0.4664 fake_prob = 0.3763 
2022-05-01 09:42:59.493903 - gail/main.py:132 - [Evaluate] iter = 1230000 episode={ returns = 3552.7681 lengths = 1000 } discounted_episode={ returns = 2195.2262 lengths = 1000 } 
2022-05-01 09:43:09.136382 - gail/main.py:164 - [TRPO] iter = 1231000 dist_mean = 0.0496 dist_std = 0.1760 vf_loss = 0.0584 grad_norm = 2.5734 nat_grad_norm = 0.0864 cg_residual = 3.3789 step_size = 0.5291 reward = 0.0000 fps = 6 mse_loss = 0.6391 
2022-05-01 09:43:18.842774 - gail/main.py:164 - [TRPO] iter = 1232000 dist_mean = 0.0618 dist_std = 0.1765 vf_loss = 0.1027 grad_norm = 3.8474 nat_grad_norm = 0.0520 cg_residual = 1.0501 step_size = 0.6274 reward = 0.0000 fps = 6 mse_loss = 0.6883 
2022-05-01 09:43:28.558224 - gail/main.py:164 - [TRPO] iter = 1233000 dist_mean = 0.0709 dist_std = 0.1767 vf_loss = 0.1355 grad_norm = 4.2999 nat_grad_norm = 0.0678 cg_residual = 2.9543 step_size = 0.5213 reward = 0.0000 fps = 6 mse_loss = 0.6577 
2022-05-01 09:43:38.429341 - gail/main.py:164 - [TRPO] iter = 1234000 dist_mean = 0.0346 dist_std = 0.1767 vf_loss = 0.0872 grad_norm = 2.3780 nat_grad_norm = 0.1445 cg_residual = 1.3976 step_size = 0.3513 reward = -0.0000 fps = 5 mse_loss = 0.6356 
2022-05-01 09:43:48.318885 - gail/main.py:164 - [TRPO] iter = 1235000 dist_mean = 0.0577 dist_std = 0.1762 vf_loss = 0.0639 grad_norm = 3.0069 nat_grad_norm = 0.0888 cg_residual = 1.3108 step_size = 0.5080 reward = -0.0000 fps = 5 mse_loss = 0.6160 
2022-05-01 09:43:48.584916 - gail/main.py:191 - [Discriminator] iter = 1235000 loss = -0.3415 grad_norm = 3.8570 grad_penalty = 0.0769 regularization = 0.0000 true_logits = -0.1308 fake_logits = -0.5492 true_prob = 0.4714 fake_prob = 0.3928 
2022-05-01 09:45:59.512170 - gail/main.py:132 - [Evaluate] iter = 1235000 episode={ returns = 3495.0046 lengths = 1000 } discounted_episode={ returns = 2160.1165 lengths = 1000 } 
2022-05-01 09:46:09.401358 - gail/main.py:164 - [TRPO] iter = 1236000 dist_mean = 0.0535 dist_std = 0.1763 vf_loss = 0.0746 grad_norm = 3.7297 nat_grad_norm = 0.0776 cg_residual = 0.2985 step_size = 0.4733 reward = 0.0000 fps = 7 mse_loss = 0.7040 
2022-05-01 09:46:19.210916 - gail/main.py:164 - [TRPO] iter = 1237000 dist_mean = 0.0848 dist_std = 0.1762 vf_loss = 0.0761 grad_norm = 2.0939 nat_grad_norm = 0.0886 cg_residual = 1.6193 step_size = 0.5560 reward = -0.0000 fps = 6 mse_loss = 0.6192 
2022-05-01 09:46:28.742087 - gail/main.py:164 - [TRPO] iter = 1238000 dist_mean = 0.0873 dist_std = 0.1755 vf_loss = 0.0762 grad_norm = 3.3150 nat_grad_norm = 0.0903 cg_residual = 0.9311 step_size = 0.4291 reward = 0.0000 fps = 6 mse_loss = 0.6653 
2022-05-01 09:46:38.624862 - gail/main.py:164 - [TRPO] iter = 1239000 dist_mean = 0.0765 dist_std = 0.1754 vf_loss = 0.1288 grad_norm = 3.6718 nat_grad_norm = 0.1078 cg_residual = 1.0915 step_size = 0.4649 reward = 0.0000 fps = 5 mse_loss = 0.6484 
2022-05-01 09:46:48.549121 - gail/main.py:164 - [TRPO] iter = 1240000 dist_mean = 0.1052 dist_std = 0.1757 vf_loss = 0.0740 grad_norm = 2.1453 nat_grad_norm = 0.0937 cg_residual = 0.3255 step_size = 0.5489 reward = 0.0000 fps = 5 mse_loss = 0.7444 
2022-05-01 09:46:48.749667 - gail/main.py:191 - [Discriminator] iter = 1240000 loss = -0.2709 grad_norm = 3.3132 grad_penalty = 0.0662 regularization = 0.0000 true_logits = -0.2026 fake_logits = -0.5398 true_prob = 0.4559 fake_prob = 0.3932 
2022-05-01 09:49:00.436481 - gail/main.py:132 - [Evaluate] iter = 1240000 episode={ returns = 3559.9036 lengths = 1000 } discounted_episode={ returns = 2192.3227 lengths = 1000 } 
2022-05-01 09:49:10.630499 - gail/main.py:164 - [TRPO] iter = 1241000 dist_mean = 0.0984 dist_std = 0.1757 vf_loss = 0.1183 grad_norm = 2.9563 nat_grad_norm = 0.0933 cg_residual = 0.6374 step_size = 0.5372 reward = 0.0000 fps = 7 mse_loss = 0.6894 
2022-05-01 09:49:20.698641 - gail/main.py:164 - [TRPO] iter = 1242000 dist_mean = 0.0947 dist_std = 0.1758 vf_loss = 0.1032 grad_norm = 2.2267 nat_grad_norm = 0.0808 cg_residual = 0.7547 step_size = 0.5281 reward = -0.0000 fps = 6 mse_loss = 0.7213 
2022-05-01 09:49:30.454774 - gail/main.py:164 - [TRPO] iter = 1243000 dist_mean = 0.0869 dist_std = 0.1755 vf_loss = 0.1220 grad_norm = 2.9678 nat_grad_norm = 0.0742 cg_residual = 0.7591 step_size = 0.5162 reward = 0.0000 fps = 6 mse_loss = 0.6438 
2022-05-01 09:49:40.010448 - gail/main.py:164 - [TRPO] iter = 1244000 dist_mean = 0.1058 dist_std = 0.1755 vf_loss = 0.1251 grad_norm = 2.8327 nat_grad_norm = 0.0690 cg_residual = 0.4401 step_size = 0.5731 reward = 0.0000 fps = 5 mse_loss = 0.7414 
2022-05-01 09:49:49.956044 - gail/main.py:164 - [TRPO] iter = 1245000 dist_mean = 0.0792 dist_std = 0.1764 vf_loss = 0.0984 grad_norm = 1.5298 nat_grad_norm = 0.0736 cg_residual = 1.0167 step_size = 0.6667 reward = -0.0000 fps = 5 mse_loss = 0.7153 
2022-05-01 09:49:50.185671 - gail/main.py:191 - [Discriminator] iter = 1245000 loss = -0.3918 grad_norm = 3.4057 grad_penalty = 0.0701 regularization = 0.0000 true_logits = -0.1363 fake_logits = -0.5982 true_prob = 0.4656 fake_prob = 0.3805 
2022-05-01 09:52:01.667578 - gail/main.py:132 - [Evaluate] iter = 1245000 episode={ returns = 3557.2756 lengths = 1000 } discounted_episode={ returns = 2171.6738 lengths = 1000 } 
2022-05-01 09:52:11.882525 - gail/main.py:164 - [TRPO] iter = 1246000 dist_mean = 0.0968 dist_std = 0.1764 vf_loss = 0.1208 grad_norm = 3.0339 nat_grad_norm = 0.0952 cg_residual = 0.9515 step_size = 0.4914 reward = -0.0000 fps = 7 mse_loss = 0.6438 
2022-05-01 09:52:21.936703 - gail/main.py:164 - [TRPO] iter = 1247000 dist_mean = 0.0808 dist_std = 0.1765 vf_loss = 0.0341 grad_norm = 2.4666 nat_grad_norm = 0.0884 cg_residual = 1.7533 step_size = 0.5255 reward = 0.0000 fps = 6 mse_loss = 0.7230 
2022-05-01 09:52:31.913522 - gail/main.py:164 - [TRPO] iter = 1248000 dist_mean = 0.0828 dist_std = 0.1762 vf_loss = 0.0772 grad_norm = 3.1518 nat_grad_norm = 0.0620 cg_residual = 1.1988 step_size = 0.6022 reward = -0.0000 fps = 6 mse_loss = 0.6215 
2022-05-01 09:52:42.590819 - gail/main.py:164 - [TRPO] iter = 1249000 dist_mean = 0.0891 dist_std = 0.1753 vf_loss = 0.0192 grad_norm = 2.8443 nat_grad_norm = 0.1024 cg_residual = 1.1740 step_size = 0.4659 reward = -0.0000 fps = 5 mse_loss = 0.6883 
2022-05-01 09:52:52.974973 - gail/main.py:164 - [TRPO] iter = 1250000 dist_mean = 0.0699 dist_std = 0.1747 vf_loss = 0.0208 grad_norm = 2.4433 nat_grad_norm = 0.1144 cg_residual = 1.7508 step_size = 0.4335 reward = -0.0000 fps = 5 mse_loss = 0.7264 
2022-05-01 09:52:53.202284 - gail/main.py:191 - [Discriminator] iter = 1250000 loss = -0.2370 grad_norm = 3.2132 grad_penalty = 0.0701 regularization = 0.0000 true_logits = -0.3099 fake_logits = -0.6171 true_prob = 0.4315 fake_prob = 0.3753 
2022-05-01 09:53:40.474769 - gail/main.py:132 - [Evaluate] iter = 1250000 episode={ returns = 1171.9659 lengths = 366 } discounted_episode={ returns = 888.8999 lengths = 341 } 
2022-05-01 09:53:50.338985 - gail/main.py:164 - [TRPO] iter = 1251000 dist_mean = 0.0890 dist_std = 0.1747 vf_loss = 0.0423 grad_norm = 2.2096 nat_grad_norm = 0.1352 cg_residual = 0.9609 step_size = 0.4289 reward = 0.0000 fps = 17 mse_loss = 0.6339 
2022-05-01 09:54:00.267126 - gail/main.py:164 - [TRPO] iter = 1252000 dist_mean = 0.1011 dist_std = 0.1736 vf_loss = 0.0920 grad_norm = 3.0812 nat_grad_norm = 0.1026 cg_residual = 1.2861 step_size = 0.4400 reward = -0.0000 fps = 14 mse_loss = 0.7427 
2022-05-01 09:54:10.472456 - gail/main.py:164 - [TRPO] iter = 1253000 dist_mean = 0.0838 dist_std = 0.1739 vf_loss = 0.0572 grad_norm = 3.1312 nat_grad_norm = 0.0985 cg_residual = 1.1005 step_size = 0.3834 reward = -0.0000 fps = 12 mse_loss = 0.6547 
2022-05-01 09:54:20.203430 - gail/main.py:164 - [TRPO] iter = 1254000 dist_mean = 0.1097 dist_std = 0.1736 vf_loss = 0.0406 grad_norm = 2.6907 nat_grad_norm = 0.1272 cg_residual = 1.0788 step_size = 0.3865 reward = 0.0000 fps = 11 mse_loss = 0.6951 
2022-05-01 09:54:29.831990 - gail/main.py:164 - [TRPO] iter = 1255000 dist_mean = 0.1241 dist_std = 0.1733 vf_loss = 0.0391 grad_norm = 2.7129 nat_grad_norm = 0.1209 cg_residual = 2.4229 step_size = 0.3820 reward = 0.0000 fps = 10 mse_loss = 0.6948 
2022-05-01 09:54:30.120990 - gail/main.py:191 - [Discriminator] iter = 1255000 loss = -0.3357 grad_norm = 3.4952 grad_penalty = 0.0646 regularization = 0.0000 true_logits = -0.3500 fake_logits = -0.7503 true_prob = 0.4245 fake_prob = 0.3494 
2022-05-01 09:56:44.204929 - gail/main.py:132 - [Evaluate] iter = 1255000 episode={ returns = 3504.6361 lengths = 1000 } discounted_episode={ returns = 2140.6415 lengths = 1000 } 
2022-05-01 09:56:53.795408 - gail/main.py:164 - [TRPO] iter = 1256000 dist_mean = 0.1080 dist_std = 0.1728 vf_loss = 0.1020 grad_norm = 2.9085 nat_grad_norm = 0.1487 cg_residual = 1.3678 step_size = 0.3800 reward = 0.0000 fps = 6 mse_loss = 0.6612 
2022-05-01 09:57:03.698423 - gail/main.py:164 - [TRPO] iter = 1257000 dist_mean = 0.1136 dist_std = 0.1729 vf_loss = 0.0225 grad_norm = 2.9705 nat_grad_norm = 0.0918 cg_residual = 1.8345 step_size = 0.4825 reward = -0.0000 fps = 6 mse_loss = 0.7856 
2022-05-01 09:57:13.749850 - gail/main.py:164 - [TRPO] iter = 1258000 dist_mean = 0.1130 dist_std = 0.1739 vf_loss = 0.1391 grad_norm = 3.0108 nat_grad_norm = 0.1292 cg_residual = 2.3402 step_size = 0.4270 reward = 0.0000 fps = 6 mse_loss = 0.6435 
2022-05-01 09:57:23.617733 - gail/main.py:164 - [TRPO] iter = 1259000 dist_mean = 0.1176 dist_std = 0.1735 vf_loss = 0.0390 grad_norm = 5.3494 nat_grad_norm = 0.0995 cg_residual = 1.4665 step_size = 0.3900 reward = -0.0000 fps = 5 mse_loss = 0.6383 
2022-05-01 09:57:33.689466 - gail/main.py:164 - [TRPO] iter = 1260000 dist_mean = 0.0717 dist_std = 0.1731 vf_loss = 0.1448 grad_norm = 2.4299 nat_grad_norm = 0.0946 cg_residual = 0.4288 step_size = 0.5230 reward = -0.0000 fps = 5 mse_loss = 0.7430 
2022-05-01 09:57:33.967658 - gail/main.py:191 - [Discriminator] iter = 1260000 loss = -0.3254 grad_norm = 3.6509 grad_penalty = 0.0735 regularization = 0.0000 true_logits = -0.3709 fake_logits = -0.7698 true_prob = 0.4192 fake_prob = 0.3393 
2022-05-01 09:59:52.603311 - gail/main.py:132 - [Evaluate] iter = 1260000 episode={ returns = 3561.6548 lengths = 1000 } discounted_episode={ returns = 2192.4027 lengths = 1000 } 
2022-05-01 10:00:02.513080 - gail/main.py:164 - [TRPO] iter = 1261000 dist_mean = 0.0547 dist_std = 0.1731 vf_loss = 0.0314 grad_norm = 2.4295 nat_grad_norm = 0.1429 cg_residual = 2.5452 step_size = 0.3704 reward = 0.0000 fps = 6 mse_loss = 0.6179 
2022-05-01 10:00:12.629900 - gail/main.py:164 - [TRPO] iter = 1262000 dist_mean = 0.0883 dist_std = 0.1728 vf_loss = 0.0209 grad_norm = 5.2747 nat_grad_norm = 0.0874 cg_residual = 3.3187 step_size = 0.4735 reward = -0.0000 fps = 6 mse_loss = 0.6351 
2022-05-01 10:00:22.791682 - gail/main.py:164 - [TRPO] iter = 1263000 dist_mean = 0.0793 dist_std = 0.1725 vf_loss = 0.0216 grad_norm = 3.1122 nat_grad_norm = 0.0915 cg_residual = 1.6571 step_size = 0.4609 reward = 0.0000 fps = 5 mse_loss = 0.6760 
2022-05-01 10:00:32.693419 - gail/main.py:164 - [TRPO] iter = 1264000 dist_mean = 0.1131 dist_std = 0.1724 vf_loss = 0.0206 grad_norm = 2.7814 nat_grad_norm = 0.2073 cg_residual = 2.2611 step_size = 0.3076 reward = 0.0000 fps = 5 mse_loss = 0.5988 
2022-05-01 10:00:42.868842 - gail/main.py:164 - [TRPO] iter = 1265000 dist_mean = 0.0665 dist_std = 0.1726 vf_loss = 0.0259 grad_norm = 2.4816 nat_grad_norm = 0.1013 cg_residual = 1.2188 step_size = 0.4462 reward = -0.0000 fps = 5 mse_loss = 0.7151 
2022-05-01 10:00:43.078517 - gail/main.py:191 - [Discriminator] iter = 1265000 loss = -0.4190 grad_norm = 3.1710 grad_penalty = 0.0581 regularization = 0.0000 true_logits = -0.2471 fake_logits = -0.7242 true_prob = 0.4455 fake_prob = 0.3465 
2022-05-01 10:03:00.460554 - gail/main.py:132 - [Evaluate] iter = 1265000 episode={ returns = 3569.4948 lengths = 1000 } discounted_episode={ returns = 2198.7967 lengths = 1000 } 
2022-05-01 10:03:10.743851 - gail/main.py:164 - [TRPO] iter = 1266000 dist_mean = 0.0699 dist_std = 0.1727 vf_loss = 0.1100 grad_norm = 2.1869 nat_grad_norm = 0.0885 cg_residual = 1.1032 step_size = 0.5173 reward = 0.0000 fps = 6 mse_loss = 0.6998 
2022-05-01 10:03:20.550723 - gail/main.py:164 - [TRPO] iter = 1267000 dist_mean = 0.0726 dist_std = 0.1725 vf_loss = 0.0592 grad_norm = 2.4806 nat_grad_norm = 0.1352 cg_residual = 1.0819 step_size = 0.4263 reward = 0.0000 fps = 6 mse_loss = 0.6999 
2022-05-01 10:03:30.614218 - gail/main.py:164 - [TRPO] iter = 1268000 dist_mean = 0.0855 dist_std = 0.1719 vf_loss = 0.0242 grad_norm = 2.9439 nat_grad_norm = 0.1051 cg_residual = 1.0416 step_size = 0.4586 reward = 0.0000 fps = 5 mse_loss = 0.6924 
2022-05-01 10:03:40.683765 - gail/main.py:164 - [TRPO] iter = 1269000 dist_mean = 0.0897 dist_std = 0.1724 vf_loss = 0.0219 grad_norm = 2.2537 nat_grad_norm = 0.0882 cg_residual = 2.2018 step_size = 0.5458 reward = -0.0000 fps = 5 mse_loss = 0.6448 
2022-05-01 10:03:50.387308 - gail/main.py:164 - [TRPO] iter = 1270000 dist_mean = 0.0740 dist_std = 0.1719 vf_loss = 0.0681 grad_norm = 1.7446 nat_grad_norm = 0.0714 cg_residual = 0.7142 step_size = 0.7216 reward = -0.0000 fps = 5 mse_loss = 0.5802 
2022-05-01 10:03:50.612709 - gail/main.py:191 - [Discriminator] iter = 1270000 loss = -0.4168 grad_norm = 3.5060 grad_penalty = 0.0571 regularization = 0.0000 true_logits = -0.2955 fake_logits = -0.7694 true_prob = 0.4347 fake_prob = 0.3383 
2022-05-01 10:06:06.172052 - gail/main.py:132 - [Evaluate] iter = 1270000 episode={ returns = 3549.6380 lengths = 1000 } discounted_episode={ returns = 2182.3758 lengths = 1000 } 
2022-05-01 10:06:15.864733 - gail/main.py:164 - [TRPO] iter = 1271000 dist_mean = 0.0773 dist_std = 0.1718 vf_loss = 0.0993 grad_norm = 2.3071 nat_grad_norm = 0.0907 cg_residual = 1.0270 step_size = 0.4946 reward = 0.0000 fps = 6 mse_loss = 0.5993 
2022-05-01 10:06:26.043011 - gail/main.py:164 - [TRPO] iter = 1272000 dist_mean = 0.0341 dist_std = 0.1719 vf_loss = 0.0739 grad_norm = 2.2680 nat_grad_norm = 0.0911 cg_residual = 1.3739 step_size = 0.5434 reward = -0.0000 fps = 6 mse_loss = 0.6927 
2022-05-01 10:06:36.191603 - gail/main.py:164 - [TRPO] iter = 1273000 dist_mean = 0.1014 dist_std = 0.1721 vf_loss = 0.0194 grad_norm = 2.2252 nat_grad_norm = 0.0917 cg_residual = 1.1536 step_size = 0.4942 reward = -0.0000 fps = 6 mse_loss = 0.6562 
2022-05-01 10:06:46.178727 - gail/main.py:164 - [TRPO] iter = 1274000 dist_mean = 0.1199 dist_std = 0.1710 vf_loss = 0.0245 grad_norm = 3.9763 nat_grad_norm = 0.0747 cg_residual = 0.9623 step_size = 0.4931 reward = -0.0000 fps = 5 mse_loss = 0.6764 
2022-05-01 10:06:56.117504 - gail/main.py:164 - [TRPO] iter = 1275000 dist_mean = 0.0730 dist_std = 0.1711 vf_loss = 0.0279 grad_norm = 4.0478 nat_grad_norm = 0.0789 cg_residual = 1.0451 step_size = 0.4598 reward = -0.0000 fps = 5 mse_loss = 0.5739 
2022-05-01 10:06:56.345402 - gail/main.py:191 - [Discriminator] iter = 1275000 loss = -0.3549 grad_norm = 3.6188 grad_penalty = 0.0637 regularization = 0.0000 true_logits = -0.3127 fake_logits = -0.7313 true_prob = 0.4323 fake_prob = 0.3456 
2022-05-01 10:09:10.861112 - gail/main.py:132 - [Evaluate] iter = 1275000 episode={ returns = 3561.2789 lengths = 1000 } discounted_episode={ returns = 2183.3627 lengths = 1000 } 
2022-05-01 10:09:20.779521 - gail/main.py:164 - [TRPO] iter = 1276000 dist_mean = 0.0503 dist_std = 0.1712 vf_loss = 0.0277 grad_norm = 3.6186 nat_grad_norm = 0.1860 cg_residual = 2.3181 step_size = 0.2540 reward = 0.0000 fps = 6 mse_loss = 0.6314 
2022-05-01 10:09:30.990931 - gail/main.py:164 - [TRPO] iter = 1277000 dist_mean = 0.0479 dist_std = 0.1712 vf_loss = 0.0238 grad_norm = 2.4935 nat_grad_norm = 0.0958 cg_residual = 0.7680 step_size = 0.4696 reward = 0.0000 fps = 6 mse_loss = 0.6176 
2022-05-01 10:09:40.969255 - gail/main.py:164 - [TRPO] iter = 1278000 dist_mean = 0.0726 dist_std = 0.1709 vf_loss = 0.0224 grad_norm = 3.0495 nat_grad_norm = 0.1070 cg_residual = 0.9793 step_size = 0.4888 reward = -0.0000 fps = 6 mse_loss = 0.6535 
2022-05-01 10:09:51.182753 - gail/main.py:164 - [TRPO] iter = 1279000 dist_mean = 0.0520 dist_std = 0.1708 vf_loss = 0.0308 grad_norm = 2.1592 nat_grad_norm = 0.0981 cg_residual = 1.4236 step_size = 0.4906 reward = -0.0000 fps = 5 mse_loss = 0.6408 
2022-05-01 10:10:01.259342 - gail/main.py:164 - [TRPO] iter = 1280000 dist_mean = 0.0032 dist_std = 0.1706 vf_loss = 0.0343 grad_norm = 4.4649 nat_grad_norm = 0.1244 cg_residual = 1.7000 step_size = 0.3009 reward = -0.0000 fps = 5 mse_loss = 0.6540 
2022-05-01 10:10:01.502448 - gail/main.py:191 - [Discriminator] iter = 1280000 loss = -0.4360 grad_norm = 4.9115 grad_penalty = 0.0679 regularization = 0.0000 true_logits = -0.2771 fake_logits = -0.7810 true_prob = 0.4405 fake_prob = 0.3371 
2022-05-01 10:12:05.810484 - gail/main.py:132 - [Evaluate] iter = 1280000 episode={ returns = 3351.8950 lengths = 927 } discounted_episode={ returns = 2065.0565 lengths = 889 } 
2022-05-01 10:12:16.234560 - gail/main.py:164 - [TRPO] iter = 1281000 dist_mean = 0.0364 dist_std = 0.1703 vf_loss = 0.0965 grad_norm = 3.3504 nat_grad_norm = 0.1362 cg_residual = 0.8286 step_size = 0.3833 reward = -0.0000 fps = 7 mse_loss = 0.5860 
2022-05-01 10:12:26.208347 - gail/main.py:164 - [TRPO] iter = 1282000 dist_mean = 0.0374 dist_std = 0.1700 vf_loss = 0.1036 grad_norm = 2.9112 nat_grad_norm = 0.0979 cg_residual = 0.4629 step_size = 0.4701 reward = 0.0000 fps = 6 mse_loss = 0.5609 
2022-05-01 10:12:36.574851 - gail/main.py:164 - [TRPO] iter = 1283000 dist_mean = 0.0345 dist_std = 0.1696 vf_loss = 0.0248 grad_norm = 2.5671 nat_grad_norm = 0.1339 cg_residual = 2.4791 step_size = 0.3557 reward = -0.0000 fps = 6 mse_loss = 0.6249 
2022-05-01 10:12:46.857094 - gail/main.py:164 - [TRPO] iter = 1284000 dist_mean = 0.0187 dist_std = 0.1692 vf_loss = 0.0236 grad_norm = 2.7881 nat_grad_norm = 0.1585 cg_residual = 1.8174 step_size = 0.3442 reward = 0.0000 fps = 6 mse_loss = 0.6325 
2022-05-01 10:12:57.360188 - gail/main.py:164 - [TRPO] iter = 1285000 dist_mean = 0.0353 dist_std = 0.1696 vf_loss = 0.0220 grad_norm = 2.6096 nat_grad_norm = 0.1402 cg_residual = 1.0365 step_size = 0.4010 reward = 0.0000 fps = 5 mse_loss = 0.6396 
2022-05-01 10:12:57.630288 - gail/main.py:191 - [Discriminator] iter = 1285000 loss = -0.3910 grad_norm = 4.3131 grad_penalty = 0.0737 regularization = 0.0000 true_logits = -0.4413 fake_logits = -0.9060 true_prob = 0.4061 fake_prob = 0.3193 
2022-05-01 10:15:02.120150 - gail/main.py:132 - [Evaluate] iter = 1285000 episode={ returns = 3301.7816 lengths = 913 } discounted_episode={ returns = 2067.2935 lengths = 890 } 
2022-05-01 10:15:12.280367 - gail/main.py:164 - [TRPO] iter = 1286000 dist_mean = 0.0346 dist_std = 0.1697 vf_loss = 0.0258 grad_norm = 2.8506 nat_grad_norm = 0.1119 cg_residual = 3.1430 step_size = 0.4426 reward = -0.0000 fps = 7 mse_loss = 0.5835 
2022-05-01 10:15:22.240280 - gail/main.py:164 - [TRPO] iter = 1287000 dist_mean = 0.0220 dist_std = 0.1700 vf_loss = 0.0154 grad_norm = 3.3499 nat_grad_norm = 0.1288 cg_residual = 0.9015 step_size = 0.4251 reward = 0.0000 fps = 6 mse_loss = 0.5562 
2022-05-01 10:15:32.347969 - gail/main.py:164 - [TRPO] iter = 1288000 dist_mean = 0.0765 dist_std = 0.1693 vf_loss = 0.0193 grad_norm = 3.0929 nat_grad_norm = 0.1132 cg_residual = 0.7329 step_size = 0.4049 reward = 0.0000 fps = 6 mse_loss = 0.5715 
2022-05-01 10:15:42.537213 - gail/main.py:164 - [TRPO] iter = 1289000 dist_mean = 0.0038 dist_std = 0.1691 vf_loss = 0.0157 grad_norm = 2.5807 nat_grad_norm = 0.1189 cg_residual = 1.1280 step_size = 0.4939 reward = -0.0000 fps = 6 mse_loss = 0.5259 
2022-05-01 10:15:52.628811 - gail/main.py:164 - [TRPO] iter = 1290000 dist_mean = 0.0295 dist_std = 0.1693 vf_loss = 0.0706 grad_norm = 2.1496 nat_grad_norm = 0.1006 cg_residual = 0.7574 step_size = 0.5097 reward = 0.0000 fps = 5 mse_loss = 0.5770 
2022-05-01 10:15:52.860586 - gail/main.py:191 - [Discriminator] iter = 1290000 loss = -0.3880 grad_norm = 3.0547 grad_penalty = 0.0666 regularization = 0.0000 true_logits = -0.2867 fake_logits = -0.7413 true_prob = 0.4387 fake_prob = 0.3508 
2022-05-01 10:17:23.381981 - gail/main.py:132 - [Evaluate] iter = 1290000 episode={ returns = 2366.5700 lengths = 660 } discounted_episode={ returns = 1725.9266 lengths = 686 } 
2022-05-01 10:17:33.273846 - gail/main.py:164 - [TRPO] iter = 1291000 dist_mean = 0.0068 dist_std = 0.1696 vf_loss = 0.0314 grad_norm = 2.0081 nat_grad_norm = 0.1678 cg_residual = 0.7157 step_size = 0.3879 reward = 0.0000 fps = 9 mse_loss = 0.6089 
2022-05-01 10:17:43.439567 - gail/main.py:164 - [TRPO] iter = 1292000 dist_mean = 0.0209 dist_std = 0.1693 vf_loss = 0.0184 grad_norm = 2.1382 nat_grad_norm = 0.1271 cg_residual = 0.8227 step_size = 0.4185 reward = -0.0000 fps = 9 mse_loss = 0.5679 
2022-05-01 10:17:53.660527 - gail/main.py:164 - [TRPO] iter = 1293000 dist_mean = 0.0210 dist_std = 0.1694 vf_loss = 0.0207 grad_norm = 1.5731 nat_grad_norm = 0.1062 cg_residual = 0.9174 step_size = 0.5280 reward = 0.0000 fps = 8 mse_loss = 0.6749 
2022-05-01 10:18:04.004371 - gail/main.py:164 - [TRPO] iter = 1294000 dist_mean = -0.0087 dist_std = 0.1688 vf_loss = 0.0310 grad_norm = 3.3089 nat_grad_norm = 0.0883 cg_residual = 0.6503 step_size = 0.4730 reward = -0.0000 fps = 7 mse_loss = 0.5436 
2022-05-01 10:18:14.027230 - gail/main.py:164 - [TRPO] iter = 1295000 dist_mean = -0.0018 dist_std = 0.1689 vf_loss = 0.0212 grad_norm = 2.3164 nat_grad_norm = 0.1189 cg_residual = 1.0022 step_size = 0.4242 reward = 0.0000 fps = 7 mse_loss = 0.5646 
2022-05-01 10:18:14.238154 - gail/main.py:191 - [Discriminator] iter = 1295000 loss = -0.4859 grad_norm = 3.5258 grad_penalty = 0.0749 regularization = 0.0000 true_logits = -0.3248 fake_logits = -0.8855 true_prob = 0.4349 fake_prob = 0.3306 
2022-05-01 10:19:40.795100 - gail/main.py:132 - [Evaluate] iter = 1295000 episode={ returns = 2296.5276 lengths = 640 } discounted_episode={ returns = 1639.6225 lengths = 638 } 
2022-05-01 10:19:50.936708 - gail/main.py:164 - [TRPO] iter = 1296000 dist_mean = -0.0073 dist_std = 0.1690 vf_loss = 0.0212 grad_norm = 2.9064 nat_grad_norm = 0.1075 cg_residual = 0.9213 step_size = 0.4334 reward = -0.0000 fps = 10 mse_loss = 0.5615 
2022-05-01 10:20:01.039797 - gail/main.py:164 - [TRPO] iter = 1297000 dist_mean = 0.0372 dist_std = 0.1692 vf_loss = 0.0172 grad_norm = 2.1331 nat_grad_norm = 0.1422 cg_residual = 1.8322 step_size = 0.3859 reward = -0.0000 fps = 9 mse_loss = 0.6704 
2022-05-01 10:20:11.184823 - gail/main.py:164 - [TRPO] iter = 1298000 dist_mean = 0.0267 dist_std = 0.1686 vf_loss = 0.0332 grad_norm = 2.9815 nat_grad_norm = 0.1041 cg_residual = 0.7894 step_size = 0.4859 reward = 0.0000 fps = 8 mse_loss = 0.5638 
2022-05-01 10:20:21.148802 - gail/main.py:164 - [TRPO] iter = 1299000 dist_mean = 0.0004 dist_std = 0.1679 vf_loss = 0.0281 grad_norm = 3.1659 nat_grad_norm = 0.1354 cg_residual = 1.0680 step_size = 0.3619 reward = 0.0000 fps = 7 mse_loss = 0.5755 
2022-05-01 10:20:31.325128 - gail/main.py:164 - [TRPO] iter = 1300000 dist_mean = -0.0203 dist_std = 0.1679 vf_loss = 0.0486 grad_norm = 2.4489 nat_grad_norm = 0.1298 cg_residual = 1.1173 step_size = 0.4425 reward = 0.0000 fps = 7 mse_loss = 0.5910 
2022-05-01 10:20:31.537919 - gail/main.py:191 - [Discriminator] iter = 1300000 loss = -0.6549 grad_norm = 3.8532 grad_penalty = 0.0904 regularization = 0.0000 true_logits = -0.2582 fake_logits = -1.0035 true_prob = 0.4510 fake_prob = 0.3146 
2022-05-01 10:21:50.364520 - gail/main.py:132 - [Evaluate] iter = 1300000 episode={ returns = 2075.9347 lengths = 574 } discounted_episode={ returns = 1516.2631 lengths = 568 } 
2022-05-01 10:22:01.210396 - gail/main.py:164 - [TRPO] iter = 1301000 dist_mean = 0.0097 dist_std = 0.1677 vf_loss = 0.0187 grad_norm = 3.9892 nat_grad_norm = 0.1324 cg_residual = 1.0215 step_size = 0.3207 reward = -0.0000 fps = 11 mse_loss = 0.5834 
2022-05-01 10:22:11.405120 - gail/main.py:164 - [TRPO] iter = 1302000 dist_mean = -0.0098 dist_std = 0.1675 vf_loss = 0.0461 grad_norm = 4.3191 nat_grad_norm = 0.1333 cg_residual = 1.4515 step_size = 0.3697 reward = 0.0000 fps = 10 mse_loss = 0.5698 
2022-05-01 10:22:21.722452 - gail/main.py:164 - [TRPO] iter = 1303000 dist_mean = 0.0088 dist_std = 0.1675 vf_loss = 0.0285 grad_norm = 4.0144 nat_grad_norm = 0.1289 cg_residual = 1.8025 step_size = 0.3179 reward = -0.0000 fps = 9 mse_loss = 0.5989 
2022-05-01 10:22:31.744216 - gail/main.py:164 - [TRPO] iter = 1304000 dist_mean = -0.0035 dist_std = 0.1675 vf_loss = 0.0337 grad_norm = 2.8617 nat_grad_norm = 0.1126 cg_residual = 0.5708 step_size = 0.4281 reward = -0.0000 fps = 8 mse_loss = 0.5733 
2022-05-01 10:22:41.989278 - gail/main.py:164 - [TRPO] iter = 1305000 dist_mean = 0.0104 dist_std = 0.1670 vf_loss = 0.0259 grad_norm = 1.9422 nat_grad_norm = 0.1056 cg_residual = 0.8794 step_size = 0.4999 reward = -0.0000 fps = 7 mse_loss = 0.5928 
2022-05-01 10:22:42.182165 - gail/main.py:191 - [Discriminator] iter = 1305000 loss = -0.6691 grad_norm = 3.5353 grad_penalty = 0.0959 regularization = 0.0000 true_logits = -0.1937 fake_logits = -0.9588 true_prob = 0.4628 fake_prob = 0.3299 
2022-05-01 10:24:14.236342 - gail/main.py:132 - [Evaluate] iter = 1305000 episode={ returns = 2384.5503 lengths = 662 } discounted_episode={ returns = 1674.1186 lengths = 653 } 
2022-05-01 10:24:24.540586 - gail/main.py:164 - [TRPO] iter = 1306000 dist_mean = -0.0309 dist_std = 0.1671 vf_loss = 0.0475 grad_norm = 2.0697 nat_grad_norm = 0.1226 cg_residual = 1.1501 step_size = 0.4541 reward = 0.0000 fps = 9 mse_loss = 0.4828 
2022-05-01 10:24:34.693317 - gail/main.py:164 - [TRPO] iter = 1307000 dist_mean = -0.0112 dist_std = 0.1662 vf_loss = 0.0480 grad_norm = 2.8739 nat_grad_norm = 0.0998 cg_residual = 1.0983 step_size = 0.4028 reward = 0.0000 fps = 8 mse_loss = 0.5372 
2022-05-01 10:24:44.739677 - gail/main.py:164 - [TRPO] iter = 1308000 dist_mean = 0.0105 dist_std = 0.1662 vf_loss = 0.0372 grad_norm = 3.2329 nat_grad_norm = 0.1344 cg_residual = 1.5094 step_size = 0.3838 reward = 0.0000 fps = 8 mse_loss = 0.5647 
2022-05-01 10:24:55.032221 - gail/main.py:164 - [TRPO] iter = 1309000 dist_mean = -0.0088 dist_std = 0.1671 vf_loss = 0.0485 grad_norm = 3.4471 nat_grad_norm = 0.1098 cg_residual = 1.5667 step_size = 0.4155 reward = 0.0000 fps = 7 mse_loss = 0.5117 
2022-05-01 10:25:05.528373 - gail/main.py:164 - [TRPO] iter = 1310000 dist_mean = 0.0116 dist_std = 0.1678 vf_loss = 0.0397 grad_norm = 3.2401 nat_grad_norm = 0.0902 cg_residual = 0.8322 step_size = 0.4588 reward = 0.0000 fps = 6 mse_loss = 0.4620 
2022-05-01 10:25:05.748402 - gail/main.py:191 - [Discriminator] iter = 1310000 loss = -0.6347 grad_norm = 3.3379 grad_penalty = 0.0965 regularization = 0.0000 true_logits = -0.2250 fake_logits = -0.9562 true_prob = 0.4597 fake_prob = 0.3263 
2022-05-01 10:26:33.822603 - gail/main.py:132 - [Evaluate] iter = 1310000 episode={ returns = 2294.9299 lengths = 645 } discounted_episode={ returns = 1625.1002 lengths = 638 } 
2022-05-01 10:26:43.921122 - gail/main.py:164 - [TRPO] iter = 1311000 dist_mean = 0.0090 dist_std = 0.1677 vf_loss = 0.0527 grad_norm = 2.9076 nat_grad_norm = 0.1083 cg_residual = 0.8378 step_size = 0.4778 reward = 0.0000 fps = 10 mse_loss = 0.4894 
2022-05-01 10:26:54.086873 - gail/main.py:164 - [TRPO] iter = 1312000 dist_mean = 0.0114 dist_std = 0.1679 vf_loss = 0.0385 grad_norm = 2.1831 nat_grad_norm = 0.1191 cg_residual = 0.7080 step_size = 0.4228 reward = -0.0000 fps = 9 mse_loss = 0.5784 
2022-05-01 10:27:04.275308 - gail/main.py:164 - [TRPO] iter = 1313000 dist_mean = 0.0073 dist_std = 0.1682 vf_loss = 0.0511 grad_norm = 2.8255 nat_grad_norm = 0.0941 cg_residual = 1.0677 step_size = 0.4366 reward = -0.0000 fps = 8 mse_loss = 0.5275 
2022-05-01 10:27:14.512263 - gail/main.py:164 - [TRPO] iter = 1314000 dist_mean = 0.0137 dist_std = 0.1679 vf_loss = 0.0420 grad_norm = 2.9476 nat_grad_norm = 0.1257 cg_residual = 1.5697 step_size = 0.4011 reward = 0.0000 fps = 7 mse_loss = 0.5116 
2022-05-01 10:27:24.664937 - gail/main.py:164 - [TRPO] iter = 1315000 dist_mean = 0.0252 dist_std = 0.1676 vf_loss = 0.0426 grad_norm = 4.4054 nat_grad_norm = 0.1384 cg_residual = 1.7725 step_size = 0.3153 reward = -0.0000 fps = 7 mse_loss = 0.5335 
2022-05-01 10:27:24.895080 - gail/main.py:191 - [Discriminator] iter = 1315000 loss = -0.4634 grad_norm = 4.2913 grad_penalty = 0.0855 regularization = 0.0000 true_logits = -0.1620 fake_logits = -0.7110 true_prob = 0.4724 fake_prob = 0.3691 
2022-05-01 10:29:40.798523 - gail/main.py:132 - [Evaluate] iter = 1315000 episode={ returns = 3528.8825 lengths = 1000 } discounted_episode={ returns = 2178.0302 lengths = 998 } 
2022-05-01 10:29:50.558119 - gail/main.py:164 - [TRPO] iter = 1316000 dist_mean = 0.0080 dist_std = 0.1681 vf_loss = 0.1287 grad_norm = 3.2700 nat_grad_norm = 0.0778 cg_residual = 2.2858 step_size = 0.5133 reward = -0.0000 fps = 6 mse_loss = 0.5751 
2022-05-01 10:30:00.396578 - gail/main.py:164 - [TRPO] iter = 1317000 dist_mean = 0.0318 dist_std = 0.1680 vf_loss = 0.0310 grad_norm = 2.7653 nat_grad_norm = 0.0974 cg_residual = 0.9154 step_size = 0.5166 reward = -0.0000 fps = 6 mse_loss = 0.5554 
2022-05-01 10:30:10.375030 - gail/main.py:164 - [TRPO] iter = 1318000 dist_mean = 0.0351 dist_std = 0.1674 vf_loss = 0.0311 grad_norm = 2.1729 nat_grad_norm = 0.1133 cg_residual = 1.6170 step_size = 0.4031 reward = -0.0000 fps = 6 mse_loss = 0.4622 
2022-05-01 10:30:20.312665 - gail/main.py:164 - [TRPO] iter = 1319000 dist_mean = 0.0270 dist_std = 0.1668 vf_loss = 0.1791 grad_norm = 5.2675 nat_grad_norm = 0.0928 cg_residual = 3.4461 step_size = 0.4704 reward = 0.0000 fps = 5 mse_loss = 0.5808 
2022-05-01 10:30:30.138503 - gail/main.py:164 - [TRPO] iter = 1320000 dist_mean = 0.0959 dist_std = 0.1665 vf_loss = 0.1231 grad_norm = 2.6783 nat_grad_norm = 0.1287 cg_residual = 1.2191 step_size = 0.3946 reward = 0.0000 fps = 5 mse_loss = 0.5867 
2022-05-01 10:30:30.355182 - gail/main.py:191 - [Discriminator] iter = 1320000 loss = -0.3599 grad_norm = 3.2071 grad_penalty = 0.0749 regularization = 0.0000 true_logits = -0.2060 fake_logits = -0.6408 true_prob = 0.4618 fake_prob = 0.3857 
2022-05-01 10:32:45.998187 - gail/main.py:132 - [Evaluate] iter = 1320000 episode={ returns = 3500.0184 lengths = 1000 } discounted_episode={ returns = 2156.9215 lengths = 1000 } 
2022-05-01 10:32:56.034337 - gail/main.py:164 - [TRPO] iter = 1321000 dist_mean = 0.0891 dist_std = 0.1662 vf_loss = 0.0449 grad_norm = 2.9724 nat_grad_norm = 0.1317 cg_residual = 2.1814 step_size = 0.3700 reward = -0.0000 fps = 6 mse_loss = 0.6248 
2022-05-01 10:33:05.270327 - gail/main.py:164 - [TRPO] iter = 1322000 dist_mean = 0.0816 dist_std = 0.1656 vf_loss = 0.0424 grad_norm = 2.8527 nat_grad_norm = 0.1071 cg_residual = 1.3165 step_size = 0.4667 reward = -0.0000 fps = 6 mse_loss = 0.6032 
2022-05-01 10:33:14.755550 - gail/main.py:164 - [TRPO] iter = 1323000 dist_mean = 0.0522 dist_std = 0.1657 vf_loss = 0.1727 grad_norm = 2.3008 nat_grad_norm = 0.0716 cg_residual = 1.4460 step_size = 0.6090 reward = -0.0000 fps = 6 mse_loss = 0.5208 
2022-05-01 10:33:24.447283 - gail/main.py:164 - [TRPO] iter = 1324000 dist_mean = 0.0851 dist_std = 0.1654 vf_loss = 0.0204 grad_norm = 2.8667 nat_grad_norm = 0.0987 cg_residual = 0.7218 step_size = 0.4222 reward = -0.0000 fps = 5 mse_loss = 0.4832 
2022-05-01 10:33:34.582420 - gail/main.py:164 - [TRPO] iter = 1325000 dist_mean = 0.0719 dist_std = 0.1656 vf_loss = 0.0218 grad_norm = 2.4953 nat_grad_norm = 0.0931 cg_residual = 2.0381 step_size = 0.4649 reward = -0.0000 fps = 5 mse_loss = 0.6130 
2022-05-01 10:33:34.821188 - gail/main.py:191 - [Discriminator] iter = 1325000 loss = -0.3181 grad_norm = 3.3248 grad_penalty = 0.0742 regularization = 0.0000 true_logits = -0.3859 fake_logits = -0.7783 true_prob = 0.4277 fake_prob = 0.3588 
2022-05-01 10:35:48.684772 - gail/main.py:132 - [Evaluate] iter = 1325000 episode={ returns = 3481.3559 lengths = 1000 } discounted_episode={ returns = 2146.1287 lengths = 1000 } 
2022-05-01 10:35:58.293798 - gail/main.py:164 - [TRPO] iter = 1326000 dist_mean = 0.0851 dist_std = 0.1651 vf_loss = 0.0279 grad_norm = 3.0366 nat_grad_norm = 0.0801 cg_residual = 0.5956 step_size = 0.5451 reward = 0.0000 fps = 6 mse_loss = 0.4811 
2022-05-01 10:36:08.011808 - gail/main.py:164 - [TRPO] iter = 1327000 dist_mean = 0.0675 dist_std = 0.1649 vf_loss = 0.0779 grad_norm = 2.1090 nat_grad_norm = 0.0694 cg_residual = 1.5778 step_size = 0.6787 reward = 0.0000 fps = 6 mse_loss = 0.5854 
2022-05-01 10:36:17.839919 - gail/main.py:164 - [TRPO] iter = 1328000 dist_mean = 0.0847 dist_std = 0.1658 vf_loss = 0.0329 grad_norm = 1.8932 nat_grad_norm = 0.0894 cg_residual = 2.2353 step_size = 0.5205 reward = -0.0000 fps = 6 mse_loss = 0.5144 
2022-05-01 10:36:27.527900 - gail/main.py:164 - [TRPO] iter = 1329000 dist_mean = 0.1119 dist_std = 0.1652 vf_loss = 0.0303 grad_norm = 1.8445 nat_grad_norm = 0.0978 cg_residual = 0.4891 step_size = 0.4969 reward = 0.0000 fps = 5 mse_loss = 0.5343 
2022-05-01 10:36:37.228088 - gail/main.py:164 - [TRPO] iter = 1330000 dist_mean = 0.1183 dist_std = 0.1651 vf_loss = 0.0196 grad_norm = 3.1235 nat_grad_norm = 0.0744 cg_residual = 0.4244 step_size = 0.5239 reward = 0.0000 fps = 5 mse_loss = 0.5646 
2022-05-01 10:36:37.449732 - gail/main.py:191 - [Discriminator] iter = 1330000 loss = -0.3638 grad_norm = 3.2034 grad_penalty = 0.0735 regularization = 0.0000 true_logits = -0.3479 fake_logits = -0.7852 true_prob = 0.4345 fake_prob = 0.3522 
2022-05-01 10:38:48.210379 - gail/main.py:132 - [Evaluate] iter = 1330000 episode={ returns = 3467.0149 lengths = 1000 } discounted_episode={ returns = 2136.5486 lengths = 1000 } 
2022-05-01 10:38:57.698103 - gail/main.py:164 - [TRPO] iter = 1331000 dist_mean = 0.0548 dist_std = 0.1650 vf_loss = 0.1081 grad_norm = 1.7257 nat_grad_norm = 0.0732 cg_residual = 0.2903 step_size = 0.5983 reward = 0.0000 fps = 7 mse_loss = 0.4632 
2022-05-01 10:39:07.555455 - gail/main.py:164 - [TRPO] iter = 1332000 dist_mean = 0.1087 dist_std = 0.1646 vf_loss = 0.0559 grad_norm = 2.8525 nat_grad_norm = 0.0909 cg_residual = 1.3694 step_size = 0.5184 reward = 0.0000 fps = 6 mse_loss = 0.4874 
2022-05-01 10:39:17.048005 - gail/main.py:164 - [TRPO] iter = 1333000 dist_mean = 0.1001 dist_std = 0.1650 vf_loss = 0.0313 grad_norm = 2.6429 nat_grad_norm = 0.0783 cg_residual = 0.5158 step_size = 0.5210 reward = 0.0000 fps = 6 mse_loss = 0.5574 
2022-05-01 10:39:26.575723 - gail/main.py:164 - [TRPO] iter = 1334000 dist_mean = 0.0790 dist_std = 0.1648 vf_loss = 0.0213 grad_norm = 3.2872 nat_grad_norm = 0.0965 cg_residual = 3.7774 step_size = 0.4723 reward = 0.0000 fps = 5 mse_loss = 0.5315 
2022-05-01 10:39:35.997931 - gail/main.py:164 - [TRPO] iter = 1335000 dist_mean = 0.0491 dist_std = 0.1651 vf_loss = 0.0303 grad_norm = 3.4173 nat_grad_norm = 0.0982 cg_residual = 1.2482 step_size = 0.4178 reward = 0.0000 fps = 5 mse_loss = 0.4645 
2022-05-01 10:39:36.200491 - gail/main.py:191 - [Discriminator] iter = 1335000 loss = -0.5988 grad_norm = 3.4045 grad_penalty = 0.0705 regularization = 0.0000 true_logits = -0.3200 fake_logits = -0.9893 true_prob = 0.4379 fake_prob = 0.3153 
2022-05-01 10:41:36.901027 - gail/main.py:132 - [Evaluate] iter = 1335000 episode={ returns = 2927.5265 lengths = 845 } discounted_episode={ returns = 2143.3203 lengths = 1000 } 
2022-05-01 10:41:46.610257 - gail/main.py:164 - [TRPO] iter = 1336000 dist_mean = 0.0422 dist_std = 0.1652 vf_loss = 0.0215 grad_norm = 2.5799 nat_grad_norm = 0.1211 cg_residual = 4.5377 step_size = 0.4101 reward = -0.0000 fps = 7 mse_loss = 0.4929 
2022-05-01 10:41:56.522271 - gail/main.py:164 - [TRPO] iter = 1337000 dist_mean = 0.0985 dist_std = 0.1654 vf_loss = 0.0208 grad_norm = 3.6931 nat_grad_norm = 0.0792 cg_residual = 3.1236 step_size = 0.4516 reward = 0.0000 fps = 7 mse_loss = 0.5036 
2022-05-01 10:42:06.833937 - gail/main.py:164 - [TRPO] iter = 1338000 dist_mean = 0.0776 dist_std = 0.1656 vf_loss = 0.0877 grad_norm = 2.1650 nat_grad_norm = 0.1186 cg_residual = 3.6453 step_size = 0.3927 reward = -0.0000 fps = 6 mse_loss = 0.4738 
2022-05-01 10:42:16.574943 - gail/main.py:164 - [TRPO] iter = 1339000 dist_mean = 0.0682 dist_std = 0.1655 vf_loss = 0.0274 grad_norm = 2.9227 nat_grad_norm = 0.1178 cg_residual = 2.1888 step_size = 0.3831 reward = -0.0000 fps = 6 mse_loss = 0.4880 
2022-05-01 10:42:26.069777 - gail/main.py:164 - [TRPO] iter = 1340000 dist_mean = 0.0725 dist_std = 0.1654 vf_loss = 0.1669 grad_norm = 3.0925 nat_grad_norm = 0.0960 cg_residual = 0.6661 step_size = 0.4811 reward = 0.0000 fps = 5 mse_loss = 0.4474 
2022-05-01 10:42:26.304894 - gail/main.py:191 - [Discriminator] iter = 1340000 loss = -0.5402 grad_norm = 4.1814 grad_penalty = 0.0641 regularization = 0.0000 true_logits = -0.3253 fake_logits = -0.9297 true_prob = 0.4380 fake_prob = 0.3257 
2022-05-01 10:43:57.369696 - gail/main.py:132 - [Evaluate] iter = 1340000 episode={ returns = 2971.4057 lengths = 854 } discounted_episode={ returns = 1282.8601 lengths = 528 } 
2022-05-01 10:44:07.451924 - gail/main.py:164 - [TRPO] iter = 1341000 dist_mean = 0.0753 dist_std = 0.1654 vf_loss = 0.1785 grad_norm = 1.9494 nat_grad_norm = 0.1113 cg_residual = 0.8205 step_size = 0.4503 reward = -0.0000 fps = 9 mse_loss = 0.4783 
2022-05-01 10:44:17.230718 - gail/main.py:164 - [TRPO] iter = 1342000 dist_mean = 0.1015 dist_std = 0.1655 vf_loss = 0.0361 grad_norm = 2.4711 nat_grad_norm = 0.0892 cg_residual = 0.6171 step_size = 0.4749 reward = -0.0000 fps = 9 mse_loss = 0.4648 
2022-05-01 10:44:26.887647 - gail/main.py:164 - [TRPO] iter = 1343000 dist_mean = 0.1008 dist_std = 0.1654 vf_loss = 0.1850 grad_norm = 2.5202 nat_grad_norm = 0.0898 cg_residual = 1.7485 step_size = 0.4807 reward = -0.0000 fps = 8 mse_loss = 0.4897 
2022-05-01 10:44:36.876116 - gail/main.py:164 - [TRPO] iter = 1344000 dist_mean = 0.0115 dist_std = 0.1656 vf_loss = 0.0903 grad_norm = 2.8428 nat_grad_norm = 0.1101 cg_residual = 2.7089 step_size = 0.4253 reward = -0.0000 fps = 7 mse_loss = 0.5049 
2022-05-01 10:44:46.600222 - gail/main.py:164 - [TRPO] iter = 1345000 dist_mean = 0.0752 dist_std = 0.1657 vf_loss = 0.0475 grad_norm = 2.6958 nat_grad_norm = 0.0985 cg_residual = 1.8894 step_size = 0.5415 reward = -0.0000 fps = 7 mse_loss = 0.4421 
2022-05-01 10:44:46.826376 - gail/main.py:191 - [Discriminator] iter = 1345000 loss = -0.4102 grad_norm = 3.2387 grad_penalty = 0.0675 regularization = 0.0000 true_logits = -0.2642 fake_logits = -0.7419 true_prob = 0.4498 fake_prob = 0.3546 
2022-05-01 10:45:28.369781 - gail/main.py:132 - [Evaluate] iter = 1345000 episode={ returns = 870.7494 lengths = 270 } discounted_episode={ returns = 872.2121 lengths = 341 } 
2022-05-01 10:45:38.674526 - gail/main.py:164 - [TRPO] iter = 1346000 dist_mean = 0.0246 dist_std = 0.1659 vf_loss = 0.1191 grad_norm = 2.6427 nat_grad_norm = 0.0846 cg_residual = 0.9477 step_size = 0.4802 reward = 0.0000 fps = 19 mse_loss = 0.5147 
2022-05-01 10:45:48.607137 - gail/main.py:164 - [TRPO] iter = 1347000 dist_mean = 0.0429 dist_std = 0.1658 vf_loss = 0.0628 grad_norm = 3.2852 nat_grad_norm = 0.1120 cg_residual = 0.8836 step_size = 0.3634 reward = 0.0000 fps = 16 mse_loss = 0.4868 
2022-05-01 10:45:58.536710 - gail/main.py:164 - [TRPO] iter = 1348000 dist_mean = 0.0428 dist_std = 0.1659 vf_loss = 0.0957 grad_norm = 2.4545 nat_grad_norm = 0.1319 cg_residual = 2.5103 step_size = 0.4126 reward = -0.0000 fps = 13 mse_loss = 0.5363 
2022-05-01 10:46:08.232061 - gail/main.py:164 - [TRPO] iter = 1349000 dist_mean = 0.0657 dist_std = 0.1658 vf_loss = 0.0370 grad_norm = 3.4222 nat_grad_norm = 0.0727 cg_residual = 2.1144 step_size = 0.5538 reward = 0.0000 fps = 12 mse_loss = 0.4952 
2022-05-01 10:46:18.141880 - gail/main.py:164 - [TRPO] iter = 1350000 dist_mean = 0.0179 dist_std = 0.1657 vf_loss = 0.0580 grad_norm = 3.0426 nat_grad_norm = 0.0711 cg_residual = 2.2869 step_size = 0.5983 reward = -0.0000 fps = 10 mse_loss = 0.5427 
2022-05-01 10:46:18.397691 - gail/main.py:191 - [Discriminator] iter = 1350000 loss = -0.3830 grad_norm = 3.4281 grad_penalty = 0.0650 regularization = 0.0000 true_logits = -0.1324 fake_logits = -0.5804 true_prob = 0.4755 fake_prob = 0.3810 
2022-05-01 10:46:54.190272 - gail/main.py:132 - [Evaluate] iter = 1350000 episode={ returns = 867.6241 lengths = 272 } discounted_episode={ returns = 730.3592 lengths = 269 } 
2022-05-01 10:47:04.064005 - gail/main.py:164 - [TRPO] iter = 1351000 dist_mean = 0.0632 dist_std = 0.1649 vf_loss = 0.1983 grad_norm = 3.9147 nat_grad_norm = 0.0977 cg_residual = 1.1501 step_size = 0.4038 reward = 0.0000 fps = 21 mse_loss = 0.4829 
2022-05-01 10:47:13.537721 - gail/main.py:164 - [TRPO] iter = 1352000 dist_mean = 0.1037 dist_std = 0.1645 vf_loss = 0.0311 grad_norm = 3.5552 nat_grad_norm = 0.0997 cg_residual = 0.7365 step_size = 0.4250 reward = 0.0000 fps = 18 mse_loss = 0.5044 
2022-05-01 10:47:23.072093 - gail/main.py:164 - [TRPO] iter = 1353000 dist_mean = 0.0653 dist_std = 0.1642 vf_loss = 0.0347 grad_norm = 3.7680 nat_grad_norm = 0.0931 cg_residual = 1.3858 step_size = 0.4160 reward = 0.0000 fps = 15 mse_loss = 0.4914 
2022-05-01 10:47:32.586862 - gail/main.py:164 - [TRPO] iter = 1354000 dist_mean = 0.0616 dist_std = 0.1638 vf_loss = 0.1605 grad_norm = 2.4641 nat_grad_norm = 0.0938 cg_residual = 6.3503 step_size = 0.4982 reward = 0.0000 fps = 13 mse_loss = 0.5082 
2022-05-01 10:47:42.089819 - gail/main.py:164 - [TRPO] iter = 1355000 dist_mean = 0.0924 dist_std = 0.1644 vf_loss = 0.0376 grad_norm = 3.1371 nat_grad_norm = 0.1097 cg_residual = 0.9722 step_size = 0.4185 reward = -0.0000 fps = 11 mse_loss = 0.5618 
2022-05-01 10:47:42.301396 - gail/main.py:191 - [Discriminator] iter = 1355000 loss = -0.5134 grad_norm = 2.8270 grad_penalty = 0.0672 regularization = 0.0000 true_logits = -0.1111 fake_logits = -0.6916 true_prob = 0.4803 fake_prob = 0.3617 
2022-05-01 10:48:33.437051 - gail/main.py:132 - [Evaluate] iter = 1355000 episode={ returns = 1342.2643 lengths = 397 } discounted_episode={ returns = 1045.9007 lengths = 398 } 
2022-05-01 10:48:42.524234 - gail/main.py:164 - [TRPO] iter = 1356000 dist_mean = 0.0318 dist_std = 0.1643 vf_loss = 0.1081 grad_norm = 2.7711 nat_grad_norm = 0.1327 cg_residual = 3.5469 step_size = 0.3803 reward = -0.0000 fps = 16 mse_loss = 0.4559 
2022-05-01 10:48:51.871195 - gail/main.py:164 - [TRPO] iter = 1357000 dist_mean = 0.0668 dist_std = 0.1643 vf_loss = 0.0383 grad_norm = 2.8614 nat_grad_norm = 0.1311 cg_residual = 3.1273 step_size = 0.3728 reward = 0.0000 fps = 14 mse_loss = 0.4762 
2022-05-01 10:49:01.544638 - gail/main.py:164 - [TRPO] iter = 1358000 dist_mean = 0.0985 dist_std = 0.1643 vf_loss = 0.1519 grad_norm = 2.9431 nat_grad_norm = 0.0955 cg_residual = 0.7284 step_size = 0.4151 reward = -0.0000 fps = 12 mse_loss = 0.4849 
2022-05-01 10:49:11.093533 - gail/main.py:164 - [TRPO] iter = 1359000 dist_mean = 0.0146 dist_std = 0.1644 vf_loss = 0.2800 grad_norm = 3.0253 nat_grad_norm = 0.0857 cg_residual = 0.7007 step_size = 0.4998 reward = -0.0000 fps = 11 mse_loss = 0.5274 
2022-05-01 10:49:20.599446 - gail/main.py:164 - [TRPO] iter = 1360000 dist_mean = -0.0109 dist_std = 0.1647 vf_loss = 0.0871 grad_norm = 3.6121 nat_grad_norm = 0.0922 cg_residual = 2.4087 step_size = 0.4097 reward = -0.0000 fps = 10 mse_loss = 0.5315 
2022-05-01 10:49:20.825800 - gail/main.py:191 - [Discriminator] iter = 1360000 loss = -0.3762 grad_norm = 3.3245 grad_penalty = 0.0528 regularization = 0.0000 true_logits = -0.0224 fake_logits = -0.4514 true_prob = 0.4980 fake_prob = 0.4079 
2022-05-01 10:51:01.245846 - gail/main.py:132 - [Evaluate] iter = 1360000 episode={ returns = 2605.1266 lengths = 746 } discounted_episode={ returns = 1805.8388 lengths = 805 } 
2022-05-01 10:51:11.226261 - gail/main.py:164 - [TRPO] iter = 1361000 dist_mean = 0.0941 dist_std = 0.1647 vf_loss = 0.1618 grad_norm = 2.7381 nat_grad_norm = 0.0912 cg_residual = 2.6896 step_size = 0.5038 reward = -0.0000 fps = 9 mse_loss = 0.4211 
2022-05-01 10:51:21.266924 - gail/main.py:164 - [TRPO] iter = 1362000 dist_mean = 0.0249 dist_std = 0.1652 vf_loss = 0.0527 grad_norm = 3.5903 nat_grad_norm = 0.1105 cg_residual = 0.9615 step_size = 0.4613 reward = 0.0000 fps = 8 mse_loss = 0.5055 
2022-05-01 10:51:30.800801 - gail/main.py:164 - [TRPO] iter = 1363000 dist_mean = 0.0309 dist_std = 0.1644 vf_loss = 0.0557 grad_norm = 3.5674 nat_grad_norm = 0.1107 cg_residual = 1.3605 step_size = 0.4327 reward = 0.0000 fps = 7 mse_loss = 0.5606 
2022-05-01 10:51:39.723740 - gail/main.py:164 - [TRPO] iter = 1364000 dist_mean = 0.0142 dist_std = 0.1640 vf_loss = 0.0562 grad_norm = 1.7626 nat_grad_norm = 0.0921 cg_residual = 0.5052 step_size = 0.5229 reward = -0.0000 fps = 7 mse_loss = 0.4563 
2022-05-01 10:51:49.151276 - gail/main.py:164 - [TRPO] iter = 1365000 dist_mean = -0.0131 dist_std = 0.1641 vf_loss = 0.0604 grad_norm = 3.2298 nat_grad_norm = 0.0898 cg_residual = 3.1454 step_size = 0.5326 reward = -0.0000 fps = 6 mse_loss = 0.4077 
2022-05-01 10:51:49.373801 - gail/main.py:191 - [Discriminator] iter = 1365000 loss = -0.4125 grad_norm = 3.1898 grad_penalty = 0.0691 regularization = 0.0000 true_logits = 0.0919 fake_logits = -0.3897 true_prob = 0.5214 fake_prob = 0.4208 
2022-05-01 10:52:36.952659 - gail/main.py:132 - [Evaluate] iter = 1365000 episode={ returns = 1109.3366 lengths = 330 } discounted_episode={ returns = 1061.6535 lengths = 390 } 
2022-05-01 10:52:46.873228 - gail/main.py:164 - [TRPO] iter = 1366000 dist_mean = 0.0203 dist_std = 0.1637 vf_loss = 0.0709 grad_norm = 2.6718 nat_grad_norm = 0.0893 cg_residual = 0.5004 step_size = 0.5649 reward = 0.0000 fps = 17 mse_loss = 0.5290 
2022-05-01 10:52:56.467269 - gail/main.py:164 - [TRPO] iter = 1367000 dist_mean = -0.0030 dist_std = 0.1640 vf_loss = 0.0641 grad_norm = 3.3411 nat_grad_norm = 0.0901 cg_residual = 2.2509 step_size = 0.4789 reward = 0.0000 fps = 14 mse_loss = 0.4647 
2022-05-01 10:53:06.417274 - gail/main.py:164 - [TRPO] iter = 1368000 dist_mean = 0.0526 dist_std = 0.1644 vf_loss = 0.0575 grad_norm = 2.6202 nat_grad_norm = 0.1391 cg_residual = 0.8233 step_size = 0.3736 reward = -0.0000 fps = 12 mse_loss = 0.5200 
2022-05-01 10:53:16.053230 - gail/main.py:164 - [TRPO] iter = 1369000 dist_mean = 0.0106 dist_std = 0.1643 vf_loss = 0.0536 grad_norm = 2.4244 nat_grad_norm = 0.1125 cg_residual = 3.6806 step_size = 0.4883 reward = -0.0000 fps = 11 mse_loss = 0.4816 
2022-05-01 10:53:25.553720 - gail/main.py:164 - [TRPO] iter = 1370000 dist_mean = 0.0173 dist_std = 0.1646 vf_loss = 0.0590 grad_norm = 2.8103 nat_grad_norm = 0.1269 cg_residual = 1.0507 step_size = 0.3981 reward = 0.0000 fps = 10 mse_loss = 0.3944 
2022-05-01 10:53:25.767602 - gail/main.py:191 - [Discriminator] iter = 1370000 loss = -0.7344 grad_norm = 3.6877 grad_penalty = 0.0665 regularization = 0.0000 true_logits = 0.2270 fake_logits = -0.5738 true_prob = 0.5482 fake_prob = 0.3935 
2022-05-01 10:54:20.082107 - gail/main.py:132 - [Evaluate] iter = 1370000 episode={ returns = 1220.4691 lengths = 361 } discounted_episode={ returns = 1233.5122 lengths = 477 } 
2022-05-01 10:54:29.721240 - gail/main.py:164 - [TRPO] iter = 1371000 dist_mean = 0.0418 dist_std = 0.1648 vf_loss = 0.0469 grad_norm = 3.5145 nat_grad_norm = 0.1075 cg_residual = 1.5631 step_size = 0.4265 reward = -0.0000 fps = 15 mse_loss = 0.4571 
2022-05-01 10:54:39.921519 - gail/main.py:164 - [TRPO] iter = 1372000 dist_mean = -0.0187 dist_std = 0.1640 vf_loss = 0.0801 grad_norm = 3.4465 nat_grad_norm = 0.1257 cg_residual = 0.9336 step_size = 0.3681 reward = -0.0000 fps = 13 mse_loss = 0.4798 
2022-05-01 10:54:49.606135 - gail/main.py:164 - [TRPO] iter = 1373000 dist_mean = -0.0113 dist_std = 0.1642 vf_loss = 0.0717 grad_norm = 2.9897 nat_grad_norm = 0.0856 cg_residual = 0.8833 step_size = 0.5394 reward = 0.0000 fps = 11 mse_loss = 0.4882 
2022-05-01 10:54:59.423145 - gail/main.py:164 - [TRPO] iter = 1374000 dist_mean = -0.0192 dist_std = 0.1640 vf_loss = 0.0483 grad_norm = 3.2954 nat_grad_norm = 0.1331 cg_residual = 1.6534 step_size = 0.3457 reward = 0.0000 fps = 10 mse_loss = 0.4420 
2022-05-01 10:55:08.901796 - gail/main.py:164 - [TRPO] iter = 1375000 dist_mean = 0.0226 dist_std = 0.1640 vf_loss = 0.0388 grad_norm = 3.1154 nat_grad_norm = 0.1232 cg_residual = 0.8977 step_size = 0.4227 reward = 0.0000 fps = 9 mse_loss = 0.5125 
2022-05-01 10:55:09.134122 - gail/main.py:191 - [Discriminator] iter = 1375000 loss = -0.5082 grad_norm = 3.2656 grad_penalty = 0.0723 regularization = 0.0000 true_logits = 0.3646 fake_logits = -0.2159 true_prob = 0.5739 fake_prob = 0.4603 
2022-05-01 10:56:34.181466 - gail/main.py:132 - [Evaluate] iter = 1375000 episode={ returns = 2168.8117 lengths = 621 } discounted_episode={ returns = 1553.4308 lengths = 650 } 
2022-05-01 10:56:43.873172 - gail/main.py:164 - [TRPO] iter = 1376000 dist_mean = 0.0410 dist_std = 0.1640 vf_loss = 0.0463 grad_norm = 1.6178 nat_grad_norm = 0.1263 cg_residual = 1.3267 step_size = 0.4279 reward = -0.0000 fps = 10 mse_loss = 0.5428 
2022-05-01 10:56:53.764312 - gail/main.py:164 - [TRPO] iter = 1377000 dist_mean = 0.0139 dist_std = 0.1641 vf_loss = 0.0329 grad_norm = 3.1087 nat_grad_norm = 0.1047 cg_residual = 1.4474 step_size = 0.4423 reward = 0.0000 fps = 9 mse_loss = 0.5256 
2022-05-01 10:57:03.542360 - gail/main.py:164 - [TRPO] iter = 1378000 dist_mean = 0.0400 dist_std = 0.1639 vf_loss = 0.0389 grad_norm = 3.1020 nat_grad_norm = 0.0914 cg_residual = 0.7647 step_size = 0.4523 reward = -0.0000 fps = 8 mse_loss = 0.5215 
2022-05-01 10:57:13.035689 - gail/main.py:164 - [TRPO] iter = 1379000 dist_mean = 0.0302 dist_std = 0.1635 vf_loss = 0.0578 grad_norm = 3.0935 nat_grad_norm = 0.1148 cg_residual = 0.9854 step_size = 0.4236 reward = 0.0000 fps = 8 mse_loss = 0.4066 
2022-05-01 10:57:22.591103 - gail/main.py:164 - [TRPO] iter = 1380000 dist_mean = 0.0178 dist_std = 0.1633 vf_loss = 0.0346 grad_norm = 2.8184 nat_grad_norm = 0.1256 cg_residual = 1.2958 step_size = 0.3710 reward = -0.0000 fps = 7 mse_loss = 0.4933 
2022-05-01 10:57:22.774951 - gail/main.py:191 - [Discriminator] iter = 1380000 loss = -0.6290 grad_norm = 2.9046 grad_penalty = 0.0689 regularization = 0.0000 true_logits = 0.3572 fake_logits = -0.3407 true_prob = 0.5711 fake_prob = 0.4382 
2022-05-01 10:59:32.905458 - gail/main.py:132 - [Evaluate] iter = 1380000 episode={ returns = 3497.1419 lengths = 1000 } discounted_episode={ returns = 2157.4985 lengths = 1000 } 
2022-05-01 10:59:42.372599 - gail/main.py:164 - [TRPO] iter = 1381000 dist_mean = 0.0381 dist_std = 0.1631 vf_loss = 0.0334 grad_norm = 2.8651 nat_grad_norm = 0.1005 cg_residual = 1.0492 step_size = 0.4085 reward = -0.0000 fps = 7 mse_loss = 0.5549 
2022-05-01 10:59:52.102220 - gail/main.py:164 - [TRPO] iter = 1382000 dist_mean = 0.0187 dist_std = 0.1629 vf_loss = 0.0217 grad_norm = 2.9230 nat_grad_norm = 0.1181 cg_residual = 5.3326 step_size = 0.4123 reward = 0.0000 fps = 6 mse_loss = 0.5038 
2022-05-01 11:00:01.689728 - gail/main.py:164 - [TRPO] iter = 1383000 dist_mean = 0.0194 dist_std = 0.1627 vf_loss = 0.0456 grad_norm = 3.7695 nat_grad_norm = 0.0945 cg_residual = 3.6290 step_size = 0.4466 reward = 0.0000 fps = 6 mse_loss = 0.4310 
2022-05-01 11:00:11.641737 - gail/main.py:164 - [TRPO] iter = 1384000 dist_mean = 0.0320 dist_std = 0.1633 vf_loss = 0.0223 grad_norm = 1.8725 nat_grad_norm = 0.1178 cg_residual = 1.0520 step_size = 0.4461 reward = 0.0000 fps = 5 mse_loss = 0.4762 
2022-05-01 11:00:21.416014 - gail/main.py:164 - [TRPO] iter = 1385000 dist_mean = 0.0131 dist_std = 0.1634 vf_loss = 0.1637 grad_norm = 2.6825 nat_grad_norm = 0.0937 cg_residual = 0.5930 step_size = 0.4823 reward = -0.0000 fps = 5 mse_loss = 0.5295 
2022-05-01 11:00:21.678886 - gail/main.py:191 - [Discriminator] iter = 1385000 loss = -0.6322 grad_norm = 3.0425 grad_penalty = 0.0622 regularization = 0.0000 true_logits = 0.3722 fake_logits = -0.3222 true_prob = 0.5747 fake_prob = 0.4439 
2022-05-01 11:02:33.408106 - gail/main.py:132 - [Evaluate] iter = 1385000 episode={ returns = 3454.6765 lengths = 1000 } discounted_episode={ returns = 2131.1848 lengths = 1000 } 
2022-05-01 11:02:43.892730 - gail/main.py:164 - [TRPO] iter = 1386000 dist_mean = 0.0137 dist_std = 0.1636 vf_loss = 0.0319 grad_norm = 2.8774 nat_grad_norm = 0.1004 cg_residual = 1.5170 step_size = 0.4047 reward = 0.0000 fps = 7 mse_loss = 0.4453 
2022-05-01 11:02:53.648578 - gail/main.py:164 - [TRPO] iter = 1387000 dist_mean = 0.0399 dist_std = 0.1631 vf_loss = 0.0340 grad_norm = 2.5229 nat_grad_norm = 0.1074 cg_residual = 1.1195 step_size = 0.4395 reward = -0.0000 fps = 6 mse_loss = 0.4770 
2022-05-01 11:03:03.531267 - gail/main.py:164 - [TRPO] iter = 1388000 dist_mean = 0.0433 dist_std = 0.1627 vf_loss = 0.2159 grad_norm = 3.9546 nat_grad_norm = 0.0682 cg_residual = 1.5352 step_size = 0.5260 reward = 0.0000 fps = 6 mse_loss = 0.4663 
2022-05-01 11:03:13.143579 - gail/main.py:164 - [TRPO] iter = 1389000 dist_mean = 0.0584 dist_std = 0.1627 vf_loss = 0.1757 grad_norm = 2.3233 nat_grad_norm = 0.0822 cg_residual = 4.2143 step_size = 0.5419 reward = -0.0000 fps = 5 mse_loss = 0.4706 
2022-05-01 11:03:23.100403 - gail/main.py:164 - [TRPO] iter = 1390000 dist_mean = 0.0521 dist_std = 0.1620 vf_loss = 0.2004 grad_norm = 2.0051 nat_grad_norm = 0.0789 cg_residual = 0.3627 step_size = 0.5424 reward = -0.0000 fps = 5 mse_loss = 0.4246 
2022-05-01 11:03:23.347836 - gail/main.py:191 - [Discriminator] iter = 1390000 loss = -0.4454 grad_norm = 3.5613 grad_penalty = 0.0689 regularization = 0.0000 true_logits = 0.4962 fake_logits = -0.0181 true_prob = 0.5961 fake_prob = 0.4984 
2022-05-01 11:05:35.433912 - gail/main.py:132 - [Evaluate] iter = 1390000 episode={ returns = 3491.8213 lengths = 1000 } discounted_episode={ returns = 2154.9508 lengths = 1000 } 
2022-05-01 11:05:45.498769 - gail/main.py:164 - [TRPO] iter = 1391000 dist_mean = 0.0598 dist_std = 0.1620 vf_loss = 0.1609 grad_norm = 2.8822 nat_grad_norm = 0.0832 cg_residual = 0.6917 step_size = 0.5325 reward = -0.0000 fps = 7 mse_loss = 0.4446 
2022-05-01 11:05:55.411540 - gail/main.py:164 - [TRPO] iter = 1392000 dist_mean = 0.0509 dist_std = 0.1623 vf_loss = 0.1336 grad_norm = 2.3909 nat_grad_norm = 0.0804 cg_residual = 0.4548 step_size = 0.5534 reward = 0.0000 fps = 6 mse_loss = 0.4331 
2022-05-01 11:06:05.580675 - gail/main.py:164 - [TRPO] iter = 1393000 dist_mean = 0.0427 dist_std = 0.1628 vf_loss = 0.2486 grad_norm = 3.2350 nat_grad_norm = 0.1011 cg_residual = 3.8435 step_size = 0.4441 reward = 0.0000 fps = 6 mse_loss = 0.4314 
2022-05-01 11:06:15.414028 - gail/main.py:164 - [TRPO] iter = 1394000 dist_mean = 0.0643 dist_std = 0.1624 vf_loss = 0.0974 grad_norm = 2.8974 nat_grad_norm = 0.0852 cg_residual = 2.6460 step_size = 0.5282 reward = 0.0000 fps = 5 mse_loss = 0.4836 
2022-05-01 11:06:25.145960 - gail/main.py:164 - [TRPO] iter = 1395000 dist_mean = 0.0402 dist_std = 0.1626 vf_loss = 0.1473 grad_norm = 2.0716 nat_grad_norm = 0.0552 cg_residual = 0.5645 step_size = 0.6961 reward = 0.0000 fps = 5 mse_loss = 0.4264 
2022-05-01 11:06:25.415925 - gail/main.py:191 - [Discriminator] iter = 1395000 loss = -0.4053 grad_norm = 3.2883 grad_penalty = 0.0643 regularization = 0.0000 true_logits = 0.4034 fake_logits = -0.0662 true_prob = 0.5777 fake_prob = 0.4879 
2022-05-01 11:08:37.689584 - gail/main.py:132 - [Evaluate] iter = 1395000 episode={ returns = 3539.9342 lengths = 1000 } discounted_episode={ returns = 2182.6725 lengths = 1000 } 
2022-05-01 11:08:47.454603 - gail/main.py:164 - [TRPO] iter = 1396000 dist_mean = 0.0340 dist_std = 0.1630 vf_loss = 0.0750 grad_norm = 1.9429 nat_grad_norm = 0.0996 cg_residual = 0.6040 step_size = 0.5354 reward = -0.0000 fps = 7 mse_loss = 0.4057 
2022-05-01 11:08:57.502394 - gail/main.py:164 - [TRPO] iter = 1397000 dist_mean = 0.0569 dist_std = 0.1621 vf_loss = 0.1245 grad_norm = 2.5815 nat_grad_norm = 0.0845 cg_residual = 2.1050 step_size = 0.5385 reward = 0.0000 fps = 6 mse_loss = 0.4529 
2022-05-01 11:09:07.492731 - gail/main.py:164 - [TRPO] iter = 1398000 dist_mean = 0.0459 dist_std = 0.1618 vf_loss = 0.1288 grad_norm = 3.2150 nat_grad_norm = 0.1008 cg_residual = 0.8177 step_size = 0.4235 reward = 0.0000 fps = 6 mse_loss = 0.3894 
2022-05-01 11:09:17.251069 - gail/main.py:164 - [TRPO] iter = 1399000 dist_mean = 0.0217 dist_std = 0.1620 vf_loss = 0.0911 grad_norm = 1.7153 nat_grad_norm = 0.0727 cg_residual = 0.6802 step_size = 0.6690 reward = -0.0000 fps = 5 mse_loss = 0.4507 
2022-05-01 11:09:26.831078 - gail/main.py:164 - [TRPO] iter = 1400000 dist_mean = 0.0382 dist_std = 0.1626 vf_loss = 0.1356 grad_norm = 2.6003 nat_grad_norm = 0.0834 cg_residual = 0.5657 step_size = 0.5445 reward = 0.0000 fps = 5 mse_loss = 0.4440 
2022-05-01 11:09:27.077709 - gail/main.py:191 - [Discriminator] iter = 1400000 loss = -0.4243 grad_norm = 3.9723 grad_penalty = 0.0591 regularization = 0.0000 true_logits = 0.3911 fake_logits = -0.0923 true_prob = 0.5707 fake_prob = 0.4828 
2022-05-01 11:11:41.008271 - gail/main.py:132 - [Evaluate] iter = 1400000 episode={ returns = 3523.8497 lengths = 1000 } discounted_episode={ returns = 2166.9856 lengths = 1000 } 
2022-05-01 11:11:50.705618 - gail/main.py:164 - [TRPO] iter = 1401000 dist_mean = 0.0360 dist_std = 0.1628 vf_loss = 0.1178 grad_norm = 1.5874 nat_grad_norm = 0.0731 cg_residual = 0.4188 step_size = 0.6373 reward = -0.0000 fps = 6 mse_loss = 0.4563 
2022-05-01 11:12:00.502815 - gail/main.py:164 - [TRPO] iter = 1402000 dist_mean = 0.0270 dist_std = 0.1627 vf_loss = 0.1257 grad_norm = 2.3018 nat_grad_norm = 0.0810 cg_residual = 0.9897 step_size = 0.5651 reward = -0.0000 fps = 6 mse_loss = 0.4041 
2022-05-01 11:12:10.243485 - gail/main.py:164 - [TRPO] iter = 1403000 dist_mean = 0.0297 dist_std = 0.1635 vf_loss = 0.0518 grad_norm = 3.6356 nat_grad_norm = 0.0959 cg_residual = 1.8204 step_size = 0.4412 reward = -0.0000 fps = 6 mse_loss = 0.4166 
2022-05-01 11:12:19.844657 - gail/main.py:164 - [TRPO] iter = 1404000 dist_mean = 0.0327 dist_std = 0.1636 vf_loss = 0.1315 grad_norm = 3.1599 nat_grad_norm = 0.1098 cg_residual = 0.6811 step_size = 0.4093 reward = -0.0000 fps = 5 mse_loss = 0.4058 
2022-05-01 11:12:29.343753 - gail/main.py:164 - [TRPO] iter = 1405000 dist_mean = 0.0384 dist_std = 0.1641 vf_loss = 0.0271 grad_norm = 2.6292 nat_grad_norm = 0.1245 cg_residual = 1.1261 step_size = 0.3970 reward = -0.0000 fps = 5 mse_loss = 0.4434 
2022-05-01 11:12:29.561743 - gail/main.py:191 - [Discriminator] iter = 1405000 loss = -0.5730 grad_norm = 3.5210 grad_penalty = 0.0748 regularization = 0.0000 true_logits = 0.3354 fake_logits = -0.3125 true_prob = 0.5613 fake_prob = 0.4419 
2022-05-01 11:14:25.761693 - gail/main.py:132 - [Evaluate] iter = 1405000 episode={ returns = 2698.5909 lengths = 775 } discounted_episode={ returns = 2153.4229 lengths = 1000 } 
2022-05-01 11:14:35.509866 - gail/main.py:164 - [TRPO] iter = 1406000 dist_mean = 0.0623 dist_std = 0.1636 vf_loss = 0.1582 grad_norm = 3.0363 nat_grad_norm = 0.0927 cg_residual = 1.5740 step_size = 0.4783 reward = -0.0000 fps = 7 mse_loss = 0.3742 
2022-05-01 11:14:45.325453 - gail/main.py:164 - [TRPO] iter = 1407000 dist_mean = 0.0521 dist_std = 0.1638 vf_loss = 0.0581 grad_norm = 2.0659 nat_grad_norm = 0.1116 cg_residual = 0.6499 step_size = 0.4831 reward = 0.0000 fps = 7 mse_loss = 0.3982 
2022-05-01 11:14:55.348276 - gail/main.py:164 - [TRPO] iter = 1408000 dist_mean = 0.0572 dist_std = 0.1637 vf_loss = 0.0239 grad_norm = 3.5098 nat_grad_norm = 0.0860 cg_residual = 0.5812 step_size = 0.4810 reward = -0.0000 fps = 6 mse_loss = 0.4421 
2022-05-01 11:15:05.134276 - gail/main.py:164 - [TRPO] iter = 1409000 dist_mean = 0.0156 dist_std = 0.1642 vf_loss = 0.1375 grad_norm = 3.1144 nat_grad_norm = 0.0741 cg_residual = 0.4519 step_size = 0.5151 reward = -0.0000 fps = 6 mse_loss = 0.4166 
2022-05-01 11:15:14.841219 - gail/main.py:164 - [TRPO] iter = 1410000 dist_mean = 0.0184 dist_std = 0.1640 vf_loss = 0.0290 grad_norm = 4.1702 nat_grad_norm = 0.1375 cg_residual = 1.8295 step_size = 0.3482 reward = -0.0000 fps = 6 mse_loss = 0.3878 
2022-05-01 11:15:15.104927 - gail/main.py:191 - [Discriminator] iter = 1410000 loss = -0.6023 grad_norm = 3.0391 grad_penalty = 0.0754 regularization = 0.0000 true_logits = 0.2806 fake_logits = -0.3971 true_prob = 0.5510 fake_prob = 0.4326 
2022-05-01 11:17:06.849243 - gail/main.py:132 - [Evaluate] iter = 1410000 episode={ returns = 2787.7023 lengths = 790 } discounted_episode={ returns = 2024.7720 lengths = 927 } 
2022-05-01 11:17:16.713280 - gail/main.py:164 - [TRPO] iter = 1411000 dist_mean = 0.0115 dist_std = 0.1644 vf_loss = 0.0197 grad_norm = 2.4293 nat_grad_norm = 0.1211 cg_residual = 1.4108 step_size = 0.4421 reward = 0.0000 fps = 8 mse_loss = 0.4408 
2022-05-01 11:17:26.479533 - gail/main.py:164 - [TRPO] iter = 1412000 dist_mean = 0.0068 dist_std = 0.1653 vf_loss = 0.1195 grad_norm = 1.6786 nat_grad_norm = 0.1067 cg_residual = 0.5705 step_size = 0.5420 reward = 0.0000 fps = 7 mse_loss = 0.3951 
2022-05-01 11:17:35.871330 - gail/main.py:164 - [TRPO] iter = 1413000 dist_mean = 0.0015 dist_std = 0.1660 vf_loss = 0.0253 grad_norm = 2.1734 nat_grad_norm = 0.1232 cg_residual = 1.0919 step_size = 0.4322 reward = -0.0000 fps = 7 mse_loss = 0.4581 
2022-05-01 11:17:45.739110 - gail/main.py:164 - [TRPO] iter = 1414000 dist_mean = 0.0275 dist_std = 0.1663 vf_loss = 0.0188 grad_norm = 4.0447 nat_grad_norm = 0.1419 cg_residual = 1.2162 step_size = 0.2861 reward = 0.0000 fps = 6 mse_loss = 0.4462 
2022-05-01 11:17:55.574250 - gail/main.py:164 - [TRPO] iter = 1415000 dist_mean = 0.0394 dist_std = 0.1662 vf_loss = 0.0264 grad_norm = 2.4976 nat_grad_norm = 0.0916 cg_residual = 2.5211 step_size = 0.5159 reward = -0.0000 fps = 6 mse_loss = 0.4223 
2022-05-01 11:17:55.842350 - gail/main.py:191 - [Discriminator] iter = 1415000 loss = -0.2927 grad_norm = 3.3342 grad_penalty = 0.0597 regularization = 0.0000 true_logits = 0.2400 fake_logits = -0.1124 true_prob = 0.5417 fake_prob = 0.4795 
2022-05-01 11:19:03.190482 - gail/main.py:132 - [Evaluate] iter = 1415000 episode={ returns = 1938.8470 lengths = 550 } discounted_episode={ returns = 1184.5304 lengths = 467 } 
2022-05-01 11:19:12.987987 - gail/main.py:164 - [TRPO] iter = 1416000 dist_mean = 0.0381 dist_std = 0.1658 vf_loss = 0.1564 grad_norm = 3.2372 nat_grad_norm = 0.1339 cg_residual = 1.0609 step_size = 0.3644 reward = -0.0000 fps = 12 mse_loss = 0.4168 
2022-05-01 11:19:22.578861 - gail/main.py:164 - [TRPO] iter = 1417000 dist_mean = 0.0340 dist_std = 0.1658 vf_loss = 0.0306 grad_norm = 3.4184 nat_grad_norm = 0.1145 cg_residual = 0.9494 step_size = 0.4274 reward = 0.0000 fps = 11 mse_loss = 0.4704 
2022-05-01 11:19:32.430104 - gail/main.py:164 - [TRPO] iter = 1418000 dist_mean = 0.0251 dist_std = 0.1657 vf_loss = 0.0614 grad_norm = 3.6375 nat_grad_norm = 0.0919 cg_residual = 1.2846 step_size = 0.4509 reward = -0.0000 fps = 10 mse_loss = 0.4129 
2022-05-01 11:19:42.020702 - gail/main.py:164 - [TRPO] iter = 1419000 dist_mean = 0.0076 dist_std = 0.1650 vf_loss = 0.0721 grad_norm = 4.1529 nat_grad_norm = 0.1246 cg_residual = 1.4203 step_size = 0.3771 reward = -0.0000 fps = 9 mse_loss = 0.3626 
2022-05-01 11:19:51.737496 - gail/main.py:164 - [TRPO] iter = 1420000 dist_mean = 0.0239 dist_std = 0.1654 vf_loss = 0.0483 grad_norm = 2.4889 nat_grad_norm = 0.1034 cg_residual = 0.5711 step_size = 0.4777 reward = 0.0000 fps = 8 mse_loss = 0.3967 
2022-05-01 11:19:51.972889 - gail/main.py:191 - [Discriminator] iter = 1420000 loss = -0.7496 grad_norm = 3.8961 grad_penalty = 0.0892 regularization = 0.0000 true_logits = 0.2306 fake_logits = -0.6082 true_prob = 0.5469 fake_prob = 0.3901 
2022-05-01 11:21:29.531646 - gail/main.py:132 - [Evaluate] iter = 1420000 episode={ returns = 2613.2557 lengths = 735 } discounted_episode={ returns = 1744.8368 lengths = 725 } 
2022-05-01 11:21:39.434223 - gail/main.py:164 - [TRPO] iter = 1421000 dist_mean = 0.0390 dist_std = 0.1657 vf_loss = 0.0545 grad_norm = 2.5280 nat_grad_norm = 0.1233 cg_residual = 1.4373 step_size = 0.3979 reward = 0.0000 fps = 9 mse_loss = 0.3879 
2022-05-01 11:21:49.278821 - gail/main.py:164 - [TRPO] iter = 1422000 dist_mean = 0.0159 dist_std = 0.1658 vf_loss = 0.0893 grad_norm = 2.4295 nat_grad_norm = 0.1122 cg_residual = 0.7036 step_size = 0.4433 reward = 0.0000 fps = 8 mse_loss = 0.4467 
2022-05-01 11:21:58.597393 - gail/main.py:164 - [TRPO] iter = 1423000 dist_mean = 0.0092 dist_std = 0.1662 vf_loss = 0.0508 grad_norm = 3.2029 nat_grad_norm = 0.1156 cg_residual = 1.0846 step_size = 0.3685 reward = 0.0000 fps = 7 mse_loss = 0.3801 
2022-05-01 11:22:09.223887 - gail/main.py:164 - [TRPO] iter = 1424000 dist_mean = 0.0213 dist_std = 0.1658 vf_loss = 0.0406 grad_norm = 3.5980 nat_grad_norm = 0.1009 cg_residual = 3.3347 step_size = 0.4409 reward = -0.0000 fps = 7 mse_loss = 0.3990 
2022-05-01 11:22:18.730090 - gail/main.py:164 - [TRPO] iter = 1425000 dist_mean = 0.0394 dist_std = 0.1653 vf_loss = 0.0363 grad_norm = 3.0917 nat_grad_norm = 0.1470 cg_residual = 1.0283 step_size = 0.3752 reward = -0.0000 fps = 6 mse_loss = 0.4209 
2022-05-01 11:22:18.947202 - gail/main.py:191 - [Discriminator] iter = 1425000 loss = -0.7044 grad_norm = 3.8489 grad_penalty = 0.0797 regularization = 0.0000 true_logits = 0.2791 fake_logits = -0.5050 true_prob = 0.5559 fake_prob = 0.4170 
2022-05-01 11:24:08.934212 - gail/main.py:132 - [Evaluate] iter = 1425000 episode={ returns = 2933.1432 lengths = 822 } discounted_episode={ returns = 2004.3935 lengths = 862 } 
2022-05-01 11:24:18.869466 - gail/main.py:164 - [TRPO] iter = 1426000 dist_mean = 0.0430 dist_std = 0.1650 vf_loss = 0.0273 grad_norm = 2.6735 nat_grad_norm = 0.1229 cg_residual = 1.1787 step_size = 0.4378 reward = 0.0000 fps = 8 mse_loss = 0.3834 
2022-05-01 11:24:28.467523 - gail/main.py:164 - [TRPO] iter = 1427000 dist_mean = 0.0048 dist_std = 0.1648 vf_loss = 0.0477 grad_norm = 4.3296 nat_grad_norm = 0.1134 cg_residual = 1.5032 step_size = 0.4012 reward = -0.0000 fps = 7 mse_loss = 0.3483 
2022-05-01 11:24:38.299142 - gail/main.py:164 - [TRPO] iter = 1428000 dist_mean = 0.0103 dist_std = 0.1646 vf_loss = 0.0380 grad_norm = 3.2415 nat_grad_norm = 0.0961 cg_residual = 0.5949 step_size = 0.4831 reward = -0.0000 fps = 7 mse_loss = 0.3914 
2022-05-01 11:24:47.978321 - gail/main.py:164 - [TRPO] iter = 1429000 dist_mean = 0.0066 dist_std = 0.1647 vf_loss = 0.0521 grad_norm = 2.3344 nat_grad_norm = 0.1044 cg_residual = 1.1053 step_size = 0.4357 reward = -0.0000 fps = 6 mse_loss = 0.4076 
2022-05-01 11:24:57.646257 - gail/main.py:164 - [TRPO] iter = 1430000 dist_mean = 0.0291 dist_std = 0.1648 vf_loss = 0.0335 grad_norm = 3.4630 nat_grad_norm = 0.0975 cg_residual = 0.9642 step_size = 0.4759 reward = -0.0000 fps = 6 mse_loss = 0.4290 
2022-05-01 11:24:57.865840 - gail/main.py:191 - [Discriminator] iter = 1430000 loss = -0.4491 grad_norm = 3.8590 grad_penalty = 0.0690 regularization = 0.0000 true_logits = 0.1878 fake_logits = -0.3303 true_prob = 0.5386 fake_prob = 0.4389 
2022-05-01 11:27:11.722459 - gail/main.py:132 - [Evaluate] iter = 1430000 episode={ returns = 3458.7252 lengths = 1000 } discounted_episode={ returns = 2134.4300 lengths = 1000 } 
2022-05-01 11:27:21.313856 - gail/main.py:164 - [TRPO] iter = 1431000 dist_mean = 0.0548 dist_std = 0.1649 vf_loss = 0.0973 grad_norm = 3.2908 nat_grad_norm = 0.0977 cg_residual = 2.4577 step_size = 0.5201 reward = 0.0000 fps = 6 mse_loss = 0.3776 
2022-05-01 11:27:30.946404 - gail/main.py:164 - [TRPO] iter = 1432000 dist_mean = 0.0470 dist_std = 0.1650 vf_loss = 0.0324 grad_norm = 2.3599 nat_grad_norm = 0.1071 cg_residual = 0.5968 step_size = 0.5521 reward = -0.0000 fps = 6 mse_loss = 0.4368 
2022-05-01 11:27:40.503622 - gail/main.py:164 - [TRPO] iter = 1433000 dist_mean = 0.0142 dist_std = 0.1639 vf_loss = 0.0527 grad_norm = 1.9995 nat_grad_norm = 0.1288 cg_residual = 0.9871 step_size = 0.4459 reward = 0.0000 fps = 6 mse_loss = 0.4052 
2022-05-01 11:27:49.925131 - gail/main.py:164 - [TRPO] iter = 1434000 dist_mean = 0.0268 dist_std = 0.1634 vf_loss = 0.0273 grad_norm = 2.5058 nat_grad_norm = 0.1076 cg_residual = 0.9798 step_size = 0.4703 reward = 0.0000 fps = 5 mse_loss = 0.3921 
2022-05-01 11:27:59.454875 - gail/main.py:164 - [TRPO] iter = 1435000 dist_mean = 0.0046 dist_std = 0.1635 vf_loss = 0.0712 grad_norm = 4.4054 nat_grad_norm = 0.0896 cg_residual = 0.9144 step_size = 0.4411 reward = 0.0000 fps = 5 mse_loss = 0.3685 
2022-05-01 11:27:59.744840 - gail/main.py:191 - [Discriminator] iter = 1435000 loss = -0.4217 grad_norm = 3.0687 grad_penalty = 0.0714 regularization = 0.0000 true_logits = 0.1954 fake_logits = -0.2977 true_prob = 0.5432 fake_prob = 0.4457 
2022-05-01 11:30:08.482674 - gail/main.py:132 - [Evaluate] iter = 1435000 episode={ returns = 3474.5299 lengths = 990 } discounted_episode={ returns = 2127.9575 lengths = 988 } 
2022-05-01 11:30:18.770602 - gail/main.py:164 - [TRPO] iter = 1436000 dist_mean = 0.0820 dist_std = 0.1639 vf_loss = 0.2248 grad_norm = 3.1249 nat_grad_norm = 0.0837 cg_residual = 4.6707 step_size = 0.4709 reward = 0.0000 fps = 7 mse_loss = 0.3960 
2022-05-01 11:30:28.446231 - gail/main.py:164 - [TRPO] iter = 1437000 dist_mean = 0.0333 dist_std = 0.1640 vf_loss = 0.0482 grad_norm = 2.3074 nat_grad_norm = 0.1268 cg_residual = 1.0994 step_size = 0.4294 reward = 0.0000 fps = 6 mse_loss = 0.3527 
2022-05-01 11:30:38.527577 - gail/main.py:164 - [TRPO] iter = 1438000 dist_mean = 0.0506 dist_std = 0.1641 vf_loss = 0.0325 grad_norm = 2.2672 nat_grad_norm = 0.1262 cg_residual = 1.0374 step_size = 0.4218 reward = -0.0000 fps = 6 mse_loss = 0.3438 
2022-05-01 11:30:48.726199 - gail/main.py:164 - [TRPO] iter = 1439000 dist_mean = 0.0363 dist_std = 0.1634 vf_loss = 0.0385 grad_norm = 3.0005 nat_grad_norm = 0.1299 cg_residual = 0.8771 step_size = 0.3887 reward = 0.0000 fps = 5 mse_loss = 0.3354 
2022-05-01 11:30:58.518119 - gail/main.py:164 - [TRPO] iter = 1440000 dist_mean = 0.0406 dist_std = 0.1632 vf_loss = 0.0650 grad_norm = 2.9955 nat_grad_norm = 0.1159 cg_residual = 1.6627 step_size = 0.3905 reward = -0.0000 fps = 5 mse_loss = 0.4130 
2022-05-01 11:30:58.748236 - gail/main.py:191 - [Discriminator] iter = 1440000 loss = -0.6011 grad_norm = 3.4053 grad_penalty = 0.0671 regularization = 0.0000 true_logits = 0.1202 fake_logits = -0.5480 true_prob = 0.5276 fake_prob = 0.3978 
2022-05-01 11:33:08.843194 - gail/main.py:132 - [Evaluate] iter = 1440000 episode={ returns = 3462.3924 lengths = 1000 } discounted_episode={ returns = 2133.5072 lengths = 1000 } 
2022-05-01 11:33:18.546192 - gail/main.py:164 - [TRPO] iter = 1441000 dist_mean = 0.0355 dist_std = 0.1635 vf_loss = 0.0221 grad_norm = 2.4133 nat_grad_norm = 0.1461 cg_residual = 1.0384 step_size = 0.4069 reward = 0.0000 fps = 7 mse_loss = 0.3338 
2022-05-01 11:33:28.071417 - gail/main.py:164 - [TRPO] iter = 1442000 dist_mean = 0.0405 dist_std = 0.1634 vf_loss = 0.0227 grad_norm = 3.6023 nat_grad_norm = 0.1368 cg_residual = 6.0968 step_size = 0.3349 reward = 0.0000 fps = 6 mse_loss = 0.3835 
2022-05-01 11:33:37.816333 - gail/main.py:164 - [TRPO] iter = 1443000 dist_mean = 0.0458 dist_std = 0.1628 vf_loss = 0.0512 grad_norm = 2.2036 nat_grad_norm = 0.1160 cg_residual = 0.6336 step_size = 0.4438 reward = -0.0000 fps = 6 mse_loss = 0.3820 
2022-05-01 11:33:47.497476 - gail/main.py:164 - [TRPO] iter = 1444000 dist_mean = 0.0144 dist_std = 0.1627 vf_loss = 0.0407 grad_norm = 3.6241 nat_grad_norm = 0.1077 cg_residual = 0.9030 step_size = 0.3981 reward = -0.0000 fps = 5 mse_loss = 0.3514 
2022-05-01 11:33:57.050571 - gail/main.py:164 - [TRPO] iter = 1445000 dist_mean = 0.0591 dist_std = 0.1628 vf_loss = 0.1222 grad_norm = 2.8329 nat_grad_norm = 0.0580 cg_residual = 1.6075 step_size = 0.6925 reward = 0.0000 fps = 5 mse_loss = 0.3353 
2022-05-01 11:33:57.251986 - gail/main.py:191 - [Discriminator] iter = 1445000 loss = -0.3218 grad_norm = 3.5565 grad_penalty = 0.0657 regularization = 0.0000 true_logits = 0.1058 fake_logits = -0.2817 true_prob = 0.5252 fake_prob = 0.4442 
2022-05-01 11:36:09.490324 - gail/main.py:132 - [Evaluate] iter = 1445000 episode={ returns = 3445.2797 lengths = 1000 } discounted_episode={ returns = 2124.7104 lengths = 1000 } 
2022-05-01 11:36:19.728316 - gail/main.py:164 - [TRPO] iter = 1446000 dist_mean = 0.0702 dist_std = 0.1633 vf_loss = 0.1546 grad_norm = 2.5394 nat_grad_norm = 0.0706 cg_residual = 1.4851 step_size = 0.6367 reward = -0.0000 fps = 7 mse_loss = 0.3318 
2022-05-01 11:36:29.601890 - gail/main.py:164 - [TRPO] iter = 1447000 dist_mean = 0.0559 dist_std = 0.1637 vf_loss = 0.0223 grad_norm = 3.3305 nat_grad_norm = 0.0952 cg_residual = 1.1357 step_size = 0.5271 reward = 0.0000 fps = 6 mse_loss = 0.3670 
2022-05-01 11:36:39.451975 - gail/main.py:164 - [TRPO] iter = 1448000 dist_mean = 0.0921 dist_std = 0.1634 vf_loss = 0.0480 grad_norm = 2.1937 nat_grad_norm = 0.0856 cg_residual = 0.8940 step_size = 0.5029 reward = 0.0000 fps = 6 mse_loss = 0.3907 
2022-05-01 11:36:49.353816 - gail/main.py:164 - [TRPO] iter = 1449000 dist_mean = 0.0335 dist_std = 0.1634 vf_loss = 0.0453 grad_norm = 3.6957 nat_grad_norm = 0.0943 cg_residual = 2.5525 step_size = 0.4466 reward = 0.0000 fps = 5 mse_loss = 0.3722 
2022-05-01 11:36:59.266465 - gail/main.py:164 - [TRPO] iter = 1450000 dist_mean = 0.0235 dist_std = 0.1634 vf_loss = 0.0376 grad_norm = 2.5996 nat_grad_norm = 0.1214 cg_residual = 1.6950 step_size = 0.4105 reward = -0.0000 fps = 5 mse_loss = 0.3750 
2022-05-01 11:36:59.481796 - gail/main.py:191 - [Discriminator] iter = 1450000 loss = -0.5885 grad_norm = 2.6121 grad_penalty = 0.0587 regularization = 0.0000 true_logits = 0.0814 fake_logits = -0.5658 true_prob = 0.5187 fake_prob = 0.3916 
2022-05-01 11:39:09.412321 - gail/main.py:132 - [Evaluate] iter = 1450000 episode={ returns = 3392.2830 lengths = 979 } discounted_episode={ returns = 2062.8279 lengths = 946 } 
2022-05-01 11:39:19.624760 - gail/main.py:164 - [TRPO] iter = 1451000 dist_mean = 0.0543 dist_std = 0.1631 vf_loss = 0.0316 grad_norm = 3.4239 nat_grad_norm = 0.1217 cg_residual = 4.7889 step_size = 0.3676 reward = 0.0000 fps = 7 mse_loss = 0.3491 
2022-05-01 11:39:29.382136 - gail/main.py:164 - [TRPO] iter = 1452000 dist_mean = 0.0387 dist_std = 0.1634 vf_loss = 0.1679 grad_norm = 2.7123 nat_grad_norm = 0.0919 cg_residual = 0.7909 step_size = 0.4958 reward = -0.0000 fps = 6 mse_loss = 0.3658 
2022-05-01 11:39:39.309173 - gail/main.py:164 - [TRPO] iter = 1453000 dist_mean = 0.0129 dist_std = 0.1633 vf_loss = 0.0260 grad_norm = 4.9506 nat_grad_norm = 0.1139 cg_residual = 1.0590 step_size = 0.3906 reward = 0.0000 fps = 6 mse_loss = 0.3728 
2022-05-01 11:39:48.993674 - gail/main.py:164 - [TRPO] iter = 1454000 dist_mean = 0.0792 dist_std = 0.1637 vf_loss = 0.0407 grad_norm = 1.9802 nat_grad_norm = 0.0675 cg_residual = 0.5717 step_size = 0.6252 reward = -0.0000 fps = 5 mse_loss = 0.3713 
2022-05-01 11:39:58.896867 - gail/main.py:164 - [TRPO] iter = 1455000 dist_mean = 0.0652 dist_std = 0.1636 vf_loss = 0.0231 grad_norm = 3.1194 nat_grad_norm = 0.1069 cg_residual = 1.0243 step_size = 0.4628 reward = -0.0000 fps = 5 mse_loss = 0.3675 
2022-05-01 11:39:59.097666 - gail/main.py:191 - [Discriminator] iter = 1455000 loss = -0.3600 grad_norm = 3.3177 grad_penalty = 0.0585 regularization = 0.0000 true_logits = 0.0978 fake_logits = -0.3208 true_prob = 0.5239 fake_prob = 0.4325 
2022-05-01 11:42:13.866871 - gail/main.py:132 - [Evaluate] iter = 1455000 episode={ returns = 3481.5092 lengths = 1000 } discounted_episode={ returns = 2149.2045 lengths = 1000 } 
2022-05-01 11:42:23.729170 - gail/main.py:164 - [TRPO] iter = 1456000 dist_mean = 0.0719 dist_std = 0.1633 vf_loss = 0.0396 grad_norm = 1.7526 nat_grad_norm = 0.0880 cg_residual = 0.7922 step_size = 0.5501 reward = -0.0000 fps = 6 mse_loss = 0.3585 
2022-05-01 11:42:33.648787 - gail/main.py:164 - [TRPO] iter = 1457000 dist_mean = 0.0418 dist_std = 0.1630 vf_loss = 0.0315 grad_norm = 3.1411 nat_grad_norm = 0.1053 cg_residual = 0.7551 step_size = 0.4011 reward = 0.0000 fps = 6 mse_loss = 0.3550 
2022-05-01 11:42:43.520683 - gail/main.py:164 - [TRPO] iter = 1458000 dist_mean = 0.0788 dist_std = 0.1629 vf_loss = 0.0380 grad_norm = 1.7062 nat_grad_norm = 0.0795 cg_residual = 0.6111 step_size = 0.5876 reward = 0.0000 fps = 6 mse_loss = 0.3487 
2022-05-01 11:42:53.291016 - gail/main.py:164 - [TRPO] iter = 1459000 dist_mean = 0.0562 dist_std = 0.1635 vf_loss = 0.0485 grad_norm = 3.5588 nat_grad_norm = 0.1027 cg_residual = 6.4571 step_size = 0.4605 reward = -0.0000 fps = 5 mse_loss = 0.3550 
2022-05-01 11:43:02.943576 - gail/main.py:164 - [TRPO] iter = 1460000 dist_mean = 0.0602 dist_std = 0.1628 vf_loss = 0.0353 grad_norm = 1.9012 nat_grad_norm = 0.0764 cg_residual = 0.5344 step_size = 0.5792 reward = -0.0000 fps = 5 mse_loss = 0.3416 
2022-05-01 11:43:03.176549 - gail/main.py:191 - [Discriminator] iter = 1460000 loss = -0.2981 grad_norm = 3.2280 grad_penalty = 0.0552 regularization = 0.0000 true_logits = 0.0231 fake_logits = -0.3303 true_prob = 0.5060 fake_prob = 0.4315 
2022-05-01 11:45:14.730848 - gail/main.py:132 - [Evaluate] iter = 1460000 episode={ returns = 3492.3287 lengths = 1000 } discounted_episode={ returns = 2154.9721 lengths = 1000 } 
2022-05-01 11:45:24.175979 - gail/main.py:164 - [TRPO] iter = 1461000 dist_mean = 0.0298 dist_std = 0.1625 vf_loss = 0.0333 grad_norm = 3.8911 nat_grad_norm = 0.1106 cg_residual = 1.2187 step_size = 0.4111 reward = -0.0000 fps = 7 mse_loss = 0.3595 
2022-05-01 11:45:34.199906 - gail/main.py:164 - [TRPO] iter = 1462000 dist_mean = 0.0156 dist_std = 0.1627 vf_loss = 0.0286 grad_norm = 3.2533 nat_grad_norm = 0.1657 cg_residual = 1.8715 step_size = 0.3645 reward = 0.0000 fps = 6 mse_loss = 0.3614 
2022-05-01 11:45:44.290452 - gail/main.py:164 - [TRPO] iter = 1463000 dist_mean = 0.0718 dist_std = 0.1630 vf_loss = 0.0848 grad_norm = 2.1825 nat_grad_norm = 0.0821 cg_residual = 0.7935 step_size = 0.5534 reward = -0.0000 fps = 6 mse_loss = 0.3893 
2022-05-01 11:45:54.071360 - gail/main.py:164 - [TRPO] iter = 1464000 dist_mean = 0.0426 dist_std = 0.1633 vf_loss = 0.0181 grad_norm = 3.0455 nat_grad_norm = 0.1005 cg_residual = 0.8435 step_size = 0.4057 reward = -0.0000 fps = 5 mse_loss = 0.3937 
2022-05-01 11:46:03.981461 - gail/main.py:164 - [TRPO] iter = 1465000 dist_mean = 0.0484 dist_std = 0.1632 vf_loss = 0.0491 grad_norm = 4.8445 nat_grad_norm = 0.0966 cg_residual = 0.5748 step_size = 0.4425 reward = -0.0000 fps = 5 mse_loss = 0.3647 
2022-05-01 11:46:04.139113 - gail/main.py:191 - [Discriminator] iter = 1465000 loss = -0.3652 grad_norm = 3.1584 grad_penalty = 0.0549 regularization = 0.0000 true_logits = 0.0722 fake_logits = -0.3480 true_prob = 0.5170 fake_prob = 0.4266 
2022-05-01 11:48:15.443343 - gail/main.py:132 - [Evaluate] iter = 1465000 episode={ returns = 3518.6641 lengths = 1000 } discounted_episode={ returns = 2171.3350 lengths = 1000 } 
2022-05-01 11:48:25.262051 - gail/main.py:164 - [TRPO] iter = 1466000 dist_mean = 0.0492 dist_std = 0.1636 vf_loss = 0.0733 grad_norm = 2.8258 nat_grad_norm = 0.0652 cg_residual = 0.6721 step_size = 0.5571 reward = 0.0000 fps = 7 mse_loss = 0.3646 
2022-05-01 11:48:35.125989 - gail/main.py:164 - [TRPO] iter = 1467000 dist_mean = 0.0574 dist_std = 0.1635 vf_loss = 0.0900 grad_norm = 5.1683 nat_grad_norm = 0.0997 cg_residual = 0.7170 step_size = 0.3803 reward = 0.0000 fps = 6 mse_loss = 0.4236 
2022-05-01 11:48:45.027658 - gail/main.py:164 - [TRPO] iter = 1468000 dist_mean = 0.0381 dist_std = 0.1632 vf_loss = 0.0159 grad_norm = 2.0384 nat_grad_norm = 0.0858 cg_residual = 0.6801 step_size = 0.5400 reward = 0.0000 fps = 6 mse_loss = 0.3988 
2022-05-01 11:48:54.970113 - gail/main.py:164 - [TRPO] iter = 1469000 dist_mean = 0.0207 dist_std = 0.1631 vf_loss = 0.0282 grad_norm = 3.6980 nat_grad_norm = 0.1094 cg_residual = 1.3300 step_size = 0.4518 reward = 0.0000 fps = 5 mse_loss = 0.3498 
2022-05-01 11:49:04.973946 - gail/main.py:164 - [TRPO] iter = 1470000 dist_mean = 0.0394 dist_std = 0.1632 vf_loss = 0.0110 grad_norm = 3.2956 nat_grad_norm = 0.1312 cg_residual = 2.4729 step_size = 0.3428 reward = -0.0000 fps = 5 mse_loss = 0.4256 
2022-05-01 11:49:05.198224 - gail/main.py:191 - [Discriminator] iter = 1470000 loss = -0.3940 grad_norm = 3.2077 grad_penalty = 0.0525 regularization = 0.0000 true_logits = 0.0035 fake_logits = -0.4430 true_prob = 0.5009 fake_prob = 0.4069 
2022-05-01 11:51:19.172689 - gail/main.py:132 - [Evaluate] iter = 1470000 episode={ returns = 3508.9023 lengths = 1000 } discounted_episode={ returns = 2160.4670 lengths = 1000 } 
2022-05-01 11:51:29.354770 - gail/main.py:164 - [TRPO] iter = 1471000 dist_mean = 0.0481 dist_std = 0.1632 vf_loss = 0.0247 grad_norm = 2.9423 nat_grad_norm = 0.1260 cg_residual = 1.5109 step_size = 0.3662 reward = -0.0000 fps = 6 mse_loss = 0.4496 
2022-05-01 11:51:39.322764 - gail/main.py:164 - [TRPO] iter = 1472000 dist_mean = 0.0684 dist_std = 0.1627 vf_loss = 0.0485 grad_norm = 1.8286 nat_grad_norm = 0.0835 cg_residual = 1.0984 step_size = 0.5410 reward = 0.0000 fps = 6 mse_loss = 0.4009 
2022-05-01 11:51:49.088042 - gail/main.py:164 - [TRPO] iter = 1473000 dist_mean = 0.0440 dist_std = 0.1628 vf_loss = 0.0186 grad_norm = 3.2859 nat_grad_norm = 0.1310 cg_residual = 1.7881 step_size = 0.3444 reward = 0.0000 fps = 6 mse_loss = 0.3846 
2022-05-01 11:51:58.398009 - gail/main.py:164 - [TRPO] iter = 1474000 dist_mean = 0.0406 dist_std = 0.1624 vf_loss = 0.0222 grad_norm = 3.1473 nat_grad_norm = 0.1091 cg_residual = 4.3495 step_size = 0.4589 reward = -0.0000 fps = 5 mse_loss = 0.3804 
2022-05-01 11:52:08.205615 - gail/main.py:164 - [TRPO] iter = 1475000 dist_mean = 0.0163 dist_std = 0.1625 vf_loss = 0.0405 grad_norm = 2.6484 nat_grad_norm = 0.1113 cg_residual = 0.8661 step_size = 0.5133 reward = 0.0000 fps = 5 mse_loss = 0.3958 
2022-05-01 11:52:08.444751 - gail/main.py:191 - [Discriminator] iter = 1475000 loss = -0.3399 grad_norm = 3.3074 grad_penalty = 0.0506 regularization = 0.0000 true_logits = -0.1320 fake_logits = -0.5224 true_prob = 0.4722 fake_prob = 0.3880 
2022-05-01 11:54:22.052792 - gail/main.py:132 - [Evaluate] iter = 1475000 episode={ returns = 3498.1538 lengths = 1000 } discounted_episode={ returns = 2152.8034 lengths = 1000 } 
2022-05-01 11:54:31.674341 - gail/main.py:164 - [TRPO] iter = 1476000 dist_mean = 0.0738 dist_std = 0.1620 vf_loss = 0.1094 grad_norm = 3.0680 nat_grad_norm = 0.0807 cg_residual = 1.1310 step_size = 0.4848 reward = -0.0000 fps = 6 mse_loss = 0.3721 
2022-05-01 11:54:41.816111 - gail/main.py:164 - [TRPO] iter = 1477000 dist_mean = 0.0486 dist_std = 0.1620 vf_loss = 0.0118 grad_norm = 3.0373 nat_grad_norm = 0.1206 cg_residual = 1.6101 step_size = 0.3877 reward = -0.0000 fps = 6 mse_loss = 0.3852 
2022-05-01 11:54:51.726403 - gail/main.py:164 - [TRPO] iter = 1478000 dist_mean = 0.0397 dist_std = 0.1619 vf_loss = 0.0276 grad_norm = 3.0013 nat_grad_norm = 0.1063 cg_residual = 1.7305 step_size = 0.4339 reward = 0.0000 fps = 6 mse_loss = 0.3618 
2022-05-01 11:55:01.114822 - gail/main.py:164 - [TRPO] iter = 1479000 dist_mean = 0.0484 dist_std = 0.1611 vf_loss = 0.0123 grad_norm = 3.2174 nat_grad_norm = 0.1064 cg_residual = 1.2146 step_size = 0.4125 reward = 0.0000 fps = 5 mse_loss = 0.3825 
2022-05-01 11:55:10.949559 - gail/main.py:164 - [TRPO] iter = 1480000 dist_mean = 0.0736 dist_std = 0.1606 vf_loss = 0.0749 grad_norm = 4.7534 nat_grad_norm = 0.0946 cg_residual = 1.5838 step_size = 0.4287 reward = 0.0000 fps = 5 mse_loss = 0.3113 
2022-05-01 11:55:11.165267 - gail/main.py:191 - [Discriminator] iter = 1480000 loss = -0.4043 grad_norm = 3.9969 grad_penalty = 0.0627 regularization = 0.0000 true_logits = -0.1775 fake_logits = -0.6445 true_prob = 0.4621 fake_prob = 0.3643 
2022-05-01 11:57:22.790282 - gail/main.py:132 - [Evaluate] iter = 1480000 episode={ returns = 3472.9008 lengths = 1000 } discounted_episode={ returns = 2141.1922 lengths = 1000 } 
2022-05-01 11:57:32.537477 - gail/main.py:164 - [TRPO] iter = 1481000 dist_mean = 0.0657 dist_std = 0.1603 vf_loss = 0.0452 grad_norm = 2.2177 nat_grad_norm = 0.0744 cg_residual = 0.9557 step_size = 0.5881 reward = 0.0000 fps = 7 mse_loss = 0.4010 
2022-05-01 11:57:42.151747 - gail/main.py:164 - [TRPO] iter = 1482000 dist_mean = 0.0789 dist_std = 0.1602 vf_loss = 0.0272 grad_norm = 2.3235 nat_grad_norm = 0.1030 cg_residual = 1.2129 step_size = 0.5026 reward = -0.0000 fps = 6 mse_loss = 0.3763 
2022-05-01 11:57:51.911355 - gail/main.py:164 - [TRPO] iter = 1483000 dist_mean = 0.0860 dist_std = 0.1603 vf_loss = 0.0295 grad_norm = 1.7654 nat_grad_norm = 0.0820 cg_residual = 1.1226 step_size = 0.5285 reward = 0.0000 fps = 6 mse_loss = 0.3836 
2022-05-01 11:58:01.702239 - gail/main.py:164 - [TRPO] iter = 1484000 dist_mean = 0.0499 dist_std = 0.1605 vf_loss = 0.0262 grad_norm = 3.6423 nat_grad_norm = 0.0865 cg_residual = 1.1473 step_size = 0.4658 reward = -0.0000 fps = 5 mse_loss = 0.3899 
2022-05-01 11:58:11.869725 - gail/main.py:164 - [TRPO] iter = 1485000 dist_mean = 0.0522 dist_std = 0.1607 vf_loss = 0.0923 grad_norm = 2.1751 nat_grad_norm = 0.0819 cg_residual = 1.8442 step_size = 0.5920 reward = -0.0000 fps = 5 mse_loss = 0.3841 
2022-05-01 11:58:12.149734 - gail/main.py:191 - [Discriminator] iter = 1485000 loss = -0.3762 grad_norm = 3.1364 grad_penalty = 0.0545 regularization = 0.0000 true_logits = -0.2923 fake_logits = -0.7230 true_prob = 0.4382 fake_prob = 0.3502 
2022-05-01 12:00:23.221108 - gail/main.py:132 - [Evaluate] iter = 1485000 episode={ returns = 3455.3577 lengths = 1000 } discounted_episode={ returns = 2133.0297 lengths = 1000 } 
2022-05-01 12:00:32.606255 - gail/main.py:164 - [TRPO] iter = 1486000 dist_mean = 0.0609 dist_std = 0.1607 vf_loss = 0.0247 grad_norm = 2.8894 nat_grad_norm = 0.1110 cg_residual = 4.6397 step_size = 0.4047 reward = -0.0000 fps = 7 mse_loss = 0.3415 
2022-05-01 12:00:42.535979 - gail/main.py:164 - [TRPO] iter = 1487000 dist_mean = 0.0691 dist_std = 0.1603 vf_loss = 0.0205 grad_norm = 3.2220 nat_grad_norm = 0.0847 cg_residual = 1.1562 step_size = 0.4931 reward = 0.0000 fps = 6 mse_loss = 0.3804 
2022-05-01 12:00:52.578395 - gail/main.py:164 - [TRPO] iter = 1488000 dist_mean = 0.0805 dist_std = 0.1602 vf_loss = 0.0228 grad_norm = 3.9208 nat_grad_norm = 0.0949 cg_residual = 0.8272 step_size = 0.4105 reward = 0.0000 fps = 6 mse_loss = 0.4093 
2022-05-01 12:01:02.506063 - gail/main.py:164 - [TRPO] iter = 1489000 dist_mean = 0.0481 dist_std = 0.1605 vf_loss = 0.0397 grad_norm = 1.9348 nat_grad_norm = 0.0747 cg_residual = 1.8743 step_size = 0.5765 reward = -0.0000 fps = 5 mse_loss = 0.3865 
2022-05-01 12:01:12.236694 - gail/main.py:164 - [TRPO] iter = 1490000 dist_mean = 0.0353 dist_std = 0.1605 vf_loss = 0.0409 grad_norm = 1.7990 nat_grad_norm = 0.1411 cg_residual = 3.0824 step_size = 0.4071 reward = -0.0000 fps = 5 mse_loss = 0.3668 
2022-05-01 12:01:12.468837 - gail/main.py:191 - [Discriminator] iter = 1490000 loss = -0.6749 grad_norm = 3.4402 grad_penalty = 0.0666 regularization = 0.0000 true_logits = -0.2210 fake_logits = -0.9624 true_prob = 0.4520 fake_prob = 0.3181 
2022-05-01 12:03:21.817712 - gail/main.py:132 - [Evaluate] iter = 1490000 episode={ returns = 3468.1193 lengths = 1000 } discounted_episode={ returns = 2135.9306 lengths = 1000 } 
2022-05-01 12:03:31.788312 - gail/main.py:164 - [TRPO] iter = 1491000 dist_mean = 0.0285 dist_std = 0.1605 vf_loss = 0.0260 grad_norm = 2.5184 nat_grad_norm = 0.1334 cg_residual = 9.0556 step_size = 0.3892 reward = -0.0000 fps = 7 mse_loss = 0.3844 
2022-05-01 12:03:41.731018 - gail/main.py:164 - [TRPO] iter = 1492000 dist_mean = 0.0463 dist_std = 0.1607 vf_loss = 0.0192 grad_norm = 3.4026 nat_grad_norm = 0.1058 cg_residual = 0.8749 step_size = 0.4353 reward = -0.0000 fps = 6 mse_loss = 0.3797 
2022-05-01 12:03:51.249980 - gail/main.py:164 - [TRPO] iter = 1493000 dist_mean = 0.0338 dist_std = 0.1604 vf_loss = 0.0182 grad_norm = 1.4568 nat_grad_norm = 0.1029 cg_residual = 0.8639 step_size = 0.4837 reward = -0.0000 fps = 6 mse_loss = 0.3672 
2022-05-01 12:04:00.771822 - gail/main.py:164 - [TRPO] iter = 1494000 dist_mean = 0.0299 dist_std = 0.1611 vf_loss = 0.0195 grad_norm = 3.0314 nat_grad_norm = 0.1389 cg_residual = 4.9920 step_size = 0.3830 reward = 0.0000 fps = 5 mse_loss = 0.3887 
2022-05-01 12:04:10.397686 - gail/main.py:164 - [TRPO] iter = 1495000 dist_mean = 0.0349 dist_std = 0.1614 vf_loss = 0.0185 grad_norm = 4.4780 nat_grad_norm = 0.1596 cg_residual = 1.8046 step_size = 0.2770 reward = -0.0000 fps = 5 mse_loss = 0.3847 
2022-05-01 12:04:10.624181 - gail/main.py:191 - [Discriminator] iter = 1495000 loss = -0.6267 grad_norm = 3.2558 grad_penalty = 0.0693 regularization = 0.0000 true_logits = -0.1110 fake_logits = -0.8071 true_prob = 0.4743 fake_prob = 0.3464 
2022-05-01 12:06:23.180795 - gail/main.py:132 - [Evaluate] iter = 1495000 episode={ returns = 3476.5710 lengths = 1000 } discounted_episode={ returns = 2139.1911 lengths = 1000 } 
2022-05-01 12:06:32.515241 - gail/main.py:164 - [TRPO] iter = 1496000 dist_mean = 0.0126 dist_std = 0.1615 vf_loss = 0.0139 grad_norm = 4.3694 nat_grad_norm = 0.0985 cg_residual = 3.2265 step_size = 0.4219 reward = -0.0000 fps = 7 mse_loss = 0.3561 
2022-05-01 12:06:42.574214 - gail/main.py:164 - [TRPO] iter = 1497000 dist_mean = 0.0526 dist_std = 0.1617 vf_loss = 0.0575 grad_norm = 2.5614 nat_grad_norm = 0.1053 cg_residual = 0.9014 step_size = 0.4443 reward = 0.0000 fps = 6 mse_loss = 0.3365 
2022-05-01 12:06:52.092432 - gail/main.py:164 - [TRPO] iter = 1498000 dist_mean = 0.0682 dist_std = 0.1618 vf_loss = 0.0935 grad_norm = 2.1558 nat_grad_norm = 0.0807 cg_residual = 1.1517 step_size = 0.5352 reward = -0.0000 fps = 6 mse_loss = 0.3831 
2022-05-01 12:07:02.336317 - gail/main.py:164 - [TRPO] iter = 1499000 dist_mean = 0.0566 dist_std = 0.1620 vf_loss = 0.0526 grad_norm = 5.2057 nat_grad_norm = 0.1218 cg_residual = 1.9005 step_size = 0.3514 reward = -0.0000 fps = 5 mse_loss = 0.3540 
2022-05-01 12:07:12.337763 - gail/main.py:164 - [TRPO] iter = 1500000 dist_mean = 0.0070 dist_std = 0.1621 vf_loss = 0.0283 grad_norm = 3.7986 nat_grad_norm = 0.0917 cg_residual = 6.5262 step_size = 0.4429 reward = -0.0000 fps = 5 mse_loss = 0.3758 
2022-05-01 12:07:12.564863 - gail/main.py:191 - [Discriminator] iter = 1500000 loss = -0.6021 grad_norm = 3.0239 grad_penalty = 0.0717 regularization = 0.0000 true_logits = 0.0628 fake_logits = -0.6109 true_prob = 0.5105 fake_prob = 0.3833 
2022-05-01 12:09:24.938825 - gail/main.py:132 - [Evaluate] iter = 1500000 episode={ returns = 3488.2337 lengths = 1000 } discounted_episode={ returns = 2144.7563 lengths = 1000 } 
2022-05-01 12:09:34.882904 - gail/main.py:164 - [TRPO] iter = 1501000 dist_mean = 0.0293 dist_std = 0.1620 vf_loss = 0.0460 grad_norm = 3.1072 nat_grad_norm = 0.1099 cg_residual = 1.1676 step_size = 0.3898 reward = 0.0000 fps = 7 mse_loss = 0.4199 
2022-05-01 12:09:44.904590 - gail/main.py:164 - [TRPO] iter = 1502000 dist_mean = 0.0378 dist_std = 0.1621 vf_loss = 0.0214 grad_norm = 3.8752 nat_grad_norm = 0.1045 cg_residual = 1.3245 step_size = 0.4559 reward = -0.0000 fps = 6 mse_loss = 0.3651 
2022-05-01 12:09:54.803607 - gail/main.py:164 - [TRPO] iter = 1503000 dist_mean = 0.0524 dist_std = 0.1621 vf_loss = 0.0179 grad_norm = 3.0888 nat_grad_norm = 0.1256 cg_residual = 0.7692 step_size = 0.3708 reward = 0.0000 fps = 6 mse_loss = 0.4067 
2022-05-01 12:10:04.451482 - gail/main.py:164 - [TRPO] iter = 1504000 dist_mean = 0.0287 dist_std = 0.1613 vf_loss = 0.0808 grad_norm = 2.5367 nat_grad_norm = 0.1230 cg_residual = 1.0752 step_size = 0.4433 reward = 0.0000 fps = 5 mse_loss = 0.3389 
2022-05-01 12:10:14.232820 - gail/main.py:164 - [TRPO] iter = 1505000 dist_mean = 0.0391 dist_std = 0.1616 vf_loss = 0.0648 grad_norm = 4.3673 nat_grad_norm = 0.0738 cg_residual = 0.8757 step_size = 0.4641 reward = 0.0000 fps = 5 mse_loss = 0.3999 
2022-05-01 12:10:14.521991 - gail/main.py:191 - [Discriminator] iter = 1505000 loss = -0.3983 grad_norm = 2.8368 grad_penalty = 0.0620 regularization = 0.0000 true_logits = 0.1005 fake_logits = -0.3598 true_prob = 0.5160 fake_prob = 0.4235 
2022-05-01 12:12:27.663121 - gail/main.py:132 - [Evaluate] iter = 1505000 episode={ returns = 3530.5232 lengths = 1000 } discounted_episode={ returns = 2169.4573 lengths = 1000 } 
2022-05-01 12:12:37.574246 - gail/main.py:164 - [TRPO] iter = 1506000 dist_mean = 0.0523 dist_std = 0.1618 vf_loss = 0.0713 grad_norm = 4.3427 nat_grad_norm = 0.1303 cg_residual = 0.9652 step_size = 0.3775 reward = 0.0000 fps = 6 mse_loss = 0.3672 
2022-05-01 12:12:47.564856 - gail/main.py:164 - [TRPO] iter = 1507000 dist_mean = 0.0541 dist_std = 0.1612 vf_loss = 0.1510 grad_norm = 5.3841 nat_grad_norm = 0.1011 cg_residual = 1.2901 step_size = 0.4075 reward = 0.0000 fps = 6 mse_loss = 0.4013 
2022-05-01 12:12:57.474936 - gail/main.py:164 - [TRPO] iter = 1508000 dist_mean = 0.0327 dist_std = 0.1615 vf_loss = 0.1599 grad_norm = 2.5810 nat_grad_norm = 0.0852 cg_residual = 2.7726 step_size = 0.4980 reward = -0.0000 fps = 6 mse_loss = 0.3568 
2022-05-01 12:13:07.251661 - gail/main.py:164 - [TRPO] iter = 1509000 dist_mean = 0.0305 dist_std = 0.1617 vf_loss = 0.0226 grad_norm = 3.5467 nat_grad_norm = 0.1009 cg_residual = 1.6247 step_size = 0.4242 reward = -0.0000 fps = 5 mse_loss = 0.4039 
2022-05-01 12:13:17.380546 - gail/main.py:164 - [TRPO] iter = 1510000 dist_mean = 0.0419 dist_std = 0.1619 vf_loss = 0.0814 grad_norm = 3.1781 nat_grad_norm = 0.0800 cg_residual = 0.6980 step_size = 0.4716 reward = 0.0000 fps = 5 mse_loss = 0.4211 
2022-05-01 12:13:17.624556 - gail/main.py:191 - [Discriminator] iter = 1510000 loss = -0.4234 grad_norm = 3.6433 grad_penalty = 0.0581 regularization = 0.0000 true_logits = 0.0426 fake_logits = -0.4388 true_prob = 0.5036 fake_prob = 0.4059 
2022-05-01 12:15:33.164362 - gail/main.py:132 - [Evaluate] iter = 1510000 episode={ returns = 3489.7729 lengths = 1000 } discounted_episode={ returns = 2140.7568 lengths = 1000 } 
2022-05-01 12:15:42.498306 - gail/main.py:164 - [TRPO] iter = 1511000 dist_mean = 0.0305 dist_std = 0.1617 vf_loss = 0.0542 grad_norm = 3.7440 nat_grad_norm = 0.1715 cg_residual = 2.9680 step_size = 0.3350 reward = 0.0000 fps = 6 mse_loss = 0.4083 
2022-05-01 12:15:52.155821 - gail/main.py:164 - [TRPO] iter = 1512000 dist_mean = 0.0276 dist_std = 0.1619 vf_loss = 0.0233 grad_norm = 2.0664 nat_grad_norm = 0.0975 cg_residual = 2.8508 step_size = 0.4918 reward = -0.0000 fps = 6 mse_loss = 0.3981 
2022-05-01 12:16:02.148233 - gail/main.py:164 - [TRPO] iter = 1513000 dist_mean = 0.0280 dist_std = 0.1624 vf_loss = 0.0230 grad_norm = 6.7868 nat_grad_norm = 0.0999 cg_residual = 2.9240 step_size = 0.3558 reward = 0.0000 fps = 6 mse_loss = 0.3680 
2022-05-01 12:16:12.350964 - gail/main.py:164 - [TRPO] iter = 1514000 dist_mean = 0.0336 dist_std = 0.1626 vf_loss = 0.0596 grad_norm = 2.7662 nat_grad_norm = 0.0870 cg_residual = 0.7950 step_size = 0.5019 reward = 0.0000 fps = 5 mse_loss = 0.3982 
2022-05-01 12:16:22.328367 - gail/main.py:164 - [TRPO] iter = 1515000 dist_mean = 0.0326 dist_std = 0.1625 vf_loss = 0.1059 grad_norm = 3.3972 nat_grad_norm = 0.0912 cg_residual = 0.9391 step_size = 0.4156 reward = -0.0000 fps = 5 mse_loss = 0.3935 
2022-05-01 12:16:22.593218 - gail/main.py:191 - [Discriminator] iter = 1515000 loss = -0.4489 grad_norm = 4.0088 grad_penalty = 0.0603 regularization = 0.0000 true_logits = 0.0223 fake_logits = -0.4870 true_prob = 0.5006 fake_prob = 0.3969 
2022-05-01 12:18:36.011865 - gail/main.py:132 - [Evaluate] iter = 1515000 episode={ returns = 3509.6239 lengths = 1000 } discounted_episode={ returns = 2154.6134 lengths = 1000 } 
2022-05-01 12:18:45.895894 - gail/main.py:164 - [TRPO] iter = 1516000 dist_mean = 0.0290 dist_std = 0.1627 vf_loss = 0.0172 grad_norm = 2.5656 nat_grad_norm = 0.1151 cg_residual = 2.0012 step_size = 0.4066 reward = 0.0000 fps = 6 mse_loss = 0.4268 
2022-05-01 12:18:55.841244 - gail/main.py:164 - [TRPO] iter = 1517000 dist_mean = 0.0395 dist_std = 0.1628 vf_loss = 0.1116 grad_norm = 3.6857 nat_grad_norm = 0.0866 cg_residual = 1.0015 step_size = 0.4336 reward = 0.0000 fps = 6 mse_loss = 0.3707 
2022-05-01 12:19:05.774571 - gail/main.py:164 - [TRPO] iter = 1518000 dist_mean = 0.0334 dist_std = 0.1627 vf_loss = 0.0563 grad_norm = 3.0878 nat_grad_norm = 0.0856 cg_residual = 2.8132 step_size = 0.5383 reward = -0.0000 fps = 6 mse_loss = 0.4296 
2022-05-01 12:19:15.770183 - gail/main.py:164 - [TRPO] iter = 1519000 dist_mean = 0.0383 dist_std = 0.1620 vf_loss = 0.0593 grad_norm = 2.9994 nat_grad_norm = 0.0700 cg_residual = 2.7761 step_size = 0.5512 reward = 0.0000 fps = 5 mse_loss = 0.4455 
2022-05-01 12:19:25.550518 - gail/main.py:164 - [TRPO] iter = 1520000 dist_mean = 0.0253 dist_std = 0.1619 vf_loss = 0.0416 grad_norm = 2.1448 nat_grad_norm = 0.0910 cg_residual = 1.6480 step_size = 0.5350 reward = 0.0000 fps = 5 mse_loss = 0.3925 
2022-05-01 12:19:25.779249 - gail/main.py:191 - [Discriminator] iter = 1520000 loss = -0.4067 grad_norm = 4.6033 grad_penalty = 0.0578 regularization = 0.0000 true_logits = -0.1256 fake_logits = -0.5901 true_prob = 0.4705 fake_prob = 0.3796 
2022-05-01 12:21:41.264138 - gail/main.py:132 - [Evaluate] iter = 1520000 episode={ returns = 3490.7526 lengths = 1000 } discounted_episode={ returns = 2157.9044 lengths = 1000 } 
2022-05-01 12:21:51.472067 - gail/main.py:164 - [TRPO] iter = 1521000 dist_mean = 0.0352 dist_std = 0.1621 vf_loss = 0.0211 grad_norm = 3.4387 nat_grad_norm = 0.1209 cg_residual = 1.1228 step_size = 0.3645 reward = -0.0000 fps = 6 mse_loss = 0.4096 
2022-05-01 12:22:01.202307 - gail/main.py:164 - [TRPO] iter = 1522000 dist_mean = 0.0386 dist_std = 0.1622 vf_loss = 0.0134 grad_norm = 3.7130 nat_grad_norm = 0.0871 cg_residual = 1.6469 step_size = 0.4019 reward = 0.0000 fps = 6 mse_loss = 0.4172 
2022-05-01 12:22:11.274737 - gail/main.py:164 - [TRPO] iter = 1523000 dist_mean = 0.0265 dist_std = 0.1622 vf_loss = 0.0307 grad_norm = 4.1028 nat_grad_norm = 0.0631 cg_residual = 0.7441 step_size = 0.5142 reward = 0.0000 fps = 6 mse_loss = 0.4414 
2022-05-01 12:22:21.392706 - gail/main.py:164 - [TRPO] iter = 1524000 dist_mean = 0.0218 dist_std = 0.1620 vf_loss = 0.1085 grad_norm = 3.3948 nat_grad_norm = 0.0966 cg_residual = 0.4751 step_size = 0.4712 reward = 0.0000 fps = 5 mse_loss = 0.3984 
2022-05-01 12:22:31.319724 - gail/main.py:164 - [TRPO] iter = 1525000 dist_mean = 0.0255 dist_std = 0.1622 vf_loss = 0.0301 grad_norm = 4.6045 nat_grad_norm = 0.0954 cg_residual = 3.0709 step_size = 0.4207 reward = 0.0000 fps = 5 mse_loss = 0.4242 
2022-05-01 12:22:31.550416 - gail/main.py:191 - [Discriminator] iter = 1525000 loss = -0.3939 grad_norm = 3.7851 grad_penalty = 0.0562 regularization = 0.0000 true_logits = -0.1560 fake_logits = -0.6062 true_prob = 0.4669 fake_prob = 0.3775 
2022-05-01 12:24:29.821556 - gail/main.py:132 - [Evaluate] iter = 1525000 episode={ returns = 3184.8970 lengths = 895 } discounted_episode={ returns = 1891.7025 lengths = 817 } 
2022-05-01 12:24:39.989853 - gail/main.py:164 - [TRPO] iter = 1526000 dist_mean = -0.0095 dist_std = 0.1618 vf_loss = 0.0175 grad_norm = 2.9013 nat_grad_norm = 0.1208 cg_residual = 1.3655 step_size = 0.3899 reward = 0.0000 fps = 7 mse_loss = 0.4107 
2022-05-01 12:24:50.168379 - gail/main.py:164 - [TRPO] iter = 1527000 dist_mean = -0.0011 dist_std = 0.1619 vf_loss = 0.1273 grad_norm = 3.3749 nat_grad_norm = 0.0943 cg_residual = 1.8418 step_size = 0.4310 reward = -0.0000 fps = 7 mse_loss = 0.3875 
2022-05-01 12:25:00.344352 - gail/main.py:164 - [TRPO] iter = 1528000 dist_mean = 0.0247 dist_std = 0.1615 vf_loss = 0.0198 grad_norm = 3.6412 nat_grad_norm = 0.0973 cg_residual = 4.7154 step_size = 0.4520 reward = 0.0000 fps = 6 mse_loss = 0.4211 
2022-05-01 12:25:10.853787 - gail/main.py:164 - [TRPO] iter = 1529000 dist_mean = 0.0097 dist_std = 0.1616 vf_loss = 0.0355 grad_norm = 3.3004 nat_grad_norm = 0.0883 cg_residual = 2.5427 step_size = 0.5151 reward = 0.0000 fps = 6 mse_loss = 0.4920 
2022-05-01 12:25:21.040817 - gail/main.py:164 - [TRPO] iter = 1530000 dist_mean = -0.0007 dist_std = 0.1622 vf_loss = 0.0285 grad_norm = 5.6192 nat_grad_norm = 0.1068 cg_residual = 4.1373 step_size = 0.3804 reward = 0.0000 fps = 5 mse_loss = 0.4282 
2022-05-01 12:25:21.297161 - gail/main.py:191 - [Discriminator] iter = 1530000 loss = -0.3905 grad_norm = 3.5674 grad_penalty = 0.0738 regularization = 0.0000 true_logits = -0.0926 fake_logits = -0.5569 true_prob = 0.4802 fake_prob = 0.3927 
2022-05-01 12:26:52.744173 - gail/main.py:132 - [Evaluate] iter = 1530000 episode={ returns = 2537.4417 lengths = 713 } discounted_episode={ returns = 1517.3603 lengths = 591 } 
2022-05-01 12:27:02.964811 - gail/main.py:164 - [TRPO] iter = 1531000 dist_mean = 0.0175 dist_std = 0.1618 vf_loss = 0.0173 grad_norm = 3.2007 nat_grad_norm = 0.1419 cg_residual = 1.8016 step_size = 0.3519 reward = -0.0000 fps = 9 mse_loss = 0.4346 
2022-05-01 12:27:12.873468 - gail/main.py:164 - [TRPO] iter = 1532000 dist_mean = -0.0025 dist_std = 0.1614 vf_loss = 0.0218 grad_norm = 3.6108 nat_grad_norm = 0.0971 cg_residual = 3.5765 step_size = 0.4621 reward = -0.0000 fps = 8 mse_loss = 0.3789 
2022-05-01 12:27:22.733126 - gail/main.py:164 - [TRPO] iter = 1533000 dist_mean = 0.0031 dist_std = 0.1619 vf_loss = 0.0285 grad_norm = 2.5451 nat_grad_norm = 0.1088 cg_residual = 0.5639 step_size = 0.4410 reward = -0.0000 fps = 8 mse_loss = 0.4590 
2022-05-01 12:27:32.929227 - gail/main.py:164 - [TRPO] iter = 1534000 dist_mean = -0.0192 dist_std = 0.1621 vf_loss = 0.0202 grad_norm = 3.4506 nat_grad_norm = 0.1108 cg_residual = 0.6926 step_size = 0.4062 reward = 0.0000 fps = 7 mse_loss = 0.3855 
2022-05-01 12:27:43.014902 - gail/main.py:164 - [TRPO] iter = 1535000 dist_mean = -0.0143 dist_std = 0.1621 vf_loss = 0.0154 grad_norm = 3.0648 nat_grad_norm = 0.1072 cg_residual = 6.1031 step_size = 0.4190 reward = -0.0000 fps = 7 mse_loss = 0.3860 
2022-05-01 12:27:43.232850 - gail/main.py:191 - [Discriminator] iter = 1535000 loss = -0.3413 grad_norm = 3.2867 grad_penalty = 0.0632 regularization = 0.0000 true_logits = -0.0633 fake_logits = -0.4678 true_prob = 0.4861 fake_prob = 0.4088 
2022-05-01 12:29:28.300912 - gail/main.py:132 - [Evaluate] iter = 1535000 episode={ returns = 2671.3214 lengths = 757 } discounted_episode={ returns = 1887.7464 lengths = 810 } 
2022-05-01 12:29:38.239903 - gail/main.py:164 - [TRPO] iter = 1536000 dist_mean = -0.0229 dist_std = 0.1621 vf_loss = 0.0180 grad_norm = 2.5034 nat_grad_norm = 0.1218 cg_residual = 1.8200 step_size = 0.4445 reward = 0.0000 fps = 8 mse_loss = 0.3627 
2022-05-01 12:29:48.242349 - gail/main.py:164 - [TRPO] iter = 1537000 dist_mean = -0.0004 dist_std = 0.1627 vf_loss = 0.0246 grad_norm = 2.3355 nat_grad_norm = 0.0869 cg_residual = 0.6583 step_size = 0.5331 reward = -0.0000 fps = 8 mse_loss = 0.3784 
2022-05-01 12:29:58.361753 - gail/main.py:164 - [TRPO] iter = 1538000 dist_mean = -0.0127 dist_std = 0.1632 vf_loss = 0.0168 grad_norm = 2.5380 nat_grad_norm = 0.0821 cg_residual = 0.8764 step_size = 0.5788 reward = 0.0000 fps = 7 mse_loss = 0.4051 
2022-05-01 12:30:08.123392 - gail/main.py:164 - [TRPO] iter = 1539000 dist_mean = -0.0131 dist_std = 0.1632 vf_loss = 0.0127 grad_norm = 2.5379 nat_grad_norm = 0.1576 cg_residual = 1.1136 step_size = 0.3535 reward = -0.0000 fps = 6 mse_loss = 0.4199 
2022-05-01 12:30:17.976701 - gail/main.py:164 - [TRPO] iter = 1540000 dist_mean = 0.0030 dist_std = 0.1629 vf_loss = 0.0446 grad_norm = 3.9113 nat_grad_norm = 0.1290 cg_residual = 1.7881 step_size = 0.3712 reward = 0.0000 fps = 6 mse_loss = 0.4624 
2022-05-01 12:30:18.206789 - gail/main.py:191 - [Discriminator] iter = 1540000 loss = -0.5307 grad_norm = 3.1055 grad_penalty = 0.0706 regularization = 0.0000 true_logits = 0.1005 fake_logits = -0.5008 true_prob = 0.5199 fake_prob = 0.4055 
2022-05-01 12:31:53.416388 - gail/main.py:132 - [Evaluate] iter = 1540000 episode={ returns = 2751.9438 lengths = 777 } discounted_episode={ returns = 1611.0839 lengths = 644 } 
2022-05-01 12:32:03.101525 - gail/main.py:164 - [TRPO] iter = 1541000 dist_mean = -0.0181 dist_std = 0.1632 vf_loss = 0.0206 grad_norm = 3.5667 nat_grad_norm = 0.0738 cg_residual = 2.0393 step_size = 0.5499 reward = 0.0000 fps = 9 mse_loss = 0.3845 
2022-05-01 12:32:13.042791 - gail/main.py:164 - [TRPO] iter = 1542000 dist_mean = -0.0138 dist_std = 0.1632 vf_loss = 0.0147 grad_norm = 3.7119 nat_grad_norm = 0.1305 cg_residual = 4.8121 step_size = 0.3599 reward = 0.0000 fps = 8 mse_loss = 0.4205 
2022-05-01 12:32:22.817734 - gail/main.py:164 - [TRPO] iter = 1543000 dist_mean = 0.0294 dist_std = 0.1633 vf_loss = 0.0265 grad_norm = 3.4686 nat_grad_norm = 0.1614 cg_residual = 2.4299 step_size = 0.3309 reward = -0.0000 fps = 8 mse_loss = 0.4614 
2022-05-01 12:32:32.753810 - gail/main.py:164 - [TRPO] iter = 1544000 dist_mean = -0.0140 dist_std = 0.1629 vf_loss = 0.0403 grad_norm = 2.6959 nat_grad_norm = 0.0996 cg_residual = 0.9930 step_size = 0.4741 reward = 0.0000 fps = 7 mse_loss = 0.4301 
2022-05-01 12:32:42.727027 - gail/main.py:164 - [TRPO] iter = 1545000 dist_mean = -0.0267 dist_std = 0.1635 vf_loss = 0.0213 grad_norm = 2.3448 nat_grad_norm = 0.0932 cg_residual = 2.2170 step_size = 0.4690 reward = -0.0000 fps = 6 mse_loss = 0.4203 
2022-05-01 12:32:42.975604 - gail/main.py:191 - [Discriminator] iter = 1545000 loss = -0.3869 grad_norm = 3.2772 grad_penalty = 0.0672 regularization = 0.0000 true_logits = 0.2407 fake_logits = -0.2134 true_prob = 0.5454 fake_prob = 0.4608 
2022-05-01 12:34:56.309440 - gail/main.py:132 - [Evaluate] iter = 1545000 episode={ returns = 3573.4181 lengths = 999 } discounted_episode={ returns = 2211.8227 lengths = 996 } 
2022-05-01 12:35:06.488391 - gail/main.py:164 - [TRPO] iter = 1546000 dist_mean = -0.0207 dist_std = 0.1637 vf_loss = 0.0169 grad_norm = 3.2571 nat_grad_norm = 0.0808 cg_residual = 3.7536 step_size = 0.4839 reward = 0.0000 fps = 6 mse_loss = 0.4347 
2022-05-01 12:35:16.380279 - gail/main.py:164 - [TRPO] iter = 1547000 dist_mean = -0.0113 dist_std = 0.1641 vf_loss = 0.0220 grad_norm = 3.5393 nat_grad_norm = 0.0974 cg_residual = 1.0385 step_size = 0.4326 reward = -0.0000 fps = 6 mse_loss = 0.4284 
2022-05-01 12:35:26.090874 - gail/main.py:164 - [TRPO] iter = 1548000 dist_mean = -0.0090 dist_std = 0.1639 vf_loss = 0.0161 grad_norm = 3.4380 nat_grad_norm = 0.1179 cg_residual = 1.3005 step_size = 0.3683 reward = -0.0000 fps = 6 mse_loss = 0.4132 
2022-05-01 12:35:36.046456 - gail/main.py:164 - [TRPO] iter = 1549000 dist_mean = -0.0143 dist_std = 0.1641 vf_loss = 0.0140 grad_norm = 4.8686 nat_grad_norm = 0.1070 cg_residual = 7.5143 step_size = 0.4158 reward = -0.0000 fps = 5 mse_loss = 0.4351 
2022-05-01 12:35:46.064793 - gail/main.py:164 - [TRPO] iter = 1550000 dist_mean = -0.0026 dist_std = 0.1642 vf_loss = 0.1004 grad_norm = 2.8606 nat_grad_norm = 0.0654 cg_residual = 2.0754 step_size = 0.5152 reward = -0.0000 fps = 5 mse_loss = 0.5017 
2022-05-01 12:35:46.289686 - gail/main.py:191 - [Discriminator] iter = 1550000 loss = -0.4728 grad_norm = 3.5687 grad_penalty = 0.0594 regularization = 0.0000 true_logits = 0.3355 fake_logits = -0.1967 true_prob = 0.5629 fake_prob = 0.4626 
2022-05-01 12:38:00.274324 - gail/main.py:132 - [Evaluate] iter = 1550000 episode={ returns = 3587.8429 lengths = 1000 } discounted_episode={ returns = 2207.0609 lengths = 1000 } 
2022-05-01 12:38:10.132180 - gail/main.py:164 - [TRPO] iter = 1551000 dist_mean = -0.0254 dist_std = 0.1636 vf_loss = 0.0145 grad_norm = 3.1543 nat_grad_norm = 0.1126 cg_residual = 0.9904 step_size = 0.4046 reward = 0.0000 fps = 6 mse_loss = 0.4233 
2022-05-01 12:38:20.164905 - gail/main.py:164 - [TRPO] iter = 1552000 dist_mean = 0.0076 dist_std = 0.1640 vf_loss = 0.0981 grad_norm = 2.6191 nat_grad_norm = 0.0692 cg_residual = 2.2637 step_size = 0.5918 reward = -0.0000 fps = 6 mse_loss = 0.4629 
2022-05-01 12:38:30.009043 - gail/main.py:164 - [TRPO] iter = 1553000 dist_mean = 0.0290 dist_std = 0.1646 vf_loss = 0.0808 grad_norm = 3.5827 nat_grad_norm = 0.0742 cg_residual = 0.6500 step_size = 0.5058 reward = 0.0000 fps = 6 mse_loss = 0.4402 
2022-05-01 12:38:39.726671 - gail/main.py:164 - [TRPO] iter = 1554000 dist_mean = -0.0011 dist_std = 0.1648 vf_loss = 0.1214 grad_norm = 1.9579 nat_grad_norm = 0.0917 cg_residual = 2.8192 step_size = 0.5575 reward = -0.0000 fps = 5 mse_loss = 0.3736 
2022-05-01 12:38:49.539242 - gail/main.py:164 - [TRPO] iter = 1555000 dist_mean = -0.0145 dist_std = 0.1646 vf_loss = 0.0339 grad_norm = 2.3064 nat_grad_norm = 0.0837 cg_residual = 1.2744 step_size = 0.4827 reward = -0.0000 fps = 5 mse_loss = 0.4204 
2022-05-01 12:38:49.788182 - gail/main.py:191 - [Discriminator] iter = 1555000 loss = -0.4439 grad_norm = 3.1664 grad_penalty = 0.0629 regularization = 0.0000 true_logits = 0.4435 fake_logits = -0.0633 true_prob = 0.5820 fake_prob = 0.4892 
2022-05-01 12:40:22.828079 - gail/main.py:132 - [Evaluate] iter = 1555000 episode={ returns = 2523.7058 lengths = 702 } discounted_episode={ returns = 1724.9143 lengths = 684 } 
2022-05-01 12:40:32.866382 - gail/main.py:164 - [TRPO] iter = 1556000 dist_mean = -0.0317 dist_std = 0.1647 vf_loss = 0.0169 grad_norm = 2.2183 nat_grad_norm = 0.1200 cg_residual = 1.5922 step_size = 0.4548 reward = 0.0000 fps = 9 mse_loss = 0.4157 
2022-05-01 12:40:42.751633 - gail/main.py:164 - [TRPO] iter = 1557000 dist_mean = 0.0289 dist_std = 0.1655 vf_loss = 0.0349 grad_norm = 2.7517 nat_grad_norm = 0.0588 cg_residual = 0.5699 step_size = 0.5801 reward = 0.0000 fps = 8 mse_loss = 0.4120 
2022-05-01 12:40:52.717436 - gail/main.py:164 - [TRPO] iter = 1558000 dist_mean = -0.0074 dist_std = 0.1656 vf_loss = 0.0202 grad_norm = 3.1147 nat_grad_norm = 0.1410 cg_residual = 1.0000 step_size = 0.3979 reward = 0.0000 fps = 8 mse_loss = 0.4241 
2022-05-01 12:41:02.515926 - gail/main.py:164 - [TRPO] iter = 1559000 dist_mean = 0.0315 dist_std = 0.1657 vf_loss = 0.0276 grad_norm = 3.0933 nat_grad_norm = 0.0911 cg_residual = 0.7372 step_size = 0.4810 reward = 0.0000 fps = 7 mse_loss = 0.3996 
2022-05-01 12:41:12.403138 - gail/main.py:164 - [TRPO] iter = 1560000 dist_mean = 0.0125 dist_std = 0.1660 vf_loss = 0.0486 grad_norm = 2.4896 nat_grad_norm = 0.0928 cg_residual = 0.9023 step_size = 0.5446 reward = 0.0000 fps = 7 mse_loss = 0.3781 
2022-05-01 12:41:12.605002 - gail/main.py:191 - [Discriminator] iter = 1560000 loss = -0.4075 grad_norm = 3.3974 grad_penalty = 0.0670 regularization = 0.0000 true_logits = 0.4583 fake_logits = -0.0162 true_prob = 0.5809 fake_prob = 0.4970 
2022-05-01 12:43:22.420512 - gail/main.py:132 - [Evaluate] iter = 1560000 episode={ returns = 3495.1932 lengths = 959 } discounted_episode={ returns = 2179.7887 lengths = 961 } 
2022-05-01 12:43:32.235736 - gail/main.py:164 - [TRPO] iter = 1561000 dist_mean = 0.0194 dist_std = 0.1659 vf_loss = 0.0700 grad_norm = 3.2111 nat_grad_norm = 0.0913 cg_residual = 2.2094 step_size = 0.5115 reward = -0.0000 fps = 7 mse_loss = 0.4242 
2022-05-01 12:43:42.014660 - gail/main.py:164 - [TRPO] iter = 1562000 dist_mean = 0.0257 dist_std = 0.1657 vf_loss = 0.0355 grad_norm = 2.8464 nat_grad_norm = 0.0928 cg_residual = 0.6411 step_size = 0.4720 reward = 0.0000 fps = 6 mse_loss = 0.4098 
2022-05-01 12:43:51.637854 - gail/main.py:164 - [TRPO] iter = 1563000 dist_mean = 0.0334 dist_std = 0.1655 vf_loss = 0.0231 grad_norm = 3.7817 nat_grad_norm = 0.0950 cg_residual = 0.8664 step_size = 0.3837 reward = -0.0000 fps = 6 mse_loss = 0.4251 
2022-05-01 12:44:01.742336 - gail/main.py:164 - [TRPO] iter = 1564000 dist_mean = 0.0149 dist_std = 0.1658 vf_loss = 0.0157 grad_norm = 3.0300 nat_grad_norm = 0.1291 cg_residual = 0.9996 step_size = 0.3609 reward = 0.0000 fps = 5 mse_loss = 0.4145 
2022-05-01 12:44:11.550644 - gail/main.py:164 - [TRPO] iter = 1565000 dist_mean = 0.0122 dist_std = 0.1661 vf_loss = 0.0186 grad_norm = 2.6551 nat_grad_norm = 0.1220 cg_residual = 1.3358 step_size = 0.4549 reward = -0.0000 fps = 5 mse_loss = 0.3967 
2022-05-01 12:44:11.815716 - gail/main.py:191 - [Discriminator] iter = 1565000 loss = -0.3617 grad_norm = 3.7158 grad_penalty = 0.0723 regularization = 0.0000 true_logits = 0.4198 fake_logits = -0.0141 true_prob = 0.5751 fake_prob = 0.5009 
2022-05-01 12:46:11.117615 - gail/main.py:132 - [Evaluate] iter = 1565000 episode={ returns = 3143.3982 lengths = 863 } discounted_episode={ returns = 2080.6018 lengths = 906 } 
2022-05-01 12:46:21.211232 - gail/main.py:164 - [TRPO] iter = 1566000 dist_mean = 0.0202 dist_std = 0.1656 vf_loss = 0.0257 grad_norm = 3.3253 nat_grad_norm = 0.0832 cg_residual = 0.6752 step_size = 0.4676 reward = 0.0000 fps = 7 mse_loss = 0.4217 
2022-05-01 12:46:31.102120 - gail/main.py:164 - [TRPO] iter = 1567000 dist_mean = 0.0186 dist_std = 0.1655 vf_loss = 0.0763 grad_norm = 3.2742 nat_grad_norm = 0.0709 cg_residual = 0.5629 step_size = 0.5187 reward = -0.0000 fps = 7 mse_loss = 0.4490 
2022-05-01 12:46:41.214133 - gail/main.py:164 - [TRPO] iter = 1568000 dist_mean = 0.0218 dist_std = 0.1656 vf_loss = 0.0737 grad_norm = 2.3405 nat_grad_norm = 0.0836 cg_residual = 0.5648 step_size = 0.5393 reward = -0.0000 fps = 6 mse_loss = 0.4101 
2022-05-01 12:46:50.914946 - gail/main.py:164 - [TRPO] iter = 1569000 dist_mean = 0.0253 dist_std = 0.1652 vf_loss = 0.1002 grad_norm = 3.4521 nat_grad_norm = 0.0666 cg_residual = 1.1984 step_size = 0.5583 reward = -0.0000 fps = 6 mse_loss = 0.4252 
2022-05-01 12:47:00.963480 - gail/main.py:164 - [TRPO] iter = 1570000 dist_mean = 0.0279 dist_std = 0.1653 vf_loss = 0.0543 grad_norm = 2.4813 nat_grad_norm = 0.1088 cg_residual = 0.7494 step_size = 0.4818 reward = -0.0000 fps = 5 mse_loss = 0.4045 
2022-05-01 12:47:01.187879 - gail/main.py:191 - [Discriminator] iter = 1570000 loss = -0.2685 grad_norm = 3.5354 grad_penalty = 0.0818 regularization = 0.0000 true_logits = 0.2205 fake_logits = -0.1299 true_prob = 0.5385 fake_prob = 0.4764 
2022-05-01 12:49:17.304433 - gail/main.py:132 - [Evaluate] iter = 1570000 episode={ returns = 3476.4138 lengths = 1000 } discounted_episode={ returns = 2148.3633 lengths = 1000 } 
2022-05-01 12:49:27.003045 - gail/main.py:164 - [TRPO] iter = 1571000 dist_mean = 0.0176 dist_std = 0.1657 vf_loss = 0.0264 grad_norm = 3.0712 nat_grad_norm = 0.0739 cg_residual = 0.4240 step_size = 0.5197 reward = 0.0000 fps = 6 mse_loss = 0.4113 
2022-05-01 12:49:36.961265 - gail/main.py:164 - [TRPO] iter = 1572000 dist_mean = 0.0258 dist_std = 0.1656 vf_loss = 0.0240 grad_norm = 2.7546 nat_grad_norm = 0.0937 cg_residual = 0.9960 step_size = 0.4570 reward = -0.0000 fps = 6 mse_loss = 0.3865 
2022-05-01 12:49:46.867662 - gail/main.py:164 - [TRPO] iter = 1573000 dist_mean = 0.0844 dist_std = 0.1649 vf_loss = 0.0341 grad_norm = 4.0915 nat_grad_norm = 0.0764 cg_residual = 1.1902 step_size = 0.5125 reward = -0.0000 fps = 6 mse_loss = 0.4103 
2022-05-01 12:49:56.581324 - gail/main.py:164 - [TRPO] iter = 1574000 dist_mean = 0.0357 dist_std = 0.1648 vf_loss = 0.0523 grad_norm = 2.7722 nat_grad_norm = 0.0853 cg_residual = 0.8670 step_size = 0.4933 reward = 0.0000 fps = 5 mse_loss = 0.4048 
2022-05-01 12:50:06.684869 - gail/main.py:164 - [TRPO] iter = 1575000 dist_mean = 0.0592 dist_std = 0.1642 vf_loss = 0.0180 grad_norm = 2.9545 nat_grad_norm = 0.1251 cg_residual = 1.0399 step_size = 0.4062 reward = 0.0000 fps = 5 mse_loss = 0.3849 
2022-05-01 12:50:06.911640 - gail/main.py:191 - [Discriminator] iter = 1575000 loss = -0.2597 grad_norm = 3.9020 grad_penalty = 0.0738 regularization = 0.0000 true_logits = 0.2549 fake_logits = -0.0787 true_prob = 0.5493 fake_prob = 0.4843 
2022-05-01 12:52:25.565030 - gail/main.py:132 - [Evaluate] iter = 1575000 episode={ returns = 3492.8933 lengths = 1000 } discounted_episode={ returns = 2158.7212 lengths = 1000 } 
2022-05-01 12:52:35.629338 - gail/main.py:164 - [TRPO] iter = 1576000 dist_mean = 0.0147 dist_std = 0.1642 vf_loss = 0.0204 grad_norm = 4.0242 nat_grad_norm = 0.0955 cg_residual = 0.6573 step_size = 0.4480 reward = -0.0000 fps = 6 mse_loss = 0.4038 
2022-05-01 12:52:45.822652 - gail/main.py:164 - [TRPO] iter = 1577000 dist_mean = 0.0446 dist_std = 0.1635 vf_loss = 0.0142 grad_norm = 1.9775 nat_grad_norm = 0.1420 cg_residual = 0.8701 step_size = 0.4273 reward = 0.0000 fps = 6 mse_loss = 0.3864 
2022-05-01 12:52:55.912745 - gail/main.py:164 - [TRPO] iter = 1578000 dist_mean = 0.0190 dist_std = 0.1633 vf_loss = 0.0289 grad_norm = 1.6269 nat_grad_norm = 0.1242 cg_residual = 1.6432 step_size = 0.4382 reward = -0.0000 fps = 5 mse_loss = 0.4126 
2022-05-01 12:53:05.725883 - gail/main.py:164 - [TRPO] iter = 1579000 dist_mean = 0.1079 dist_std = 0.1632 vf_loss = 0.0185 grad_norm = 3.3122 nat_grad_norm = 0.0923 cg_residual = 0.5906 step_size = 0.4413 reward = 0.0000 fps = 5 mse_loss = 0.3965 
2022-05-01 12:53:15.536774 - gail/main.py:164 - [TRPO] iter = 1580000 dist_mean = 0.0576 dist_std = 0.1633 vf_loss = 0.0185 grad_norm = 2.1174 nat_grad_norm = 0.1058 cg_residual = 1.1081 step_size = 0.4559 reward = 0.0000 fps = 5 mse_loss = 0.4646 
2022-05-01 12:53:15.748282 - gail/main.py:191 - [Discriminator] iter = 1580000 loss = -0.3965 grad_norm = 4.9391 grad_penalty = 0.0717 regularization = 0.0000 true_logits = 0.0416 fake_logits = -0.4267 true_prob = 0.5077 fake_prob = 0.4148 
2022-05-01 12:55:31.420358 - gail/main.py:132 - [Evaluate] iter = 1580000 episode={ returns = 3484.0053 lengths = 1000 } discounted_episode={ returns = 2152.6138 lengths = 1000 } 
2022-05-01 12:55:41.328365 - gail/main.py:164 - [TRPO] iter = 1581000 dist_mean = 0.1146 dist_std = 0.1632 vf_loss = 0.0236 grad_norm = 2.9550 nat_grad_norm = 0.0688 cg_residual = 0.5789 step_size = 0.5312 reward = 0.0000 fps = 6 mse_loss = 0.4078 
2022-05-01 12:55:51.675914 - gail/main.py:164 - [TRPO] iter = 1582000 dist_mean = 0.0708 dist_std = 0.1630 vf_loss = 0.0171 grad_norm = 2.6617 nat_grad_norm = 0.1248 cg_residual = 2.1201 step_size = 0.3940 reward = 0.0000 fps = 6 mse_loss = 0.4303 
2022-05-01 12:56:01.704168 - gail/main.py:164 - [TRPO] iter = 1583000 dist_mean = 0.0575 dist_std = 0.1624 vf_loss = 0.0134 grad_norm = 2.8074 nat_grad_norm = 0.1269 cg_residual = 1.3345 step_size = 0.3909 reward = -0.0000 fps = 6 mse_loss = 0.4514 
2022-05-01 12:56:11.472442 - gail/main.py:164 - [TRPO] iter = 1584000 dist_mean = 0.0861 dist_std = 0.1626 vf_loss = 0.0155 grad_norm = 2.6855 nat_grad_norm = 0.1005 cg_residual = 0.9790 step_size = 0.4776 reward = 0.0000 fps = 5 mse_loss = 0.3938 
2022-05-01 12:56:21.453055 - gail/main.py:164 - [TRPO] iter = 1585000 dist_mean = 0.1111 dist_std = 0.1622 vf_loss = 0.0121 grad_norm = 3.1769 nat_grad_norm = 0.1160 cg_residual = 1.2030 step_size = 0.3937 reward = 0.0000 fps = 5 mse_loss = 0.4069 
2022-05-01 12:56:21.727225 - gail/main.py:191 - [Discriminator] iter = 1585000 loss = -0.3472 grad_norm = 3.7422 grad_penalty = 0.0618 regularization = 0.0000 true_logits = -0.1373 fake_logits = -0.5463 true_prob = 0.4699 fake_prob = 0.3849 
2022-05-01 12:58:33.603527 - gail/main.py:132 - [Evaluate] iter = 1585000 episode={ returns = 3499.3872 lengths = 1000 } discounted_episode={ returns = 2162.4079 lengths = 1000 } 
2022-05-01 12:58:43.349927 - gail/main.py:164 - [TRPO] iter = 1586000 dist_mean = 0.0881 dist_std = 0.1623 vf_loss = 0.0129 grad_norm = 2.7926 nat_grad_norm = 0.1227 cg_residual = 1.3029 step_size = 0.3983 reward = -0.0000 fps = 7 mse_loss = 0.4122 
2022-05-01 12:58:53.029143 - gail/main.py:164 - [TRPO] iter = 1587000 dist_mean = 0.0447 dist_std = 0.1621 vf_loss = 0.0131 grad_norm = 3.0182 nat_grad_norm = 0.1440 cg_residual = 1.4094 step_size = 0.3517 reward = -0.0000 fps = 6 mse_loss = 0.3960 
2022-05-01 12:59:02.786897 - gail/main.py:164 - [TRPO] iter = 1588000 dist_mean = 0.1074 dist_std = 0.1618 vf_loss = 0.0153 grad_norm = 2.8562 nat_grad_norm = 0.1093 cg_residual = 1.8088 step_size = 0.3915 reward = 0.0000 fps = 6 mse_loss = 0.4063 
2022-05-01 12:59:12.779872 - gail/main.py:164 - [TRPO] iter = 1589000 dist_mean = 0.0998 dist_std = 0.1616 vf_loss = 0.0122 grad_norm = 3.0828 nat_grad_norm = 0.0929 cg_residual = 0.9280 step_size = 0.4543 reward = 0.0000 fps = 5 mse_loss = 0.3856 
2022-05-01 12:59:22.701078 - gail/main.py:164 - [TRPO] iter = 1590000 dist_mean = 0.1018 dist_std = 0.1611 vf_loss = 0.0270 grad_norm = 2.8029 nat_grad_norm = 0.1189 cg_residual = 1.7926 step_size = 0.3934 reward = -0.0000 fps = 5 mse_loss = 0.3935 
2022-05-01 12:59:22.924034 - gail/main.py:191 - [Discriminator] iter = 1590000 loss = -0.4580 grad_norm = 3.5312 grad_penalty = 0.0668 regularization = 0.0000 true_logits = -0.2388 fake_logits = -0.7636 true_prob = 0.4501 fake_prob = 0.3438 
2022-05-01 13:01:37.244712 - gail/main.py:132 - [Evaluate] iter = 1590000 episode={ returns = 3467.1983 lengths = 1000 } discounted_episode={ returns = 2143.4718 lengths = 1000 } 
2022-05-01 13:01:47.033514 - gail/main.py:164 - [TRPO] iter = 1591000 dist_mean = 0.0764 dist_std = 0.1605 vf_loss = 0.0261 grad_norm = 1.8943 nat_grad_norm = 0.0957 cg_residual = 0.7059 step_size = 0.4967 reward = -0.0000 fps = 6 mse_loss = 0.4545 
2022-05-01 13:01:56.939339 - gail/main.py:164 - [TRPO] iter = 1592000 dist_mean = 0.1269 dist_std = 0.1605 vf_loss = 0.0174 grad_norm = 4.2655 nat_grad_norm = 0.0801 cg_residual = 1.7341 step_size = 0.5088 reward = 0.0000 fps = 6 mse_loss = 0.3996 
2022-05-01 13:02:06.848492 - gail/main.py:164 - [TRPO] iter = 1593000 dist_mean = 0.1104 dist_std = 0.1603 vf_loss = 0.0146 grad_norm = 3.7910 nat_grad_norm = 0.0932 cg_residual = 0.8350 step_size = 0.4358 reward = 0.0000 fps = 6 mse_loss = 0.3760 
2022-05-01 13:02:16.539529 - gail/main.py:164 - [TRPO] iter = 1594000 dist_mean = 0.1292 dist_std = 0.1605 vf_loss = 0.0383 grad_norm = 5.2530 nat_grad_norm = 0.0806 cg_residual = 0.6499 step_size = 0.4585 reward = 0.0000 fps = 5 mse_loss = 0.4009 
2022-05-01 13:02:26.529197 - gail/main.py:164 - [TRPO] iter = 1595000 dist_mean = 0.0985 dist_std = 0.1601 vf_loss = 0.0123 grad_norm = 3.1464 nat_grad_norm = 0.0804 cg_residual = 1.4542 step_size = 0.5140 reward = -0.0000 fps = 5 mse_loss = 0.3789 
2022-05-01 13:02:26.740100 - gail/main.py:191 - [Discriminator] iter = 1595000 loss = -0.4789 grad_norm = 4.0226 grad_penalty = 0.0650 regularization = 0.0000 true_logits = -0.3486 fake_logits = -0.8925 true_prob = 0.4267 fake_prob = 0.3186 
2022-05-01 13:04:37.919184 - gail/main.py:132 - [Evaluate] iter = 1595000 episode={ returns = 3441.2428 lengths = 1000 } discounted_episode={ returns = 2111.4272 lengths = 1000 } 
2022-05-01 13:04:47.983861 - gail/main.py:164 - [TRPO] iter = 1596000 dist_mean = 0.1007 dist_std = 0.1597 vf_loss = 0.0223 grad_norm = 4.6189 nat_grad_norm = 0.0844 cg_residual = 1.1033 step_size = 0.4605 reward = -0.0000 fps = 7 mse_loss = 0.4162 
2022-05-01 13:04:57.388221 - gail/main.py:164 - [TRPO] iter = 1597000 dist_mean = 0.0840 dist_std = 0.1593 vf_loss = 0.0227 grad_norm = 4.0106 nat_grad_norm = 0.0812 cg_residual = 0.6574 step_size = 0.4122 reward = -0.0000 fps = 6 mse_loss = 0.3763 
2022-05-01 13:05:07.151168 - gail/main.py:164 - [TRPO] iter = 1598000 dist_mean = 0.0912 dist_std = 0.1591 vf_loss = 0.0234 grad_norm = 4.1810 nat_grad_norm = 0.0814 cg_residual = 0.7255 step_size = 0.4921 reward = -0.0000 fps = 6 mse_loss = 0.3860 
2022-05-01 13:05:17.109821 - gail/main.py:164 - [TRPO] iter = 1599000 dist_mean = 0.0854 dist_std = 0.1590 vf_loss = 0.0169 grad_norm = 4.3244 nat_grad_norm = 0.1171 cg_residual = 1.7293 step_size = 0.3785 reward = 0.0000 fps = 5 mse_loss = 0.4268 
2022-05-01 13:05:26.753932 - gail/main.py:164 - [TRPO] iter = 1600000 dist_mean = 0.0948 dist_std = 0.1587 vf_loss = 0.0144 grad_norm = 2.6808 nat_grad_norm = 0.0900 cg_residual = 0.9143 step_size = 0.5098 reward = 0.0000 fps = 5 mse_loss = 0.4210 
2022-05-01 13:05:27.075087 - gail/main.py:191 - [Discriminator] iter = 1600000 loss = -0.5586 grad_norm = 3.1151 grad_penalty = 0.0609 regularization = 0.0000 true_logits = -0.3695 fake_logits = -0.9889 true_prob = 0.4241 fake_prob = 0.3042 
2022-05-01 13:07:40.230117 - gail/main.py:132 - [Evaluate] iter = 1600000 episode={ returns = 3427.7121 lengths = 1000 } discounted_episode={ returns = 2101.8774 lengths = 1000 } 
2022-05-01 13:07:50.214691 - gail/main.py:164 - [TRPO] iter = 1601000 dist_mean = 0.0592 dist_std = 0.1587 vf_loss = 0.0276 grad_norm = 3.0526 nat_grad_norm = 0.1326 cg_residual = 1.7331 step_size = 0.3600 reward = -0.0000 fps = 6 mse_loss = 0.4040 
2022-05-01 13:07:59.746704 - gail/main.py:164 - [TRPO] iter = 1602000 dist_mean = 0.0862 dist_std = 0.1583 vf_loss = 0.0341 grad_norm = 3.3430 nat_grad_norm = 0.0764 cg_residual = 0.8250 step_size = 0.4838 reward = 0.0000 fps = 6 mse_loss = 0.4050 
2022-05-01 13:08:09.620209 - gail/main.py:164 - [TRPO] iter = 1603000 dist_mean = 0.0786 dist_std = 0.1583 vf_loss = 0.0191 grad_norm = 2.5410 nat_grad_norm = 0.1014 cg_residual = 1.6845 step_size = 0.4721 reward = -0.0000 fps = 6 mse_loss = 0.3854 
2022-05-01 13:08:19.341472 - gail/main.py:164 - [TRPO] iter = 1604000 dist_mean = 0.0569 dist_std = 0.1591 vf_loss = 0.0205 grad_norm = 3.1249 nat_grad_norm = 0.0940 cg_residual = 1.5151 step_size = 0.4245 reward = -0.0000 fps = 5 mse_loss = 0.3870 
2022-05-01 13:08:29.213772 - gail/main.py:164 - [TRPO] iter = 1605000 dist_mean = 0.0703 dist_std = 0.1594 vf_loss = 0.0378 grad_norm = 2.3173 nat_grad_norm = 0.0701 cg_residual = 0.6778 step_size = 0.5568 reward = -0.0000 fps = 5 mse_loss = 0.3658 
2022-05-01 13:08:29.537172 - gail/main.py:191 - [Discriminator] iter = 1605000 loss = -0.4459 grad_norm = 3.6346 grad_penalty = 0.0674 regularization = 0.0000 true_logits = -0.4400 fake_logits = -0.9533 true_prob = 0.4117 fake_prob = 0.3132 
2022-05-01 13:10:40.860255 - gail/main.py:132 - [Evaluate] iter = 1605000 episode={ returns = 3420.6841 lengths = 1000 } discounted_episode={ returns = 2092.4254 lengths = 1000 } 
2022-05-01 13:10:51.141056 - gail/main.py:164 - [TRPO] iter = 1606000 dist_mean = 0.0620 dist_std = 0.1591 vf_loss = 0.0666 grad_norm = 3.4196 nat_grad_norm = 0.0775 cg_residual = 0.7048 step_size = 0.5304 reward = 0.0000 fps = 7 mse_loss = 0.3586 
2022-05-01 13:11:01.323562 - gail/main.py:164 - [TRPO] iter = 1607000 dist_mean = 0.0642 dist_std = 0.1589 vf_loss = 0.0538 grad_norm = 3.5143 nat_grad_norm = 0.0696 cg_residual = 0.5743 step_size = 0.5220 reward = -0.0000 fps = 6 mse_loss = 0.3708 
2022-05-01 13:11:11.199303 - gail/main.py:164 - [TRPO] iter = 1608000 dist_mean = 0.0571 dist_std = 0.1592 vf_loss = 0.0378 grad_norm = 2.4221 nat_grad_norm = 0.1203 cg_residual = 1.1429 step_size = 0.4343 reward = -0.0000 fps = 6 mse_loss = 0.3765 
2022-05-01 13:11:21.391368 - gail/main.py:164 - [TRPO] iter = 1609000 dist_mean = 0.0537 dist_std = 0.1593 vf_loss = 0.0361 grad_norm = 3.1662 nat_grad_norm = 0.0849 cg_residual = 2.3887 step_size = 0.4803 reward = -0.0000 fps = 5 mse_loss = 0.3432 
2022-05-01 13:11:31.582447 - gail/main.py:164 - [TRPO] iter = 1610000 dist_mean = 0.0590 dist_std = 0.1593 vf_loss = 0.0290 grad_norm = 3.2949 nat_grad_norm = 0.0861 cg_residual = 0.8276 step_size = 0.4621 reward = -0.0000 fps = 5 mse_loss = 0.3504 
2022-05-01 13:11:31.827650 - gail/main.py:191 - [Discriminator] iter = 1610000 loss = -0.4467 grad_norm = 3.1478 grad_penalty = 0.0666 regularization = 0.0000 true_logits = -0.3684 fake_logits = -0.8817 true_prob = 0.4263 fake_prob = 0.3246 
2022-05-01 13:13:44.673228 - gail/main.py:132 - [Evaluate] iter = 1610000 episode={ returns = 3366.8119 lengths = 1000 } discounted_episode={ returns = 2080.4158 lengths = 1000 } 
2022-05-01 13:13:54.319645 - gail/main.py:164 - [TRPO] iter = 1611000 dist_mean = 0.0557 dist_std = 0.1597 vf_loss = 0.0474 grad_norm = 2.5516 nat_grad_norm = 0.0975 cg_residual = 4.2621 step_size = 0.5382 reward = -0.0000 fps = 7 mse_loss = 0.3981 
2022-05-01 13:14:04.390064 - gail/main.py:164 - [TRPO] iter = 1612000 dist_mean = 0.0579 dist_std = 0.1588 vf_loss = 0.1367 grad_norm = 2.8918 nat_grad_norm = 0.0595 cg_residual = 0.3002 step_size = 0.5722 reward = 0.0000 fps = 6 mse_loss = 0.3495 
2022-05-01 13:14:14.404384 - gail/main.py:164 - [TRPO] iter = 1613000 dist_mean = 0.0541 dist_std = 0.1588 vf_loss = 0.0381 grad_norm = 3.5633 nat_grad_norm = 0.0796 cg_residual = 0.9020 step_size = 0.5071 reward = -0.0000 fps = 6 mse_loss = 0.4255 
2022-05-01 13:14:24.254415 - gail/main.py:164 - [TRPO] iter = 1614000 dist_mean = 0.0512 dist_std = 0.1589 vf_loss = 0.0270 grad_norm = 4.0090 nat_grad_norm = 0.0823 cg_residual = 4.6090 step_size = 0.5428 reward = -0.0000 fps = 5 mse_loss = 0.3633 
2022-05-01 13:14:34.410520 - gail/main.py:164 - [TRPO] iter = 1615000 dist_mean = 0.0555 dist_std = 0.1599 vf_loss = 0.0319 grad_norm = 3.5708 nat_grad_norm = 0.0907 cg_residual = 0.8912 step_size = 0.4260 reward = -0.0000 fps = 5 mse_loss = 0.3854 
2022-05-01 13:14:34.671774 - gail/main.py:191 - [Discriminator] iter = 1615000 loss = -0.4559 grad_norm = 2.8848 grad_penalty = 0.0694 regularization = 0.0000 true_logits = -0.3077 fake_logits = -0.8330 true_prob = 0.4360 fake_prob = 0.3325 
2022-05-01 13:16:51.446604 - gail/main.py:132 - [Evaluate] iter = 1615000 episode={ returns = 3325.8524 lengths = 1000 } discounted_episode={ returns = 2063.0585 lengths = 1000 } 
2022-05-01 13:17:01.480091 - gail/main.py:164 - [TRPO] iter = 1616000 dist_mean = 0.0430 dist_std = 0.1597 vf_loss = 0.0325 grad_norm = 3.0828 nat_grad_norm = 0.0924 cg_residual = 2.3072 step_size = 0.4961 reward = 0.0000 fps = 6 mse_loss = 0.4225 
2022-05-01 13:17:11.409881 - gail/main.py:164 - [TRPO] iter = 1617000 dist_mean = 0.0567 dist_std = 0.1602 vf_loss = 0.0416 grad_norm = 3.1255 nat_grad_norm = 0.0783 cg_residual = 1.0201 step_size = 0.4652 reward = 0.0000 fps = 6 mse_loss = 0.4006 
2022-05-01 13:17:21.496265 - gail/main.py:164 - [TRPO] iter = 1618000 dist_mean = 0.0566 dist_std = 0.1602 vf_loss = 0.0398 grad_norm = 4.1024 nat_grad_norm = 0.0841 cg_residual = 1.0921 step_size = 0.4398 reward = -0.0000 fps = 5 mse_loss = 0.3899 
2022-05-01 13:17:31.550987 - gail/main.py:164 - [TRPO] iter = 1619000 dist_mean = 0.0603 dist_std = 0.1598 vf_loss = 0.0431 grad_norm = 4.1207 nat_grad_norm = 0.0803 cg_residual = 2.6250 step_size = 0.4431 reward = 0.0000 fps = 5 mse_loss = 0.4501 
2022-05-01 13:17:41.452317 - gail/main.py:164 - [TRPO] iter = 1620000 dist_mean = 0.0189 dist_std = 0.1598 vf_loss = 0.0274 grad_norm = 2.8451 nat_grad_norm = 0.1055 cg_residual = 4.1059 step_size = 0.4296 reward = -0.0000 fps = 5 mse_loss = 0.4566 
2022-05-01 13:17:41.679403 - gail/main.py:191 - [Discriminator] iter = 1620000 loss = -0.3356 grad_norm = 3.1794 grad_penalty = 0.0656 regularization = 0.0000 true_logits = -0.0781 fake_logits = -0.4792 true_prob = 0.4790 fake_prob = 0.4031 
2022-05-01 13:19:53.255265 - gail/main.py:132 - [Evaluate] iter = 1620000 episode={ returns = 3448.0165 lengths = 1000 } discounted_episode={ returns = 2109.1132 lengths = 974 } 
2022-05-01 13:20:03.155067 - gail/main.py:164 - [TRPO] iter = 1621000 dist_mean = 0.0129 dist_std = 0.1599 vf_loss = 0.0172 grad_norm = 2.2294 nat_grad_norm = 0.1017 cg_residual = 1.1916 step_size = 0.4735 reward = 0.0000 fps = 7 mse_loss = 0.3890 
2022-05-01 13:20:12.877648 - gail/main.py:164 - [TRPO] iter = 1622000 dist_mean = 0.0195 dist_std = 0.1591 vf_loss = 0.0324 grad_norm = 2.6302 nat_grad_norm = 0.0868 cg_residual = 1.1140 step_size = 0.5048 reward = 0.0000 fps = 6 mse_loss = 0.3875 
2022-05-01 13:20:22.850552 - gail/main.py:164 - [TRPO] iter = 1623000 dist_mean = 0.0249 dist_std = 0.1594 vf_loss = 0.0145 grad_norm = 3.3572 nat_grad_norm = 0.0877 cg_residual = 0.7630 step_size = 0.4790 reward = -0.0000 fps = 6 mse_loss = 0.4515 
2022-05-01 13:20:32.736183 - gail/main.py:164 - [TRPO] iter = 1624000 dist_mean = 0.0188 dist_std = 0.1597 vf_loss = 0.0209 grad_norm = 2.7760 nat_grad_norm = 0.1091 cg_residual = 1.7841 step_size = 0.4651 reward = -0.0000 fps = 5 mse_loss = 0.4225 
2022-05-01 13:20:42.412247 - gail/main.py:164 - [TRPO] iter = 1625000 dist_mean = 0.0135 dist_std = 0.1590 vf_loss = 0.0275 grad_norm = 4.0590 nat_grad_norm = 0.1096 cg_residual = 1.6874 step_size = 0.4362 reward = 0.0000 fps = 5 mse_loss = 0.4003 
2022-05-01 13:20:42.634340 - gail/main.py:191 - [Discriminator] iter = 1625000 loss = -0.3852 grad_norm = 3.1253 grad_penalty = 0.0501 regularization = 0.0000 true_logits = 0.0917 fake_logits = -0.3436 true_prob = 0.5136 fake_prob = 0.4338 
2022-05-01 13:21:53.538046 - gail/main.py:132 - [Evaluate] iter = 1625000 episode={ returns = 1922.9216 lengths = 548 } discounted_episode={ returns = 1430.9043 lengths = 541 } 
2022-05-01 13:22:03.325653 - gail/main.py:164 - [TRPO] iter = 1626000 dist_mean = 0.0125 dist_std = 0.1590 vf_loss = 0.0297 grad_norm = 5.0727 nat_grad_norm = 0.1050 cg_residual = 6.6237 step_size = 0.4319 reward = 0.0000 fps = 12 mse_loss = 0.3889 
2022-05-01 13:22:12.834519 - gail/main.py:164 - [TRPO] iter = 1627000 dist_mean = 0.0217 dist_std = 0.1585 vf_loss = 0.0253 grad_norm = 3.6113 nat_grad_norm = 0.1077 cg_residual = 0.9671 step_size = 0.4282 reward = -0.0000 fps = 11 mse_loss = 0.4041 
2022-05-01 13:22:22.729375 - gail/main.py:164 - [TRPO] iter = 1628000 dist_mean = 0.0118 dist_std = 0.1584 vf_loss = 0.0382 grad_norm = 2.4570 nat_grad_norm = 0.0958 cg_residual = 1.0560 step_size = 0.4997 reward = -0.0000 fps = 9 mse_loss = 0.4164 
2022-05-01 13:22:32.457695 - gail/main.py:164 - [TRPO] iter = 1629000 dist_mean = 0.0252 dist_std = 0.1585 vf_loss = 0.0254 grad_norm = 3.8496 nat_grad_norm = 0.1186 cg_residual = 0.9652 step_size = 0.3885 reward = -0.0000 fps = 9 mse_loss = 0.4213 
2022-05-01 13:22:42.083741 - gail/main.py:164 - [TRPO] iter = 1630000 dist_mean = 0.0149 dist_std = 0.1589 vf_loss = 0.0179 grad_norm = 3.6995 nat_grad_norm = 0.0739 cg_residual = 0.9002 step_size = 0.5558 reward = 0.0000 fps = 8 mse_loss = 0.3745 
2022-05-01 13:22:42.327556 - gail/main.py:191 - [Discriminator] iter = 1630000 loss = -0.4338 grad_norm = 3.1643 grad_penalty = 0.0518 regularization = 0.0000 true_logits = 0.3752 fake_logits = -0.1105 true_prob = 0.5758 fake_prob = 0.4815 
2022-05-01 13:23:48.742682 - gail/main.py:132 - [Evaluate] iter = 1630000 episode={ returns = 1737.4527 lengths = 494 } discounted_episode={ returns = 1350.3829 lengths = 501 } 
2022-05-01 13:23:58.424345 - gail/main.py:164 - [TRPO] iter = 1631000 dist_mean = 0.0136 dist_std = 0.1590 vf_loss = 0.0346 grad_norm = 3.4171 nat_grad_norm = 0.1042 cg_residual = 1.7810 step_size = 0.4591 reward = 0.0000 fps = 13 mse_loss = 0.3779 
2022-05-01 13:24:08.383346 - gail/main.py:164 - [TRPO] iter = 1632000 dist_mean = 0.0147 dist_std = 0.1588 vf_loss = 0.0159 grad_norm = 3.3909 nat_grad_norm = 0.1164 cg_residual = 1.2202 step_size = 0.4122 reward = 0.0000 fps = 11 mse_loss = 0.4165 
2022-05-01 13:24:18.271750 - gail/main.py:164 - [TRPO] iter = 1633000 dist_mean = 0.0280 dist_std = 0.1587 vf_loss = 0.0343 grad_norm = 3.1969 nat_grad_norm = 0.1382 cg_residual = 0.7571 step_size = 0.3863 reward = -0.0000 fps = 10 mse_loss = 0.4059 
2022-05-01 13:24:28.401032 - gail/main.py:164 - [TRPO] iter = 1634000 dist_mean = 0.0175 dist_std = 0.1593 vf_loss = 0.0190 grad_norm = 2.9206 nat_grad_norm = 0.1145 cg_residual = 1.0436 step_size = 0.4278 reward = -0.0000 fps = 9 mse_loss = 0.3826 
2022-05-01 13:24:38.287012 - gail/main.py:164 - [TRPO] iter = 1635000 dist_mean = 0.0327 dist_std = 0.1590 vf_loss = 0.0316 grad_norm = 2.4962 nat_grad_norm = 0.1147 cg_residual = 2.9907 step_size = 0.4032 reward = 0.0000 fps = 8 mse_loss = 0.4068 
2022-05-01 13:24:38.499071 - gail/main.py:191 - [Discriminator] iter = 1635000 loss = -0.3601 grad_norm = 3.0581 grad_penalty = 0.0536 regularization = 0.0000 true_logits = 0.4690 fake_logits = 0.0553 true_prob = 0.5952 fake_prob = 0.5132 
2022-05-01 13:25:33.827563 - gail/main.py:132 - [Evaluate] iter = 1635000 episode={ returns = 1488.6229 lengths = 424 } discounted_episode={ returns = 1182.3545 lengths = 423 } 
2022-05-01 13:25:43.740389 - gail/main.py:164 - [TRPO] iter = 1636000 dist_mean = 0.0158 dist_std = 0.1587 vf_loss = 0.0137 grad_norm = 4.2348 nat_grad_norm = 0.1306 cg_residual = 1.9620 step_size = 0.3771 reward = 0.0000 fps = 15 mse_loss = 0.3887 
2022-05-01 13:25:53.694228 - gail/main.py:164 - [TRPO] iter = 1637000 dist_mean = 0.0210 dist_std = 0.1587 vf_loss = 0.0217 grad_norm = 3.2591 nat_grad_norm = 0.1252 cg_residual = 2.4075 step_size = 0.3734 reward = 0.0000 fps = 13 mse_loss = 0.4372 
2022-05-01 13:26:03.783873 - gail/main.py:164 - [TRPO] iter = 1638000 dist_mean = 0.0128 dist_std = 0.1586 vf_loss = 0.0131 grad_norm = 4.2516 nat_grad_norm = 0.1296 cg_residual = 2.9337 step_size = 0.3580 reward = -0.0000 fps = 11 mse_loss = 0.3391 
2022-05-01 13:26:13.704275 - gail/main.py:164 - [TRPO] iter = 1639000 dist_mean = 0.0150 dist_std = 0.1585 vf_loss = 0.0150 grad_norm = 3.4790 nat_grad_norm = 0.0979 cg_residual = 2.5216 step_size = 0.4650 reward = -0.0000 fps = 10 mse_loss = 0.3983 
2022-05-01 13:26:23.334262 - gail/main.py:164 - [TRPO] iter = 1640000 dist_mean = 0.0320 dist_std = 0.1583 vf_loss = 0.0211 grad_norm = 3.1135 nat_grad_norm = 0.1116 cg_residual = 5.4178 step_size = 0.4545 reward = -0.0000 fps = 9 mse_loss = 0.4296 
2022-05-01 13:26:23.600762 - gail/main.py:191 - [Discriminator] iter = 1640000 loss = -0.4966 grad_norm = 3.0675 grad_penalty = 0.0533 regularization = 0.0000 true_logits = 0.5955 fake_logits = 0.0457 true_prob = 0.6206 fake_prob = 0.5137 
2022-05-01 13:27:13.755286 - gail/main.py:132 - [Evaluate] iter = 1640000 episode={ returns = 1294.9533 lengths = 374 } discounted_episode={ returns = 1075.5307 lengths = 382 } 
2022-05-01 13:27:23.206342 - gail/main.py:164 - [TRPO] iter = 1641000 dist_mean = 0.0159 dist_std = 0.1580 vf_loss = 0.0206 grad_norm = 2.3901 nat_grad_norm = 0.0857 cg_residual = 1.1358 step_size = 0.4927 reward = -0.0000 fps = 16 mse_loss = 0.3742 
2022-05-01 13:27:32.869243 - gail/main.py:164 - [TRPO] iter = 1642000 dist_mean = 0.0245 dist_std = 0.1582 vf_loss = 0.0157 grad_norm = 4.6741 nat_grad_norm = 0.1175 cg_residual = 4.4005 step_size = 0.4089 reward = 0.0000 fps = 14 mse_loss = 0.3600 
2022-05-01 13:27:42.545887 - gail/main.py:164 - [TRPO] iter = 1643000 dist_mean = 0.0188 dist_std = 0.1583 vf_loss = 0.0167 grad_norm = 3.9801 nat_grad_norm = 0.0877 cg_residual = 1.2845 step_size = 0.4269 reward = 0.0000 fps = 12 mse_loss = 0.3683 
2022-05-01 13:27:52.157536 - gail/main.py:164 - [TRPO] iter = 1644000 dist_mean = 0.0474 dist_std = 0.1585 vf_loss = 0.0656 grad_norm = 3.7330 nat_grad_norm = 0.0758 cg_residual = 0.7312 step_size = 0.4930 reward = -0.0000 fps = 11 mse_loss = 0.3522 
2022-05-01 13:28:01.712436 - gail/main.py:164 - [TRPO] iter = 1645000 dist_mean = 0.0161 dist_std = 0.1588 vf_loss = 0.0236 grad_norm = 2.8860 nat_grad_norm = 0.1082 cg_residual = 6.1080 step_size = 0.4294 reward = -0.0000 fps = 10 mse_loss = 0.4172 
2022-05-01 13:28:01.949592 - gail/main.py:191 - [Discriminator] iter = 1645000 loss = -0.4216 grad_norm = 2.8148 grad_penalty = 0.0521 regularization = 0.0000 true_logits = 0.6839 fake_logits = 0.2102 true_prob = 0.6396 fake_prob = 0.5470 
2022-05-01 13:29:13.048834 - gail/main.py:132 - [Evaluate] iter = 1645000 episode={ returns = 1945.8785 lengths = 552 } discounted_episode={ returns = 1354.5787 lengths = 525 } 
2022-05-01 13:29:22.635381 - gail/main.py:164 - [TRPO] iter = 1646000 dist_mean = 0.0465 dist_std = 0.1587 vf_loss = 0.0802 grad_norm = 4.3994 nat_grad_norm = 0.0841 cg_residual = 4.1702 step_size = 0.4201 reward = -0.0000 fps = 12 mse_loss = 0.4142 
2022-05-01 13:29:31.869244 - gail/main.py:164 - [TRPO] iter = 1647000 dist_mean = 0.0427 dist_std = 0.1587 vf_loss = 0.0518 grad_norm = 4.1627 nat_grad_norm = 0.1026 cg_residual = 4.9108 step_size = 0.4385 reward = -0.0000 fps = 11 mse_loss = 0.3637 
2022-05-01 13:29:41.803955 - gail/main.py:164 - [TRPO] iter = 1648000 dist_mean = 0.0361 dist_std = 0.1593 vf_loss = 0.0358 grad_norm = 3.4625 nat_grad_norm = 0.0870 cg_residual = 0.9757 step_size = 0.4621 reward = 0.0000 fps = 10 mse_loss = 0.3811 
2022-05-01 13:29:51.737090 - gail/main.py:164 - [TRPO] iter = 1649000 dist_mean = 0.0365 dist_std = 0.1591 vf_loss = 0.0407 grad_norm = 3.6909 nat_grad_norm = 0.0907 cg_residual = 1.1346 step_size = 0.3942 reward = 0.0000 fps = 9 mse_loss = 0.3615 
2022-05-01 13:30:01.275613 - gail/main.py:164 - [TRPO] iter = 1650000 dist_mean = 0.0309 dist_std = 0.1591 vf_loss = 0.0419 grad_norm = 5.6962 nat_grad_norm = 0.1023 cg_residual = 3.2441 step_size = 0.3496 reward = 0.0000 fps = 8 mse_loss = 0.3139 
2022-05-01 13:30:01.488127 - gail/main.py:191 - [Discriminator] iter = 1650000 loss = -0.2774 grad_norm = 3.0610 grad_penalty = 0.0472 regularization = 0.0000 true_logits = 0.7448 fake_logits = 0.4203 true_prob = 0.6521 fake_prob = 0.5906 
2022-05-01 13:31:42.640679 - gail/main.py:132 - [Evaluate] iter = 1650000 episode={ returns = 2839.4623 lengths = 777 } discounted_episode={ returns = 1873.7573 lengths = 757 } 
2022-05-01 13:31:52.081733 - gail/main.py:164 - [TRPO] iter = 1651000 dist_mean = 0.0310 dist_std = 0.1592 vf_loss = 0.0420 grad_norm = 2.7425 nat_grad_norm = 0.0837 cg_residual = 0.8275 step_size = 0.4805 reward = 0.0000 fps = 9 mse_loss = 0.3888 
2022-05-01 13:32:01.883903 - gail/main.py:164 - [TRPO] iter = 1652000 dist_mean = 0.0168 dist_std = 0.1594 vf_loss = 0.0283 grad_norm = 2.5711 nat_grad_norm = 0.1216 cg_residual = 2.5346 step_size = 0.4019 reward = -0.0000 fps = 8 mse_loss = 0.3436 
2022-05-01 13:32:11.648826 - gail/main.py:164 - [TRPO] iter = 1653000 dist_mean = 0.0301 dist_std = 0.1588 vf_loss = 0.0379 grad_norm = 4.2946 nat_grad_norm = 0.1166 cg_residual = 2.0565 step_size = 0.3617 reward = 0.0000 fps = 7 mse_loss = 0.3421 
2022-05-01 13:32:21.712153 - gail/main.py:164 - [TRPO] iter = 1654000 dist_mean = 0.0235 dist_std = 0.1587 vf_loss = 0.0810 grad_norm = 4.4145 nat_grad_norm = 0.0766 cg_residual = 0.9337 step_size = 0.4976 reward = -0.0000 fps = 7 mse_loss = 0.3553 
2022-05-01 13:32:31.718192 - gail/main.py:164 - [TRPO] iter = 1655000 dist_mean = 0.0243 dist_std = 0.1589 vf_loss = 0.1126 grad_norm = 2.6971 nat_grad_norm = 0.0806 cg_residual = 1.0018 step_size = 0.5079 reward = 0.0000 fps = 6 mse_loss = 0.4182 
2022-05-01 13:32:31.916392 - gail/main.py:191 - [Discriminator] iter = 1655000 loss = -0.2973 grad_norm = 3.6873 grad_penalty = 0.0451 regularization = 0.0000 true_logits = 0.7996 fake_logits = 0.4573 true_prob = 0.6628 fake_prob = 0.5999 
2022-05-01 13:34:44.260978 - gail/main.py:132 - [Evaluate] iter = 1655000 episode={ returns = 3604.8773 lengths = 1000 } discounted_episode={ returns = 2222.9066 lengths = 1000 } 
2022-05-01 13:34:54.254742 - gail/main.py:164 - [TRPO] iter = 1656000 dist_mean = 0.0272 dist_std = 0.1592 vf_loss = 0.0784 grad_norm = 3.0314 nat_grad_norm = 0.0795 cg_residual = 1.1758 step_size = 0.4996 reward = -0.0000 fps = 7 mse_loss = 0.3735 
2022-05-01 13:35:03.749521 - gail/main.py:164 - [TRPO] iter = 1657000 dist_mean = -0.0011 dist_std = 0.1592 vf_loss = 0.0534 grad_norm = 2.8438 nat_grad_norm = 0.0896 cg_residual = 1.1347 step_size = 0.5023 reward = -0.0000 fps = 6 mse_loss = 0.3749 
2022-05-01 13:35:13.185014 - gail/main.py:164 - [TRPO] iter = 1658000 dist_mean = 0.0285 dist_std = 0.1588 vf_loss = 0.1053 grad_norm = 2.3909 nat_grad_norm = 0.0973 cg_residual = 0.7837 step_size = 0.4669 reward = -0.0000 fps = 6 mse_loss = 0.3636 
2022-05-01 13:35:22.850073 - gail/main.py:164 - [TRPO] iter = 1659000 dist_mean = 0.0166 dist_std = 0.1587 vf_loss = 0.1150 grad_norm = 2.8768 nat_grad_norm = 0.0902 cg_residual = 1.0654 step_size = 0.4770 reward = 0.0000 fps = 5 mse_loss = 0.3579 
2022-05-01 13:35:32.632379 - gail/main.py:164 - [TRPO] iter = 1660000 dist_mean = 0.0335 dist_std = 0.1584 vf_loss = 0.1035 grad_norm = 3.3665 nat_grad_norm = 0.0858 cg_residual = 2.0660 step_size = 0.4910 reward = -0.0000 fps = 5 mse_loss = 0.3665 
2022-05-01 13:35:32.836726 - gail/main.py:191 - [Discriminator] iter = 1660000 loss = -0.2715 grad_norm = 3.0076 grad_penalty = 0.0469 regularization = 0.0000 true_logits = 0.7258 fake_logits = 0.4074 true_prob = 0.6471 fake_prob = 0.5886 
2022-05-01 13:37:45.123679 - gail/main.py:132 - [Evaluate] iter = 1660000 episode={ returns = 3615.0273 lengths = 994 } discounted_episode={ returns = 2233.6808 lengths = 1000 } 
2022-05-01 13:37:54.713460 - gail/main.py:164 - [TRPO] iter = 1661000 dist_mean = 0.0203 dist_std = 0.1582 vf_loss = 0.1033 grad_norm = 2.3505 nat_grad_norm = 0.0971 cg_residual = 1.1888 step_size = 0.4972 reward = -0.0000 fps = 7 mse_loss = 0.3487 
2022-05-01 13:38:04.393633 - gail/main.py:164 - [TRPO] iter = 1662000 dist_mean = 0.0433 dist_std = 0.1586 vf_loss = 0.1273 grad_norm = 3.6320 nat_grad_norm = 0.1018 cg_residual = 0.6880 step_size = 0.4870 reward = 0.0000 fps = 6 mse_loss = 0.3246 
2022-05-01 13:38:14.145380 - gail/main.py:164 - [TRPO] iter = 1663000 dist_mean = 0.0184 dist_std = 0.1581 vf_loss = 0.0561 grad_norm = 3.6287 nat_grad_norm = 0.0901 cg_residual = 0.9498 step_size = 0.4716 reward = -0.0000 fps = 6 mse_loss = 0.3925 
2022-05-01 13:38:23.976970 - gail/main.py:164 - [TRPO] iter = 1664000 dist_mean = 0.0327 dist_std = 0.1580 vf_loss = 0.1005 grad_norm = 3.5589 nat_grad_norm = 0.0860 cg_residual = 0.8032 step_size = 0.4559 reward = 0.0000 fps = 5 mse_loss = 0.3925 
2022-05-01 13:38:33.615175 - gail/main.py:164 - [TRPO] iter = 1665000 dist_mean = 0.0410 dist_std = 0.1579 vf_loss = 0.0889 grad_norm = 3.6190 nat_grad_norm = 0.0765 cg_residual = 0.6593 step_size = 0.5269 reward = -0.0000 fps = 5 mse_loss = 0.3778 
2022-05-01 13:38:33.836182 - gail/main.py:191 - [Discriminator] iter = 1665000 loss = -0.2211 grad_norm = 4.1188 grad_penalty = 0.0443 regularization = 0.0000 true_logits = 0.6132 fake_logits = 0.3478 true_prob = 0.6275 fake_prob = 0.5767 
2022-05-01 13:40:43.816982 - gail/main.py:132 - [Evaluate] iter = 1665000 episode={ returns = 3615.5445 lengths = 1000 } discounted_episode={ returns = 2224.6497 lengths = 1000 } 
2022-05-01 13:40:53.804824 - gail/main.py:164 - [TRPO] iter = 1666000 dist_mean = 0.0415 dist_std = 0.1575 vf_loss = 0.1176 grad_norm = 3.5393 nat_grad_norm = 0.0960 cg_residual = 0.8816 step_size = 0.4513 reward = -0.0000 fps = 7 mse_loss = 0.3765 
2022-05-01 13:41:03.581099 - gail/main.py:164 - [TRPO] iter = 1667000 dist_mean = 0.0407 dist_std = 0.1576 vf_loss = 0.0392 grad_norm = 3.1951 nat_grad_norm = 0.1298 cg_residual = 2.0175 step_size = 0.3795 reward = 0.0000 fps = 6 mse_loss = 0.3573 
2022-05-01 13:41:13.198472 - gail/main.py:164 - [TRPO] iter = 1668000 dist_mean = 0.0084 dist_std = 0.1572 vf_loss = 0.0534 grad_norm = 4.3853 nat_grad_norm = 0.0967 cg_residual = 2.7556 step_size = 0.4588 reward = 0.0000 fps = 6 mse_loss = 0.3257 
2022-05-01 13:41:23.350537 - gail/main.py:164 - [TRPO] iter = 1669000 dist_mean = 0.0215 dist_std = 0.1570 vf_loss = 0.0960 grad_norm = 2.7044 nat_grad_norm = 0.0948 cg_residual = 1.2446 step_size = 0.4685 reward = 0.0000 fps = 5 mse_loss = 0.3551 
2022-05-01 13:41:33.330272 - gail/main.py:164 - [TRPO] iter = 1670000 dist_mean = 0.0578 dist_std = 0.1571 vf_loss = 0.0759 grad_norm = 2.1790 nat_grad_norm = 0.1161 cg_residual = 1.2537 step_size = 0.4206 reward = 0.0000 fps = 5 mse_loss = 0.3662 
2022-05-01 13:41:33.543015 - gail/main.py:191 - [Discriminator] iter = 1670000 loss = -0.4414 grad_norm = 3.9248 grad_penalty = 0.0504 regularization = 0.0000 true_logits = 0.5086 fake_logits = 0.0167 true_prob = 0.6090 fake_prob = 0.5066 
2022-05-01 13:43:36.894318 - gail/main.py:132 - [Evaluate] iter = 1670000 episode={ returns = 3239.5735 lengths = 918 } discounted_episode={ returns = 2056.9951 lengths = 938 } 
2022-05-01 13:43:46.349117 - gail/main.py:164 - [TRPO] iter = 1671000 dist_mean = 0.0298 dist_std = 0.1566 vf_loss = 0.0296 grad_norm = 2.9438 nat_grad_norm = 0.1287 cg_residual = 2.3481 step_size = 0.3841 reward = 0.0000 fps = 7 mse_loss = 0.2985 
2022-05-01 13:43:56.033087 - gail/main.py:164 - [TRPO] iter = 1672000 dist_mean = 0.0400 dist_std = 0.1568 vf_loss = 0.0637 grad_norm = 2.7989 nat_grad_norm = 0.1148 cg_residual = 1.2098 step_size = 0.4258 reward = -0.0000 fps = 7 mse_loss = 0.3166 
2022-05-01 13:44:05.575125 - gail/main.py:164 - [TRPO] iter = 1673000 dist_mean = 0.0436 dist_std = 0.1572 vf_loss = 0.0668 grad_norm = 2.5720 nat_grad_norm = 0.0940 cg_residual = 1.2160 step_size = 0.4988 reward = 0.0000 fps = 6 mse_loss = 0.3652 
2022-05-01 13:44:15.529658 - gail/main.py:164 - [TRPO] iter = 1674000 dist_mean = 0.0387 dist_std = 0.1569 vf_loss = 0.1630 grad_norm = 2.6569 nat_grad_norm = 0.0831 cg_residual = 1.1969 step_size = 0.5513 reward = -0.0000 fps = 6 mse_loss = 0.3379 
2022-05-01 13:44:25.584967 - gail/main.py:164 - [TRPO] iter = 1675000 dist_mean = 0.0281 dist_std = 0.1572 vf_loss = 0.0552 grad_norm = 2.1337 nat_grad_norm = 0.0988 cg_residual = 0.8202 step_size = 0.4935 reward = 0.0000 fps = 5 mse_loss = 0.3616 
2022-05-01 13:44:25.857288 - gail/main.py:191 - [Discriminator] iter = 1675000 loss = -0.3947 grad_norm = 3.4884 grad_penalty = 0.0542 regularization = 0.0000 true_logits = 0.4059 fake_logits = -0.0430 true_prob = 0.5886 fake_prob = 0.4924 
2022-05-01 13:46:36.111553 - gail/main.py:132 - [Evaluate] iter = 1675000 episode={ returns = 3628.4975 lengths = 1000 } discounted_episode={ returns = 2228.7232 lengths = 1000 } 
2022-05-01 13:46:45.997688 - gail/main.py:164 - [TRPO] iter = 1676000 dist_mean = 0.0374 dist_std = 0.1571 vf_loss = 0.0439 grad_norm = 2.6346 nat_grad_norm = 0.0848 cg_residual = 1.7299 step_size = 0.4576 reward = 0.0000 fps = 7 mse_loss = 0.3773 
2022-05-01 13:46:55.873065 - gail/main.py:164 - [TRPO] iter = 1677000 dist_mean = 0.0484 dist_std = 0.1578 vf_loss = 0.0479 grad_norm = 2.6068 nat_grad_norm = 0.1131 cg_residual = 2.0113 step_size = 0.4614 reward = 0.0000 fps = 6 mse_loss = 0.3379 
2022-05-01 13:47:06.046096 - gail/main.py:164 - [TRPO] iter = 1678000 dist_mean = 0.0199 dist_std = 0.1582 vf_loss = 0.0410 grad_norm = 3.2912 nat_grad_norm = 0.1037 cg_residual = 1.2490 step_size = 0.4382 reward = -0.0000 fps = 6 mse_loss = 0.3018 
2022-05-01 13:47:15.840555 - gail/main.py:164 - [TRPO] iter = 1679000 dist_mean = 0.0450 dist_std = 0.1576 vf_loss = 0.0621 grad_norm = 3.7720 nat_grad_norm = 0.0629 cg_residual = 2.6656 step_size = 0.6006 reward = 0.0000 fps = 5 mse_loss = 0.3349 
2022-05-01 13:47:25.391962 - gail/main.py:164 - [TRPO] iter = 1680000 dist_mean = 0.0718 dist_std = 0.1579 vf_loss = 0.0380 grad_norm = 3.1502 nat_grad_norm = 0.1198 cg_residual = 1.0634 step_size = 0.4187 reward = 0.0000 fps = 5 mse_loss = 0.3545 
2022-05-01 13:47:25.669706 - gail/main.py:191 - [Discriminator] iter = 1680000 loss = -0.6067 grad_norm = 4.5396 grad_penalty = 0.0675 regularization = 0.0000 true_logits = 0.2070 fake_logits = -0.4672 true_prob = 0.5471 fake_prob = 0.4052 
2022-05-01 13:49:02.806306 - gail/main.py:132 - [Evaluate] iter = 1680000 episode={ returns = 2854.9772 lengths = 812 } discounted_episode={ returns = 1571.3231 lengths = 676 } 
2022-05-01 13:49:12.732426 - gail/main.py:164 - [TRPO] iter = 1681000 dist_mean = 0.0400 dist_std = 0.1571 vf_loss = 0.0657 grad_norm = 3.5666 nat_grad_norm = 0.1077 cg_residual = 1.0122 step_size = 0.3947 reward = -0.0000 fps = 9 mse_loss = 0.3845 
2022-05-01 13:49:22.311339 - gail/main.py:164 - [TRPO] iter = 1682000 dist_mean = 0.1145 dist_std = 0.1572 vf_loss = 0.0541 grad_norm = 3.3709 nat_grad_norm = 0.1176 cg_residual = 1.3624 step_size = 0.3819 reward = -0.0000 fps = 8 mse_loss = 0.3458 
2022-05-01 13:49:31.979888 - gail/main.py:164 - [TRPO] iter = 1683000 dist_mean = 0.0501 dist_std = 0.1568 vf_loss = 0.2887 grad_norm = 3.2221 nat_grad_norm = 0.0885 cg_residual = 1.1268 step_size = 0.4803 reward = 0.0000 fps = 7 mse_loss = 0.3500 
2022-05-01 13:49:41.369427 - gail/main.py:164 - [TRPO] iter = 1684000 dist_mean = 0.0287 dist_std = 0.1569 vf_loss = 0.1477 grad_norm = 3.3533 nat_grad_norm = 0.0753 cg_residual = 2.0576 step_size = 0.5417 reward = 0.0000 fps = 7 mse_loss = 0.3639 
2022-05-01 13:49:51.031924 - gail/main.py:164 - [TRPO] iter = 1685000 dist_mean = 0.0477 dist_std = 0.1563 vf_loss = 0.0776 grad_norm = 2.8136 nat_grad_norm = 0.1145 cg_residual = 1.5663 step_size = 0.3682 reward = 0.0000 fps = 6 mse_loss = 0.3171 
2022-05-01 13:49:51.270033 - gail/main.py:191 - [Discriminator] iter = 1685000 loss = -0.3698 grad_norm = 4.2847 grad_penalty = 0.0661 regularization = 0.0000 true_logits = 0.0407 fake_logits = -0.3952 true_prob = 0.5114 fake_prob = 0.4240 
2022-05-01 13:51:45.504864 - gail/main.py:132 - [Evaluate] iter = 1685000 episode={ returns = 2936.0252 lengths = 831 } discounted_episode={ returns = 2085.1186 lengths = 934 } 
2022-05-01 13:51:55.037189 - gail/main.py:164 - [TRPO] iter = 1686000 dist_mean = 0.0244 dist_std = 0.1563 vf_loss = 0.0861 grad_norm = 3.4387 nat_grad_norm = 0.1080 cg_residual = 1.3706 step_size = 0.4027 reward = -0.0000 fps = 8 mse_loss = 0.3591 
2022-05-01 13:52:04.516637 - gail/main.py:164 - [TRPO] iter = 1687000 dist_mean = 0.0409 dist_std = 0.1566 vf_loss = 0.2171 grad_norm = 3.6642 nat_grad_norm = 0.1120 cg_residual = 1.7137 step_size = 0.3722 reward = -0.0000 fps = 7 mse_loss = 0.3242 
2022-05-01 13:52:14.134016 - gail/main.py:164 - [TRPO] iter = 1688000 dist_mean = 0.0185 dist_std = 0.1562 vf_loss = 0.0901 grad_norm = 3.2910 nat_grad_norm = 0.1019 cg_residual = 0.8745 step_size = 0.4693 reward = 0.0000 fps = 7 mse_loss = 0.3562 
2022-05-01 13:52:23.752313 - gail/main.py:164 - [TRPO] iter = 1689000 dist_mean = 0.0467 dist_std = 0.1562 vf_loss = 0.1318 grad_norm = 2.1887 nat_grad_norm = 0.1203 cg_residual = 1.7052 step_size = 0.3825 reward = 0.0000 fps = 6 mse_loss = 0.3740 
2022-05-01 13:52:33.249107 - gail/main.py:164 - [TRPO] iter = 1690000 dist_mean = 0.0253 dist_std = 0.1566 vf_loss = 0.1336 grad_norm = 4.0740 nat_grad_norm = 0.0824 cg_residual = 1.5344 step_size = 0.4769 reward = 0.0000 fps = 6 mse_loss = 0.3329 
2022-05-01 13:52:33.463439 - gail/main.py:191 - [Discriminator] iter = 1690000 loss = -0.1826 grad_norm = 3.7835 grad_penalty = 0.0542 regularization = 0.0000 true_logits = -0.0443 fake_logits = -0.2812 true_prob = 0.4939 fake_prob = 0.4426 
2022-05-01 13:53:54.006368 - gail/main.py:132 - [Evaluate] iter = 1690000 episode={ returns = 2129.2402 lengths = 605 } discounted_episode={ returns = 1575.6508 lengths = 625 } 
2022-05-01 13:54:03.570433 - gail/main.py:164 - [TRPO] iter = 1691000 dist_mean = 0.0102 dist_std = 0.1560 vf_loss = 0.0903 grad_norm = 3.2693 nat_grad_norm = 0.1053 cg_residual = 1.6645 step_size = 0.3939 reward = -0.0000 fps = 11 mse_loss = 0.3435 
2022-05-01 13:54:13.420560 - gail/main.py:164 - [TRPO] iter = 1692000 dist_mean = 0.0263 dist_std = 0.1562 vf_loss = 0.0931 grad_norm = 2.2399 nat_grad_norm = 0.1245 cg_residual = 1.1293 step_size = 0.4018 reward = -0.0000 fps = 10 mse_loss = 0.3460 
2022-05-01 13:54:23.443587 - gail/main.py:164 - [TRPO] iter = 1693000 dist_mean = 0.0400 dist_std = 0.1562 vf_loss = 0.1146 grad_norm = 1.8863 nat_grad_norm = 0.1008 cg_residual = 1.0047 step_size = 0.4916 reward = -0.0000 fps = 9 mse_loss = 0.3018 
2022-05-01 13:54:32.783854 - gail/main.py:164 - [TRPO] iter = 1694000 dist_mean = 0.0297 dist_std = 0.1562 vf_loss = 0.0849 grad_norm = 2.5094 nat_grad_norm = 0.1211 cg_residual = 1.6370 step_size = 0.3973 reward = -0.0000 fps = 8 mse_loss = 0.3005 
2022-05-01 13:54:42.719787 - gail/main.py:164 - [TRPO] iter = 1695000 dist_mean = 0.0360 dist_std = 0.1561 vf_loss = 0.0925 grad_norm = 3.4532 nat_grad_norm = 0.0907 cg_residual = 1.4026 step_size = 0.3884 reward = 0.0000 fps = 7 mse_loss = 0.3359 
2022-05-01 13:54:42.929409 - gail/main.py:191 - [Discriminator] iter = 1695000 loss = -0.3496 grad_norm = 3.3600 grad_penalty = 0.0470 regularization = 0.0000 true_logits = 0.0353 fake_logits = -0.3612 true_prob = 0.5105 fake_prob = 0.4265 
2022-05-01 13:55:41.668743 - gail/main.py:132 - [Evaluate] iter = 1695000 episode={ returns = 1579.1245 lengths = 457 } discounted_episode={ returns = 1222.3839 lengths = 448 } 
2022-05-01 13:55:51.736826 - gail/main.py:164 - [TRPO] iter = 1696000 dist_mean = 0.0153 dist_std = 0.1563 vf_loss = 0.1297 grad_norm = 2.7006 nat_grad_norm = 0.1157 cg_residual = 1.1271 step_size = 0.4178 reward = -0.0000 fps = 14 mse_loss = 0.3946 
2022-05-01 13:56:01.532887 - gail/main.py:164 - [TRPO] iter = 1697000 dist_mean = 0.0540 dist_std = 0.1566 vf_loss = 0.0836 grad_norm = 2.4023 nat_grad_norm = 0.1029 cg_residual = 1.0201 step_size = 0.4372 reward = -0.0000 fps = 12 mse_loss = 0.3532 
2022-05-01 13:56:11.113871 - gail/main.py:164 - [TRPO] iter = 1698000 dist_mean = 0.0258 dist_std = 0.1564 vf_loss = 0.0983 grad_norm = 3.5220 nat_grad_norm = 0.1102 cg_residual = 2.5668 step_size = 0.4265 reward = 0.0000 fps = 11 mse_loss = 0.3457 
2022-05-01 13:56:20.998109 - gail/main.py:164 - [TRPO] iter = 1699000 dist_mean = 0.0139 dist_std = 0.1562 vf_loss = 0.0736 grad_norm = 4.9181 nat_grad_norm = 0.1114 cg_residual = 1.7302 step_size = 0.3835 reward = 0.0000 fps = 10 mse_loss = 0.3502 
2022-05-01 13:56:30.783465 - gail/main.py:164 - [TRPO] iter = 1700000 dist_mean = 0.0363 dist_std = 0.1560 vf_loss = 0.0862 grad_norm = 4.5352 nat_grad_norm = 0.1160 cg_residual = 1.8985 step_size = 0.3742 reward = -0.0000 fps = 9 mse_loss = 0.3231 
2022-05-01 13:56:31.011392 - gail/main.py:191 - [Discriminator] iter = 1700000 loss = -0.4130 grad_norm = 3.7325 grad_penalty = 0.0510 regularization = 0.0000 true_logits = 0.1302 fake_logits = -0.3338 true_prob = 0.5319 fake_prob = 0.4329 
2022-05-01 13:57:41.877404 - gail/main.py:132 - [Evaluate] iter = 1700000 episode={ returns = 1954.8365 lengths = 551 } discounted_episode={ returns = 1432.6316 lengths = 540 } 
2022-05-01 13:57:51.694904 - gail/main.py:164 - [TRPO] iter = 1701000 dist_mean = 0.0314 dist_std = 0.1560 vf_loss = 0.1000 grad_norm = 2.0291 nat_grad_norm = 0.1140 cg_residual = 4.2425 step_size = 0.4302 reward = 0.0000 fps = 12 mse_loss = 0.3302 
2022-05-01 13:58:01.329652 - gail/main.py:164 - [TRPO] iter = 1702000 dist_mean = 0.0336 dist_std = 0.1563 vf_loss = 0.0866 grad_norm = 2.6545 nat_grad_norm = 0.1006 cg_residual = 1.9063 step_size = 0.4452 reward = 0.0000 fps = 11 mse_loss = 0.3571 
2022-05-01 13:58:11.176591 - gail/main.py:164 - [TRPO] iter = 1703000 dist_mean = 0.0212 dist_std = 0.1562 vf_loss = 0.1195 grad_norm = 5.2962 nat_grad_norm = 0.0812 cg_residual = 1.1076 step_size = 0.4505 reward = -0.0000 fps = 9 mse_loss = 0.3554 
2022-05-01 13:58:21.097288 - gail/main.py:164 - [TRPO] iter = 1704000 dist_mean = 0.0224 dist_std = 0.1564 vf_loss = 0.0488 grad_norm = 2.5792 nat_grad_norm = 0.0995 cg_residual = 1.4394 step_size = 0.5025 reward = -0.0000 fps = 9 mse_loss = 0.3452 
2022-05-01 13:58:31.005637 - gail/main.py:164 - [TRPO] iter = 1705000 dist_mean = 0.0193 dist_std = 0.1558 vf_loss = 0.0577 grad_norm = 3.4856 nat_grad_norm = 0.1105 cg_residual = 1.4323 step_size = 0.3729 reward = -0.0000 fps = 8 mse_loss = 0.3162 
2022-05-01 13:58:31.235716 - gail/main.py:191 - [Discriminator] iter = 1705000 loss = -0.2716 grad_norm = 3.5061 grad_penalty = 0.0540 regularization = 0.0000 true_logits = 0.0796 fake_logits = -0.2460 true_prob = 0.5204 fake_prob = 0.4487 
2022-05-01 14:00:04.676593 - gail/main.py:132 - [Evaluate] iter = 1705000 episode={ returns = 2269.3828 lengths = 642 } discounted_episode={ returns = 1806.4881 lengths = 763 } 
2022-05-01 14:00:14.908382 - gail/main.py:164 - [TRPO] iter = 1706000 dist_mean = 0.0429 dist_std = 0.1561 vf_loss = 0.1762 grad_norm = 2.2118 nat_grad_norm = 0.0721 cg_residual = 0.8106 step_size = 0.5563 reward = -0.0000 fps = 9 mse_loss = 0.3527 
2022-05-01 14:00:24.709522 - gail/main.py:164 - [TRPO] iter = 1707000 dist_mean = 0.0449 dist_std = 0.1564 vf_loss = 0.0662 grad_norm = 3.6950 nat_grad_norm = 0.0934 cg_residual = 0.8756 step_size = 0.4584 reward = -0.0000 fps = 8 mse_loss = 0.3313 
2022-05-01 14:00:34.479193 - gail/main.py:164 - [TRPO] iter = 1708000 dist_mean = 0.0360 dist_std = 0.1563 vf_loss = 0.0474 grad_norm = 3.2402 nat_grad_norm = 0.1027 cg_residual = 1.7238 step_size = 0.4115 reward = 0.0000 fps = 8 mse_loss = 0.3133 
2022-05-01 14:00:44.128781 - gail/main.py:164 - [TRPO] iter = 1709000 dist_mean = 0.0195 dist_std = 0.1562 vf_loss = 0.0918 grad_norm = 2.5506 nat_grad_norm = 0.1042 cg_residual = 1.3836 step_size = 0.4538 reward = -0.0000 fps = 7 mse_loss = 0.3601 
2022-05-01 14:00:53.602608 - gail/main.py:164 - [TRPO] iter = 1710000 dist_mean = 0.0156 dist_std = 0.1560 vf_loss = 0.1905 grad_norm = 3.1905 nat_grad_norm = 0.1110 cg_residual = 1.5581 step_size = 0.4701 reward = 0.0000 fps = 7 mse_loss = 0.3431 
2022-05-01 14:00:53.822252 - gail/main.py:191 - [Discriminator] iter = 1710000 loss = -0.4469 grad_norm = 4.5898 grad_penalty = 0.0529 regularization = 0.0000 true_logits = 0.0671 fake_logits = -0.4327 true_prob = 0.5172 fake_prob = 0.4043 
2022-05-01 14:02:51.629465 - gail/main.py:132 - [Evaluate] iter = 1710000 episode={ returns = 3283.5515 lengths = 921 } discounted_episode={ returns = 2016.6792 lengths = 892 } 
2022-05-01 14:03:00.970865 - gail/main.py:164 - [TRPO] iter = 1711000 dist_mean = 0.0438 dist_std = 0.1556 vf_loss = 0.1888 grad_norm = 3.4343 nat_grad_norm = 0.1001 cg_residual = 4.8436 step_size = 0.4337 reward = -0.0000 fps = 7 mse_loss = 0.3960 
2022-05-01 14:03:10.500483 - gail/main.py:164 - [TRPO] iter = 1712000 dist_mean = 0.0220 dist_std = 0.1555 vf_loss = 0.1230 grad_norm = 2.9247 nat_grad_norm = 0.0772 cg_residual = 0.7673 step_size = 0.5803 reward = 0.0000 fps = 7 mse_loss = 0.3194 
2022-05-01 14:03:19.956684 - gail/main.py:164 - [TRPO] iter = 1713000 dist_mean = 0.0077 dist_std = 0.1552 vf_loss = 0.1123 grad_norm = 3.0753 nat_grad_norm = 0.0909 cg_residual = 1.5595 step_size = 0.4588 reward = 0.0000 fps = 6 mse_loss = 0.3585 
2022-05-01 14:03:29.546876 - gail/main.py:164 - [TRPO] iter = 1714000 dist_mean = 0.0205 dist_std = 0.1547 vf_loss = 0.0984 grad_norm = 2.6708 nat_grad_norm = 0.1119 cg_residual = 1.7534 step_size = 0.4272 reward = 0.0000 fps = 6 mse_loss = 0.3638 
2022-05-01 14:03:39.536861 - gail/main.py:164 - [TRPO] iter = 1715000 dist_mean = 0.0321 dist_std = 0.1546 vf_loss = 0.1398 grad_norm = 4.3645 nat_grad_norm = 0.0975 cg_residual = 0.9128 step_size = 0.4359 reward = -0.0000 fps = 6 mse_loss = 0.3359 
2022-05-01 14:03:39.777830 - gail/main.py:191 - [Discriminator] iter = 1715000 loss = -0.2645 grad_norm = 3.3954 grad_penalty = 0.0434 regularization = 0.0000 true_logits = 0.0989 fake_logits = -0.2091 true_prob = 0.5245 fake_prob = 0.4550 
2022-05-01 14:05:24.155006 - gail/main.py:132 - [Evaluate] iter = 1715000 episode={ returns = 2762.7824 lengths = 784 } discounted_episode={ returns = 1891.0672 lengths = 813 } 
2022-05-01 14:05:33.949874 - gail/main.py:164 - [TRPO] iter = 1716000 dist_mean = 0.0088 dist_std = 0.1549 vf_loss = 0.0778 grad_norm = 3.9343 nat_grad_norm = 0.0906 cg_residual = 1.1211 step_size = 0.4954 reward = -0.0000 fps = 8 mse_loss = 0.3414 
2022-05-01 14:05:43.456162 - gail/main.py:164 - [TRPO] iter = 1717000 dist_mean = 0.0151 dist_std = 0.1550 vf_loss = 0.1393 grad_norm = 3.7217 nat_grad_norm = 0.0823 cg_residual = 1.1446 step_size = 0.4672 reward = -0.0000 fps = 8 mse_loss = 0.3590 
2022-05-01 14:05:53.415070 - gail/main.py:164 - [TRPO] iter = 1718000 dist_mean = 0.0243 dist_std = 0.1553 vf_loss = 0.0979 grad_norm = 3.0566 nat_grad_norm = 0.1130 cg_residual = 6.8652 step_size = 0.4090 reward = 0.0000 fps = 7 mse_loss = 0.3539 
2022-05-01 14:06:03.350512 - gail/main.py:164 - [TRPO] iter = 1719000 dist_mean = 0.0272 dist_std = 0.1549 vf_loss = 0.1210 grad_norm = 4.6621 nat_grad_norm = 0.1079 cg_residual = 2.0602 step_size = 0.4024 reward = -0.0000 fps = 6 mse_loss = 0.3431 
2022-05-01 14:06:13.008782 - gail/main.py:164 - [TRPO] iter = 1720000 dist_mean = 0.0290 dist_std = 0.1552 vf_loss = 0.0651 grad_norm = 2.9265 nat_grad_norm = 0.0859 cg_residual = 2.6076 step_size = 0.5128 reward = 0.0000 fps = 6 mse_loss = 0.3599 
2022-05-01 14:06:13.275146 - gail/main.py:191 - [Discriminator] iter = 1720000 loss = -0.2703 grad_norm = 2.8815 grad_penalty = 0.0436 regularization = 0.0000 true_logits = 0.1090 fake_logits = -0.2049 true_prob = 0.5259 fake_prob = 0.4550 
2022-05-01 14:08:24.419739 - gail/main.py:132 - [Evaluate] iter = 1720000 episode={ returns = 3576.0701 lengths = 999 } discounted_episode={ returns = 2200.0937 lengths = 997 } 
2022-05-01 14:08:33.791858 - gail/main.py:164 - [TRPO] iter = 1721000 dist_mean = 0.0243 dist_std = 0.1550 vf_loss = 0.0365 grad_norm = 3.1629 nat_grad_norm = 0.1015 cg_residual = 1.3065 step_size = 0.4292 reward = 0.0000 fps = 7 mse_loss = 0.3640 
2022-05-01 14:08:43.458406 - gail/main.py:164 - [TRPO] iter = 1722000 dist_mean = 0.0137 dist_std = 0.1555 vf_loss = 0.0502 grad_norm = 3.0673 nat_grad_norm = 0.1061 cg_residual = 2.6175 step_size = 0.3983 reward = 0.0000 fps = 6 mse_loss = 0.3634 
2022-05-01 14:08:53.382436 - gail/main.py:164 - [TRPO] iter = 1723000 dist_mean = 0.0109 dist_std = 0.1553 vf_loss = 0.0777 grad_norm = 2.6157 nat_grad_norm = 0.0918 cg_residual = 0.9424 step_size = 0.4815 reward = 0.0000 fps = 6 mse_loss = 0.3679 
2022-05-01 14:09:03.488709 - gail/main.py:164 - [TRPO] iter = 1724000 dist_mean = 0.0246 dist_std = 0.1555 vf_loss = 0.0743 grad_norm = 4.5005 nat_grad_norm = 0.1127 cg_residual = 1.7409 step_size = 0.3748 reward = 0.0000 fps = 5 mse_loss = 0.3074 
2022-05-01 14:09:12.926418 - gail/main.py:164 - [TRPO] iter = 1725000 dist_mean = 0.0350 dist_std = 0.1558 vf_loss = 0.0696 grad_norm = 1.7982 nat_grad_norm = 0.0922 cg_residual = 1.6769 step_size = 0.5153 reward = -0.0000 fps = 5 mse_loss = 0.3271 
2022-05-01 14:09:13.171803 - gail/main.py:191 - [Discriminator] iter = 1725000 loss = -0.3521 grad_norm = 3.4041 grad_penalty = 0.0540 regularization = 0.0000 true_logits = 0.0743 fake_logits = -0.3318 true_prob = 0.5178 fake_prob = 0.4315 
2022-05-01 14:11:25.206385 - gail/main.py:132 - [Evaluate] iter = 1725000 episode={ returns = 3609.9598 lengths = 1000 } discounted_episode={ returns = 2222.9459 lengths = 1000 } 
2022-05-01 14:11:35.016108 - gail/main.py:164 - [TRPO] iter = 1726000 dist_mean = 0.0139 dist_std = 0.1563 vf_loss = 0.1722 grad_norm = 3.0157 nat_grad_norm = 0.0771 cg_residual = 1.2804 step_size = 0.5437 reward = -0.0000 fps = 7 mse_loss = 0.3266 
2022-05-01 14:11:45.033891 - gail/main.py:164 - [TRPO] iter = 1727000 dist_mean = 0.0137 dist_std = 0.1564 vf_loss = 0.0334 grad_norm = 2.4800 nat_grad_norm = 0.1057 cg_residual = 1.3055 step_size = 0.4488 reward = -0.0000 fps = 6 mse_loss = 0.3486 
2022-05-01 14:11:54.872044 - gail/main.py:164 - [TRPO] iter = 1728000 dist_mean = 0.0191 dist_std = 0.1562 vf_loss = 0.0708 grad_norm = 3.3873 nat_grad_norm = 0.0896 cg_residual = 2.8122 step_size = 0.4256 reward = 0.0000 fps = 6 mse_loss = 0.3383 
2022-05-01 14:12:04.572397 - gail/main.py:164 - [TRPO] iter = 1729000 dist_mean = 0.0224 dist_std = 0.1564 vf_loss = 0.0568 grad_norm = 3.1625 nat_grad_norm = 0.1079 cg_residual = 3.2915 step_size = 0.4165 reward = -0.0000 fps = 5 mse_loss = 0.3632 
2022-05-01 14:12:14.113431 - gail/main.py:164 - [TRPO] iter = 1730000 dist_mean = 0.0266 dist_std = 0.1568 vf_loss = 0.1419 grad_norm = 2.2962 nat_grad_norm = 0.0620 cg_residual = 2.5391 step_size = 0.6795 reward = 0.0000 fps = 5 mse_loss = 0.3203 
2022-05-01 14:12:14.351181 - gail/main.py:191 - [Discriminator] iter = 1730000 loss = -0.2605 grad_norm = 3.2109 grad_penalty = 0.0436 regularization = 0.0000 true_logits = 0.1315 fake_logits = -0.1725 true_prob = 0.5306 fake_prob = 0.4624 
2022-05-01 14:14:16.188655 - gail/main.py:132 - [Evaluate] iter = 1730000 episode={ returns = 3491.4210 lengths = 959 } discounted_episode={ returns = 2137.0288 lengths = 938 } 
2022-05-01 14:14:25.687275 - gail/main.py:164 - [TRPO] iter = 1731000 dist_mean = 0.0111 dist_std = 0.1564 vf_loss = 0.0296 grad_norm = 3.6496 nat_grad_norm = 0.0995 cg_residual = 1.5224 step_size = 0.4123 reward = -0.0000 fps = 7 mse_loss = 0.3222 
2022-05-01 14:14:35.339717 - gail/main.py:164 - [TRPO] iter = 1732000 dist_mean = 0.0385 dist_std = 0.1565 vf_loss = 0.0361 grad_norm = 3.1876 nat_grad_norm = 0.1180 cg_residual = 3.1994 step_size = 0.3760 reward = -0.0000 fps = 7 mse_loss = 0.3270 
2022-05-01 14:14:45.137682 - gail/main.py:164 - [TRPO] iter = 1733000 dist_mean = 0.0166 dist_std = 0.1563 vf_loss = 0.1111 grad_norm = 1.9954 nat_grad_norm = 0.0807 cg_residual = 0.6659 step_size = 0.5574 reward = 0.0000 fps = 6 mse_loss = 0.3241 
2022-05-01 14:14:54.846510 - gail/main.py:164 - [TRPO] iter = 1734000 dist_mean = 0.0050 dist_std = 0.1558 vf_loss = 0.0397 grad_norm = 4.7647 nat_grad_norm = 0.0771 cg_residual = 1.4107 step_size = 0.4859 reward = 0.0000 fps = 6 mse_loss = 0.3422 
2022-05-01 14:15:04.523072 - gail/main.py:164 - [TRPO] iter = 1735000 dist_mean = 0.0234 dist_std = 0.1558 vf_loss = 0.0494 grad_norm = 2.9320 nat_grad_norm = 0.1239 cg_residual = 2.5017 step_size = 0.4035 reward = 0.0000 fps = 5 mse_loss = 0.3232 
2022-05-01 14:15:04.719800 - gail/main.py:191 - [Discriminator] iter = 1735000 loss = -0.4252 grad_norm = 3.9598 grad_penalty = 0.0544 regularization = 0.0000 true_logits = 0.1595 fake_logits = -0.3202 true_prob = 0.5373 fake_prob = 0.4326 
2022-05-01 14:16:42.429169 - gail/main.py:132 - [Evaluate] iter = 1735000 episode={ returns = 2734.3991 lengths = 756 } discounted_episode={ returns = 1848.9852 lengths = 758 } 
2022-05-01 14:16:52.178173 - gail/main.py:164 - [TRPO] iter = 1736000 dist_mean = 0.0378 dist_std = 0.1556 vf_loss = 0.0490 grad_norm = 3.1844 nat_grad_norm = 0.0980 cg_residual = 0.9665 step_size = 0.4430 reward = 0.0000 fps = 9 mse_loss = 0.3324 
2022-05-01 14:17:01.923851 - gail/main.py:164 - [TRPO] iter = 1737000 dist_mean = 0.0369 dist_std = 0.1558 vf_loss = 0.0320 grad_norm = 2.9976 nat_grad_norm = 0.0984 cg_residual = 1.4032 step_size = 0.4513 reward = 0.0000 fps = 8 mse_loss = 0.3251 
2022-05-01 14:17:11.569841 - gail/main.py:164 - [TRPO] iter = 1738000 dist_mean = 0.0289 dist_std = 0.1559 vf_loss = 0.0537 grad_norm = 3.0247 nat_grad_norm = 0.1168 cg_residual = 4.3494 step_size = 0.4112 reward = -0.0000 fps = 7 mse_loss = 0.3817 
2022-05-01 14:17:21.289858 - gail/main.py:164 - [TRPO] iter = 1739000 dist_mean = 0.0300 dist_std = 0.1560 vf_loss = 0.0449 grad_norm = 5.5320 nat_grad_norm = 0.0935 cg_residual = 1.2260 step_size = 0.4286 reward = -0.0000 fps = 7 mse_loss = 0.3093 
2022-05-01 14:17:30.907496 - gail/main.py:164 - [TRPO] iter = 1740000 dist_mean = 0.0426 dist_std = 0.1562 vf_loss = 0.1442 grad_norm = 2.5325 nat_grad_norm = 0.0869 cg_residual = 0.8265 step_size = 0.5222 reward = 0.0000 fps = 6 mse_loss = 0.3383 
2022-05-01 14:17:31.124040 - gail/main.py:191 - [Discriminator] iter = 1740000 loss = -0.2004 grad_norm = 4.7678 grad_penalty = 0.0531 regularization = 0.0000 true_logits = 0.1621 fake_logits = -0.0915 true_prob = 0.5369 fake_prob = 0.4818 
2022-05-01 14:19:35.269384 - gail/main.py:132 - [Evaluate] iter = 1740000 episode={ returns = 3357.9897 lengths = 925 } discounted_episode={ returns = 2173.5871 lengths = 957 } 
2022-05-01 14:19:45.023391 - gail/main.py:164 - [TRPO] iter = 1741000 dist_mean = 0.0448 dist_std = 0.1562 vf_loss = 0.0966 grad_norm = 2.5212 nat_grad_norm = 0.0707 cg_residual = 0.7517 step_size = 0.6266 reward = 0.0000 fps = 7 mse_loss = 0.3429 
2022-05-01 14:19:54.735726 - gail/main.py:164 - [TRPO] iter = 1742000 dist_mean = 0.0433 dist_std = 0.1561 vf_loss = 0.0329 grad_norm = 4.0858 nat_grad_norm = 0.1060 cg_residual = 1.8360 step_size = 0.4654 reward = 0.0000 fps = 6 mse_loss = 0.3629 
2022-05-01 14:20:04.507945 - gail/main.py:164 - [TRPO] iter = 1743000 dist_mean = 0.0592 dist_std = 0.1560 vf_loss = 0.1130 grad_norm = 5.4896 nat_grad_norm = 0.0956 cg_residual = 5.2250 step_size = 0.4121 reward = -0.0000 fps = 6 mse_loss = 0.3346 
2022-05-01 14:20:14.259868 - gail/main.py:164 - [TRPO] iter = 1744000 dist_mean = 0.0578 dist_std = 0.1561 vf_loss = 0.0369 grad_norm = 3.1806 nat_grad_norm = 0.0987 cg_residual = 3.0720 step_size = 0.4090 reward = 0.0000 fps = 6 mse_loss = 0.3618 
2022-05-01 14:20:24.125785 - gail/main.py:164 - [TRPO] iter = 1745000 dist_mean = 0.0674 dist_std = 0.1558 vf_loss = 0.0966 grad_norm = 2.9712 nat_grad_norm = 0.0856 cg_residual = 1.1136 step_size = 0.4608 reward = 0.0000 fps = 5 mse_loss = 0.3455 
2022-05-01 14:20:24.345044 - gail/main.py:191 - [Discriminator] iter = 1745000 loss = -0.2182 grad_norm = 4.5334 grad_penalty = 0.0524 regularization = 0.0000 true_logits = 0.2213 fake_logits = -0.0492 true_prob = 0.5494 fake_prob = 0.4903 
2022-05-01 14:22:35.943847 - gail/main.py:132 - [Evaluate] iter = 1745000 episode={ returns = 3618.1391 lengths = 1000 } discounted_episode={ returns = 2233.1248 lengths = 1000 } 
2022-05-01 14:22:45.681074 - gail/main.py:164 - [TRPO] iter = 1746000 dist_mean = 0.0634 dist_std = 0.1554 vf_loss = 0.0838 grad_norm = 2.5881 nat_grad_norm = 0.0885 cg_residual = 1.2079 step_size = 0.4722 reward = 0.0000 fps = 7 mse_loss = 0.3205 
2022-05-01 14:22:55.528189 - gail/main.py:164 - [TRPO] iter = 1747000 dist_mean = 0.0687 dist_std = 0.1557 vf_loss = 0.0432 grad_norm = 3.4878 nat_grad_norm = 0.1059 cg_residual = 1.3859 step_size = 0.4518 reward = -0.0000 fps = 6 mse_loss = 0.3084 
2022-05-01 14:23:05.171268 - gail/main.py:164 - [TRPO] iter = 1748000 dist_mean = 0.0739 dist_std = 0.1564 vf_loss = 0.0632 grad_norm = 4.5710 nat_grad_norm = 0.0910 cg_residual = 1.1695 step_size = 0.4404 reward = 0.0000 fps = 6 mse_loss = 0.2967 
2022-05-01 14:23:15.191177 - gail/main.py:164 - [TRPO] iter = 1749000 dist_mean = 0.0894 dist_std = 0.1562 vf_loss = 0.0373 grad_norm = 3.4884 nat_grad_norm = 0.0942 cg_residual = 1.1895 step_size = 0.4052 reward = 0.0000 fps = 5 mse_loss = 0.2884 
2022-05-01 14:23:24.839544 - gail/main.py:164 - [TRPO] iter = 1750000 dist_mean = 0.0717 dist_std = 0.1564 vf_loss = 0.0793 grad_norm = 3.8125 nat_grad_norm = 0.0697 cg_residual = 1.4005 step_size = 0.5084 reward = -0.0000 fps = 5 mse_loss = 0.3143 
2022-05-01 14:23:25.072232 - gail/main.py:191 - [Discriminator] iter = 1750000 loss = -0.2164 grad_norm = 5.3144 grad_penalty = 0.0536 regularization = 0.0000 true_logits = 0.1477 fake_logits = -0.1223 true_prob = 0.5333 fake_prob = 0.4723 
2022-05-01 14:25:40.891395 - gail/main.py:132 - [Evaluate] iter = 1750000 episode={ returns = 3626.3520 lengths = 1000 } discounted_episode={ returns = 2233.3729 lengths = 1000 } 
2022-05-01 14:25:50.856163 - gail/main.py:164 - [TRPO] iter = 1751000 dist_mean = 0.0870 dist_std = 0.1562 vf_loss = 0.0352 grad_norm = 2.6923 nat_grad_norm = 0.1065 cg_residual = 0.7644 step_size = 0.4087 reward = -0.0000 fps = 6 mse_loss = 0.3176 
2022-05-01 14:26:00.561779 - gail/main.py:164 - [TRPO] iter = 1752000 dist_mean = 0.0858 dist_std = 0.1558 vf_loss = 0.0759 grad_norm = 4.1058 nat_grad_norm = 0.0922 cg_residual = 1.8219 step_size = 0.3913 reward = -0.0000 fps = 6 mse_loss = 0.3315 
2022-05-01 14:26:10.619991 - gail/main.py:164 - [TRPO] iter = 1753000 dist_mean = 0.0661 dist_std = 0.1557 vf_loss = 0.0380 grad_norm = 3.6265 nat_grad_norm = 0.0835 cg_residual = 5.3380 step_size = 0.4478 reward = 0.0000 fps = 6 mse_loss = 0.3308 
2022-05-01 14:26:20.577975 - gail/main.py:164 - [TRPO] iter = 1754000 dist_mean = 0.0884 dist_std = 0.1553 vf_loss = 0.0461 grad_norm = 2.9523 nat_grad_norm = 0.1145 cg_residual = 1.3228 step_size = 0.3783 reward = 0.0000 fps = 5 mse_loss = 0.2969 
2022-05-01 14:26:30.595795 - gail/main.py:164 - [TRPO] iter = 1755000 dist_mean = 0.0772 dist_std = 0.1554 vf_loss = 0.0398 grad_norm = 3.0137 nat_grad_norm = 0.0793 cg_residual = 0.9635 step_size = 0.4813 reward = 0.0000 fps = 5 mse_loss = 0.3118 
2022-05-01 14:26:30.816745 - gail/main.py:191 - [Discriminator] iter = 1755000 loss = -0.2479 grad_norm = 4.6733 grad_penalty = 0.0526 regularization = 0.0000 true_logits = 0.0645 fake_logits = -0.2360 true_prob = 0.5144 fake_prob = 0.4452 
2022-05-01 14:28:43.257921 - gail/main.py:132 - [Evaluate] iter = 1755000 episode={ returns = 3585.5784 lengths = 1000 } discounted_episode={ returns = 2207.3330 lengths = 1000 } 
2022-05-01 14:28:53.011885 - gail/main.py:164 - [TRPO] iter = 1756000 dist_mean = 0.0774 dist_std = 0.1552 vf_loss = 0.0316 grad_norm = 4.2017 nat_grad_norm = 0.0991 cg_residual = 2.3532 step_size = 0.3754 reward = 0.0000 fps = 7 mse_loss = 0.3055 
2022-05-01 14:29:02.399437 - gail/main.py:164 - [TRPO] iter = 1757000 dist_mean = 0.0747 dist_std = 0.1551 vf_loss = 0.0574 grad_norm = 3.4351 nat_grad_norm = 0.0865 cg_residual = 1.2262 step_size = 0.4260 reward = 0.0000 fps = 6 mse_loss = 0.3084 
2022-05-01 14:29:12.349229 - gail/main.py:164 - [TRPO] iter = 1758000 dist_mean = 0.0921 dist_std = 0.1548 vf_loss = 0.0904 grad_norm = 3.5153 nat_grad_norm = 0.1791 cg_residual = 2.8010 step_size = 0.2953 reward = -0.0000 fps = 6 mse_loss = 0.3373 
2022-05-01 14:29:21.937775 - gail/main.py:164 - [TRPO] iter = 1759000 dist_mean = 0.0712 dist_std = 0.1548 vf_loss = 0.0516 grad_norm = 2.7993 nat_grad_norm = 0.0907 cg_residual = 1.5013 step_size = 0.5127 reward = -0.0000 fps = 5 mse_loss = 0.3203 
2022-05-01 14:29:31.589050 - gail/main.py:164 - [TRPO] iter = 1760000 dist_mean = 0.0684 dist_std = 0.1545 vf_loss = 0.1022 grad_norm = 4.6244 nat_grad_norm = 0.0869 cg_residual = 1.0323 step_size = 0.4914 reward = 0.0000 fps = 5 mse_loss = 0.3312 
2022-05-01 14:29:31.844616 - gail/main.py:191 - [Discriminator] iter = 1760000 loss = -0.2720 grad_norm = 3.8960 grad_penalty = 0.0553 regularization = 0.0000 true_logits = -0.0646 fake_logits = -0.3919 true_prob = 0.4841 fake_prob = 0.4086 
2022-05-01 14:31:40.583168 - gail/main.py:132 - [Evaluate] iter = 1760000 episode={ returns = 3598.3053 lengths = 1000 } discounted_episode={ returns = 2220.0913 lengths = 1000 } 
2022-05-01 14:31:50.281840 - gail/main.py:164 - [TRPO] iter = 1761000 dist_mean = 0.0661 dist_std = 0.1545 vf_loss = 0.0479 grad_norm = 3.7270 nat_grad_norm = 0.0645 cg_residual = 0.6793 step_size = 0.4892 reward = 0.0000 fps = 7 mse_loss = 0.2997 
2022-05-01 14:31:59.679205 - gail/main.py:164 - [TRPO] iter = 1762000 dist_mean = 0.0565 dist_std = 0.1543 vf_loss = 0.0537 grad_norm = 3.6564 nat_grad_norm = 0.0958 cg_residual = 1.2654 step_size = 0.4023 reward = 0.0000 fps = 6 mse_loss = 0.3364 
2022-05-01 14:32:09.472538 - gail/main.py:164 - [TRPO] iter = 1763000 dist_mean = 0.0705 dist_std = 0.1541 vf_loss = 0.0492 grad_norm = 4.6984 nat_grad_norm = 0.0828 cg_residual = 1.4929 step_size = 0.4712 reward = 0.0000 fps = 6 mse_loss = 0.3357 
2022-05-01 14:32:19.199036 - gail/main.py:164 - [TRPO] iter = 1764000 dist_mean = 0.0722 dist_std = 0.1544 vf_loss = 0.1214 grad_norm = 2.3278 nat_grad_norm = 0.1082 cg_residual = 1.8657 step_size = 0.4856 reward = -0.0000 fps = 5 mse_loss = 0.3083 
2022-05-01 14:32:29.020532 - gail/main.py:164 - [TRPO] iter = 1765000 dist_mean = 0.0426 dist_std = 0.1546 vf_loss = 0.0455 grad_norm = 4.4239 nat_grad_norm = 0.0906 cg_residual = 1.4933 step_size = 0.4475 reward = 0.0000 fps = 5 mse_loss = 0.2962 
2022-05-01 14:32:29.229212 - gail/main.py:191 - [Discriminator] iter = 1765000 loss = -0.2847 grad_norm = 4.0841 grad_penalty = 0.0540 regularization = 0.0000 true_logits = -0.1307 fake_logits = -0.4695 true_prob = 0.4692 fake_prob = 0.3913 
2022-05-01 14:34:42.156342 - gail/main.py:132 - [Evaluate] iter = 1765000 episode={ returns = 3612.4415 lengths = 1000 } discounted_episode={ returns = 2230.1088 lengths = 1000 } 
2022-05-01 14:34:51.755006 - gail/main.py:164 - [TRPO] iter = 1766000 dist_mean = 0.0437 dist_std = 0.1549 vf_loss = 0.0558 grad_norm = 3.8142 nat_grad_norm = 0.1082 cg_residual = 1.6425 step_size = 0.3324 reward = 0.0000 fps = 7 mse_loss = 0.3266 
2022-05-01 14:35:01.236628 - gail/main.py:164 - [TRPO] iter = 1767000 dist_mean = 0.0640 dist_std = 0.1548 vf_loss = 0.0693 grad_norm = 3.2208 nat_grad_norm = 0.1103 cg_residual = 1.4758 step_size = 0.3691 reward = 0.0000 fps = 6 mse_loss = 0.3014 
2022-05-01 14:35:11.220253 - gail/main.py:164 - [TRPO] iter = 1768000 dist_mean = 0.0564 dist_std = 0.1549 vf_loss = 0.1412 grad_norm = 4.6307 nat_grad_norm = 0.0725 cg_residual = 4.4115 step_size = 0.4916 reward = 0.0000 fps = 6 mse_loss = 0.2935 
2022-05-01 14:35:21.059369 - gail/main.py:164 - [TRPO] iter = 1769000 dist_mean = 0.0284 dist_std = 0.1551 vf_loss = 0.1112 grad_norm = 3.1291 nat_grad_norm = 0.0990 cg_residual = 1.7925 step_size = 0.3957 reward = -0.0000 fps = 5 mse_loss = 0.3175 
2022-05-01 14:35:30.437720 - gail/main.py:164 - [TRPO] iter = 1770000 dist_mean = 0.0369 dist_std = 0.1551 vf_loss = 0.0736 grad_norm = 3.6104 nat_grad_norm = 0.0819 cg_residual = 0.7622 step_size = 0.5120 reward = 0.0000 fps = 5 mse_loss = 0.3409 
2022-05-01 14:35:30.667100 - gail/main.py:191 - [Discriminator] iter = 1770000 loss = -0.2596 grad_norm = 4.0708 grad_penalty = 0.0473 regularization = 0.0000 true_logits = -0.1213 fake_logits = -0.4282 true_prob = 0.4711 fake_prob = 0.3996 
2022-05-01 14:37:41.665576 - gail/main.py:132 - [Evaluate] iter = 1770000 episode={ returns = 3629.3287 lengths = 1000 } discounted_episode={ returns = 2238.3435 lengths = 1000 } 
2022-05-01 14:37:51.218589 - gail/main.py:164 - [TRPO] iter = 1771000 dist_mean = 0.0469 dist_std = 0.1547 vf_loss = 0.1096 grad_norm = 2.7576 nat_grad_norm = 0.0945 cg_residual = 3.0608 step_size = 0.4727 reward = -0.0000 fps = 7 mse_loss = 0.3084 
2022-05-01 14:38:00.825354 - gail/main.py:164 - [TRPO] iter = 1772000 dist_mean = 0.0439 dist_std = 0.1542 vf_loss = 0.0521 grad_norm = 2.6382 nat_grad_norm = 0.0913 cg_residual = 0.9235 step_size = 0.5248 reward = -0.0000 fps = 6 mse_loss = 0.2971 
2022-05-01 14:38:10.707222 - gail/main.py:164 - [TRPO] iter = 1773000 dist_mean = 0.0241 dist_std = 0.1543 vf_loss = 0.0936 grad_norm = 2.7362 nat_grad_norm = 0.0928 cg_residual = 0.8930 step_size = 0.4191 reward = 0.0000 fps = 6 mse_loss = 0.3668 
2022-05-01 14:38:20.427973 - gail/main.py:164 - [TRPO] iter = 1774000 dist_mean = 0.0116 dist_std = 0.1544 vf_loss = 0.1477 grad_norm = 4.2816 nat_grad_norm = 0.1191 cg_residual = 2.3325 step_size = 0.3776 reward = 0.0000 fps = 5 mse_loss = 0.3298 
2022-05-01 14:38:30.482725 - gail/main.py:164 - [TRPO] iter = 1775000 dist_mean = 0.0041 dist_std = 0.1545 vf_loss = 0.0859 grad_norm = 4.0178 nat_grad_norm = 0.0803 cg_residual = 3.1348 step_size = 0.4649 reward = -0.0000 fps = 5 mse_loss = 0.3305 
2022-05-01 14:38:30.704691 - gail/main.py:191 - [Discriminator] iter = 1775000 loss = -0.2203 grad_norm = 3.5702 grad_penalty = 0.0439 regularization = 0.0000 true_logits = -0.0893 fake_logits = -0.3535 true_prob = 0.4783 fake_prob = 0.4175 
2022-05-01 14:40:40.053656 - gail/main.py:132 - [Evaluate] iter = 1775000 episode={ returns = 3637.4333 lengths = 1000 } discounted_episode={ returns = 2250.3236 lengths = 1000 } 
2022-05-01 14:40:49.844782 - gail/main.py:164 - [TRPO] iter = 1776000 dist_mean = 0.0049 dist_std = 0.1548 vf_loss = 0.0609 grad_norm = 3.2947 nat_grad_norm = 0.1080 cg_residual = 2.2450 step_size = 0.4105 reward = 0.0000 fps = 7 mse_loss = 0.2924 
2022-05-01 14:40:59.818481 - gail/main.py:164 - [TRPO] iter = 1777000 dist_mean = 0.0273 dist_std = 0.1545 vf_loss = 0.0611 grad_norm = 3.3448 nat_grad_norm = 0.0982 cg_residual = 2.3543 step_size = 0.4229 reward = 0.0000 fps = 6 mse_loss = 0.2747 
2022-05-01 14:41:09.545388 - gail/main.py:164 - [TRPO] iter = 1778000 dist_mean = -0.0018 dist_std = 0.1545 vf_loss = 0.0986 grad_norm = 3.3481 nat_grad_norm = 0.0889 cg_residual = 3.8198 step_size = 0.4689 reward = 0.0000 fps = 6 mse_loss = 0.3410 
2022-05-01 14:41:19.336693 - gail/main.py:164 - [TRPO] iter = 1779000 dist_mean = -0.0092 dist_std = 0.1544 vf_loss = 0.0424 grad_norm = 2.8981 nat_grad_norm = 0.0975 cg_residual = 8.5490 step_size = 0.4121 reward = 0.0000 fps = 5 mse_loss = 0.2857 
2022-05-01 14:41:29.274714 - gail/main.py:164 - [TRPO] iter = 1780000 dist_mean = -0.0137 dist_std = 0.1542 vf_loss = 0.0442 grad_norm = 2.8512 nat_grad_norm = 0.0941 cg_residual = 3.1536 step_size = 0.4768 reward = -0.0000 fps = 5 mse_loss = 0.2917 
2022-05-01 14:41:29.527702 - gail/main.py:191 - [Discriminator] iter = 1780000 loss = -0.2438 grad_norm = 5.0797 grad_penalty = 0.0497 regularization = 0.0000 true_logits = -0.0193 fake_logits = -0.3127 true_prob = 0.4943 fake_prob = 0.4265 
2022-05-01 14:42:40.602213 - gail/main.py:132 - [Evaluate] iter = 1780000 episode={ returns = 2009.2193 lengths = 553 } discounted_episode={ returns = 1431.1983 lengths = 519 } 
2022-05-01 14:42:50.423235 - gail/main.py:164 - [TRPO] iter = 1781000 dist_mean = 0.0035 dist_std = 0.1541 vf_loss = 0.0647 grad_norm = 3.7649 nat_grad_norm = 0.0683 cg_residual = 3.6260 step_size = 0.5012 reward = -0.0000 fps = 12 mse_loss = 0.3062 
2022-05-01 14:42:59.838575 - gail/main.py:164 - [TRPO] iter = 1782000 dist_mean = -0.0054 dist_std = 0.1542 vf_loss = 0.0337 grad_norm = 3.5348 nat_grad_norm = 0.1115 cg_residual = 11.3329 step_size = 0.4049 reward = -0.0000 fps = 11 mse_loss = 0.3200 
2022-05-01 14:43:09.258256 - gail/main.py:164 - [TRPO] iter = 1783000 dist_mean = 0.0036 dist_std = 0.1543 vf_loss = 0.0473 grad_norm = 3.1810 nat_grad_norm = 0.0861 cg_residual = 1.1734 step_size = 0.4770 reward = 0.0000 fps = 10 mse_loss = 0.2599 
2022-05-01 14:43:19.333117 - gail/main.py:164 - [TRPO] iter = 1784000 dist_mean = -0.0036 dist_std = 0.1538 vf_loss = 0.0520 grad_norm = 3.9666 nat_grad_norm = 0.0938 cg_residual = 6.3131 step_size = 0.3902 reward = 0.0000 fps = 9 mse_loss = 0.2963 
2022-05-01 14:43:28.819803 - gail/main.py:164 - [TRPO] iter = 1785000 dist_mean = -0.0057 dist_std = 0.1535 vf_loss = 0.0753 grad_norm = 4.8324 nat_grad_norm = 0.1123 cg_residual = 1.5387 step_size = 0.3396 reward = -0.0000 fps = 8 mse_loss = 0.2935 
2022-05-01 14:43:29.100725 - gail/main.py:191 - [Discriminator] iter = 1785000 loss = -0.2710 grad_norm = 8.3056 grad_penalty = 0.0577 regularization = 0.0000 true_logits = -0.0171 fake_logits = -0.3458 true_prob = 0.4941 fake_prob = 0.4194 
2022-05-01 14:44:24.900533 - gail/main.py:132 - [Evaluate] iter = 1785000 episode={ returns = 1531.0089 lengths = 425 } discounted_episode={ returns = 1202.7269 lengths = 418 } 
2022-05-01 14:44:34.233614 - gail/main.py:164 - [TRPO] iter = 1786000 dist_mean = -0.0085 dist_std = 0.1536 vf_loss = 0.0603 grad_norm = 3.0858 nat_grad_norm = 0.0976 cg_residual = 1.6840 step_size = 0.3975 reward = 0.0000 fps = 15 mse_loss = 0.2876 
2022-05-01 14:44:43.884195 - gail/main.py:164 - [TRPO] iter = 1787000 dist_mean = 0.0055 dist_std = 0.1533 vf_loss = 0.0315 grad_norm = 3.2282 nat_grad_norm = 0.0990 cg_residual = 2.1679 step_size = 0.4213 reward = 0.0000 fps = 13 mse_loss = 0.2731 
2022-05-01 14:44:53.372825 - gail/main.py:164 - [TRPO] iter = 1788000 dist_mean = -0.0206 dist_std = 0.1534 vf_loss = 0.0354 grad_norm = 3.7483 nat_grad_norm = 0.1190 cg_residual = 7.6636 step_size = 0.3516 reward = -0.0000 fps = 11 mse_loss = 0.2592 
2022-05-01 14:45:03.088178 - gail/main.py:164 - [TRPO] iter = 1789000 dist_mean = -0.0184 dist_std = 0.1530 vf_loss = 0.0342 grad_norm = 4.7990 nat_grad_norm = 0.0865 cg_residual = 5.4873 step_size = 0.4364 reward = 0.0000 fps = 10 mse_loss = 0.2780 
2022-05-01 14:45:12.598797 - gail/main.py:164 - [TRPO] iter = 1790000 dist_mean = 0.0071 dist_std = 0.1529 vf_loss = 0.0341 grad_norm = 3.9658 nat_grad_norm = 0.0748 cg_residual = 5.8058 step_size = 0.5301 reward = 0.0000 fps = 9 mse_loss = 0.2889 
2022-05-01 14:45:12.830333 - gail/main.py:191 - [Discriminator] iter = 1790000 loss = -0.3212 grad_norm = 4.2932 grad_penalty = 0.0463 regularization = 0.0000 true_logits = 0.0154 fake_logits = -0.3521 true_prob = 0.5019 fake_prob = 0.4177 
2022-05-01 14:46:17.148759 - gail/main.py:132 - [Evaluate] iter = 1790000 episode={ returns = 1804.7018 lengths = 495 } discounted_episode={ returns = 1394.2085 lengths = 499 } 
2022-05-01 14:46:26.687309 - gail/main.py:164 - [TRPO] iter = 1791000 dist_mean = 0.0020 dist_std = 0.1524 vf_loss = 0.0272 grad_norm = 2.9109 nat_grad_norm = 0.0825 cg_residual = 2.8066 step_size = 0.4854 reward = 0.0000 fps = 13 mse_loss = 0.2842 
2022-05-01 14:46:36.260425 - gail/main.py:164 - [TRPO] iter = 1792000 dist_mean = 0.0079 dist_std = 0.1527 vf_loss = 0.0422 grad_norm = 2.7645 nat_grad_norm = 0.0698 cg_residual = 1.3486 step_size = 0.4761 reward = 0.0000 fps = 11 mse_loss = 0.2892 
2022-05-01 14:46:46.054645 - gail/main.py:164 - [TRPO] iter = 1793000 dist_mean = 0.0071 dist_std = 0.1523 vf_loss = 0.0326 grad_norm = 3.0934 nat_grad_norm = 0.0936 cg_residual = 2.0188 step_size = 0.4755 reward = -0.0000 fps = 10 mse_loss = 0.3027 
2022-05-01 14:46:55.536424 - gail/main.py:164 - [TRPO] iter = 1794000 dist_mean = -0.0109 dist_std = 0.1517 vf_loss = 0.0251 grad_norm = 4.4002 nat_grad_norm = 0.0930 cg_residual = 2.0236 step_size = 0.4394 reward = -0.0000 fps = 9 mse_loss = 0.2436 
2022-05-01 14:47:05.217199 - gail/main.py:164 - [TRPO] iter = 1795000 dist_mean = 0.0034 dist_std = 0.1518 vf_loss = 0.0567 grad_norm = 3.4632 nat_grad_norm = 0.0636 cg_residual = 2.7550 step_size = 0.5021 reward = -0.0000 fps = 8 mse_loss = 0.2936 
2022-05-01 14:47:05.432676 - gail/main.py:191 - [Discriminator] iter = 1795000 loss = -0.3020 grad_norm = 2.9481 grad_penalty = 0.0486 regularization = 0.0000 true_logits = 0.0652 fake_logits = -0.2854 true_prob = 0.5126 fake_prob = 0.4335 
2022-05-01 14:49:01.554581 - gail/main.py:132 - [Evaluate] iter = 1795000 episode={ returns = 3209.8617 lengths = 888 } discounted_episode={ returns = 2129.5002 lengths = 923 } 
2022-05-01 14:49:11.301961 - gail/main.py:164 - [TRPO] iter = 1796000 dist_mean = 0.0206 dist_std = 0.1516 vf_loss = 0.0535 grad_norm = 3.3171 nat_grad_norm = 0.1080 cg_residual = 1.8243 step_size = 0.4481 reward = 0.0000 fps = 7 mse_loss = 0.2714 
2022-05-01 14:49:20.875324 - gail/main.py:164 - [TRPO] iter = 1797000 dist_mean = 0.0033 dist_std = 0.1512 vf_loss = 0.0651 grad_norm = 3.7446 nat_grad_norm = 0.0889 cg_residual = 2.7007 step_size = 0.4280 reward = -0.0000 fps = 7 mse_loss = 0.3031 
2022-05-01 14:49:30.558027 - gail/main.py:164 - [TRPO] iter = 1798000 dist_mean = 0.0308 dist_std = 0.1510 vf_loss = 0.0871 grad_norm = 4.3749 nat_grad_norm = 0.0970 cg_residual = 1.9828 step_size = 0.4447 reward = -0.0000 fps = 6 mse_loss = 0.2987 
2022-05-01 14:49:40.132483 - gail/main.py:164 - [TRPO] iter = 1799000 dist_mean = 0.0204 dist_std = 0.1511 vf_loss = 0.0769 grad_norm = 3.9052 nat_grad_norm = 0.0900 cg_residual = 1.3563 step_size = 0.4586 reward = 0.0000 fps = 6 mse_loss = 0.3008 
2022-05-01 14:49:49.714468 - gail/main.py:164 - [TRPO] iter = 1800000 dist_mean = 0.0293 dist_std = 0.1507 vf_loss = 0.0324 grad_norm = 2.8953 nat_grad_norm = 0.0911 cg_residual = 1.4825 step_size = 0.4424 reward = 0.0000 fps = 6 mse_loss = 0.2800 
2022-05-01 14:49:49.943655 - gail/main.py:191 - [Discriminator] iter = 1800000 loss = -0.2034 grad_norm = 4.7645 grad_penalty = 0.0528 regularization = 0.0000 true_logits = 0.0312 fake_logits = -0.2249 true_prob = 0.5045 fake_prob = 0.4471 
2022-05-01 14:51:59.977233 - gail/main.py:132 - [Evaluate] iter = 1800000 episode={ returns = 3648.9925 lengths = 1000 } discounted_episode={ returns = 2255.6456 lengths = 1000 } 
2022-05-01 14:52:09.940581 - gail/main.py:164 - [TRPO] iter = 1801000 dist_mean = 0.0115 dist_std = 0.1509 vf_loss = 0.0264 grad_norm = 2.8993 nat_grad_norm = 0.0795 cg_residual = 1.8729 step_size = 0.4651 reward = 0.0000 fps = 7 mse_loss = 0.3135 
2022-05-01 14:52:19.604722 - gail/main.py:164 - [TRPO] iter = 1802000 dist_mean = 0.0222 dist_std = 0.1509 vf_loss = 0.0647 grad_norm = 2.7015 nat_grad_norm = 0.0864 cg_residual = 0.8741 step_size = 0.4620 reward = -0.0000 fps = 6 mse_loss = 0.3074 
2022-05-01 14:52:29.043985 - gail/main.py:164 - [TRPO] iter = 1803000 dist_mean = 0.0245 dist_std = 0.1508 vf_loss = 0.0336 grad_norm = 4.1274 nat_grad_norm = 0.0938 cg_residual = 0.6047 step_size = 0.4211 reward = -0.0000 fps = 6 mse_loss = 0.2648 
2022-05-01 14:52:38.795825 - gail/main.py:164 - [TRPO] iter = 1804000 dist_mean = 0.0291 dist_std = 0.1510 vf_loss = 0.0385 grad_norm = 4.8524 nat_grad_norm = 0.0844 cg_residual = 1.5423 step_size = 0.4331 reward = -0.0000 fps = 5 mse_loss = 0.2656 
2022-05-01 14:52:48.656476 - gail/main.py:164 - [TRPO] iter = 1805000 dist_mean = 0.0376 dist_std = 0.1504 vf_loss = 0.0411 grad_norm = 3.6401 nat_grad_norm = 0.0732 cg_residual = 1.5084 step_size = 0.5519 reward = -0.0000 fps = 5 mse_loss = 0.2714 
2022-05-01 14:52:48.920115 - gail/main.py:191 - [Discriminator] iter = 1805000 loss = -0.2559 grad_norm = 4.9821 grad_penalty = 0.0562 regularization = 0.0000 true_logits = -0.1153 fake_logits = -0.4274 true_prob = 0.4722 fake_prob = 0.4021 
2022-05-01 14:54:57.791658 - gail/main.py:132 - [Evaluate] iter = 1805000 episode={ returns = 3628.6798 lengths = 1000 } discounted_episode={ returns = 2245.0599 lengths = 1000 } 
2022-05-01 14:55:07.439324 - gail/main.py:164 - [TRPO] iter = 1806000 dist_mean = 0.0333 dist_std = 0.1503 vf_loss = 0.0440 grad_norm = 2.7950 nat_grad_norm = 0.0939 cg_residual = 1.1816 step_size = 0.4477 reward = 0.0000 fps = 7 mse_loss = 0.2831 
2022-05-01 14:55:16.898783 - gail/main.py:164 - [TRPO] iter = 1807000 dist_mean = 0.0262 dist_std = 0.1503 vf_loss = 0.0219 grad_norm = 2.5266 nat_grad_norm = 0.0820 cg_residual = 0.7120 step_size = 0.4649 reward = 0.0000 fps = 6 mse_loss = 0.2831 
2022-05-01 14:55:26.336421 - gail/main.py:164 - [TRPO] iter = 1808000 dist_mean = 0.0416 dist_std = 0.1502 vf_loss = 0.0206 grad_norm = 4.2451 nat_grad_norm = 0.0798 cg_residual = 1.5533 step_size = 0.4501 reward = 0.0000 fps = 6 mse_loss = 0.3071 
2022-05-01 14:55:36.146874 - gail/main.py:164 - [TRPO] iter = 1809000 dist_mean = 0.0563 dist_std = 0.1503 vf_loss = 0.0325 grad_norm = 2.9864 nat_grad_norm = 0.0918 cg_residual = 4.2199 step_size = 0.4773 reward = -0.0000 fps = 5 mse_loss = 0.2447 
2022-05-01 14:55:45.709669 - gail/main.py:164 - [TRPO] iter = 1810000 dist_mean = 0.0327 dist_std = 0.1504 vf_loss = 0.0187 grad_norm = 2.6277 nat_grad_norm = 0.0901 cg_residual = 1.1783 step_size = 0.4864 reward = -0.0000 fps = 5 mse_loss = 0.2849 
2022-05-01 14:55:45.919227 - gail/main.py:191 - [Discriminator] iter = 1810000 loss = -0.2991 grad_norm = 3.8563 grad_penalty = 0.0522 regularization = 0.0000 true_logits = -0.2229 fake_logits = -0.5742 true_prob = 0.4475 fake_prob = 0.3697 
2022-05-01 14:57:50.529738 - gail/main.py:132 - [Evaluate] iter = 1810000 episode={ returns = 3395.9736 lengths = 937 } discounted_episode={ returns = 2183.5835 lengths = 961 } 
2022-05-01 14:58:00.283722 - gail/main.py:164 - [TRPO] iter = 1811000 dist_mean = 0.0284 dist_std = 0.1502 vf_loss = 0.0254 grad_norm = 3.7101 nat_grad_norm = 0.0957 cg_residual = 1.6005 step_size = 0.4222 reward = -0.0000 fps = 7 mse_loss = 0.3082 
2022-05-01 14:58:09.798654 - gail/main.py:164 - [TRPO] iter = 1812000 dist_mean = 0.0395 dist_std = 0.1504 vf_loss = 0.0567 grad_norm = 4.0357 nat_grad_norm = 0.0682 cg_residual = 0.6546 step_size = 0.4597 reward = -0.0000 fps = 6 mse_loss = 0.2790 
2022-05-01 14:58:19.727287 - gail/main.py:164 - [TRPO] iter = 1813000 dist_mean = 0.0329 dist_std = 0.1505 vf_loss = 0.0329 grad_norm = 3.4058 nat_grad_norm = 0.0991 cg_residual = 1.0964 step_size = 0.4470 reward = -0.0000 fps = 6 mse_loss = 0.2997 
2022-05-01 14:58:29.416627 - gail/main.py:164 - [TRPO] iter = 1814000 dist_mean = 0.0126 dist_std = 0.1504 vf_loss = 0.0236 grad_norm = 4.1110 nat_grad_norm = 0.0907 cg_residual = 1.2044 step_size = 0.3840 reward = 0.0000 fps = 6 mse_loss = 0.2930 
2022-05-01 14:58:39.009239 - gail/main.py:164 - [TRPO] iter = 1815000 dist_mean = 0.0346 dist_std = 0.1504 vf_loss = 0.0270 grad_norm = 2.3853 nat_grad_norm = 0.0804 cg_residual = 0.7829 step_size = 0.4629 reward = 0.0000 fps = 5 mse_loss = 0.2809 
2022-05-01 14:58:39.237213 - gail/main.py:191 - [Discriminator] iter = 1815000 loss = -0.2576 grad_norm = 3.6805 grad_penalty = 0.0485 regularization = 0.0000 true_logits = -0.2521 fake_logits = -0.5582 true_prob = 0.4414 fake_prob = 0.3713 
2022-05-01 15:00:44.597419 - gail/main.py:132 - [Evaluate] iter = 1815000 episode={ returns = 3478.4262 lengths = 963 } discounted_episode={ returns = 2202.0751 lengths = 977 } 
2022-05-01 15:00:54.594892 - gail/main.py:164 - [TRPO] iter = 1816000 dist_mean = 0.0701 dist_std = 0.1503 vf_loss = 0.0612 grad_norm = 3.5511 nat_grad_norm = 0.0818 cg_residual = 1.8655 step_size = 0.5277 reward = 0.0000 fps = 7 mse_loss = 0.2702 
2022-05-01 15:01:04.432881 - gail/main.py:164 - [TRPO] iter = 1817000 dist_mean = 0.0227 dist_std = 0.1501 vf_loss = 0.0254 grad_norm = 3.7388 nat_grad_norm = 0.0946 cg_residual = 1.0394 step_size = 0.3997 reward = 0.0000 fps = 6 mse_loss = 0.2825 
2022-05-01 15:01:13.807665 - gail/main.py:164 - [TRPO] iter = 1818000 dist_mean = 0.0538 dist_std = 0.1503 vf_loss = 0.0387 grad_norm = 4.5439 nat_grad_norm = 0.0724 cg_residual = 6.0660 step_size = 0.5028 reward = 0.0000 fps = 6 mse_loss = 0.2683 
2022-05-01 15:01:23.355183 - gail/main.py:164 - [TRPO] iter = 1819000 dist_mean = 0.0371 dist_std = 0.1506 vf_loss = 0.0367 grad_norm = 3.0259 nat_grad_norm = 0.0816 cg_residual = 1.6168 step_size = 0.4742 reward = -0.0000 fps = 6 mse_loss = 0.2721 
2022-05-01 15:01:32.785057 - gail/main.py:164 - [TRPO] iter = 1820000 dist_mean = 0.0440 dist_std = 0.1500 vf_loss = 0.0332 grad_norm = 3.2661 nat_grad_norm = 0.0698 cg_residual = 1.7534 step_size = 0.4959 reward = -0.0000 fps = 5 mse_loss = 0.2730 
2022-05-01 15:01:33.001593 - gail/main.py:191 - [Discriminator] iter = 1820000 loss = -0.2528 grad_norm = 3.7827 grad_penalty = 0.0490 regularization = 0.0000 true_logits = -0.2000 fake_logits = -0.5018 true_prob = 0.4526 fake_prob = 0.3838 
2022-05-01 15:03:17.141196 - gail/main.py:132 - [Evaluate] iter = 1820000 episode={ returns = 2944.4680 lengths = 845 } discounted_episode={ returns = 1601.2402 lengths = 751 } 
2022-05-01 15:03:26.480635 - gail/main.py:164 - [TRPO] iter = 1821000 dist_mean = 0.0607 dist_std = 0.1501 vf_loss = 0.0469 grad_norm = 3.1742 nat_grad_norm = 0.0991 cg_residual = 3.4921 step_size = 0.4416 reward = 0.0000 fps = 8 mse_loss = 0.2500 
2022-05-01 15:03:36.375866 - gail/main.py:164 - [TRPO] iter = 1822000 dist_mean = 0.0745 dist_std = 0.1502 vf_loss = 0.0312 grad_norm = 3.5264 nat_grad_norm = 0.1006 cg_residual = 2.7731 step_size = 0.3579 reward = -0.0000 fps = 8 mse_loss = 0.3040 
2022-05-01 15:03:45.916157 - gail/main.py:164 - [TRPO] iter = 1823000 dist_mean = 0.0709 dist_std = 0.1502 vf_loss = 0.0292 grad_norm = 5.0881 nat_grad_norm = 0.1030 cg_residual = 2.6952 step_size = 0.3384 reward = 0.0000 fps = 7 mse_loss = 0.2714 
2022-05-01 15:03:55.862201 - gail/main.py:164 - [TRPO] iter = 1824000 dist_mean = 0.0363 dist_std = 0.1500 vf_loss = 0.0220 grad_norm = 3.1746 nat_grad_norm = 0.0890 cg_residual = 4.5584 step_size = 0.4583 reward = -0.0000 fps = 7 mse_loss = 0.2807 
2022-05-01 15:04:05.648931 - gail/main.py:164 - [TRPO] iter = 1825000 dist_mean = 0.0609 dist_std = 0.1501 vf_loss = 0.0409 grad_norm = 3.1672 nat_grad_norm = 0.0811 cg_residual = 3.3776 step_size = 0.4929 reward = 0.0000 fps = 6 mse_loss = 0.2647 
2022-05-01 15:04:05.868501 - gail/main.py:191 - [Discriminator] iter = 1825000 loss = -0.2740 grad_norm = 3.9285 grad_penalty = 0.0464 regularization = 0.0000 true_logits = -0.1457 fake_logits = -0.4661 true_prob = 0.4648 fake_prob = 0.3920 
2022-05-01 15:06:16.309977 - gail/main.py:132 - [Evaluate] iter = 1825000 episode={ returns = 3547.9434 lengths = 1000 } discounted_episode={ returns = 2189.1678 lengths = 1000 } 
2022-05-01 15:06:25.836105 - gail/main.py:164 - [TRPO] iter = 1826000 dist_mean = 0.0461 dist_std = 0.1503 vf_loss = 0.0216 grad_norm = 3.1694 nat_grad_norm = 0.0883 cg_residual = 9.2549 step_size = 0.4275 reward = -0.0000 fps = 7 mse_loss = 0.2597 
2022-05-01 15:06:36.219138 - gail/main.py:164 - [TRPO] iter = 1827000 dist_mean = 0.0317 dist_std = 0.1505 vf_loss = 0.0442 grad_norm = 5.7741 nat_grad_norm = 0.0927 cg_residual = 1.3611 step_size = 0.4209 reward = 0.0000 fps = 6 mse_loss = 0.2525 
2022-05-01 15:06:46.028503 - gail/main.py:164 - [TRPO] iter = 1828000 dist_mean = 0.0715 dist_std = 0.1503 vf_loss = 0.0571 grad_norm = 2.8036 nat_grad_norm = 0.0930 cg_residual = 1.9864 step_size = 0.4538 reward = 0.0000 fps = 6 mse_loss = 0.2683 
2022-05-01 15:06:55.645891 - gail/main.py:164 - [TRPO] iter = 1829000 dist_mean = 0.0395 dist_std = 0.1505 vf_loss = 0.0605 grad_norm = 2.7212 nat_grad_norm = 0.0957 cg_residual = 2.5052 step_size = 0.4726 reward = -0.0000 fps = 5 mse_loss = 0.2650 
2022-05-01 15:07:05.484400 - gail/main.py:164 - [TRPO] iter = 1830000 dist_mean = 0.0471 dist_std = 0.1497 vf_loss = 0.0201 grad_norm = 2.5842 nat_grad_norm = 0.1184 cg_residual = 3.0216 step_size = 0.3978 reward = 0.0000 fps = 5 mse_loss = 0.2794 
2022-05-01 15:07:05.696458 - gail/main.py:191 - [Discriminator] iter = 1830000 loss = -0.2407 grad_norm = 6.7219 grad_penalty = 0.0514 regularization = 0.0000 true_logits = -0.2003 fake_logits = -0.4924 true_prob = 0.4519 fake_prob = 0.3871 
2022-05-01 15:09:15.956461 - gail/main.py:132 - [Evaluate] iter = 1830000 episode={ returns = 3618.8666 lengths = 1000 } discounted_episode={ returns = 2228.0682 lengths = 1000 } 
2022-05-01 15:09:25.864342 - gail/main.py:164 - [TRPO] iter = 1831000 dist_mean = 0.0733 dist_std = 0.1491 vf_loss = 0.0616 grad_norm = 2.4072 nat_grad_norm = 0.0848 cg_residual = 1.8352 step_size = 0.4730 reward = -0.0000 fps = 7 mse_loss = 0.2825 
2022-05-01 15:09:35.485569 - gail/main.py:164 - [TRPO] iter = 1832000 dist_mean = 0.0315 dist_std = 0.1491 vf_loss = 0.0546 grad_norm = 3.6015 nat_grad_norm = 0.0763 cg_residual = 4.0151 step_size = 0.5003 reward = -0.0000 fps = 6 mse_loss = 0.2509 
2022-05-01 15:09:45.085497 - gail/main.py:164 - [TRPO] iter = 1833000 dist_mean = 0.0418 dist_std = 0.1486 vf_loss = 0.0987 grad_norm = 3.1767 nat_grad_norm = 0.0657 cg_residual = 2.7684 step_size = 0.5104 reward = 0.0000 fps = 6 mse_loss = 0.2523 
2022-05-01 15:09:54.864555 - gail/main.py:164 - [TRPO] iter = 1834000 dist_mean = 0.0582 dist_std = 0.1486 vf_loss = 0.0590 grad_norm = 3.1393 nat_grad_norm = 0.0739 cg_residual = 0.8152 step_size = 0.4657 reward = -0.0000 fps = 5 mse_loss = 0.2864 
2022-05-01 15:10:04.183272 - gail/main.py:164 - [TRPO] iter = 1835000 dist_mean = 0.0763 dist_std = 0.1487 vf_loss = 0.0624 grad_norm = 2.9036 nat_grad_norm = 0.0917 cg_residual = 1.6291 step_size = 0.5233 reward = -0.0000 fps = 5 mse_loss = 0.2741 
2022-05-01 15:10:04.416692 - gail/main.py:191 - [Discriminator] iter = 1835000 loss = -0.2775 grad_norm = 5.1907 grad_penalty = 0.0478 regularization = 0.0000 true_logits = -0.1629 fake_logits = -0.4883 true_prob = 0.4598 fake_prob = 0.3883 
2022-05-01 15:12:16.057341 - gail/main.py:132 - [Evaluate] iter = 1835000 episode={ returns = 3586.4051 lengths = 1000 } discounted_episode={ returns = 2211.0990 lengths = 1000 } 
2022-05-01 15:12:25.839513 - gail/main.py:164 - [TRPO] iter = 1836000 dist_mean = 0.0487 dist_std = 0.1481 vf_loss = 0.0320 grad_norm = 3.0841 nat_grad_norm = 0.0741 cg_residual = 4.3219 step_size = 0.4714 reward = -0.0000 fps = 7 mse_loss = 0.2803 
2022-05-01 15:12:35.320428 - gail/main.py:164 - [TRPO] iter = 1837000 dist_mean = 0.0268 dist_std = 0.1482 vf_loss = 0.0267 grad_norm = 2.9863 nat_grad_norm = 0.0674 cg_residual = 4.7965 step_size = 0.5707 reward = -0.0000 fps = 6 mse_loss = 0.2696 
2022-05-01 15:12:44.893445 - gail/main.py:164 - [TRPO] iter = 1838000 dist_mean = 0.0438 dist_std = 0.1484 vf_loss = 0.0475 grad_norm = 3.1868 nat_grad_norm = 0.0796 cg_residual = 0.8937 step_size = 0.5364 reward = 0.0000 fps = 6 mse_loss = 0.2898 
2022-05-01 15:12:54.608169 - gail/main.py:164 - [TRPO] iter = 1839000 dist_mean = 0.0265 dist_std = 0.1486 vf_loss = 0.0280 grad_norm = 2.4758 nat_grad_norm = 0.1068 cg_residual = 5.5429 step_size = 0.4579 reward = -0.0000 fps = 5 mse_loss = 0.2688 
2022-05-01 15:13:04.469980 - gail/main.py:164 - [TRPO] iter = 1840000 dist_mean = 0.0520 dist_std = 0.1482 vf_loss = 0.0821 grad_norm = 4.2741 nat_grad_norm = 0.0994 cg_residual = 1.3113 step_size = 0.3710 reward = -0.0000 fps = 5 mse_loss = 0.2774 
2022-05-01 15:13:04.701645 - gail/main.py:191 - [Discriminator] iter = 1840000 loss = -0.2969 grad_norm = 3.4699 grad_penalty = 0.0484 regularization = 0.0000 true_logits = -0.1476 fake_logits = -0.4929 true_prob = 0.4620 fake_prob = 0.3895 
2022-05-01 15:15:15.488780 - gail/main.py:132 - [Evaluate] iter = 1840000 episode={ returns = 3585.1618 lengths = 1000 } discounted_episode={ returns = 2212.7473 lengths = 1000 } 
2022-05-01 15:15:25.289631 - gail/main.py:164 - [TRPO] iter = 1841000 dist_mean = 0.0491 dist_std = 0.1483 vf_loss = 0.1046 grad_norm = 3.5987 nat_grad_norm = 0.0723 cg_residual = 2.1798 step_size = 0.4877 reward = 0.0000 fps = 7 mse_loss = 0.2587 
2022-05-01 15:15:34.789131 - gail/main.py:164 - [TRPO] iter = 1842000 dist_mean = 0.0130 dist_std = 0.1481 vf_loss = 0.0799 grad_norm = 1.9886 nat_grad_norm = 0.0699 cg_residual = 1.8886 step_size = 0.5870 reward = 0.0000 fps = 6 mse_loss = 0.2530 
2022-05-01 15:15:44.576131 - gail/main.py:164 - [TRPO] iter = 1843000 dist_mean = 0.0286 dist_std = 0.1481 vf_loss = 0.1045 grad_norm = 2.0564 nat_grad_norm = 0.0668 cg_residual = 2.8107 step_size = 0.5734 reward = -0.0000 fps = 6 mse_loss = 0.2757 
2022-05-01 15:15:54.852195 - gail/main.py:164 - [TRPO] iter = 1844000 dist_mean = 0.0592 dist_std = 0.1483 vf_loss = 0.1635 grad_norm = 2.9425 nat_grad_norm = 0.0723 cg_residual = 1.5308 step_size = 0.4584 reward = 0.0000 fps = 5 mse_loss = 0.2424 
2022-05-01 15:16:04.610209 - gail/main.py:164 - [TRPO] iter = 1845000 dist_mean = 0.0266 dist_std = 0.1480 vf_loss = 0.0649 grad_norm = 3.1166 nat_grad_norm = 0.0535 cg_residual = 2.3064 step_size = 0.5526 reward = 0.0000 fps = 5 mse_loss = 0.2677 
2022-05-01 15:16:04.826910 - gail/main.py:191 - [Discriminator] iter = 1845000 loss = -0.3179 grad_norm = 4.0181 grad_penalty = 0.0553 regularization = 0.0000 true_logits = -0.1314 fake_logits = -0.5046 true_prob = 0.4643 fake_prob = 0.3921 
2022-05-01 15:18:15.962970 - gail/main.py:132 - [Evaluate] iter = 1845000 episode={ returns = 3603.2256 lengths = 1000 } discounted_episode={ returns = 2224.6635 lengths = 1000 } 
2022-05-01 15:18:25.161994 - gail/main.py:164 - [TRPO] iter = 1846000 dist_mean = 0.0065 dist_std = 0.1480 vf_loss = 0.0764 grad_norm = 2.2209 nat_grad_norm = 0.0673 cg_residual = 2.6386 step_size = 0.5365 reward = 0.0000 fps = 7 mse_loss = 0.2885 
2022-05-01 15:18:34.904123 - gail/main.py:164 - [TRPO] iter = 1847000 dist_mean = -0.0042 dist_std = 0.1480 vf_loss = 0.0151 grad_norm = 2.7876 nat_grad_norm = 0.0792 cg_residual = 1.5803 step_size = 0.5039 reward = 0.0000 fps = 6 mse_loss = 0.2716 
2022-05-01 15:18:44.773240 - gail/main.py:164 - [TRPO] iter = 1848000 dist_mean = 0.0450 dist_std = 0.1479 vf_loss = 0.0556 grad_norm = 4.1369 nat_grad_norm = 0.0714 cg_residual = 5.1010 step_size = 0.5194 reward = -0.0000 fps = 6 mse_loss = 0.2554 
2022-05-01 15:18:54.209057 - gail/main.py:164 - [TRPO] iter = 1849000 dist_mean = 0.0264 dist_std = 0.1482 vf_loss = 0.1284 grad_norm = 4.0089 nat_grad_norm = 0.0465 cg_residual = 1.4612 step_size = 0.5857 reward = -0.0000 fps = 5 mse_loss = 0.2724 
2022-05-01 15:19:04.076061 - gail/main.py:164 - [TRPO] iter = 1850000 dist_mean = 0.0372 dist_std = 0.1484 vf_loss = 0.0472 grad_norm = 5.4259 nat_grad_norm = 0.0707 cg_residual = 1.8841 step_size = 0.4436 reward = -0.0000 fps = 5 mse_loss = 0.2672 
2022-05-01 15:19:04.303957 - gail/main.py:191 - [Discriminator] iter = 1850000 loss = -0.3616 grad_norm = 3.2369 grad_penalty = 0.0520 regularization = 0.0000 true_logits = -0.1074 fake_logits = -0.5210 true_prob = 0.4642 fake_prob = 0.3863 
2022-05-01 15:21:13.348050 - gail/main.py:132 - [Evaluate] iter = 1850000 episode={ returns = 3616.5497 lengths = 1000 } discounted_episode={ returns = 2233.6457 lengths = 1000 } 
2022-05-01 15:21:23.341621 - gail/main.py:164 - [TRPO] iter = 1851000 dist_mean = 0.0120 dist_std = 0.1484 vf_loss = 0.0473 grad_norm = 4.0804 nat_grad_norm = 0.0839 cg_residual = 3.3655 step_size = 0.4812 reward = 0.0000 fps = 7 mse_loss = 0.2451 
2022-05-01 15:21:33.227336 - gail/main.py:164 - [TRPO] iter = 1852000 dist_mean = 0.0105 dist_std = 0.1482 vf_loss = 0.1136 grad_norm = 2.3236 nat_grad_norm = 0.0647 cg_residual = 2.5997 step_size = 0.6513 reward = -0.0000 fps = 6 mse_loss = 0.2499 
2022-05-01 15:21:43.058997 - gail/main.py:164 - [TRPO] iter = 1853000 dist_mean = 0.0102 dist_std = 0.1481 vf_loss = 0.1189 grad_norm = 2.7980 nat_grad_norm = 0.0731 cg_residual = 0.9298 step_size = 0.5678 reward = 0.0000 fps = 6 mse_loss = 0.2517 
2022-05-01 15:21:52.760022 - gail/main.py:164 - [TRPO] iter = 1854000 dist_mean = -0.0017 dist_std = 0.1482 vf_loss = 0.1107 grad_norm = 6.3569 nat_grad_norm = 0.0655 cg_residual = 2.6609 step_size = 0.4588 reward = 0.0000 fps = 5 mse_loss = 0.2636 
2022-05-01 15:22:03.179065 - gail/main.py:164 - [TRPO] iter = 1855000 dist_mean = 0.0054 dist_std = 0.1481 vf_loss = 0.1019 grad_norm = 4.5001 nat_grad_norm = 0.0761 cg_residual = 6.2951 step_size = 0.4773 reward = 0.0000 fps = 5 mse_loss = 0.3178 
2022-05-01 15:22:03.386360 - gail/main.py:191 - [Discriminator] iter = 1855000 loss = -0.2891 grad_norm = 3.4815 grad_penalty = 0.0527 regularization = 0.0000 true_logits = -0.1301 fake_logits = -0.4719 true_prob = 0.4611 fake_prob = 0.3952 
2022-05-01 15:24:14.505287 - gail/main.py:132 - [Evaluate] iter = 1855000 episode={ returns = 3663.1366 lengths = 1000 } discounted_episode={ returns = 2259.7147 lengths = 1000 } 
2022-05-01 15:24:24.290678 - gail/main.py:164 - [TRPO] iter = 1856000 dist_mean = 0.0043 dist_std = 0.1479 vf_loss = 0.0776 grad_norm = 2.6035 nat_grad_norm = 0.0827 cg_residual = 1.8272 step_size = 0.4934 reward = 0.0000 fps = 7 mse_loss = 0.2761 
2022-05-01 15:24:34.258791 - gail/main.py:164 - [TRPO] iter = 1857000 dist_mean = 0.0013 dist_std = 0.1478 vf_loss = 0.0525 grad_norm = 2.3868 nat_grad_norm = 0.0587 cg_residual = 1.6694 step_size = 0.6264 reward = -0.0000 fps = 6 mse_loss = 0.2731 
2022-05-01 15:24:44.129821 - gail/main.py:164 - [TRPO] iter = 1858000 dist_mean = 0.0167 dist_std = 0.1479 vf_loss = 0.0570 grad_norm = 2.9701 nat_grad_norm = 0.0689 cg_residual = 2.5940 step_size = 0.5809 reward = -0.0000 fps = 6 mse_loss = 0.2682 
2022-05-01 15:24:53.771622 - gail/main.py:164 - [TRPO] iter = 1859000 dist_mean = -0.0040 dist_std = 0.1480 vf_loss = 0.0451 grad_norm = 4.1229 nat_grad_norm = 0.0537 cg_residual = 3.0931 step_size = 0.5803 reward = 0.0000 fps = 5 mse_loss = 0.2788 
2022-05-01 15:25:03.525134 - gail/main.py:164 - [TRPO] iter = 1860000 dist_mean = 0.0220 dist_std = 0.1482 vf_loss = 0.0586 grad_norm = 2.6961 nat_grad_norm = 0.0717 cg_residual = 0.7027 step_size = 0.5149 reward = 0.0000 fps = 5 mse_loss = 0.2632 
2022-05-01 15:25:03.743194 - gail/main.py:191 - [Discriminator] iter = 1860000 loss = -0.2666 grad_norm = 4.2904 grad_penalty = 0.0590 regularization = 0.0000 true_logits = -0.1633 fake_logits = -0.4888 true_prob = 0.4567 fake_prob = 0.3912 
2022-05-01 15:27:16.320019 - gail/main.py:132 - [Evaluate] iter = 1860000 episode={ returns = 3665.7384 lengths = 1000 } discounted_episode={ returns = 2261.3415 lengths = 1000 } 
2022-05-01 15:27:25.460861 - gail/main.py:164 - [TRPO] iter = 1861000 dist_mean = 0.0079 dist_std = 0.1480 vf_loss = 0.0862 grad_norm = 2.4523 nat_grad_norm = 0.0822 cg_residual = 7.7837 step_size = 0.5303 reward = -0.0000 fps = 7 mse_loss = 0.2541 
2022-05-01 15:27:35.394017 - gail/main.py:164 - [TRPO] iter = 1862000 dist_mean = 0.0173 dist_std = 0.1477 vf_loss = 0.0663 grad_norm = 3.6687 nat_grad_norm = 0.0711 cg_residual = 2.4680 step_size = 0.5152 reward = -0.0000 fps = 6 mse_loss = 0.2417 
2022-05-01 15:27:45.016102 - gail/main.py:164 - [TRPO] iter = 1863000 dist_mean = 0.0229 dist_std = 0.1474 vf_loss = 0.0460 grad_norm = 3.6162 nat_grad_norm = 0.1098 cg_residual = 3.5710 step_size = 0.3837 reward = 0.0000 fps = 6 mse_loss = 0.2478 
2022-05-01 15:27:54.521028 - gail/main.py:164 - [TRPO] iter = 1864000 dist_mean = 0.0373 dist_std = 0.1474 vf_loss = 0.0863 grad_norm = 2.7284 nat_grad_norm = 0.0861 cg_residual = 2.9165 step_size = 0.5175 reward = -0.0000 fps = 5 mse_loss = 0.2298 
2022-05-01 15:28:04.182141 - gail/main.py:164 - [TRPO] iter = 1865000 dist_mean = -0.0083 dist_std = 0.1468 vf_loss = 0.0140 grad_norm = 2.0336 nat_grad_norm = 0.1168 cg_residual = 2.3579 step_size = 0.4678 reward = -0.0000 fps = 5 mse_loss = 0.2784 
2022-05-01 15:28:04.409860 - gail/main.py:191 - [Discriminator] iter = 1865000 loss = -0.2677 grad_norm = 4.1731 grad_penalty = 0.0627 regularization = 0.0000 true_logits = -0.1357 fake_logits = -0.4661 true_prob = 0.4666 fake_prob = 0.3968 
2022-05-01 15:30:14.255989 - gail/main.py:132 - [Evaluate] iter = 1865000 episode={ returns = 3671.1430 lengths = 1000 } discounted_episode={ returns = 2267.2703 lengths = 1000 } 
2022-05-01 15:30:24.016634 - gail/main.py:164 - [TRPO] iter = 1866000 dist_mean = 0.0098 dist_std = 0.1467 vf_loss = 0.0528 grad_norm = 4.1374 nat_grad_norm = 0.0740 cg_residual = 1.9639 step_size = 0.4350 reward = -0.0000 fps = 7 mse_loss = 0.2385 
2022-05-01 15:30:33.907260 - gail/main.py:164 - [TRPO] iter = 1867000 dist_mean = 0.0089 dist_std = 0.1467 vf_loss = 0.0672 grad_norm = 2.8935 nat_grad_norm = 0.0827 cg_residual = 1.3139 step_size = 0.5655 reward = -0.0000 fps = 6 mse_loss = 0.2595 
2022-05-01 15:30:44.080146 - gail/main.py:164 - [TRPO] iter = 1868000 dist_mean = 0.0139 dist_std = 0.1463 vf_loss = 0.0671 grad_norm = 3.9566 nat_grad_norm = 0.0730 cg_residual = 1.5485 step_size = 0.4798 reward = 0.0000 fps = 6 mse_loss = 0.2437 
2022-05-01 15:30:53.643020 - gail/main.py:164 - [TRPO] iter = 1869000 dist_mean = 0.0210 dist_std = 0.1464 vf_loss = 0.0314 grad_norm = 3.8500 nat_grad_norm = 0.0750 cg_residual = 1.3187 step_size = 0.4924 reward = 0.0000 fps = 5 mse_loss = 0.2673 
2022-05-01 15:31:03.220249 - gail/main.py:164 - [TRPO] iter = 1870000 dist_mean = 0.0235 dist_std = 0.1464 vf_loss = 0.0296 grad_norm = 4.7374 nat_grad_norm = 0.0874 cg_residual = 5.9392 step_size = 0.4399 reward = 0.0000 fps = 5 mse_loss = 0.2449 
2022-05-01 15:31:03.407500 - gail/main.py:191 - [Discriminator] iter = 1870000 loss = -0.1841 grad_norm = 3.9827 grad_penalty = 0.0605 regularization = 0.0000 true_logits = -0.1042 fake_logits = -0.3487 true_prob = 0.4738 fake_prob = 0.4187 
2022-05-01 15:33:15.476028 - gail/main.py:132 - [Evaluate] iter = 1870000 episode={ returns = 3639.2335 lengths = 1000 } discounted_episode={ returns = 2245.0319 lengths = 1000 } 
2022-05-01 15:33:25.584862 - gail/main.py:164 - [TRPO] iter = 1871000 dist_mean = 0.0348 dist_std = 0.1459 vf_loss = 0.0366 grad_norm = 4.0251 nat_grad_norm = 0.0805 cg_residual = 2.9448 step_size = 0.4345 reward = -0.0000 fps = 7 mse_loss = 0.2356 
2022-05-01 15:33:35.672809 - gail/main.py:164 - [TRPO] iter = 1872000 dist_mean = 0.0420 dist_std = 0.1461 vf_loss = 0.0419 grad_norm = 4.0148 nat_grad_norm = 0.0738 cg_residual = 1.7369 step_size = 0.4880 reward = -0.0000 fps = 6 mse_loss = 0.2694 
2022-05-01 15:33:45.498616 - gail/main.py:164 - [TRPO] iter = 1873000 dist_mean = 0.0552 dist_std = 0.1456 vf_loss = 0.0302 grad_norm = 3.3280 nat_grad_norm = 0.0850 cg_residual = 1.2923 step_size = 0.4557 reward = -0.0000 fps = 6 mse_loss = 0.2626 
2022-05-01 15:33:55.278983 - gail/main.py:164 - [TRPO] iter = 1874000 dist_mean = 0.0524 dist_std = 0.1455 vf_loss = 0.0405 grad_norm = 3.5336 nat_grad_norm = 0.0685 cg_residual = 3.4290 step_size = 0.5427 reward = 0.0000 fps = 5 mse_loss = 0.2485 
2022-05-01 15:34:04.992104 - gail/main.py:164 - [TRPO] iter = 1875000 dist_mean = 0.0550 dist_std = 0.1458 vf_loss = 0.0320 grad_norm = 4.2528 nat_grad_norm = 0.0844 cg_residual = 1.6521 step_size = 0.4540 reward = -0.0000 fps = 5 mse_loss = 0.2374 
2022-05-01 15:34:05.218641 - gail/main.py:191 - [Discriminator] iter = 1875000 loss = -0.2164 grad_norm = 4.2431 grad_penalty = 0.0479 regularization = 0.0000 true_logits = -0.0906 fake_logits = -0.3549 true_prob = 0.4734 fake_prob = 0.4206 
2022-05-01 15:36:16.609342 - gail/main.py:132 - [Evaluate] iter = 1875000 episode={ returns = 3588.3030 lengths = 1000 } discounted_episode={ returns = 2214.6992 lengths = 1000 } 
2022-05-01 15:36:26.020853 - gail/main.py:164 - [TRPO] iter = 1876000 dist_mean = 0.0553 dist_std = 0.1459 vf_loss = 0.0357 grad_norm = 4.2275 nat_grad_norm = 0.0771 cg_residual = 2.9952 step_size = 0.4917 reward = -0.0000 fps = 7 mse_loss = 0.2317 
2022-05-01 15:36:35.703566 - gail/main.py:164 - [TRPO] iter = 1877000 dist_mean = 0.0499 dist_std = 0.1457 vf_loss = 0.0370 grad_norm = 4.3899 nat_grad_norm = 0.0629 cg_residual = 0.5726 step_size = 0.4431 reward = -0.0000 fps = 6 mse_loss = 0.2399 
2022-05-01 15:36:45.823565 - gail/main.py:164 - [TRPO] iter = 1878000 dist_mean = 0.0705 dist_std = 0.1456 vf_loss = 0.0422 grad_norm = 4.7051 nat_grad_norm = 0.0710 cg_residual = 5.7054 step_size = 0.4580 reward = -0.0000 fps = 6 mse_loss = 0.2643 
2022-05-01 15:36:55.670565 - gail/main.py:164 - [TRPO] iter = 1879000 dist_mean = 0.0695 dist_std = 0.1455 vf_loss = 0.0368 grad_norm = 3.5585 nat_grad_norm = 0.0876 cg_residual = 1.6211 step_size = 0.4191 reward = 0.0000 fps = 5 mse_loss = 0.2617 
2022-05-01 15:37:05.322029 - gail/main.py:164 - [TRPO] iter = 1880000 dist_mean = 0.0538 dist_std = 0.1452 vf_loss = 0.0381 grad_norm = 4.0280 nat_grad_norm = 0.0730 cg_residual = 1.6393 step_size = 0.4312 reward = 0.0000 fps = 5 mse_loss = 0.2470 
2022-05-01 15:37:05.559784 - gail/main.py:191 - [Discriminator] iter = 1880000 loss = -0.1789 grad_norm = 4.4429 grad_penalty = 0.0528 regularization = 0.0000 true_logits = -0.0687 fake_logits = -0.3003 true_prob = 0.4768 fake_prob = 0.4285 
2022-05-01 15:39:16.493940 - gail/main.py:132 - [Evaluate] iter = 1880000 episode={ returns = 3543.5877 lengths = 1000 } discounted_episode={ returns = 2186.8083 lengths = 1000 } 
2022-05-01 15:39:26.219017 - gail/main.py:164 - [TRPO] iter = 1881000 dist_mean = 0.0521 dist_std = 0.1453 vf_loss = 0.0269 grad_norm = 3.7625 nat_grad_norm = 0.0765 cg_residual = 1.3183 step_size = 0.4362 reward = 0.0000 fps = 7 mse_loss = 0.2650 
2022-05-01 15:39:36.087180 - gail/main.py:164 - [TRPO] iter = 1882000 dist_mean = 0.0765 dist_std = 0.1454 vf_loss = 0.0724 grad_norm = 3.6958 nat_grad_norm = 0.0963 cg_residual = 2.4946 step_size = 0.4006 reward = -0.0000 fps = 6 mse_loss = 0.2403 
2022-05-01 15:39:45.774794 - gail/main.py:164 - [TRPO] iter = 1883000 dist_mean = 0.0736 dist_std = 0.1457 vf_loss = 0.0324 grad_norm = 4.8357 nat_grad_norm = 0.0855 cg_residual = 3.1851 step_size = 0.3879 reward = -0.0000 fps = 6 mse_loss = 0.2783 
2022-05-01 15:39:55.521074 - gail/main.py:164 - [TRPO] iter = 1884000 dist_mean = 0.0782 dist_std = 0.1457 vf_loss = 0.0182 grad_norm = 2.3177 nat_grad_norm = 0.1204 cg_residual = 7.9372 step_size = 0.4223 reward = 0.0000 fps = 5 mse_loss = 0.2696 
2022-05-01 15:40:05.231475 - gail/main.py:164 - [TRPO] iter = 1885000 dist_mean = 0.0710 dist_std = 0.1453 vf_loss = 0.0187 grad_norm = 4.0823 nat_grad_norm = 0.1010 cg_residual = 1.9208 step_size = 0.3834 reward = 0.0000 fps = 5 mse_loss = 0.2776 
2022-05-01 15:40:05.464602 - gail/main.py:191 - [Discriminator] iter = 1885000 loss = -0.2468 grad_norm = 4.1820 grad_penalty = 0.0524 regularization = 0.0000 true_logits = -0.2633 fake_logits = -0.5625 true_prob = 0.4361 fake_prob = 0.3751 
2022-05-01 15:42:17.754198 - gail/main.py:132 - [Evaluate] iter = 1885000 episode={ returns = 3527.6798 lengths = 1000 } discounted_episode={ returns = 2171.5325 lengths = 1000 } 
2022-05-01 15:42:27.005986 - gail/main.py:164 - [TRPO] iter = 1886000 dist_mean = 0.0602 dist_std = 0.1455 vf_loss = 0.0295 grad_norm = 4.6384 nat_grad_norm = 0.0747 cg_residual = 0.9304 step_size = 0.4451 reward = 0.0000 fps = 7 mse_loss = 0.2826 
2022-05-01 15:42:36.734076 - gail/main.py:164 - [TRPO] iter = 1887000 dist_mean = 0.0766 dist_std = 0.1456 vf_loss = 0.0274 grad_norm = 3.6738 nat_grad_norm = 0.0878 cg_residual = 1.4042 step_size = 0.4323 reward = 0.0000 fps = 6 mse_loss = 0.2680 
2022-05-01 15:42:46.650072 - gail/main.py:164 - [TRPO] iter = 1888000 dist_mean = 0.0970 dist_std = 0.1452 vf_loss = 0.0251 grad_norm = 4.0683 nat_grad_norm = 0.0969 cg_residual = 1.6593 step_size = 0.4249 reward = 0.0000 fps = 6 mse_loss = 0.2813 
2022-05-01 15:42:56.271321 - gail/main.py:164 - [TRPO] iter = 1889000 dist_mean = 0.0669 dist_std = 0.1446 vf_loss = 0.0320 grad_norm = 3.8874 nat_grad_norm = 0.1195 cg_residual = 2.9566 step_size = 0.3392 reward = 0.0000 fps = 5 mse_loss = 0.2618 
2022-05-01 15:43:05.720039 - gail/main.py:164 - [TRPO] iter = 1890000 dist_mean = 0.0765 dist_std = 0.1447 vf_loss = 0.0165 grad_norm = 3.1819 nat_grad_norm = 0.0939 cg_residual = 1.5773 step_size = 0.4176 reward = -0.0000 fps = 5 mse_loss = 0.2833 
2022-05-01 15:43:05.941223 - gail/main.py:191 - [Discriminator] iter = 1890000 loss = -0.2601 grad_norm = 3.6361 grad_penalty = 0.0544 regularization = 0.0000 true_logits = -0.4675 fake_logits = -0.7820 true_prob = 0.3950 fake_prob = 0.3343 
2022-05-01 15:45:15.249235 - gail/main.py:132 - [Evaluate] iter = 1890000 episode={ returns = 3506.2342 lengths = 1000 } discounted_episode={ returns = 2161.2453 lengths = 1000 } 
2022-05-01 15:45:24.915941 - gail/main.py:164 - [TRPO] iter = 1891000 dist_mean = 0.0665 dist_std = 0.1446 vf_loss = 0.0189 grad_norm = 3.5020 nat_grad_norm = 0.1067 cg_residual = 1.6412 step_size = 0.3650 reward = -0.0000 fps = 7 mse_loss = 0.2686 
2022-05-01 15:45:34.575474 - gail/main.py:164 - [TRPO] iter = 1892000 dist_mean = 0.0655 dist_std = 0.1445 vf_loss = 0.0292 grad_norm = 3.5238 nat_grad_norm = 0.0908 cg_residual = 1.0949 step_size = 0.5293 reward = 0.0000 fps = 6 mse_loss = 0.2906 
2022-05-01 15:45:44.542247 - gail/main.py:164 - [TRPO] iter = 1893000 dist_mean = 0.0690 dist_std = 0.1443 vf_loss = 0.0247 grad_norm = 2.4315 nat_grad_norm = 0.0817 cg_residual = 0.9372 step_size = 0.4902 reward = 0.0000 fps = 6 mse_loss = 0.2717 
2022-05-01 15:45:53.752661 - gail/main.py:164 - [TRPO] iter = 1894000 dist_mean = 0.0715 dist_std = 0.1439 vf_loss = 0.0134 grad_norm = 4.4511 nat_grad_norm = 0.0782 cg_residual = 0.9284 step_size = 0.4293 reward = -0.0000 fps = 5 mse_loss = 0.2632 
2022-05-01 15:46:03.527708 - gail/main.py:164 - [TRPO] iter = 1895000 dist_mean = 0.0711 dist_std = 0.1440 vf_loss = 0.0197 grad_norm = 4.4241 nat_grad_norm = 0.0920 cg_residual = 1.7670 step_size = 0.3950 reward = 0.0000 fps = 5 mse_loss = 0.2839 
2022-05-01 15:46:03.738118 - gail/main.py:191 - [Discriminator] iter = 1895000 loss = -0.3688 grad_norm = 3.3397 grad_penalty = 0.0570 regularization = 0.0000 true_logits = -0.6716 fake_logits = -1.0974 true_prob = 0.3548 fake_prob = 0.2768 
2022-05-01 15:48:14.304581 - gail/main.py:132 - [Evaluate] iter = 1895000 episode={ returns = 3482.0070 lengths = 1000 } discounted_episode={ returns = 2145.8474 lengths = 1000 } 
2022-05-01 15:48:24.185250 - gail/main.py:164 - [TRPO] iter = 1896000 dist_mean = 0.0802 dist_std = 0.1442 vf_loss = 0.0384 grad_norm = 3.8882 nat_grad_norm = 0.0862 cg_residual = 1.1535 step_size = 0.4081 reward = 0.0000 fps = 7 mse_loss = 0.2815 
2022-05-01 15:48:33.893688 - gail/main.py:164 - [TRPO] iter = 1897000 dist_mean = 0.0610 dist_std = 0.1444 vf_loss = 0.0305 grad_norm = 3.5609 nat_grad_norm = 0.0646 cg_residual = 0.6533 step_size = 0.5017 reward = 0.0000 fps = 6 mse_loss = 0.2527 
2022-05-01 15:48:43.460828 - gail/main.py:164 - [TRPO] iter = 1898000 dist_mean = 0.0641 dist_std = 0.1444 vf_loss = 0.0383 grad_norm = 4.0294 nat_grad_norm = 0.0761 cg_residual = 0.9705 step_size = 0.4653 reward = 0.0000 fps = 6 mse_loss = 0.2674 
2022-05-01 15:48:52.997082 - gail/main.py:164 - [TRPO] iter = 1899000 dist_mean = 0.0688 dist_std = 0.1444 vf_loss = 0.0329 grad_norm = 4.1398 nat_grad_norm = 0.0688 cg_residual = 1.2106 step_size = 0.4446 reward = 0.0000 fps = 5 mse_loss = 0.2831 
2022-05-01 15:49:02.420846 - gail/main.py:164 - [TRPO] iter = 1900000 dist_mean = 0.0650 dist_std = 0.1444 vf_loss = 0.0346 grad_norm = 3.6807 nat_grad_norm = 0.0649 cg_residual = 0.9970 step_size = 0.4680 reward = -0.0000 fps = 5 mse_loss = 0.2975 
2022-05-01 15:49:02.701699 - gail/main.py:191 - [Discriminator] iter = 1900000 loss = -0.3240 grad_norm = 3.4232 grad_penalty = 0.0639 regularization = 0.0000 true_logits = -0.7000 fake_logits = -1.0879 true_prob = 0.3510 fake_prob = 0.2754 
2022-05-01 15:51:09.931883 - gail/main.py:132 - [Evaluate] iter = 1900000 episode={ returns = 3553.5954 lengths = 1000 } discounted_episode={ returns = 2192.3228 lengths = 1000 } 
2022-05-01 15:51:19.530793 - gail/main.py:164 - [TRPO] iter = 1901000 dist_mean = 0.0635 dist_std = 0.1445 vf_loss = 0.1099 grad_norm = 4.5864 nat_grad_norm = 0.0984 cg_residual = 2.1364 step_size = 0.3522 reward = -0.0000 fps = 7 mse_loss = 0.2586 
2022-05-01 15:51:29.099776 - gail/main.py:164 - [TRPO] iter = 1902000 dist_mean = 0.0498 dist_std = 0.1446 vf_loss = 0.0693 grad_norm = 3.4043 nat_grad_norm = 0.0798 cg_residual = 0.9097 step_size = 0.4109 reward = 0.0000 fps = 6 mse_loss = 0.2547 
2022-05-01 15:51:38.943396 - gail/main.py:164 - [TRPO] iter = 1903000 dist_mean = 0.0534 dist_std = 0.1451 vf_loss = 0.2011 grad_norm = 5.3476 nat_grad_norm = 0.0762 cg_residual = 0.9675 step_size = 0.3960 reward = 0.0000 fps = 6 mse_loss = 0.2870 
2022-05-01 15:51:48.524215 - gail/main.py:164 - [TRPO] iter = 1904000 dist_mean = 0.0564 dist_std = 0.1454 vf_loss = 0.1531 grad_norm = 4.9230 nat_grad_norm = 0.0883 cg_residual = 1.6616 step_size = 0.3553 reward = -0.0000 fps = 6 mse_loss = 0.2667 
2022-05-01 15:51:58.002183 - gail/main.py:164 - [TRPO] iter = 1905000 dist_mean = 0.1041 dist_std = 0.1453 vf_loss = 0.1834 grad_norm = 3.5269 nat_grad_norm = 0.0670 cg_residual = 1.4813 step_size = 0.4988 reward = 0.0000 fps = 5 mse_loss = 0.2718 
2022-05-01 15:51:58.222774 - gail/main.py:191 - [Discriminator] iter = 1905000 loss = -1.0118 grad_norm = 4.6340 grad_penalty = 0.0903 regularization = 0.0000 true_logits = -0.6552 fake_logits = -1.7574 true_prob = 0.3596 fake_prob = 0.2137 
2022-05-01 15:52:01.337267 - gail/main.py:132 - [Evaluate] iter = 1905000 episode={ returns = 23.4224 lengths = 21 } discounted_episode={ returns = 22.6922 lengths = 20 } 
2022-05-01 15:52:11.141164 - gail/main.py:164 - [TRPO] iter = 1906000 dist_mean = 0.0299 dist_std = 0.1456 vf_loss = 0.0485 grad_norm = 2.7449 nat_grad_norm = 0.0869 cg_residual = 2.4510 step_size = 0.4913 reward = 0.0000 fps = 77 mse_loss = 0.2626 
2022-05-01 15:52:21.060230 - gail/main.py:164 - [TRPO] iter = 1907000 dist_mean = 0.1955 dist_std = 0.1454 vf_loss = 0.2074 grad_norm = 5.9352 nat_grad_norm = 0.0272 cg_residual = 0.4008 step_size = 0.8803 reward = 0.0000 fps = 43 mse_loss = 0.2697 
2022-05-01 15:52:30.773119 - gail/main.py:164 - [TRPO] iter = 1908000 dist_mean = 0.1881 dist_std = 0.1451 vf_loss = 0.2088 grad_norm = 10.1637 nat_grad_norm = 0.0420 cg_residual = 0.4602 step_size = 0.5068 reward = -0.0000 fps = 30 mse_loss = 0.2579 
2022-05-01 15:52:40.521030 - gail/main.py:164 - [TRPO] iter = 1909000 dist_mean = 0.0572 dist_std = 0.1453 vf_loss = 0.0514 grad_norm = 3.7320 nat_grad_norm = 0.0625 cg_residual = 1.1827 step_size = 0.4490 reward = 0.0000 fps = 23 mse_loss = 0.2796 
2022-05-01 15:52:50.500846 - gail/main.py:164 - [TRPO] iter = 1910000 dist_mean = 0.1847 dist_std = 0.1456 vf_loss = 0.0282 grad_norm = 2.2464 nat_grad_norm = 0.1527 cg_residual = 1.0196 step_size = 0.3978 reward = 0.0000 fps = 19 mse_loss = 0.2996 
2022-05-01 15:52:50.730487 - gail/main.py:191 - [Discriminator] iter = 1910000 loss = -4.7864 grad_norm = 7.6169 grad_penalty = 0.4647 regularization = 0.0000 true_logits = -0.2871 fake_logits = -5.5382 true_prob = 0.4454 fake_prob = 0.0308 
2022-05-01 15:52:53.393643 - gail/main.py:132 - [Evaluate] iter = 1910000 episode={ returns = 20.7435 lengths = 19 } discounted_episode={ returns = 20.6722 lengths = 19 } 
2022-05-01 15:53:03.153286 - gail/main.py:164 - [TRPO] iter = 1911000 dist_mean = 0.2006 dist_std = 0.1453 vf_loss = 0.2100 grad_norm = 9.0189 nat_grad_norm = 0.0427 cg_residual = 0.7339 step_size = 0.5109 reward = -0.0000 fps = 80 mse_loss = 0.2689 
2022-05-01 15:53:12.968385 - gail/main.py:164 - [TRPO] iter = 1912000 dist_mean = 0.1915 dist_std = 0.1446 vf_loss = 0.1765 grad_norm = 10.4622 nat_grad_norm = 0.0432 cg_residual = 1.9143 step_size = 0.4778 reward = -0.0000 fps = 45 mse_loss = 0.2873 
2022-05-01 15:53:22.743470 - gail/main.py:164 - [TRPO] iter = 1913000 dist_mean = 0.1894 dist_std = 0.1446 vf_loss = 0.1874 grad_norm = 11.5330 nat_grad_norm = 0.0392 cg_residual = 0.1977 step_size = 0.4322 reward = 0.0000 fps = 31 mse_loss = 0.3140 
2022-05-01 15:53:32.600999 - gail/main.py:164 - [TRPO] iter = 1914000 dist_mean = 0.1829 dist_std = 0.1447 vf_loss = 1.2338 grad_norm = 6.6256 nat_grad_norm = 0.0831 cg_residual = 1.8737 step_size = 0.3712 reward = 0.0000 fps = 23 mse_loss = 0.2855 
2022-05-01 15:53:42.433266 - gail/main.py:164 - [TRPO] iter = 1915000 dist_mean = 0.1478 dist_std = 0.1449 vf_loss = 1.4433 grad_norm = 4.4877 nat_grad_norm = 0.0790 cg_residual = 2.0473 step_size = 0.3922 reward = 0.0000 fps = 19 mse_loss = 0.2702 
2022-05-01 15:53:42.671604 - gail/main.py:191 - [Discriminator] iter = 1915000 loss = -4.3057 grad_norm = 5.6861 grad_penalty = 0.5401 regularization = 0.0000 true_logits = 0.2357 fake_logits = -4.6102 true_prob = 0.5248 fake_prob = 0.1631 
2022-05-01 15:53:45.763732 - gail/main.py:132 - [Evaluate] iter = 1915000 episode={ returns = 24.9851 lengths = 22 } discounted_episode={ returns = 24.2661 lengths = 21 } 
2022-05-01 15:53:55.846666 - gail/main.py:164 - [TRPO] iter = 1916000 dist_mean = 0.1828 dist_std = 0.1451 vf_loss = 4.6818 grad_norm = 6.0558 nat_grad_norm = 0.1316 cg_residual = 1.3371 step_size = 0.3565 reward = -0.0000 fps = 76 mse_loss = 0.2848 
2022-05-01 15:54:05.741383 - gail/main.py:164 - [TRPO] iter = 1917000 dist_mean = 0.0905 dist_std = 0.1456 vf_loss = 1.7352 grad_norm = 4.4521 nat_grad_norm = 0.0700 cg_residual = 0.8677 step_size = 0.4367 reward = -0.0000 fps = 43 mse_loss = 0.3061 
2022-05-01 15:54:15.239994 - gail/main.py:164 - [TRPO] iter = 1918000 dist_mean = 0.0768 dist_std = 0.1457 vf_loss = 1.5438 grad_norm = 3.1436 nat_grad_norm = 0.0797 cg_residual = 0.8834 step_size = 0.4740 reward = -0.0000 fps = 30 mse_loss = 0.2696 
2022-05-01 15:54:24.616538 - gail/main.py:164 - [TRPO] iter = 1919000 dist_mean = 0.0703 dist_std = 0.1458 vf_loss = 1.0126 grad_norm = 5.3047 nat_grad_norm = 0.0662 cg_residual = 2.7654 step_size = 0.4690 reward = -0.0000 fps = 23 mse_loss = 0.3035 
2022-05-01 15:54:34.003382 - gail/main.py:164 - [TRPO] iter = 1920000 dist_mean = 0.0722 dist_std = 0.1459 vf_loss = 0.0997 grad_norm = 2.6522 nat_grad_norm = 0.0730 cg_residual = 4.1918 step_size = 0.4899 reward = 0.0000 fps = 19 mse_loss = 0.2898 
2022-05-01 15:54:34.215982 - gail/main.py:191 - [Discriminator] iter = 1920000 loss = -0.0798 grad_norm = 5.2775 grad_penalty = 0.2132 regularization = 0.0000 true_logits = 0.1059 fake_logits = -0.1872 true_prob = 0.5045 fake_prob = 0.4575 
2022-05-01 15:56:29.799682 - gail/main.py:132 - [Evaluate] iter = 1920000 episode={ returns = 2950.9585 lengths = 896 } discounted_episode={ returns = 1885.3700 lengths = 887 } 
2022-05-01 15:56:39.773648 - gail/main.py:164 - [TRPO] iter = 1921000 dist_mean = 0.0652 dist_std = 0.1459 vf_loss = 0.3205 grad_norm = 4.0192 nat_grad_norm = 0.0888 cg_residual = 6.5058 step_size = 0.4399 reward = -0.0000 fps = 7 mse_loss = 0.2979 
2022-05-01 15:56:49.479257 - gail/main.py:164 - [TRPO] iter = 1922000 dist_mean = 0.0600 dist_std = 0.1461 vf_loss = 0.0897 grad_norm = 3.3624 nat_grad_norm = 0.0926 cg_residual = 1.3117 step_size = 0.4101 reward = 0.0000 fps = 7 mse_loss = 0.2826 
2022-05-01 15:56:59.260389 - gail/main.py:164 - [TRPO] iter = 1923000 dist_mean = 0.0675 dist_std = 0.1461 vf_loss = 0.4227 grad_norm = 4.4249 nat_grad_norm = 0.0959 cg_residual = 1.6624 step_size = 0.3716 reward = 0.0000 fps = 6 mse_loss = 0.3107 
2022-05-01 15:57:09.166227 - gail/main.py:164 - [TRPO] iter = 1924000 dist_mean = 0.0582 dist_std = 0.1462 vf_loss = 0.0801 grad_norm = 3.4580 nat_grad_norm = 0.0623 cg_residual = 1.2235 step_size = 0.5336 reward = 0.0000 fps = 6 mse_loss = 0.2635 
2022-05-01 15:57:18.124816 - gail/main.py:164 - [TRPO] iter = 1925000 dist_mean = 0.0538 dist_std = 0.1462 vf_loss = 0.0559 grad_norm = 3.9842 nat_grad_norm = 0.0818 cg_residual = 1.3220 step_size = 0.4224 reward = 0.0000 fps = 6 mse_loss = 0.3056 
2022-05-01 15:57:18.328621 - gail/main.py:191 - [Discriminator] iter = 1925000 loss = -0.3589 grad_norm = 3.7070 grad_penalty = 0.0710 regularization = 0.0000 true_logits = -0.1430 fake_logits = -0.5729 true_prob = 0.4730 fake_prob = 0.4259 
2022-05-01 15:59:26.294036 - gail/main.py:132 - [Evaluate] iter = 1925000 episode={ returns = 3513.9459 lengths = 1000 } discounted_episode={ returns = 2174.8107 lengths = 1000 } 
2022-05-01 15:59:35.666052 - gail/main.py:164 - [TRPO] iter = 1926000 dist_mean = 0.0560 dist_std = 0.1464 vf_loss = 0.2338 grad_norm = 3.7389 nat_grad_norm = 0.0921 cg_residual = 1.5639 step_size = 0.4254 reward = -0.0000 fps = 7 mse_loss = 0.3122 
2022-05-01 15:59:45.744051 - gail/main.py:164 - [TRPO] iter = 1927000 dist_mean = 0.0914 dist_std = 0.1464 vf_loss = 0.0946 grad_norm = 3.5829 nat_grad_norm = 0.0690 cg_residual = 1.6152 step_size = 0.5112 reward = 0.0000 fps = 6 mse_loss = 0.2898 
2022-05-01 15:59:55.162249 - gail/main.py:164 - [TRPO] iter = 1928000 dist_mean = 0.0668 dist_std = 0.1462 vf_loss = 0.1201 grad_norm = 3.8755 nat_grad_norm = 0.0675 cg_residual = 6.2052 step_size = 0.4771 reward = -0.0000 fps = 6 mse_loss = 0.2968 
2022-05-01 16:00:05.132519 - gail/main.py:164 - [TRPO] iter = 1929000 dist_mean = 0.0582 dist_std = 0.1463 vf_loss = 0.0368 grad_norm = 3.5380 nat_grad_norm = 0.1136 cg_residual = 4.4766 step_size = 0.3718 reward = -0.0000 fps = 5 mse_loss = 0.2897 
2022-05-01 16:00:15.124137 - gail/main.py:164 - [TRPO] iter = 1930000 dist_mean = 0.0854 dist_std = 0.1465 vf_loss = 0.0561 grad_norm = 2.9756 nat_grad_norm = 0.0697 cg_residual = 5.1580 step_size = 0.5093 reward = 0.0000 fps = 5 mse_loss = 0.2747 
2022-05-01 16:00:15.357616 - gail/main.py:191 - [Discriminator] iter = 1930000 loss = -0.3740 grad_norm = 2.8934 grad_penalty = 0.0555 regularization = 0.0000 true_logits = -0.0884 fake_logits = -0.5180 true_prob = 0.4839 fake_prob = 0.4080 
2022-05-01 16:02:23.516973 - gail/main.py:132 - [Evaluate] iter = 1930000 episode={ returns = 3556.8316 lengths = 1000 } discounted_episode={ returns = 2195.2562 lengths = 1000 } 
2022-05-01 16:02:33.203716 - gail/main.py:164 - [TRPO] iter = 1931000 dist_mean = 0.0727 dist_std = 0.1463 vf_loss = 0.0322 grad_norm = 5.3964 nat_grad_norm = 0.0736 cg_residual = 5.6275 step_size = 0.4142 reward = -0.0000 fps = 7 mse_loss = 0.2821 
2022-05-01 16:02:42.888995 - gail/main.py:164 - [TRPO] iter = 1932000 dist_mean = 0.0692 dist_std = 0.1463 vf_loss = 0.0470 grad_norm = 3.6201 nat_grad_norm = 0.1150 cg_residual = 5.3775 step_size = 0.4215 reward = 0.0000 fps = 6 mse_loss = 0.2734 
2022-05-01 16:02:52.679225 - gail/main.py:164 - [TRPO] iter = 1933000 dist_mean = 0.0898 dist_std = 0.1461 vf_loss = 0.0230 grad_norm = 3.4049 nat_grad_norm = 0.0886 cg_residual = 2.1371 step_size = 0.3873 reward = -0.0000 fps = 6 mse_loss = 0.2938 
2022-05-01 16:03:02.226493 - gail/main.py:164 - [TRPO] iter = 1934000 dist_mean = 0.0923 dist_std = 0.1458 vf_loss = 0.0278 grad_norm = 3.1331 nat_grad_norm = 0.1049 cg_residual = 1.8530 step_size = 0.4024 reward = 0.0000 fps = 5 mse_loss = 0.3242 
2022-05-01 16:03:12.260411 - gail/main.py:164 - [TRPO] iter = 1935000 dist_mean = 0.0822 dist_std = 0.1458 vf_loss = 0.0241 grad_norm = 4.3264 nat_grad_norm = 0.0741 cg_residual = 3.0436 step_size = 0.4247 reward = -0.0000 fps = 5 mse_loss = 0.3068 
2022-05-01 16:03:12.506971 - gail/main.py:191 - [Discriminator] iter = 1935000 loss = -0.2945 grad_norm = 3.3138 grad_penalty = 0.0417 regularization = 0.0000 true_logits = -0.1368 fake_logits = -0.4731 true_prob = 0.4711 fake_prob = 0.4183 
2022-05-01 16:05:22.187376 - gail/main.py:132 - [Evaluate] iter = 1935000 episode={ returns = 3573.0938 lengths = 1000 } discounted_episode={ returns = 2205.9773 lengths = 1000 } 
2022-05-01 16:05:31.824588 - gail/main.py:164 - [TRPO] iter = 1936000 dist_mean = 0.0978 dist_std = 0.1456 vf_loss = 0.0449 grad_norm = 3.5375 nat_grad_norm = 0.1224 cg_residual = 2.2016 step_size = 0.4165 reward = -0.0000 fps = 7 mse_loss = 0.2871 
2022-05-01 16:05:41.702634 - gail/main.py:164 - [TRPO] iter = 1937000 dist_mean = 0.0875 dist_std = 0.1462 vf_loss = 0.0227 grad_norm = 2.7602 nat_grad_norm = 0.1068 cg_residual = 3.8253 step_size = 0.4013 reward = 0.0000 fps = 6 mse_loss = 0.2917 
2022-05-01 16:05:51.460378 - gail/main.py:164 - [TRPO] iter = 1938000 dist_mean = 0.1019 dist_std = 0.1463 vf_loss = 0.0753 grad_norm = 2.0112 nat_grad_norm = 0.1013 cg_residual = 1.7905 step_size = 0.4966 reward = -0.0000 fps = 6 mse_loss = 0.3156 
2022-05-01 16:06:01.172108 - gail/main.py:164 - [TRPO] iter = 1939000 dist_mean = 0.0703 dist_std = 0.1465 vf_loss = 0.0178 grad_norm = 1.8935 nat_grad_norm = 0.0766 cg_residual = 7.0697 step_size = 0.5078 reward = -0.0000 fps = 5 mse_loss = 0.3027 
2022-05-01 16:06:10.872510 - gail/main.py:164 - [TRPO] iter = 1940000 dist_mean = 0.0913 dist_std = 0.1465 vf_loss = 0.0184 grad_norm = 2.7426 nat_grad_norm = 0.0647 cg_residual = 4.0304 step_size = 0.5168 reward = -0.0000 fps = 5 mse_loss = 0.2864 
2022-05-01 16:06:11.141659 - gail/main.py:191 - [Discriminator] iter = 1940000 loss = -0.3324 grad_norm = 2.4659 grad_penalty = 0.0418 regularization = 0.0000 true_logits = -0.1884 fake_logits = -0.5626 true_prob = 0.4585 fake_prob = 0.4029 
2022-05-01 16:08:21.278586 - gail/main.py:132 - [Evaluate] iter = 1940000 episode={ returns = 3593.0560 lengths = 1000 } discounted_episode={ returns = 2220.2737 lengths = 1000 } 
2022-05-01 16:08:30.660231 - gail/main.py:164 - [TRPO] iter = 1941000 dist_mean = 0.0781 dist_std = 0.1467 vf_loss = 0.0324 grad_norm = 3.5592 nat_grad_norm = 0.0944 cg_residual = 2.1870 step_size = 0.4398 reward = -0.0000 fps = 7 mse_loss = 0.3138 
2022-05-01 16:08:40.146361 - gail/main.py:164 - [TRPO] iter = 1942000 dist_mean = 0.0641 dist_std = 0.1462 vf_loss = 0.0172 grad_norm = 2.9484 nat_grad_norm = 0.1077 cg_residual = 1.9531 step_size = 0.3807 reward = 0.0000 fps = 6 mse_loss = 0.2867 
2022-05-01 16:08:50.031326 - gail/main.py:164 - [TRPO] iter = 1943000 dist_mean = 0.0700 dist_std = 0.1461 vf_loss = 0.0254 grad_norm = 2.8651 nat_grad_norm = 0.0901 cg_residual = 1.7378 step_size = 0.4618 reward = -0.0000 fps = 6 mse_loss = 0.3011 
2022-05-01 16:08:59.526420 - gail/main.py:164 - [TRPO] iter = 1944000 dist_mean = 0.0713 dist_std = 0.1459 vf_loss = 0.0148 grad_norm = 2.8378 nat_grad_norm = 0.0697 cg_residual = 2.4233 step_size = 0.4896 reward = 0.0000 fps = 5 mse_loss = 0.3100 
2022-05-01 16:09:09.360327 - gail/main.py:164 - [TRPO] iter = 1945000 dist_mean = 0.0718 dist_std = 0.1461 vf_loss = 0.0326 grad_norm = 4.7430 nat_grad_norm = 0.0782 cg_residual = 1.4173 step_size = 0.4683 reward = -0.0000 fps = 5 mse_loss = 0.3023 
2022-05-01 16:09:09.578013 - gail/main.py:191 - [Discriminator] iter = 1945000 loss = -0.4583 grad_norm = 2.9294 grad_penalty = 0.0449 regularization = 0.0000 true_logits = -0.2162 fake_logits = -0.7194 true_prob = 0.4522 fake_prob = 0.3803 
2022-05-01 16:11:19.595387 - gail/main.py:132 - [Evaluate] iter = 1945000 episode={ returns = 3611.5412 lengths = 1000 } discounted_episode={ returns = 2230.2744 lengths = 1000 } 
2022-05-01 16:11:29.119560 - gail/main.py:164 - [TRPO] iter = 1946000 dist_mean = 0.0632 dist_std = 0.1464 vf_loss = 0.0219 grad_norm = 3.2509 nat_grad_norm = 0.0853 cg_residual = 7.7204 step_size = 0.4264 reward = -0.0000 fps = 7 mse_loss = 0.3087 
2022-05-01 16:11:38.623315 - gail/main.py:164 - [TRPO] iter = 1947000 dist_mean = 0.0671 dist_std = 0.1465 vf_loss = 0.0228 grad_norm = 3.7709 nat_grad_norm = 0.0723 cg_residual = 4.4028 step_size = 0.4770 reward = -0.0000 fps = 6 mse_loss = 0.3419 
2022-05-01 16:11:48.233975 - gail/main.py:164 - [TRPO] iter = 1948000 dist_mean = 0.0641 dist_std = 0.1465 vf_loss = 0.0165 grad_norm = 2.6923 nat_grad_norm = 0.0798 cg_residual = 2.0829 step_size = 0.5082 reward = 0.0000 fps = 6 mse_loss = 0.2934 
2022-05-01 16:11:57.763753 - gail/main.py:164 - [TRPO] iter = 1949000 dist_mean = 0.0515 dist_std = 0.1466 vf_loss = 0.0293 grad_norm = 2.6229 nat_grad_norm = 0.1383 cg_residual = 4.6614 step_size = 0.3598 reward = -0.0000 fps = 5 mse_loss = 0.3275 
2022-05-01 16:12:07.484273 - gail/main.py:164 - [TRPO] iter = 1950000 dist_mean = 0.0923 dist_std = 0.1463 vf_loss = 0.0174 grad_norm = 5.5127 nat_grad_norm = 0.0806 cg_residual = 6.9538 step_size = 0.3653 reward = -0.0000 fps = 5 mse_loss = 0.3288 
2022-05-01 16:12:07.690830 - gail/main.py:191 - [Discriminator] iter = 1950000 loss = -0.2539 grad_norm = 2.8879 grad_penalty = 0.0465 regularization = 0.0000 true_logits = -0.3084 fake_logits = -0.6087 true_prob = 0.4413 fake_prob = 0.3869 
2022-05-01 16:14:18.221579 - gail/main.py:132 - [Evaluate] iter = 1950000 episode={ returns = 3610.5640 lengths = 1000 } discounted_episode={ returns = 2227.0868 lengths = 1000 } 
2022-05-01 16:14:27.537812 - gail/main.py:164 - [TRPO] iter = 1951000 dist_mean = 0.0569 dist_std = 0.1464 vf_loss = 0.0109 grad_norm = 2.9658 nat_grad_norm = 0.1122 cg_residual = 3.6768 step_size = 0.3807 reward = -0.0000 fps = 7 mse_loss = 0.3312 
2022-05-01 16:14:37.387908 - gail/main.py:164 - [TRPO] iter = 1952000 dist_mean = 0.1045 dist_std = 0.1464 vf_loss = 0.0524 grad_norm = 4.8892 nat_grad_norm = 0.0805 cg_residual = 1.3183 step_size = 0.5101 reward = 0.0000 fps = 6 mse_loss = 0.3511 
2022-05-01 16:14:46.932559 - gail/main.py:164 - [TRPO] iter = 1953000 dist_mean = 0.0751 dist_std = 0.1463 vf_loss = 0.0138 grad_norm = 2.6894 nat_grad_norm = 0.0721 cg_residual = 2.2895 step_size = 0.5128 reward = -0.0000 fps = 6 mse_loss = 0.3289 
2022-05-01 16:14:56.652014 - gail/main.py:164 - [TRPO] iter = 1954000 dist_mean = 0.0868 dist_std = 0.1462 vf_loss = 0.0211 grad_norm = 2.9308 nat_grad_norm = 0.0841 cg_residual = 3.5610 step_size = 0.4709 reward = 0.0000 fps = 5 mse_loss = 0.3244 
2022-05-01 16:15:06.335276 - gail/main.py:164 - [TRPO] iter = 1955000 dist_mean = 0.0518 dist_std = 0.1466 vf_loss = 0.0172 grad_norm = 2.9556 nat_grad_norm = 0.0826 cg_residual = 2.0558 step_size = 0.4315 reward = 0.0000 fps = 5 mse_loss = 0.3132 
2022-05-01 16:15:06.545723 - gail/main.py:191 - [Discriminator] iter = 1955000 loss = -0.3990 grad_norm = 2.8598 grad_penalty = 0.0363 regularization = 0.0000 true_logits = -0.1058 fake_logits = -0.5411 true_prob = 0.4708 fake_prob = 0.3933 
2022-05-01 16:17:15.705339 - gail/main.py:132 - [Evaluate] iter = 1955000 episode={ returns = 3593.2732 lengths = 1000 } discounted_episode={ returns = 2217.8867 lengths = 1000 } 
2022-05-01 16:17:25.173228 - gail/main.py:164 - [TRPO] iter = 1956000 dist_mean = 0.0514 dist_std = 0.1466 vf_loss = 0.0154 grad_norm = 3.1983 nat_grad_norm = 0.0918 cg_residual = 1.9100 step_size = 0.4554 reward = 0.0000 fps = 7 mse_loss = 0.3275 
2022-05-01 16:17:34.865855 - gail/main.py:164 - [TRPO] iter = 1957000 dist_mean = 0.0484 dist_std = 0.1464 vf_loss = 0.0192 grad_norm = 3.3646 nat_grad_norm = 0.0728 cg_residual = 4.8891 step_size = 0.4856 reward = 0.0000 fps = 6 mse_loss = 0.3238 
2022-05-01 16:17:44.430710 - gail/main.py:164 - [TRPO] iter = 1958000 dist_mean = 0.0492 dist_std = 0.1466 vf_loss = 0.0132 grad_norm = 3.0457 nat_grad_norm = 0.0883 cg_residual = 1.2001 step_size = 0.4673 reward = -0.0000 fps = 6 mse_loss = 0.3437 
2022-05-01 16:17:54.024581 - gail/main.py:164 - [TRPO] iter = 1959000 dist_mean = 0.0525 dist_std = 0.1468 vf_loss = 0.0133 grad_norm = 3.7082 nat_grad_norm = 0.0757 cg_residual = 3.5563 step_size = 0.4490 reward = -0.0000 fps = 5 mse_loss = 0.3589 
2022-05-01 16:18:03.826822 - gail/main.py:164 - [TRPO] iter = 1960000 dist_mean = 0.0797 dist_std = 0.1466 vf_loss = 0.0147 grad_norm = 3.4638 nat_grad_norm = 0.0801 cg_residual = 2.9266 step_size = 0.4453 reward = -0.0000 fps = 5 mse_loss = 0.3268 
2022-05-01 16:18:04.066621 - gail/main.py:191 - [Discriminator] iter = 1960000 loss = -0.3266 grad_norm = 2.9018 grad_penalty = 0.0437 regularization = 0.0000 true_logits = -0.1183 fake_logits = -0.4885 true_prob = 0.4701 fake_prob = 0.4020 
2022-05-01 16:20:15.164599 - gail/main.py:132 - [Evaluate] iter = 1960000 episode={ returns = 3607.9590 lengths = 1000 } discounted_episode={ returns = 2233.2435 lengths = 1000 } 
2022-05-01 16:20:24.778955 - gail/main.py:164 - [TRPO] iter = 1961000 dist_mean = 0.0808 dist_std = 0.1465 vf_loss = 0.0174 grad_norm = 3.5380 nat_grad_norm = 0.0796 cg_residual = 4.4644 step_size = 0.4263 reward = 0.0000 fps = 7 mse_loss = 0.3140 
2022-05-01 16:20:34.605813 - gail/main.py:164 - [TRPO] iter = 1962000 dist_mean = 0.0669 dist_std = 0.1463 vf_loss = 0.0440 grad_norm = 4.9076 nat_grad_norm = 0.0626 cg_residual = 1.4131 step_size = 0.4574 reward = 0.0000 fps = 6 mse_loss = 0.3201 
2022-05-01 16:20:44.363874 - gail/main.py:164 - [TRPO] iter = 1963000 dist_mean = 0.0654 dist_std = 0.1462 vf_loss = 0.0199 grad_norm = 3.1718 nat_grad_norm = 0.0841 cg_residual = 2.9726 step_size = 0.4361 reward = -0.0000 fps = 6 mse_loss = 0.3352 
2022-05-01 16:20:53.808848 - gail/main.py:164 - [TRPO] iter = 1964000 dist_mean = 0.0590 dist_std = 0.1463 vf_loss = 0.0179 grad_norm = 5.0111 nat_grad_norm = 0.0549 cg_residual = 1.6536 step_size = 0.4706 reward = 0.0000 fps = 5 mse_loss = 0.3465 
2022-05-01 16:21:03.423911 - gail/main.py:164 - [TRPO] iter = 1965000 dist_mean = 0.0953 dist_std = 0.1463 vf_loss = 0.0299 grad_norm = 3.4859 nat_grad_norm = 0.0808 cg_residual = 3.7556 step_size = 0.4525 reward = -0.0000 fps = 5 mse_loss = 0.3604 
2022-05-01 16:21:03.614770 - gail/main.py:191 - [Discriminator] iter = 1965000 loss = -0.6215 grad_norm = 2.5812 grad_penalty = 0.0435 regularization = 0.0000 true_logits = 0.0851 fake_logits = -0.5798 true_prob = 0.5053 fake_prob = 0.3892 
2022-05-01 16:23:14.727280 - gail/main.py:132 - [Evaluate] iter = 1965000 episode={ returns = 3612.7571 lengths = 1000 } discounted_episode={ returns = 2237.3670 lengths = 1000 } 
2022-05-01 16:23:24.463086 - gail/main.py:164 - [TRPO] iter = 1966000 dist_mean = 0.0597 dist_std = 0.1461 vf_loss = 0.0684 grad_norm = 2.5919 nat_grad_norm = 0.0669 cg_residual = 2.6942 step_size = 0.5076 reward = -0.0000 fps = 7 mse_loss = 0.3369 
2022-05-01 16:23:34.170335 - gail/main.py:164 - [TRPO] iter = 1967000 dist_mean = 0.0383 dist_std = 0.1463 vf_loss = 0.0176 grad_norm = 4.4225 nat_grad_norm = 0.0978 cg_residual = 1.8259 step_size = 0.3990 reward = 0.0000 fps = 6 mse_loss = 0.3131 
2022-05-01 16:23:43.423292 - gail/main.py:164 - [TRPO] iter = 1968000 dist_mean = 0.0497 dist_std = 0.1463 vf_loss = 0.0185 grad_norm = 3.6042 nat_grad_norm = 0.0924 cg_residual = 1.7069 step_size = 0.4565 reward = 0.0000 fps = 6 mse_loss = 0.3309 
2022-05-01 16:23:52.782374 - gail/main.py:164 - [TRPO] iter = 1969000 dist_mean = 0.0822 dist_std = 0.1461 vf_loss = 0.0371 grad_norm = 4.4808 nat_grad_norm = 0.0919 cg_residual = 4.1875 step_size = 0.4202 reward = 0.0000 fps = 5 mse_loss = 0.3685 
2022-05-01 16:24:02.575797 - gail/main.py:164 - [TRPO] iter = 1970000 dist_mean = 0.0387 dist_std = 0.1464 vf_loss = 0.0513 grad_norm = 2.9705 nat_grad_norm = 0.0833 cg_residual = 1.0606 step_size = 0.4390 reward = 0.0000 fps = 5 mse_loss = 0.3275 
2022-05-01 16:24:02.819997 - gail/main.py:191 - [Discriminator] iter = 1970000 loss = -0.3942 grad_norm = 2.7997 grad_penalty = 0.0451 regularization = 0.0000 true_logits = 0.1228 fake_logits = -0.3166 true_prob = 0.5093 fake_prob = 0.4335 
2022-05-01 16:26:16.496196 - gail/main.py:132 - [Evaluate] iter = 1970000 episode={ returns = 3624.8669 lengths = 1000 } discounted_episode={ returns = 2240.2858 lengths = 1000 } 
2022-05-01 16:26:26.449623 - gail/main.py:164 - [TRPO] iter = 1971000 dist_mean = 0.0446 dist_std = 0.1463 vf_loss = 0.0339 grad_norm = 3.8455 nat_grad_norm = 0.0755 cg_residual = 4.0407 step_size = 0.4042 reward = -0.0000 fps = 6 mse_loss = 0.3208 
2022-05-01 16:26:36.409251 - gail/main.py:164 - [TRPO] iter = 1972000 dist_mean = 0.0556 dist_std = 0.1465 vf_loss = 0.0272 grad_norm = 2.5155 nat_grad_norm = 0.0841 cg_residual = 1.5493 step_size = 0.5198 reward = -0.0000 fps = 6 mse_loss = 0.3455 
2022-05-01 16:26:46.468851 - gail/main.py:164 - [TRPO] iter = 1973000 dist_mean = 0.0546 dist_std = 0.1462 vf_loss = 0.0185 grad_norm = 4.0606 nat_grad_norm = 0.0949 cg_residual = 1.7034 step_size = 0.4088 reward = 0.0000 fps = 6 mse_loss = 0.3197 
2022-05-01 16:26:56.167175 - gail/main.py:164 - [TRPO] iter = 1974000 dist_mean = 0.0376 dist_std = 0.1462 vf_loss = 0.0453 grad_norm = 3.7387 nat_grad_norm = 0.0813 cg_residual = 9.6419 step_size = 0.4291 reward = -0.0000 fps = 5 mse_loss = 0.3398 
2022-05-01 16:27:05.817704 - gail/main.py:164 - [TRPO] iter = 1975000 dist_mean = 0.0496 dist_std = 0.1461 vf_loss = 0.0149 grad_norm = 4.0671 nat_grad_norm = 0.0826 cg_residual = 2.0268 step_size = 0.4393 reward = 0.0000 fps = 5 mse_loss = 0.3309 
2022-05-01 16:27:06.039935 - gail/main.py:191 - [Discriminator] iter = 1975000 loss = -0.4298 grad_norm = 3.5610 grad_penalty = 0.0392 regularization = 0.0000 true_logits = 0.2272 fake_logits = -0.2419 true_prob = 0.5265 fake_prob = 0.4502 
2022-05-01 16:29:15.799707 - gail/main.py:132 - [Evaluate] iter = 1975000 episode={ returns = 3621.9843 lengths = 1000 } discounted_episode={ returns = 2243.6116 lengths = 1000 } 
2022-05-01 16:29:25.440351 - gail/main.py:164 - [TRPO] iter = 1976000 dist_mean = 0.0365 dist_std = 0.1459 vf_loss = 0.0116 grad_norm = 4.2235 nat_grad_norm = 0.0766 cg_residual = 1.3907 step_size = 0.4117 reward = 0.0000 fps = 7 mse_loss = 0.3314 
2022-05-01 16:29:35.117811 - gail/main.py:164 - [TRPO] iter = 1977000 dist_mean = 0.0366 dist_std = 0.1459 vf_loss = 0.0191 grad_norm = 3.0126 nat_grad_norm = 0.0772 cg_residual = 1.3291 step_size = 0.4760 reward = -0.0000 fps = 6 mse_loss = 0.2917 
2022-05-01 16:29:44.772214 - gail/main.py:164 - [TRPO] iter = 1978000 dist_mean = 0.0386 dist_std = 0.1457 vf_loss = 0.0220 grad_norm = 4.4201 nat_grad_norm = 0.1024 cg_residual = 4.1519 step_size = 0.3590 reward = -0.0000 fps = 6 mse_loss = 0.3274 
2022-05-01 16:29:53.810097 - gail/main.py:164 - [TRPO] iter = 1979000 dist_mean = 0.0477 dist_std = 0.1455 vf_loss = 0.0132 grad_norm = 3.9215 nat_grad_norm = 0.0650 cg_residual = 3.6835 step_size = 0.5310 reward = -0.0000 fps = 5 mse_loss = 0.3067 
2022-05-01 16:30:03.623931 - gail/main.py:164 - [TRPO] iter = 1980000 dist_mean = 0.0438 dist_std = 0.1454 vf_loss = 0.0203 grad_norm = 3.7839 nat_grad_norm = 0.0934 cg_residual = 1.2999 step_size = 0.3854 reward = -0.0000 fps = 5 mse_loss = 0.3607 
2022-05-01 16:30:03.823862 - gail/main.py:191 - [Discriminator] iter = 1980000 loss = -0.3130 grad_norm = 3.6958 grad_penalty = 0.0446 regularization = 0.0000 true_logits = 0.2893 fake_logits = -0.0683 true_prob = 0.5431 fake_prob = 0.4796 
2022-05-01 16:32:14.154517 - gail/main.py:132 - [Evaluate] iter = 1980000 episode={ returns = 3617.5026 lengths = 1000 } discounted_episode={ returns = 2241.5405 lengths = 1000 } 
2022-05-01 16:32:23.409578 - gail/main.py:164 - [TRPO] iter = 1981000 dist_mean = 0.0311 dist_std = 0.1453 vf_loss = 0.0182 grad_norm = 3.7193 nat_grad_norm = 0.0821 cg_residual = 1.3391 step_size = 0.4290 reward = -0.0000 fps = 7 mse_loss = 0.3323 
2022-05-01 16:32:33.017251 - gail/main.py:164 - [TRPO] iter = 1982000 dist_mean = 0.0334 dist_std = 0.1451 vf_loss = 0.0191 grad_norm = 3.1438 nat_grad_norm = 0.0742 cg_residual = 6.8233 step_size = 0.4465 reward = -0.0000 fps = 6 mse_loss = 0.3443 
2022-05-01 16:32:42.424374 - gail/main.py:164 - [TRPO] iter = 1983000 dist_mean = 0.0282 dist_std = 0.1449 vf_loss = 0.0259 grad_norm = 4.2468 nat_grad_norm = 0.1543 cg_residual = 33.7704 step_size = 0.2918 reward = 0.0000 fps = 6 mse_loss = 0.3154 
2022-05-01 16:32:52.302538 - gail/main.py:164 - [TRPO] iter = 1984000 dist_mean = 0.0281 dist_std = 0.1449 vf_loss = 0.0314 grad_norm = 3.5517 nat_grad_norm = 0.0892 cg_residual = 5.0666 step_size = 0.3947 reward = 0.0000 fps = 5 mse_loss = 0.3352 
2022-05-01 16:33:02.540919 - gail/main.py:164 - [TRPO] iter = 1985000 dist_mean = 0.0257 dist_std = 0.1449 vf_loss = 0.0125 grad_norm = 4.2886 nat_grad_norm = 0.0934 cg_residual = 8.2299 step_size = 0.4183 reward = 0.0000 fps = 5 mse_loss = 0.3514 
2022-05-01 16:33:02.781442 - gail/main.py:191 - [Discriminator] iter = 1985000 loss = -0.3811 grad_norm = 3.1968 grad_penalty = 0.0446 regularization = 0.0000 true_logits = 0.3985 fake_logits = -0.0272 true_prob = 0.5636 fake_prob = 0.4879 
2022-05-01 16:35:14.755787 - gail/main.py:132 - [Evaluate] iter = 1985000 episode={ returns = 3622.6274 lengths = 1000 } discounted_episode={ returns = 2242.7444 lengths = 1000 } 
2022-05-01 16:35:24.562935 - gail/main.py:164 - [TRPO] iter = 1986000 dist_mean = 0.0405 dist_std = 0.1445 vf_loss = 0.0145 grad_norm = 2.4376 nat_grad_norm = 0.0932 cg_residual = 8.2940 step_size = 0.4591 reward = 0.0000 fps = 7 mse_loss = 0.3596 
2022-05-01 16:35:34.327432 - gail/main.py:164 - [TRPO] iter = 1987000 dist_mean = 0.0314 dist_std = 0.1445 vf_loss = 0.0151 grad_norm = 5.9069 nat_grad_norm = 0.0730 cg_residual = 1.6973 step_size = 0.4346 reward = -0.0000 fps = 6 mse_loss = 0.3132 
2022-05-01 16:35:44.152723 - gail/main.py:164 - [TRPO] iter = 1988000 dist_mean = 0.0532 dist_std = 0.1446 vf_loss = 0.0147 grad_norm = 3.1168 nat_grad_norm = 0.0808 cg_residual = 2.2717 step_size = 0.4111 reward = 0.0000 fps = 6 mse_loss = 0.3197 
2022-05-01 16:35:54.369343 - gail/main.py:164 - [TRPO] iter = 1989000 dist_mean = 0.0282 dist_std = 0.1444 vf_loss = 0.0246 grad_norm = 3.1658 nat_grad_norm = 0.0853 cg_residual = 4.6199 step_size = 0.4813 reward = 0.0000 fps = 5 mse_loss = 0.3082 
2022-05-01 16:36:04.268363 - gail/main.py:164 - [TRPO] iter = 1990000 dist_mean = 0.0331 dist_std = 0.1445 vf_loss = 0.0244 grad_norm = 5.9086 nat_grad_norm = 0.0885 cg_residual = 5.0436 step_size = 0.3958 reward = 0.0000 fps = 5 mse_loss = 0.3143 
2022-05-01 16:36:04.463130 - gail/main.py:191 - [Discriminator] iter = 1990000 loss = -0.3196 grad_norm = 3.3626 grad_penalty = 0.0389 regularization = 0.0000 true_logits = 0.3751 fake_logits = 0.0165 true_prob = 0.5656 fake_prob = 0.4990 
2022-05-01 16:38:14.978686 - gail/main.py:132 - [Evaluate] iter = 1990000 episode={ returns = 3613.5352 lengths = 1000 } discounted_episode={ returns = 2234.4024 lengths = 1000 } 
2022-05-01 16:38:24.540688 - gail/main.py:164 - [TRPO] iter = 1991000 dist_mean = 0.0382 dist_std = 0.1442 vf_loss = 0.0159 grad_norm = 3.9695 nat_grad_norm = 0.0765 cg_residual = 2.5425 step_size = 0.4853 reward = -0.0000 fps = 7 mse_loss = 0.2989 
2022-05-01 16:38:34.267823 - gail/main.py:164 - [TRPO] iter = 1992000 dist_mean = 0.0240 dist_std = 0.1441 vf_loss = 0.0206 grad_norm = 4.4928 nat_grad_norm = 0.0863 cg_residual = 3.5949 step_size = 0.3953 reward = -0.0000 fps = 6 mse_loss = 0.2953 
2022-05-01 16:38:44.062889 - gail/main.py:164 - [TRPO] iter = 1993000 dist_mean = 0.0372 dist_std = 0.1442 vf_loss = 0.0172 grad_norm = 4.0982 nat_grad_norm = 0.0844 cg_residual = 4.1486 step_size = 0.3829 reward = -0.0000 fps = 6 mse_loss = 0.3297 
2022-05-01 16:38:54.544359 - gail/main.py:164 - [TRPO] iter = 1994000 dist_mean = 0.0258 dist_std = 0.1442 vf_loss = 0.0179 grad_norm = 4.3127 nat_grad_norm = 0.0730 cg_residual = 1.8980 step_size = 0.4476 reward = 0.0000 fps = 5 mse_loss = 0.2838 
2022-05-01 16:39:04.447431 - gail/main.py:164 - [TRPO] iter = 1995000 dist_mean = 0.0163 dist_std = 0.1442 vf_loss = 0.0160 grad_norm = 4.0324 nat_grad_norm = 0.0769 cg_residual = 5.6335 step_size = 0.4361 reward = 0.0000 fps = 5 mse_loss = 0.3158 
2022-05-01 16:39:04.664105 - gail/main.py:191 - [Discriminator] iter = 1995000 loss = -0.3541 grad_norm = 3.6990 grad_penalty = 0.0432 regularization = 0.0000 true_logits = 0.4863 fake_logits = 0.0890 true_prob = 0.5925 fake_prob = 0.5122 
2022-05-01 16:41:16.765162 - gail/main.py:132 - [Evaluate] iter = 1995000 episode={ returns = 3601.1861 lengths = 1000 } discounted_episode={ returns = 2232.7981 lengths = 1000 } 
2022-05-01 16:41:26.337146 - gail/main.py:164 - [TRPO] iter = 1996000 dist_mean = 0.0168 dist_std = 0.1445 vf_loss = 0.0198 grad_norm = 3.8101 nat_grad_norm = 0.0729 cg_residual = 4.9936 step_size = 0.4636 reward = 0.0000 fps = 7 mse_loss = 0.2843 
2022-05-01 16:41:35.944588 - gail/main.py:164 - [TRPO] iter = 1997000 dist_mean = 0.0351 dist_std = 0.1446 vf_loss = 0.0448 grad_norm = 3.7060 nat_grad_norm = 0.0714 cg_residual = 6.4473 step_size = 0.5062 reward = -0.0000 fps = 6 mse_loss = 0.2867 
2022-05-01 16:41:46.008636 - gail/main.py:164 - [TRPO] iter = 1998000 dist_mean = 0.0305 dist_std = 0.1448 vf_loss = 0.0801 grad_norm = 2.7277 nat_grad_norm = 0.0696 cg_residual = 1.1478 step_size = 0.4896 reward = -0.0000 fps = 6 mse_loss = 0.2701 
2022-05-01 16:41:55.771966 - gail/main.py:164 - [TRPO] iter = 1999000 dist_mean = 0.0288 dist_std = 0.1450 vf_loss = 0.0656 grad_norm = 4.2789 nat_grad_norm = 0.0785 cg_residual = 1.3308 step_size = 0.4345 reward = -0.0000 fps = 5 mse_loss = 0.3058 
2022-05-01 16:42:05.281149 - gail/main.py:164 - [TRPO] iter = 2000000 dist_mean = 0.0231 dist_std = 0.1451 vf_loss = 0.0256 grad_norm = 4.9461 nat_grad_norm = 0.0679 cg_residual = 2.7597 step_size = 0.4463 reward = 0.0000 fps = 5 mse_loss = 0.3024 
2022-05-01 16:42:05.492060 - gail/main.py:191 - [Discriminator] iter = 2000000 loss = -0.3032 grad_norm = 3.1720 grad_penalty = 0.0433 regularization = 0.0000 true_logits = 0.4964 fake_logits = 0.1499 true_prob = 0.5948 fake_prob = 0.5271 
2022-05-01 16:44:19.269842 - gail/main.py:132 - [Evaluate] iter = 2000000 episode={ returns = 3621.3757 lengths = 1000 } discounted_episode={ returns = 2240.8115 lengths = 1000 } 
2022-05-01 16:44:29.139484 - gail/main.py:164 - [TRPO] iter = 2001000 dist_mean = 0.0293 dist_std = 0.1451 vf_loss = 0.0325 grad_norm = 3.7675 nat_grad_norm = 0.0981 cg_residual = 4.2242 step_size = 0.4057 reward = 0.0000 fps = 6 mse_loss = 0.3206 
2022-05-01 16:44:38.998826 - gail/main.py:164 - [TRPO] iter = 2002000 dist_mean = 0.0337 dist_std = 0.1453 vf_loss = 0.0384 grad_norm = 3.8778 nat_grad_norm = 0.0786 cg_residual = 2.9875 step_size = 0.4758 reward = 0.0000 fps = 6 mse_loss = 0.3092 
2022-05-01 16:44:48.903559 - gail/main.py:164 - [TRPO] iter = 2003000 dist_mean = 0.0396 dist_std = 0.1451 vf_loss = 0.0437 grad_norm = 2.9510 nat_grad_norm = 0.0628 cg_residual = 4.0538 step_size = 0.6017 reward = -0.0000 fps = 6 mse_loss = 0.2978 
2022-05-01 16:44:58.809000 - gail/main.py:164 - [TRPO] iter = 2004000 dist_mean = 0.0215 dist_std = 0.1456 vf_loss = 0.0161 grad_norm = 3.2726 nat_grad_norm = 0.0767 cg_residual = 8.3780 step_size = 0.4432 reward = 0.0000 fps = 5 mse_loss = 0.2827 
2022-05-01 16:45:09.253253 - gail/main.py:164 - [TRPO] iter = 2005000 dist_mean = -0.0003 dist_std = 0.1455 vf_loss = 0.0533 grad_norm = 3.8427 nat_grad_norm = 0.0641 cg_residual = 1.6106 step_size = 0.5759 reward = -0.0000 fps = 5 mse_loss = 0.2659 
2022-05-01 16:45:09.527489 - gail/main.py:191 - [Discriminator] iter = 2005000 loss = -0.1992 grad_norm = 3.8334 grad_penalty = 0.0547 regularization = 0.0000 true_logits = 0.5607 fake_logits = 0.3067 true_prob = 0.6088 fake_prob = 0.5528 
2022-05-01 16:47:24.523144 - gail/main.py:132 - [Evaluate] iter = 2005000 episode={ returns = 3651.0096 lengths = 1000 } discounted_episode={ returns = 2251.2190 lengths = 1000 } 
2022-05-01 16:47:34.422226 - gail/main.py:164 - [TRPO] iter = 2006000 dist_mean = 0.0300 dist_std = 0.1457 vf_loss = 0.0606 grad_norm = 4.5435 nat_grad_norm = 0.0754 cg_residual = 3.2002 step_size = 0.5060 reward = -0.0000 fps = 6 mse_loss = 0.3207 
2022-05-01 16:47:44.502744 - gail/main.py:164 - [TRPO] iter = 2007000 dist_mean = 0.0325 dist_std = 0.1459 vf_loss = 0.0508 grad_norm = 3.2555 nat_grad_norm = 0.0673 cg_residual = 4.7911 step_size = 0.5692 reward = 0.0000 fps = 6 mse_loss = 0.2748 
2022-05-01 16:47:54.306691 - gail/main.py:164 - [TRPO] iter = 2008000 dist_mean = 0.0303 dist_std = 0.1457 vf_loss = 0.0339 grad_norm = 4.2085 nat_grad_norm = 0.0559 cg_residual = 2.7504 step_size = 0.5225 reward = 0.0000 fps = 6 mse_loss = 0.3023 
2022-05-01 16:48:04.050095 - gail/main.py:164 - [TRPO] iter = 2009000 dist_mean = 0.0243 dist_std = 0.1458 vf_loss = 0.0855 grad_norm = 4.6491 nat_grad_norm = 0.0638 cg_residual = 4.3704 step_size = 0.4907 reward = 0.0000 fps = 5 mse_loss = 0.2589 
2022-05-01 16:48:13.789046 - gail/main.py:164 - [TRPO] iter = 2010000 dist_mean = 0.0208 dist_std = 0.1456 vf_loss = 0.0487 grad_norm = 4.4005 nat_grad_norm = 0.0556 cg_residual = 4.2242 step_size = 0.4798 reward = -0.0000 fps = 5 mse_loss = 0.2758 
2022-05-01 16:48:14.008270 - gail/main.py:191 - [Discriminator] iter = 2010000 loss = -0.3407 grad_norm = 3.9211 grad_penalty = 0.0584 regularization = 0.0000 true_logits = 0.7485 fake_logits = 0.3494 true_prob = 0.6455 fake_prob = 0.5656 
2022-05-01 16:50:24.256235 - gail/main.py:132 - [Evaluate] iter = 2010000 episode={ returns = 3639.5980 lengths = 1000 } discounted_episode={ returns = 2236.0938 lengths = 1000 } 
2022-05-01 16:50:34.045562 - gail/main.py:164 - [TRPO] iter = 2011000 dist_mean = 0.0110 dist_std = 0.1455 vf_loss = 0.0563 grad_norm = 3.4074 nat_grad_norm = 0.0815 cg_residual = 3.9048 step_size = 0.4861 reward = -0.0000 fps = 7 mse_loss = 0.2617 
2022-05-01 16:50:43.843490 - gail/main.py:164 - [TRPO] iter = 2012000 dist_mean = -0.0029 dist_std = 0.1457 vf_loss = 0.0264 grad_norm = 2.3453 nat_grad_norm = 0.0846 cg_residual = 4.0562 step_size = 0.5425 reward = 0.0000 fps = 6 mse_loss = 0.3021 
2022-05-01 16:50:53.791191 - gail/main.py:164 - [TRPO] iter = 2013000 dist_mean = 0.0073 dist_std = 0.1459 vf_loss = 0.0428 grad_norm = 4.0867 nat_grad_norm = 0.0644 cg_residual = 2.7751 step_size = 0.5757 reward = -0.0000 fps = 6 mse_loss = 0.2744 
2022-05-01 16:51:03.546146 - gail/main.py:164 - [TRPO] iter = 2014000 dist_mean = 0.0166 dist_std = 0.1458 vf_loss = 0.0324 grad_norm = 3.8589 nat_grad_norm = 0.0653 cg_residual = 2.1970 step_size = 0.5404 reward = -0.0000 fps = 5 mse_loss = 0.2544 
2022-05-01 16:51:13.317008 - gail/main.py:164 - [TRPO] iter = 2015000 dist_mean = 0.0107 dist_std = 0.1460 vf_loss = 0.0650 grad_norm = 4.0716 nat_grad_norm = 0.0611 cg_residual = 3.4375 step_size = 0.4867 reward = 0.0000 fps = 5 mse_loss = 0.2727 
2022-05-01 16:51:13.552724 - gail/main.py:191 - [Discriminator] iter = 2015000 loss = -0.2506 grad_norm = 3.1505 grad_penalty = 0.0565 regularization = 0.0000 true_logits = 0.7945 fake_logits = 0.4875 true_prob = 0.6556 fake_prob = 0.5836 
2022-05-01 16:53:21.134461 - gail/main.py:132 - [Evaluate] iter = 2015000 episode={ returns = 3655.5575 lengths = 1000 } discounted_episode={ returns = 2247.8628 lengths = 1000 } 
2022-05-01 16:53:30.441861 - gail/main.py:164 - [TRPO] iter = 2016000 dist_mean = 0.0140 dist_std = 0.1460 vf_loss = 0.0545 grad_norm = 4.2139 nat_grad_norm = 0.0883 cg_residual = 6.4032 step_size = 0.4856 reward = -0.0000 fps = 7 mse_loss = 0.2791 
2022-05-01 16:53:39.892634 - gail/main.py:164 - [TRPO] iter = 2017000 dist_mean = 0.0104 dist_std = 0.1463 vf_loss = 0.0171 grad_norm = 4.4328 nat_grad_norm = 0.0799 cg_residual = 8.2502 step_size = 0.4376 reward = -0.0000 fps = 6 mse_loss = 0.3030 
2022-05-01 16:53:49.697874 - gail/main.py:164 - [TRPO] iter = 2018000 dist_mean = 0.0013 dist_std = 0.1464 vf_loss = 0.0214 grad_norm = 3.5602 nat_grad_norm = 0.0955 cg_residual = 15.7461 step_size = 0.3179 reward = 0.0000 fps = 6 mse_loss = 0.2684 
2022-05-01 16:53:59.144996 - gail/main.py:164 - [TRPO] iter = 2019000 dist_mean = 0.0028 dist_std = 0.1464 vf_loss = 0.0584 grad_norm = 4.5315 nat_grad_norm = 0.0770 cg_residual = 5.3790 step_size = 0.4520 reward = 0.0000 fps = 6 mse_loss = 0.2764 
2022-05-01 16:54:08.684465 - gail/main.py:164 - [TRPO] iter = 2020000 dist_mean = 0.0128 dist_std = 0.1462 vf_loss = 0.0577 grad_norm = 4.0110 nat_grad_norm = 0.0672 cg_residual = 4.6292 step_size = 0.4668 reward = -0.0000 fps = 5 mse_loss = 0.2874 
2022-05-01 16:54:08.881362 - gail/main.py:191 - [Discriminator] iter = 2020000 loss = -0.3728 grad_norm = 4.0316 grad_penalty = 0.0595 regularization = 0.0000 true_logits = 0.9476 fake_logits = 0.5154 true_prob = 0.6764 fake_prob = 0.5907 
2022-05-01 16:56:18.138017 - gail/main.py:132 - [Evaluate] iter = 2020000 episode={ returns = 3652.2564 lengths = 1000 } discounted_episode={ returns = 2246.2323 lengths = 1000 } 
2022-05-01 16:56:27.448410 - gail/main.py:164 - [TRPO] iter = 2021000 dist_mean = 0.0001 dist_std = 0.1462 vf_loss = 0.0465 grad_norm = 5.7485 nat_grad_norm = 0.0549 cg_residual = 1.2695 step_size = 0.5956 reward = 0.0000 fps = 7 mse_loss = 0.2641 
2022-05-01 16:56:36.830166 - gail/main.py:164 - [TRPO] iter = 2022000 dist_mean = 0.0125 dist_std = 0.1461 vf_loss = 0.0250 grad_norm = 2.5872 nat_grad_norm = 0.0781 cg_residual = 2.0986 step_size = 0.4475 reward = 0.0000 fps = 6 mse_loss = 0.2899 
2022-05-01 16:56:46.072754 - gail/main.py:164 - [TRPO] iter = 2023000 dist_mean = 0.0181 dist_std = 0.1459 vf_loss = 0.0233 grad_norm = 4.1913 nat_grad_norm = 0.0611 cg_residual = 1.7322 step_size = 0.5271 reward = 0.0000 fps = 6 mse_loss = 0.2920 
2022-05-01 16:56:55.710054 - gail/main.py:164 - [TRPO] iter = 2024000 dist_mean = 0.0141 dist_std = 0.1461 vf_loss = 0.0418 grad_norm = 3.8824 nat_grad_norm = 0.0623 cg_residual = 0.7820 step_size = 0.5299 reward = -0.0000 fps = 5 mse_loss = 0.2469 
2022-05-01 16:57:04.981815 - gail/main.py:164 - [TRPO] iter = 2025000 dist_mean = 0.0126 dist_std = 0.1462 vf_loss = 0.0680 grad_norm = 4.4724 nat_grad_norm = 0.0978 cg_residual = 3.0564 step_size = 0.3501 reward = -0.0000 fps = 5 mse_loss = 0.2893 
2022-05-01 16:57:05.215252 - gail/main.py:191 - [Discriminator] iter = 2025000 loss = -0.4263 grad_norm = 3.0083 grad_penalty = 0.0560 regularization = 0.0000 true_logits = 0.9860 fake_logits = 0.5037 true_prob = 0.6803 fake_prob = 0.5773 
2022-05-01 16:59:11.538143 - gail/main.py:132 - [Evaluate] iter = 2025000 episode={ returns = 3662.4866 lengths = 1000 } discounted_episode={ returns = 2256.4476 lengths = 1000 } 
2022-05-01 16:59:21.046223 - gail/main.py:164 - [TRPO] iter = 2026000 dist_mean = 0.0072 dist_std = 0.1460 vf_loss = 0.0206 grad_norm = 3.1240 nat_grad_norm = 0.0848 cg_residual = 7.3769 step_size = 0.4575 reward = 0.0000 fps = 7 mse_loss = 0.2634 
2022-05-01 16:59:30.675770 - gail/main.py:164 - [TRPO] iter = 2027000 dist_mean = 0.0046 dist_std = 0.1459 vf_loss = 0.0462 grad_norm = 3.4988 nat_grad_norm = 0.0901 cg_residual = 5.4995 step_size = 0.3968 reward = -0.0000 fps = 6 mse_loss = 0.2902 
2022-05-01 16:59:40.295045 - gail/main.py:164 - [TRPO] iter = 2028000 dist_mean = -0.0020 dist_std = 0.1459 vf_loss = 0.0310 grad_norm = 6.6820 nat_grad_norm = 0.0673 cg_residual = 8.4777 step_size = 0.4422 reward = -0.0000 fps = 6 mse_loss = 0.2330 
2022-05-01 16:59:49.924135 - gail/main.py:164 - [TRPO] iter = 2029000 dist_mean = 0.0460 dist_std = 0.1459 vf_loss = 0.0215 grad_norm = 7.3084 nat_grad_norm = 0.0731 cg_residual = 2.3670 step_size = 0.4172 reward = -0.0000 fps = 6 mse_loss = 0.2524 
2022-05-01 16:59:59.324015 - gail/main.py:164 - [TRPO] iter = 2030000 dist_mean = 0.0395 dist_std = 0.1458 vf_loss = 0.0403 grad_norm = 3.2703 nat_grad_norm = 0.0959 cg_residual = 1.2193 step_size = 0.4143 reward = 0.0000 fps = 5 mse_loss = 0.2857 
2022-05-01 16:59:59.585211 - gail/main.py:191 - [Discriminator] iter = 2030000 loss = -0.4624 grad_norm = 3.2868 grad_penalty = 0.0565 regularization = 0.0000 true_logits = 1.0607 fake_logits = 0.5418 true_prob = 0.6894 fake_prob = 0.5864 
2022-05-01 17:02:07.617608 - gail/main.py:132 - [Evaluate] iter = 2030000 episode={ returns = 3667.9921 lengths = 1000 } discounted_episode={ returns = 2257.2616 lengths = 1000 } 
2022-05-01 17:02:17.162916 - gail/main.py:164 - [TRPO] iter = 2031000 dist_mean = 0.0224 dist_std = 0.1460 vf_loss = 0.0660 grad_norm = 4.6548 nat_grad_norm = 0.0581 cg_residual = 1.8809 step_size = 0.5343 reward = 0.0000 fps = 7 mse_loss = 0.2654 
2022-05-01 17:02:26.914623 - gail/main.py:164 - [TRPO] iter = 2032000 dist_mean = 0.0145 dist_std = 0.1456 vf_loss = 0.0410 grad_norm = 3.4117 nat_grad_norm = 0.0894 cg_residual = 5.8674 step_size = 0.4432 reward = 0.0000 fps = 6 mse_loss = 0.2717 
2022-05-01 17:02:36.654596 - gail/main.py:164 - [TRPO] iter = 2033000 dist_mean = 0.0405 dist_std = 0.1457 vf_loss = 0.0297 grad_norm = 2.6904 nat_grad_norm = 0.0771 cg_residual = 4.6845 step_size = 0.4967 reward = 0.0000 fps = 6 mse_loss = 0.2687 
2022-05-01 17:02:46.341921 - gail/main.py:164 - [TRPO] iter = 2034000 dist_mean = 0.0488 dist_std = 0.1457 vf_loss = 0.0280 grad_norm = 3.1721 nat_grad_norm = 0.0850 cg_residual = 7.6582 step_size = 0.4677 reward = -0.0000 fps = 5 mse_loss = 0.2698 
2022-05-01 17:02:55.816401 - gail/main.py:164 - [TRPO] iter = 2035000 dist_mean = 0.0531 dist_std = 0.1456 vf_loss = 0.0207 grad_norm = 4.9604 nat_grad_norm = 0.0979 cg_residual = 8.2476 step_size = 0.3821 reward = -0.0000 fps = 5 mse_loss = 0.2852 
2022-05-01 17:02:56.019372 - gail/main.py:191 - [Discriminator] iter = 2035000 loss = -0.4545 grad_norm = 3.5823 grad_penalty = 0.0524 regularization = 0.0000 true_logits = 1.0181 fake_logits = 0.5113 true_prob = 0.6649 fake_prob = 0.5782 
2022-05-01 17:05:03.639562 - gail/main.py:132 - [Evaluate] iter = 2035000 episode={ returns = 3631.3544 lengths = 1000 } discounted_episode={ returns = 2226.0665 lengths = 1000 } 
2022-05-01 17:05:13.033287 - gail/main.py:164 - [TRPO] iter = 2036000 dist_mean = 0.0521 dist_std = 0.1457 vf_loss = 0.0245 grad_norm = 6.6762 nat_grad_norm = 0.0702 cg_residual = 3.8063 step_size = 0.4750 reward = 0.0000 fps = 7 mse_loss = 0.2648 
2022-05-01 17:05:22.403912 - gail/main.py:164 - [TRPO] iter = 2037000 dist_mean = 0.0546 dist_std = 0.1456 vf_loss = 0.0523 grad_norm = 3.6990 nat_grad_norm = 0.0756 cg_residual = 4.1408 step_size = 0.4633 reward = 0.0000 fps = 6 mse_loss = 0.2874 
2022-05-01 17:05:31.787150 - gail/main.py:164 - [TRPO] iter = 2038000 dist_mean = 0.0540 dist_std = 0.1458 vf_loss = 0.0182 grad_norm = 4.5916 nat_grad_norm = 0.0805 cg_residual = 6.1967 step_size = 0.5484 reward = -0.0000 fps = 6 mse_loss = 0.2764 
2022-05-01 17:05:41.372275 - gail/main.py:164 - [TRPO] iter = 2039000 dist_mean = 0.0725 dist_std = 0.1453 vf_loss = 0.0167 grad_norm = 2.4585 nat_grad_norm = 0.0659 cg_residual = 6.3831 step_size = 0.5173 reward = 0.0000 fps = 6 mse_loss = 0.2706 
2022-05-01 17:05:50.943488 - gail/main.py:164 - [TRPO] iter = 2040000 dist_mean = 0.0819 dist_std = 0.1456 vf_loss = 0.0366 grad_norm = 5.0753 nat_grad_norm = 0.0581 cg_residual = 3.0642 step_size = 0.4970 reward = 0.0000 fps = 5 mse_loss = 0.2880 
2022-05-01 17:05:51.167861 - gail/main.py:191 - [Discriminator] iter = 2040000 loss = -0.3157 grad_norm = 2.8282 grad_penalty = 0.0513 regularization = 0.0000 true_logits = 0.9298 fake_logits = 0.5628 true_prob = 0.6498 fake_prob = 0.5894 
2022-05-01 17:07:59.450250 - gail/main.py:132 - [Evaluate] iter = 2040000 episode={ returns = 3557.5341 lengths = 1000 } discounted_episode={ returns = 2189.6958 lengths = 1000 } 
2022-05-01 17:08:08.968659 - gail/main.py:164 - [TRPO] iter = 2041000 dist_mean = 0.0861 dist_std = 0.1457 vf_loss = 0.0487 grad_norm = 3.1452 nat_grad_norm = 0.0744 cg_residual = 4.6502 step_size = 0.5281 reward = 0.0000 fps = 7 mse_loss = 0.2823 
2022-05-01 17:08:18.629156 - gail/main.py:164 - [TRPO] iter = 2042000 dist_mean = 0.0646 dist_std = 0.1458 vf_loss = 0.0420 grad_norm = 3.5637 nat_grad_norm = 0.0803 cg_residual = 6.6912 step_size = 0.4741 reward = -0.0000 fps = 6 mse_loss = 0.2746 
2022-05-01 17:08:27.541062 - gail/main.py:164 - [TRPO] iter = 2043000 dist_mean = 0.1186 dist_std = 0.1459 vf_loss = 0.0328 grad_norm = 3.0569 nat_grad_norm = 0.0833 cg_residual = 6.3509 step_size = 0.5429 reward = -0.0000 fps = 6 mse_loss = 0.2904 
2022-05-01 17:08:37.342048 - gail/main.py:164 - [TRPO] iter = 2044000 dist_mean = 0.0706 dist_std = 0.1455 vf_loss = 0.1885 grad_norm = 2.8424 nat_grad_norm = 0.0841 cg_residual = 1.4715 step_size = 0.4511 reward = 0.0000 fps = 6 mse_loss = 0.2514 
2022-05-01 17:08:46.934606 - gail/main.py:164 - [TRPO] iter = 2045000 dist_mean = 0.0636 dist_std = 0.1455 vf_loss = 0.0289 grad_norm = 6.9484 nat_grad_norm = 0.0773 cg_residual = 4.3182 step_size = 0.4412 reward = -0.0000 fps = 5 mse_loss = 0.2747 
2022-05-01 17:08:47.161073 - gail/main.py:191 - [Discriminator] iter = 2045000 loss = -0.2760 grad_norm = 2.5952 grad_penalty = 0.0475 regularization = 0.0000 true_logits = 0.8860 fake_logits = 0.5625 true_prob = 0.6332 fake_prob = 0.5766 
2022-05-01 17:10:57.010904 - gail/main.py:132 - [Evaluate] iter = 2045000 episode={ returns = 3533.9215 lengths = 1000 } discounted_episode={ returns = 2175.0708 lengths = 1000 } 
2022-05-01 17:11:06.856569 - gail/main.py:164 - [TRPO] iter = 2046000 dist_mean = 0.0910 dist_std = 0.1454 vf_loss = 0.0416 grad_norm = 3.7865 nat_grad_norm = 0.0545 cg_residual = 3.7149 step_size = 0.5282 reward = -0.0000 fps = 7 mse_loss = 0.2465 
2022-05-01 17:11:16.385801 - gail/main.py:164 - [TRPO] iter = 2047000 dist_mean = 0.0901 dist_std = 0.1454 vf_loss = 0.0318 grad_norm = 4.4566 nat_grad_norm = 0.0692 cg_residual = 5.3687 step_size = 0.4421 reward = -0.0000 fps = 6 mse_loss = 0.3029 
2022-05-01 17:11:26.240530 - gail/main.py:164 - [TRPO] iter = 2048000 dist_mean = 0.0831 dist_std = 0.1455 vf_loss = 0.0484 grad_norm = 3.9260 nat_grad_norm = 0.0850 cg_residual = 1.6782 step_size = 0.4387 reward = -0.0000 fps = 6 mse_loss = 0.2920 
2022-05-01 17:11:35.852446 - gail/main.py:164 - [TRPO] iter = 2049000 dist_mean = 0.0683 dist_std = 0.1453 vf_loss = 0.0395 grad_norm = 4.2057 nat_grad_norm = 0.0935 cg_residual = 11.2703 step_size = 0.3842 reward = -0.0000 fps = 5 mse_loss = 0.2831 
2022-05-01 17:11:45.764127 - gail/main.py:164 - [TRPO] iter = 2050000 dist_mean = 0.0796 dist_std = 0.1453 vf_loss = 0.0318 grad_norm = 3.7907 nat_grad_norm = 0.1015 cg_residual = 8.4876 step_size = 0.3988 reward = 0.0000 fps = 5 mse_loss = 0.2900 
2022-05-01 17:11:45.972827 - gail/main.py:191 - [Discriminator] iter = 2050000 loss = -0.1879 grad_norm = 3.0099 grad_penalty = 0.0470 regularization = 0.0000 true_logits = 0.7371 fake_logits = 0.5022 true_prob = 0.6050 fake_prob = 0.5752 
2022-05-01 17:13:55.400306 - gail/main.py:132 - [Evaluate] iter = 2050000 episode={ returns = 3527.8943 lengths = 1000 } discounted_episode={ returns = 2171.5024 lengths = 1000 } 
2022-05-01 17:14:05.062117 - gail/main.py:164 - [TRPO] iter = 2051000 dist_mean = 0.1304 dist_std = 0.1452 vf_loss = 0.0240 grad_norm = 3.7821 nat_grad_norm = 0.0665 cg_residual = 5.9374 step_size = 0.4859 reward = -0.0000 fps = 7 mse_loss = 0.2558 
2022-05-01 17:14:14.736123 - gail/main.py:164 - [TRPO] iter = 2052000 dist_mean = 0.1302 dist_std = 0.1452 vf_loss = 0.0374 grad_norm = 4.3006 nat_grad_norm = 0.1029 cg_residual = 2.4487 step_size = 0.3803 reward = -0.0000 fps = 6 mse_loss = 0.2787 
2022-05-01 17:14:24.225459 - gail/main.py:164 - [TRPO] iter = 2053000 dist_mean = 0.1111 dist_std = 0.1449 vf_loss = 0.0293 grad_norm = 4.0727 nat_grad_norm = 0.0721 cg_residual = 5.7669 step_size = 0.4417 reward = 0.0000 fps = 6 mse_loss = 0.2815 
2022-05-01 17:14:33.722208 - gail/main.py:164 - [TRPO] iter = 2054000 dist_mean = 0.0958 dist_std = 0.1453 vf_loss = 0.0199 grad_norm = 3.8880 nat_grad_norm = 0.1112 cg_residual = 5.1166 step_size = 0.4018 reward = -0.0000 fps = 5 mse_loss = 0.2688 
2022-05-01 17:14:43.151416 - gail/main.py:164 - [TRPO] iter = 2055000 dist_mean = 0.0883 dist_std = 0.1451 vf_loss = 0.0279 grad_norm = 3.3952 nat_grad_norm = 0.1076 cg_residual = 3.9299 step_size = 0.3899 reward = -0.0000 fps = 5 mse_loss = 0.2648 
2022-05-01 17:14:43.378018 - gail/main.py:191 - [Discriminator] iter = 2055000 loss = -0.0017 grad_norm = 3.2685 grad_penalty = 0.0603 regularization = 0.0000 true_logits = 0.4981 fake_logits = 0.4360 true_prob = 0.5661 fake_prob = 0.5704 
2022-05-01 17:16:52.232919 - gail/main.py:132 - [Evaluate] iter = 2055000 episode={ returns = 3506.0216 lengths = 1000 } discounted_episode={ returns = 2166.7504 lengths = 1000 } 
2022-05-01 17:17:01.713790 - gail/main.py:164 - [TRPO] iter = 2056000 dist_mean = 0.1034 dist_std = 0.1451 vf_loss = 0.0320 grad_norm = 4.0162 nat_grad_norm = 0.0810 cg_residual = 1.0713 step_size = 0.4316 reward = -0.0000 fps = 7 mse_loss = 0.2918 
2022-05-01 17:17:11.000051 - gail/main.py:164 - [TRPO] iter = 2057000 dist_mean = 0.0996 dist_std = 0.1449 vf_loss = 0.0426 grad_norm = 5.3802 nat_grad_norm = 0.0939 cg_residual = 13.6731 step_size = 0.3405 reward = 0.0000 fps = 6 mse_loss = 0.2551 
2022-05-01 17:17:20.854916 - gail/main.py:164 - [TRPO] iter = 2058000 dist_mean = 0.0977 dist_std = 0.1450 vf_loss = 0.0318 grad_norm = 3.3577 nat_grad_norm = 0.0824 cg_residual = 1.7673 step_size = 0.4846 reward = -0.0000 fps = 6 mse_loss = 0.3064 
2022-05-01 17:17:29.908641 - gail/main.py:164 - [TRPO] iter = 2059000 dist_mean = 0.0858 dist_std = 0.1452 vf_loss = 0.0297 grad_norm = 3.4456 nat_grad_norm = 0.0884 cg_residual = 1.0195 step_size = 0.4375 reward = -0.0000 fps = 6 mse_loss = 0.2961 
2022-05-01 17:17:39.498364 - gail/main.py:164 - [TRPO] iter = 2060000 dist_mean = 0.0752 dist_std = 0.1455 vf_loss = 0.0260 grad_norm = 3.1880 nat_grad_norm = 0.0743 cg_residual = 1.5964 step_size = 0.4635 reward = 0.0000 fps = 5 mse_loss = 0.3119 
2022-05-01 17:17:39.715336 - gail/main.py:191 - [Discriminator] iter = 2060000 loss = -0.1564 grad_norm = 4.0752 grad_penalty = 0.0571 regularization = 0.0000 true_logits = 0.1759 fake_logits = -0.0376 true_prob = 0.5170 fake_prob = 0.4838 
2022-05-01 17:19:25.437104 - gail/main.py:132 - [Evaluate] iter = 2060000 episode={ returns = 2987.8945 lengths = 855 } discounted_episode={ returns = 1693.8276 lengths = 773 } 
2022-05-01 17:19:34.825791 - gail/main.py:164 - [TRPO] iter = 2061000 dist_mean = 0.0835 dist_std = 0.1455 vf_loss = 0.0300 grad_norm = 3.7691 nat_grad_norm = 0.0877 cg_residual = 9.2213 step_size = 0.4034 reward = -0.0000 fps = 8 mse_loss = 0.3146 
2022-05-01 17:19:44.359914 - gail/main.py:164 - [TRPO] iter = 2062000 dist_mean = 0.0902 dist_std = 0.1457 vf_loss = 0.0344 grad_norm = 6.3973 nat_grad_norm = 0.1444 cg_residual = 2.8515 step_size = 0.2715 reward = 0.0000 fps = 8 mse_loss = 0.2560 
2022-05-01 17:19:54.059273 - gail/main.py:164 - [TRPO] iter = 2063000 dist_mean = 0.0614 dist_std = 0.1457 vf_loss = 0.0356 grad_norm = 3.5338 nat_grad_norm = 0.1035 cg_residual = 2.1931 step_size = 0.3669 reward = 0.0000 fps = 7 mse_loss = 0.3082 
2022-05-01 17:20:03.545142 - gail/main.py:164 - [TRPO] iter = 2064000 dist_mean = 0.0814 dist_std = 0.1457 vf_loss = 0.0275 grad_norm = 4.2576 nat_grad_norm = 0.0890 cg_residual = 10.9841 step_size = 0.4191 reward = -0.0000 fps = 6 mse_loss = 0.3026 
2022-05-01 17:20:13.234556 - gail/main.py:164 - [TRPO] iter = 2065000 dist_mean = 0.0482 dist_std = 0.1454 vf_loss = 0.0343 grad_norm = 4.4831 nat_grad_norm = 0.1161 cg_residual = 2.8032 step_size = 0.3119 reward = -0.0000 fps = 6 mse_loss = 0.2965 
2022-05-01 17:20:13.468494 - gail/main.py:191 - [Discriminator] iter = 2065000 loss = -0.3510 grad_norm = 3.7914 grad_penalty = 0.0691 regularization = 0.0000 true_logits = -0.3471 fake_logits = -0.7671 true_prob = 0.4243 fake_prob = 0.3562 
2022-05-01 17:21:39.552760 - gail/main.py:132 - [Evaluate] iter = 2065000 episode={ returns = 2208.0594 lengths = 677 } discounted_episode={ returns = 1539.6947 lengths = 668 } 
2022-05-01 17:21:49.012773 - gail/main.py:164 - [TRPO] iter = 2066000 dist_mean = 0.0571 dist_std = 0.1454 vf_loss = 0.0442 grad_norm = 3.5276 nat_grad_norm = 0.1030 cg_residual = 4.6706 step_size = 0.3852 reward = 0.0000 fps = 10 mse_loss = 0.2965 
2022-05-01 17:21:58.494549 - gail/main.py:164 - [TRPO] iter = 2067000 dist_mean = 0.0492 dist_std = 0.1455 vf_loss = 0.0368 grad_norm = 4.0594 nat_grad_norm = 0.0869 cg_residual = 4.4756 step_size = 0.4080 reward = -0.0000 fps = 9 mse_loss = 0.2927 
2022-05-01 17:22:08.104150 - gail/main.py:164 - [TRPO] iter = 2068000 dist_mean = 0.0351 dist_std = 0.1457 vf_loss = 0.0362 grad_norm = 4.7774 nat_grad_norm = 0.0985 cg_residual = 2.8902 step_size = 0.4277 reward = 0.0000 fps = 8 mse_loss = 0.2614 
2022-05-01 17:22:17.732425 - gail/main.py:164 - [TRPO] iter = 2069000 dist_mean = 0.0604 dist_std = 0.1457 vf_loss = 0.0642 grad_norm = 3.2024 nat_grad_norm = 0.0991 cg_residual = 12.9997 step_size = 0.4145 reward = -0.0000 fps = 8 mse_loss = 0.2814 
2022-05-01 17:22:27.350388 - gail/main.py:164 - [TRPO] iter = 2070000 dist_mean = 0.0417 dist_std = 0.1461 vf_loss = 0.0463 grad_norm = 2.9583 nat_grad_norm = 0.0945 cg_residual = 2.0728 step_size = 0.3810 reward = 0.0000 fps = 7 mse_loss = 0.3116 
2022-05-01 17:22:27.565335 - gail/main.py:191 - [Discriminator] iter = 2070000 loss = -0.5144 grad_norm = 3.5682 grad_penalty = 0.0918 regularization = 0.0000 true_logits = -0.6691 fake_logits = -1.2754 true_prob = 0.3658 fake_prob = 0.2664 
2022-05-01 17:24:19.262874 - gail/main.py:132 - [Evaluate] iter = 2070000 episode={ returns = 2787.7686 lengths = 859 } discounted_episode={ returns = 1871.1005 lengths = 872 } 
2022-05-01 17:24:28.492656 - gail/main.py:164 - [TRPO] iter = 2071000 dist_mean = 0.0430 dist_std = 0.1461 vf_loss = 0.0582 grad_norm = 3.0417 nat_grad_norm = 0.1131 cg_residual = 5.5505 step_size = 0.3759 reward = 0.0000 fps = 8 mse_loss = 0.2703 
2022-05-01 17:24:38.232552 - gail/main.py:164 - [TRPO] iter = 2072000 dist_mean = 0.0687 dist_std = 0.1464 vf_loss = 0.0365 grad_norm = 2.3702 nat_grad_norm = 0.1137 cg_residual = 21.4179 step_size = 0.3897 reward = 0.0000 fps = 7 mse_loss = 0.2735 
2022-05-01 17:24:48.465776 - gail/main.py:164 - [TRPO] iter = 2073000 dist_mean = 0.0502 dist_std = 0.1460 vf_loss = 0.0578 grad_norm = 3.3088 nat_grad_norm = 0.1045 cg_residual = 2.9686 step_size = 0.3829 reward = -0.0000 fps = 7 mse_loss = 0.2807 
2022-05-01 17:24:57.958446 - gail/main.py:164 - [TRPO] iter = 2074000 dist_mean = 0.0653 dist_std = 0.1460 vf_loss = 0.1009 grad_norm = 5.4376 nat_grad_norm = 0.1064 cg_residual = 3.3227 step_size = 0.3490 reward = 0.0000 fps = 6 mse_loss = 0.2722 
2022-05-01 17:25:07.752089 - gail/main.py:164 - [TRPO] iter = 2075000 dist_mean = 0.0520 dist_std = 0.1461 vf_loss = 0.1138 grad_norm = 4.6822 nat_grad_norm = 0.1048 cg_residual = 7.5510 step_size = 0.3706 reward = -0.0000 fps = 6 mse_loss = 0.3043 
2022-05-01 17:25:07.979746 - gail/main.py:191 - [Discriminator] iter = 2075000 loss = -0.4235 grad_norm = 3.4754 grad_penalty = 0.0839 regularization = 0.0000 true_logits = -0.9482 fake_logits = -1.4556 true_prob = 0.3190 fake_prob = 0.2385 
2022-05-01 17:27:18.943720 - gail/main.py:132 - [Evaluate] iter = 2075000 episode={ returns = 3574.6752 lengths = 1000 } discounted_episode={ returns = 2206.5069 lengths = 1000 } 
2022-05-01 17:27:28.315222 - gail/main.py:164 - [TRPO] iter = 2076000 dist_mean = 0.0544 dist_std = 0.1459 vf_loss = 0.2180 grad_norm = 3.7537 nat_grad_norm = 0.0885 cg_residual = 3.6399 step_size = 0.4370 reward = -0.0000 fps = 7 mse_loss = 0.3046 
2022-05-01 17:27:37.869805 - gail/main.py:164 - [TRPO] iter = 2077000 dist_mean = 0.0422 dist_std = 0.1458 vf_loss = 0.0920 grad_norm = 3.0109 nat_grad_norm = 0.1212 cg_residual = 11.4462 step_size = 0.3371 reward = 0.0000 fps = 6 mse_loss = 0.2800 
2022-05-01 17:27:47.763163 - gail/main.py:164 - [TRPO] iter = 2078000 dist_mean = 0.0153 dist_std = 0.1459 vf_loss = 0.0554 grad_norm = 5.9375 nat_grad_norm = 0.1055 cg_residual = 4.1345 step_size = 0.3632 reward = 0.0000 fps = 6 mse_loss = 0.3019 
2022-05-01 17:27:57.166368 - gail/main.py:164 - [TRPO] iter = 2079000 dist_mean = 0.0657 dist_std = 0.1461 vf_loss = 0.1035 grad_norm = 2.4583 nat_grad_norm = 0.0666 cg_residual = 4.4383 step_size = 0.5473 reward = -0.0000 fps = 5 mse_loss = 0.2885 
2022-05-01 17:28:06.940610 - gail/main.py:164 - [TRPO] iter = 2080000 dist_mean = 0.0666 dist_std = 0.1461 vf_loss = 0.0960 grad_norm = 3.3247 nat_grad_norm = 0.0733 cg_residual = 8.8862 step_size = 0.4349 reward = -0.0000 fps = 5 mse_loss = 0.2569 
2022-05-01 17:28:07.170070 - gail/main.py:191 - [Discriminator] iter = 2080000 loss = -0.3747 grad_norm = 3.1484 grad_penalty = 0.0635 regularization = 0.0000 true_logits = -1.0127 fake_logits = -1.4508 true_prob = 0.3062 fake_prob = 0.2379 
2022-05-01 17:30:13.542953 - gail/main.py:132 - [Evaluate] iter = 2080000 episode={ returns = 3584.5546 lengths = 1000 } discounted_episode={ returns = 2198.9210 lengths = 1000 } 
2022-05-01 17:30:23.058622 - gail/main.py:164 - [TRPO] iter = 2081000 dist_mean = 0.0956 dist_std = 0.1459 vf_loss = 0.0961 grad_norm = 4.2989 nat_grad_norm = 0.1345 cg_residual = 4.2505 step_size = 0.3348 reward = -0.0000 fps = 7 mse_loss = 0.2985 
2022-05-01 17:30:32.652277 - gail/main.py:164 - [TRPO] iter = 2082000 dist_mean = 0.0663 dist_std = 0.1457 vf_loss = 0.0748 grad_norm = 4.3990 nat_grad_norm = 0.1045 cg_residual = 4.2925 step_size = 0.3773 reward = -0.0000 fps = 6 mse_loss = 0.2869 
2022-05-01 17:30:42.043814 - gail/main.py:164 - [TRPO] iter = 2083000 dist_mean = 0.0819 dist_std = 0.1455 vf_loss = 0.0751 grad_norm = 4.2339 nat_grad_norm = 0.0649 cg_residual = 4.7922 step_size = 0.4811 reward = -0.0000 fps = 6 mse_loss = 0.3007 
2022-05-01 17:30:51.519118 - gail/main.py:164 - [TRPO] iter = 2084000 dist_mean = 0.0294 dist_std = 0.1453 vf_loss = 0.0343 grad_norm = 4.1456 nat_grad_norm = 0.1150 cg_residual = 3.5794 step_size = 0.3298 reward = -0.0000 fps = 6 mse_loss = 0.2839 
2022-05-01 17:31:01.059634 - gail/main.py:164 - [TRPO] iter = 2085000 dist_mean = 0.0525 dist_std = 0.1456 vf_loss = 0.0332 grad_norm = 3.2847 nat_grad_norm = 0.1122 cg_residual = 3.0697 step_size = 0.3651 reward = -0.0000 fps = 5 mse_loss = 0.2898 
2022-05-01 17:31:01.312804 - gail/main.py:191 - [Discriminator] iter = 2085000 loss = -0.4033 grad_norm = 3.0644 grad_penalty = 0.0575 regularization = 0.0000 true_logits = -1.0103 fake_logits = -1.4710 true_prob = 0.3086 fake_prob = 0.2350 
2022-05-01 17:33:06.567762 - gail/main.py:132 - [Evaluate] iter = 2085000 episode={ returns = 3565.0396 lengths = 1000 } discounted_episode={ returns = 2200.2271 lengths = 1000 } 
2022-05-01 17:33:16.192908 - gail/main.py:164 - [TRPO] iter = 2086000 dist_mean = 0.0687 dist_std = 0.1460 vf_loss = 0.0624 grad_norm = 3.1645 nat_grad_norm = 0.0892 cg_residual = 1.2613 step_size = 0.4135 reward = -0.0000 fps = 7 mse_loss = 0.2804 
2022-05-01 17:33:25.434494 - gail/main.py:164 - [TRPO] iter = 2087000 dist_mean = 0.0430 dist_std = 0.1459 vf_loss = 0.0503 grad_norm = 3.8083 nat_grad_norm = 0.0856 cg_residual = 1.9425 step_size = 0.4786 reward = -0.0000 fps = 6 mse_loss = 0.2575 
2022-05-01 17:33:34.897455 - gail/main.py:164 - [TRPO] iter = 2088000 dist_mean = 0.0552 dist_std = 0.1459 vf_loss = 0.1070 grad_norm = 2.9860 nat_grad_norm = 0.0610 cg_residual = 1.2417 step_size = 0.5269 reward = 0.0000 fps = 6 mse_loss = 0.2768 
2022-05-01 17:33:44.446463 - gail/main.py:164 - [TRPO] iter = 2089000 dist_mean = 0.0177 dist_std = 0.1457 vf_loss = 0.0389 grad_norm = 2.6146 nat_grad_norm = 0.1120 cg_residual = 3.1667 step_size = 0.4162 reward = -0.0000 fps = 6 mse_loss = 0.2893 
2022-05-01 17:33:54.064759 - gail/main.py:164 - [TRPO] iter = 2090000 dist_mean = 0.0477 dist_std = 0.1457 vf_loss = 0.0917 grad_norm = 4.6708 nat_grad_norm = 0.0730 cg_residual = 4.3840 step_size = 0.4798 reward = -0.0000 fps = 5 mse_loss = 0.2508 
2022-05-01 17:33:54.288346 - gail/main.py:191 - [Discriminator] iter = 2090000 loss = -0.3613 grad_norm = 3.6800 grad_penalty = 0.0597 regularization = 0.0000 true_logits = -1.0996 fake_logits = -1.5206 true_prob = 0.2953 fake_prob = 0.2274 
2022-05-01 17:36:01.829881 - gail/main.py:132 - [Evaluate] iter = 2090000 episode={ returns = 3573.9821 lengths = 1000 } discounted_episode={ returns = 2204.9620 lengths = 1000 } 
2022-05-01 17:36:11.222912 - gail/main.py:164 - [TRPO] iter = 2091000 dist_mean = 0.0263 dist_std = 0.1455 vf_loss = 0.0367 grad_norm = 4.8647 nat_grad_norm = 0.0862 cg_residual = 9.6763 step_size = 0.3930 reward = -0.0000 fps = 7 mse_loss = 0.2481 
2022-05-01 17:36:20.538742 - gail/main.py:164 - [TRPO] iter = 2092000 dist_mean = 0.0108 dist_std = 0.1457 vf_loss = 0.0426 grad_norm = 3.5947 nat_grad_norm = 0.1025 cg_residual = 2.9709 step_size = 0.3842 reward = 0.0000 fps = 6 mse_loss = 0.2826 
2022-05-01 17:36:29.989950 - gail/main.py:164 - [TRPO] iter = 2093000 dist_mean = 0.0424 dist_std = 0.1458 vf_loss = 0.0555 grad_norm = 5.1848 nat_grad_norm = 0.0865 cg_residual = 8.9964 step_size = 0.4603 reward = -0.0000 fps = 6 mse_loss = 0.2686 
2022-05-01 17:36:39.666202 - gail/main.py:164 - [TRPO] iter = 2094000 dist_mean = 0.0135 dist_std = 0.1459 vf_loss = 0.0873 grad_norm = 3.4533 nat_grad_norm = 0.0678 cg_residual = 6.8740 step_size = 0.5080 reward = 0.0000 fps = 6 mse_loss = 0.2514 
2022-05-01 17:36:49.334108 - gail/main.py:164 - [TRPO] iter = 2095000 dist_mean = 0.0161 dist_std = 0.1459 vf_loss = 0.0247 grad_norm = 4.7001 nat_grad_norm = 0.0792 cg_residual = 4.6992 step_size = 0.4132 reward = 0.0000 fps = 5 mse_loss = 0.2507 
2022-05-01 17:36:49.542470 - gail/main.py:191 - [Discriminator] iter = 2095000 loss = -0.1105 grad_norm = 5.5733 grad_penalty = 0.0671 regularization = 0.0000 true_logits = -1.1816 fake_logits = -1.3592 true_prob = 0.2823 fake_prob = 0.2500 
2022-05-01 17:38:54.795621 - gail/main.py:132 - [Evaluate] iter = 2095000 episode={ returns = 3571.8131 lengths = 1000 } discounted_episode={ returns = 2211.0247 lengths = 1000 } 
2022-05-01 17:39:04.085613 - gail/main.py:164 - [TRPO] iter = 2096000 dist_mean = 0.0085 dist_std = 0.1456 vf_loss = 0.1452 grad_norm = 2.6465 nat_grad_norm = 0.1029 cg_residual = 2.0269 step_size = 0.4252 reward = 0.0000 fps = 7 mse_loss = 0.2425 
2022-05-01 17:39:13.467045 - gail/main.py:164 - [TRPO] iter = 2097000 dist_mean = -0.0167 dist_std = 0.1456 vf_loss = 0.0339 grad_norm = 3.2099 nat_grad_norm = 0.0776 cg_residual = 7.2441 step_size = 0.4787 reward = -0.0000 fps = 6 mse_loss = 0.2440 
2022-05-01 17:39:22.648114 - gail/main.py:164 - [TRPO] iter = 2098000 dist_mean = 0.0051 dist_std = 0.1456 vf_loss = 0.0309 grad_norm = 4.3043 nat_grad_norm = 0.1331 cg_residual = 5.4097 step_size = 0.3360 reward = 0.0000 fps = 6 mse_loss = 0.2640 
2022-05-01 17:39:31.794377 - gail/main.py:164 - [TRPO] iter = 2099000 dist_mean = 0.0283 dist_std = 0.1455 vf_loss = 0.1124 grad_norm = 3.7689 nat_grad_norm = 0.0691 cg_residual = 1.9038 step_size = 0.5323 reward = 0.0000 fps = 6 mse_loss = 0.2897 
2022-05-01 17:39:41.172586 - gail/main.py:164 - [TRPO] iter = 2100000 dist_mean = -0.0095 dist_std = 0.1454 vf_loss = 0.0408 grad_norm = 6.0857 nat_grad_norm = 0.0877 cg_residual = 3.1574 step_size = 0.4114 reward = -0.0000 fps = 5 mse_loss = 0.2701 
2022-05-01 17:39:41.488443 - gail/main.py:191 - [Discriminator] iter = 2100000 loss = -0.1521 grad_norm = 3.3820 grad_penalty = 0.0538 regularization = 0.0000 true_logits = -1.0134 fake_logits = -1.2194 true_prob = 0.3020 fake_prob = 0.2683 
2022-05-01 17:41:47.565532 - gail/main.py:132 - [Evaluate] iter = 2100000 episode={ returns = 3614.9183 lengths = 1000 } discounted_episode={ returns = 2225.0757 lengths = 1000 } 
2022-05-01 17:41:56.901639 - gail/main.py:164 - [TRPO] iter = 2101000 dist_mean = -0.0220 dist_std = 0.1456 vf_loss = 0.0317 grad_norm = 4.7375 nat_grad_norm = 0.1028 cg_residual = 3.5590 step_size = 0.3566 reward = 0.0000 fps = 7 mse_loss = 0.2566 
2022-05-01 17:42:06.508289 - gail/main.py:164 - [TRPO] iter = 2102000 dist_mean = 0.0056 dist_std = 0.1455 vf_loss = 0.0323 grad_norm = 4.2439 nat_grad_norm = 0.1196 cg_residual = 1.3844 step_size = 0.3902 reward = -0.0000 fps = 6 mse_loss = 0.2585 
2022-05-01 17:42:15.599682 - gail/main.py:164 - [TRPO] iter = 2103000 dist_mean = -0.0059 dist_std = 0.1453 vf_loss = 0.0565 grad_norm = 3.0370 nat_grad_norm = 0.0748 cg_residual = 4.4322 step_size = 0.5046 reward = -0.0000 fps = 6 mse_loss = 0.2773 
2022-05-01 17:42:24.979378 - gail/main.py:164 - [TRPO] iter = 2104000 dist_mean = -0.0090 dist_std = 0.1452 vf_loss = 0.0301 grad_norm = 3.3453 nat_grad_norm = 0.0803 cg_residual = 1.1583 step_size = 0.4772 reward = -0.0000 fps = 6 mse_loss = 0.2701 
2022-05-01 17:42:34.408777 - gail/main.py:164 - [TRPO] iter = 2105000 dist_mean = -0.0113 dist_std = 0.1453 vf_loss = 0.0199 grad_norm = 3.9088 nat_grad_norm = 0.0887 cg_residual = 2.2460 step_size = 0.4578 reward = 0.0000 fps = 5 mse_loss = 0.2632 
2022-05-01 17:42:34.631565 - gail/main.py:191 - [Discriminator] iter = 2105000 loss = -0.1153 grad_norm = 3.4414 grad_penalty = 0.0505 regularization = 0.0000 true_logits = -0.9100 fake_logits = -1.0757 true_prob = 0.3197 fake_prob = 0.2865 
2022-05-01 17:44:35.720713 - gail/main.py:132 - [Evaluate] iter = 2105000 episode={ returns = 3566.0305 lengths = 987 } discounted_episode={ returns = 2164.4086 lengths = 953 } 
2022-05-01 17:44:45.322603 - gail/main.py:164 - [TRPO] iter = 2106000 dist_mean = 0.0074 dist_std = 0.1453 vf_loss = 0.0309 grad_norm = 2.4864 nat_grad_norm = 0.0895 cg_residual = 3.3018 step_size = 0.4526 reward = 0.0000 fps = 7 mse_loss = 0.2688 
2022-05-01 17:44:54.851671 - gail/main.py:164 - [TRPO] iter = 2107000 dist_mean = 0.0275 dist_std = 0.1450 vf_loss = 0.0252 grad_norm = 4.9810 nat_grad_norm = 0.0847 cg_residual = 7.4985 step_size = 0.4352 reward = -0.0000 fps = 7 mse_loss = 0.2672 
2022-05-01 17:45:03.838609 - gail/main.py:164 - [TRPO] iter = 2108000 dist_mean = 0.0108 dist_std = 0.1450 vf_loss = 0.0175 grad_norm = 4.1675 nat_grad_norm = 0.0771 cg_residual = 1.4973 step_size = 0.4650 reward = -0.0000 fps = 6 mse_loss = 0.2722 
2022-05-01 17:45:13.109693 - gail/main.py:164 - [TRPO] iter = 2109000 dist_mean = -0.0082 dist_std = 0.1451 vf_loss = 0.0213 grad_norm = 2.8592 nat_grad_norm = 0.1027 cg_residual = 1.3330 step_size = 0.4257 reward = -0.0000 fps = 6 mse_loss = 0.2880 
2022-05-01 17:45:22.773055 - gail/main.py:164 - [TRPO] iter = 2110000 dist_mean = 0.0144 dist_std = 0.1450 vf_loss = 0.0672 grad_norm = 3.2028 nat_grad_norm = 0.0839 cg_residual = 2.9932 step_size = 0.4908 reward = 0.0000 fps = 5 mse_loss = 0.2592 
2022-05-01 17:45:23.002194 - gail/main.py:191 - [Discriminator] iter = 2110000 loss = -0.3262 grad_norm = 3.9407 grad_penalty = 0.0493 regularization = 0.0000 true_logits = -0.7987 fake_logits = -1.1741 true_prob = 0.3374 fake_prob = 0.2782 
2022-05-01 17:47:20.395160 - gail/main.py:132 - [Evaluate] iter = 2110000 episode={ returns = 3454.6858 lengths = 955 } discounted_episode={ returns = 2097.3976 lengths = 913 } 
2022-05-01 17:47:29.674645 - gail/main.py:164 - [TRPO] iter = 2111000 dist_mean = -0.0313 dist_std = 0.1447 vf_loss = 0.0214 grad_norm = 3.3424 nat_grad_norm = 0.1032 cg_residual = 6.3846 step_size = 0.3881 reward = 0.0000 fps = 7 mse_loss = 0.2648 
2022-05-01 17:47:39.083516 - gail/main.py:164 - [TRPO] iter = 2112000 dist_mean = -0.0204 dist_std = 0.1447 vf_loss = 0.0254 grad_norm = 3.0846 nat_grad_norm = 0.0766 cg_residual = 2.7275 step_size = 0.4726 reward = -0.0000 fps = 7 mse_loss = 0.2546 
2022-05-01 17:47:48.211155 - gail/main.py:164 - [TRPO] iter = 2113000 dist_mean = -0.0054 dist_std = 0.1446 vf_loss = 0.0280 grad_norm = 3.7573 nat_grad_norm = 0.0991 cg_residual = 15.1815 step_size = 0.3981 reward = 0.0000 fps = 6 mse_loss = 0.2310 
2022-05-01 17:47:57.477789 - gail/main.py:164 - [TRPO] iter = 2114000 dist_mean = -0.0165 dist_std = 0.1446 vf_loss = 0.0214 grad_norm = 4.2518 nat_grad_norm = 0.1009 cg_residual = 1.2423 step_size = 0.3734 reward = -0.0000 fps = 6 mse_loss = 0.2604 
2022-05-01 17:48:06.800908 - gail/main.py:164 - [TRPO] iter = 2115000 dist_mean = 0.0017 dist_std = 0.1447 vf_loss = 0.0414 grad_norm = 5.4508 nat_grad_norm = 0.0999 cg_residual = 1.6077 step_size = 0.3891 reward = 0.0000 fps = 6 mse_loss = 0.2635 
2022-05-01 17:48:07.048387 - gail/main.py:191 - [Discriminator] iter = 2115000 loss = -0.1656 grad_norm = 2.9531 grad_penalty = 0.0485 regularization = 0.0000 true_logits = -0.6787 fake_logits = -0.8928 true_prob = 0.3613 fake_prob = 0.3197 
2022-05-01 17:50:12.704791 - gail/main.py:132 - [Evaluate] iter = 2115000 episode={ returns = 3627.2935 lengths = 1000 } discounted_episode={ returns = 2248.8142 lengths = 1000 } 
2022-05-01 17:50:22.271353 - gail/main.py:164 - [TRPO] iter = 2116000 dist_mean = -0.0331 dist_std = 0.1447 vf_loss = 0.0241 grad_norm = 3.6405 nat_grad_norm = 0.0915 cg_residual = 4.9513 step_size = 0.4324 reward = 0.0000 fps = 7 mse_loss = 0.2474 
2022-05-01 17:50:31.246606 - gail/main.py:164 - [TRPO] iter = 2117000 dist_mean = -0.0002 dist_std = 0.1443 vf_loss = 0.0162 grad_norm = 2.9681 nat_grad_norm = 0.1205 cg_residual = 2.7538 step_size = 0.3599 reward = 0.0000 fps = 6 mse_loss = 0.2687 
2022-05-01 17:50:40.488397 - gail/main.py:164 - [TRPO] iter = 2118000 dist_mean = 0.0060 dist_std = 0.1444 vf_loss = 0.0810 grad_norm = 2.2930 nat_grad_norm = 0.0648 cg_residual = 4.3591 step_size = 0.6349 reward = -0.0000 fps = 6 mse_loss = 0.2702 
2022-05-01 17:50:49.933881 - gail/main.py:164 - [TRPO] iter = 2119000 dist_mean = 0.0062 dist_std = 0.1447 vf_loss = 0.0295 grad_norm = 2.7132 nat_grad_norm = 0.0843 cg_residual = 2.1133 step_size = 0.5157 reward = 0.0000 fps = 6 mse_loss = 0.2497 
2022-05-01 17:50:59.397763 - gail/main.py:164 - [TRPO] iter = 2120000 dist_mean = -0.0138 dist_std = 0.1446 vf_loss = 0.0730 grad_norm = 3.5460 nat_grad_norm = 0.0876 cg_residual = 4.2115 step_size = 0.4254 reward = 0.0000 fps = 5 mse_loss = 0.2773 
2022-05-01 17:50:59.680727 - gail/main.py:191 - [Discriminator] iter = 2120000 loss = -0.3052 grad_norm = 3.3954 grad_penalty = 0.0478 regularization = 0.0000 true_logits = -0.4932 fake_logits = -0.8462 true_prob = 0.3964 fake_prob = 0.3270 
2022-05-01 17:53:03.698390 - gail/main.py:132 - [Evaluate] iter = 2120000 episode={ returns = 3629.9497 lengths = 1000 } discounted_episode={ returns = 2244.6119 lengths = 1000 } 
2022-05-01 17:53:12.865259 - gail/main.py:164 - [TRPO] iter = 2121000 dist_mean = -0.0075 dist_std = 0.1445 vf_loss = 0.0256 grad_norm = 3.6236 nat_grad_norm = 0.0850 cg_residual = 4.0161 step_size = 0.4831 reward = -0.0000 fps = 7 mse_loss = 0.2943 
2022-05-01 17:53:22.201807 - gail/main.py:164 - [TRPO] iter = 2122000 dist_mean = -0.0080 dist_std = 0.1444 vf_loss = 0.0188 grad_norm = 4.8097 nat_grad_norm = 0.1192 cg_residual = 4.7525 step_size = 0.3662 reward = -0.0000 fps = 7 mse_loss = 0.2624 
2022-05-01 17:53:31.362993 - gail/main.py:164 - [TRPO] iter = 2123000 dist_mean = -0.0154 dist_std = 0.1444 vf_loss = 0.0919 grad_norm = 2.0168 nat_grad_norm = 0.0547 cg_residual = 0.8615 step_size = 0.6840 reward = -0.0000 fps = 6 mse_loss = 0.2736 
2022-05-01 17:53:40.814198 - gail/main.py:164 - [TRPO] iter = 2124000 dist_mean = 0.0163 dist_std = 0.1443 vf_loss = 0.0911 grad_norm = 2.9974 nat_grad_norm = 0.0855 cg_residual = 1.5012 step_size = 0.4602 reward = -0.0000 fps = 6 mse_loss = 0.2529 
2022-05-01 17:53:50.160126 - gail/main.py:164 - [TRPO] iter = 2125000 dist_mean = 0.0098 dist_std = 0.1442 vf_loss = 0.0781 grad_norm = 2.6922 nat_grad_norm = 0.0679 cg_residual = 5.4959 step_size = 0.5451 reward = -0.0000 fps = 5 mse_loss = 0.2434 
2022-05-01 17:53:50.368447 - gail/main.py:191 - [Discriminator] iter = 2125000 loss = -0.2756 grad_norm = 3.4018 grad_penalty = 0.0521 regularization = 0.0000 true_logits = -0.3567 fake_logits = -0.6845 true_prob = 0.4237 fake_prob = 0.3557 
2022-05-01 17:56:00.156710 - gail/main.py:132 - [Evaluate] iter = 2125000 episode={ returns = 3629.8100 lengths = 1000 } discounted_episode={ returns = 2243.7212 lengths = 1000 } 
2022-05-01 17:56:09.862408 - gail/main.py:164 - [TRPO] iter = 2126000 dist_mean = 0.0266 dist_std = 0.1439 vf_loss = 0.0814 grad_norm = 3.5690 nat_grad_norm = 0.0920 cg_residual = 2.2411 step_size = 0.4753 reward = -0.0000 fps = 7 mse_loss = 0.2709 
2022-05-01 17:56:19.712971 - gail/main.py:164 - [TRPO] iter = 2127000 dist_mean = 0.0276 dist_std = 0.1434 vf_loss = 0.0665 grad_norm = 2.4677 nat_grad_norm = 0.0728 cg_residual = 2.8399 step_size = 0.6176 reward = -0.0000 fps = 6 mse_loss = 0.2611 
2022-05-01 17:56:29.040098 - gail/main.py:164 - [TRPO] iter = 2128000 dist_mean = 0.0199 dist_std = 0.1430 vf_loss = 0.0326 grad_norm = 4.5069 nat_grad_norm = 0.0824 cg_residual = 1.9603 step_size = 0.4484 reward = 0.0000 fps = 6 mse_loss = 0.2567 
2022-05-01 17:56:38.381973 - gail/main.py:164 - [TRPO] iter = 2129000 dist_mean = 0.0056 dist_std = 0.1428 vf_loss = 0.0467 grad_norm = 4.2926 nat_grad_norm = 0.0749 cg_residual = 2.2091 step_size = 0.5664 reward = -0.0000 fps = 5 mse_loss = 0.2594 
2022-05-01 17:56:47.944231 - gail/main.py:164 - [TRPO] iter = 2130000 dist_mean = 0.0244 dist_std = 0.1432 vf_loss = 0.0219 grad_norm = 3.5873 nat_grad_norm = 0.0807 cg_residual = 5.7983 step_size = 0.4981 reward = 0.0000 fps = 5 mse_loss = 0.2600 
2022-05-01 17:56:48.151392 - gail/main.py:191 - [Discriminator] iter = 2130000 loss = -0.1789 grad_norm = 3.9362 grad_penalty = 0.0480 regularization = 0.0000 true_logits = -0.3251 fake_logits = -0.5520 true_prob = 0.4280 fake_prob = 0.3843 
2022-05-01 17:58:52.776409 - gail/main.py:132 - [Evaluate] iter = 2130000 episode={ returns = 3631.5065 lengths = 1000 } discounted_episode={ returns = 2243.6785 lengths = 1000 } 
2022-05-01 17:59:02.249696 - gail/main.py:164 - [TRPO] iter = 2131000 dist_mean = 0.0298 dist_std = 0.1428 vf_loss = 0.0590 grad_norm = 3.1827 nat_grad_norm = 0.0651 cg_residual = 2.4183 step_size = 0.5982 reward = 0.0000 fps = 7 mse_loss = 0.2548 
2022-05-01 17:59:11.748513 - gail/main.py:164 - [TRPO] iter = 2132000 dist_mean = 0.0309 dist_std = 0.1426 vf_loss = 0.0518 grad_norm = 2.9623 nat_grad_norm = 0.0713 cg_residual = 1.6142 step_size = 0.5895 reward = 0.0000 fps = 6 mse_loss = 0.2452 
2022-05-01 17:59:20.969381 - gail/main.py:164 - [TRPO] iter = 2133000 dist_mean = 0.0119 dist_std = 0.1431 vf_loss = 0.0428 grad_norm = 3.0456 nat_grad_norm = 0.0800 cg_residual = 1.1631 step_size = 0.4989 reward = 0.0000 fps = 6 mse_loss = 0.2996 
2022-05-01 17:59:30.598460 - gail/main.py:164 - [TRPO] iter = 2134000 dist_mean = 0.0227 dist_std = 0.1428 vf_loss = 0.0627 grad_norm = 2.8334 nat_grad_norm = 0.0692 cg_residual = 0.9955 step_size = 0.5339 reward = 0.0000 fps = 6 mse_loss = 0.2565 
2022-05-01 17:59:39.955147 - gail/main.py:164 - [TRPO] iter = 2135000 dist_mean = 0.0216 dist_std = 0.1429 vf_loss = 0.0698 grad_norm = 3.0515 nat_grad_norm = 0.0857 cg_residual = 2.1378 step_size = 0.4680 reward = -0.0000 fps = 5 mse_loss = 0.2796 
2022-05-01 17:59:40.191769 - gail/main.py:191 - [Discriminator] iter = 2135000 loss = -0.2801 grad_norm = 3.3159 grad_penalty = 0.0462 regularization = 0.0000 true_logits = -0.1696 fake_logits = -0.4959 true_prob = 0.4598 fake_prob = 0.3954 
2022-05-01 18:01:48.125857 - gail/main.py:132 - [Evaluate] iter = 2135000 episode={ returns = 3625.7978 lengths = 1000 } discounted_episode={ returns = 2236.1955 lengths = 1000 } 
2022-05-01 18:01:57.387213 - gail/main.py:164 - [TRPO] iter = 2136000 dist_mean = 0.0274 dist_std = 0.1431 vf_loss = 0.0556 grad_norm = 3.8344 nat_grad_norm = 0.0646 cg_residual = 2.3221 step_size = 0.4988 reward = 0.0000 fps = 7 mse_loss = 0.2656 
2022-05-01 18:02:07.048463 - gail/main.py:164 - [TRPO] iter = 2137000 dist_mean = 0.0002 dist_std = 0.1428 vf_loss = 0.0343 grad_norm = 3.5847 nat_grad_norm = 0.0650 cg_residual = 1.8031 step_size = 0.5760 reward = 0.0000 fps = 6 mse_loss = 0.2387 
2022-05-01 18:02:16.508018 - gail/main.py:164 - [TRPO] iter = 2138000 dist_mean = 0.0176 dist_std = 0.1428 vf_loss = 0.0699 grad_norm = 5.4113 nat_grad_norm = 0.0806 cg_residual = 7.0979 step_size = 0.4779 reward = -0.0000 fps = 6 mse_loss = 0.2611 
2022-05-01 18:02:25.480377 - gail/main.py:164 - [TRPO] iter = 2139000 dist_mean = 0.0153 dist_std = 0.1424 vf_loss = 0.0164 grad_norm = 3.5505 nat_grad_norm = 0.0904 cg_residual = 1.8617 step_size = 0.4760 reward = 0.0000 fps = 6 mse_loss = 0.2557 
2022-05-01 18:02:34.925227 - gail/main.py:164 - [TRPO] iter = 2140000 dist_mean = 0.0339 dist_std = 0.1422 vf_loss = 0.0580 grad_norm = 4.0669 nat_grad_norm = 0.0577 cg_residual = 1.9830 step_size = 0.6331 reward = -0.0000 fps = 5 mse_loss = 0.2373 
2022-05-01 18:02:35.162991 - gail/main.py:191 - [Discriminator] iter = 2140000 loss = -0.3272 grad_norm = 2.8368 grad_penalty = 0.0457 regularization = 0.0000 true_logits = -0.0358 fake_logits = -0.4087 true_prob = 0.4859 fake_prob = 0.4161 
2022-05-01 18:04:41.024636 - gail/main.py:132 - [Evaluate] iter = 2140000 episode={ returns = 3619.2912 lengths = 1000 } discounted_episode={ returns = 2230.6320 lengths = 1000 } 
2022-05-01 18:04:50.230166 - gail/main.py:164 - [TRPO] iter = 2141000 dist_mean = 0.0500 dist_std = 0.1423 vf_loss = 0.0393 grad_norm = 3.0541 nat_grad_norm = 0.0660 cg_residual = 3.2256 step_size = 0.5415 reward = 0.0000 fps = 7 mse_loss = 0.2791 
2022-05-01 18:04:59.412563 - gail/main.py:164 - [TRPO] iter = 2142000 dist_mean = 0.0539 dist_std = 0.1421 vf_loss = 0.0398 grad_norm = 5.1554 nat_grad_norm = 0.0870 cg_residual = 2.4966 step_size = 0.3868 reward = 0.0000 fps = 6 mse_loss = 0.2843 
2022-05-01 18:05:08.855832 - gail/main.py:164 - [TRPO] iter = 2143000 dist_mean = 0.0639 dist_std = 0.1421 vf_loss = 0.0469 grad_norm = 4.1361 nat_grad_norm = 0.0795 cg_residual = 3.6464 step_size = 0.4378 reward = 0.0000 fps = 6 mse_loss = 0.2328 
2022-05-01 18:05:18.445566 - gail/main.py:164 - [TRPO] iter = 2144000 dist_mean = 0.0235 dist_std = 0.1421 vf_loss = 0.0333 grad_norm = 2.8156 nat_grad_norm = 0.0914 cg_residual = 2.2947 step_size = 0.4595 reward = 0.0000 fps = 6 mse_loss = 0.2562 
2022-05-01 18:05:27.976787 - gail/main.py:164 - [TRPO] iter = 2145000 dist_mean = 0.0520 dist_std = 0.1420 vf_loss = 0.0404 grad_norm = 5.1879 nat_grad_norm = 0.0724 cg_residual = 4.8171 step_size = 0.4372 reward = -0.0000 fps = 5 mse_loss = 0.2488 
2022-05-01 18:05:28.206413 - gail/main.py:191 - [Discriminator] iter = 2145000 loss = -0.1964 grad_norm = 3.5470 grad_penalty = 0.0462 regularization = 0.0000 true_logits = -0.1078 fake_logits = -0.3504 true_prob = 0.4722 fake_prob = 0.4297 
2022-05-01 18:07:33.636822 - gail/main.py:132 - [Evaluate] iter = 2145000 episode={ returns = 3615.4183 lengths = 1000 } discounted_episode={ returns = 2230.1565 lengths = 1000 } 
2022-05-01 18:07:42.929288 - gail/main.py:164 - [TRPO] iter = 2146000 dist_mean = 0.0297 dist_std = 0.1421 vf_loss = 0.0447 grad_norm = 3.3086 nat_grad_norm = 0.0842 cg_residual = 2.1596 step_size = 0.4768 reward = 0.0000 fps = 7 mse_loss = 0.2854 
2022-05-01 18:07:52.268766 - gail/main.py:164 - [TRPO] iter = 2147000 dist_mean = 0.0634 dist_std = 0.1418 vf_loss = 0.0725 grad_norm = 6.4396 nat_grad_norm = 0.0647 cg_residual = 6.9363 step_size = 0.4470 reward = -0.0000 fps = 6 mse_loss = 0.2551 
2022-05-01 18:08:01.700768 - gail/main.py:164 - [TRPO] iter = 2148000 dist_mean = 0.0665 dist_std = 0.1420 vf_loss = 0.0291 grad_norm = 2.7771 nat_grad_norm = 0.0794 cg_residual = 1.2515 step_size = 0.4386 reward = -0.0000 fps = 6 mse_loss = 0.2854 
2022-05-01 18:08:11.113783 - gail/main.py:164 - [TRPO] iter = 2149000 dist_mean = 0.0593 dist_std = 0.1419 vf_loss = 0.0656 grad_norm = 3.8497 nat_grad_norm = 0.0585 cg_residual = 4.1216 step_size = 0.5105 reward = -0.0000 fps = 6 mse_loss = 0.2582 
2022-05-01 18:08:20.646787 - gail/main.py:164 - [TRPO] iter = 2150000 dist_mean = 0.0566 dist_std = 0.1418 vf_loss = 0.0594 grad_norm = 2.8522 nat_grad_norm = 0.0566 cg_residual = 2.1173 step_size = 0.6050 reward = 0.0000 fps = 5 mse_loss = 0.2477 
2022-05-01 18:08:20.880848 - gail/main.py:191 - [Discriminator] iter = 2150000 loss = -0.2283 grad_norm = 2.8183 grad_penalty = 0.0435 regularization = 0.0000 true_logits = -0.0314 fake_logits = -0.3032 true_prob = 0.4861 fake_prob = 0.4390 
2022-05-01 18:10:26.830711 - gail/main.py:132 - [Evaluate] iter = 2150000 episode={ returns = 3605.8124 lengths = 1000 } discounted_episode={ returns = 2227.2513 lengths = 1000 } 
2022-05-01 18:10:36.007904 - gail/main.py:164 - [TRPO] iter = 2151000 dist_mean = 0.0693 dist_std = 0.1418 vf_loss = 0.0430 grad_norm = 3.5900 nat_grad_norm = 0.0763 cg_residual = 2.5318 step_size = 0.4877 reward = -0.0000 fps = 7 mse_loss = 0.2554 
2022-05-01 18:10:45.513349 - gail/main.py:164 - [TRPO] iter = 2152000 dist_mean = 0.0663 dist_std = 0.1416 vf_loss = 0.0388 grad_norm = 2.6786 nat_grad_norm = 0.0898 cg_residual = 2.2050 step_size = 0.4783 reward = -0.0000 fps = 6 mse_loss = 0.2775 
2022-05-01 18:10:55.257075 - gail/main.py:164 - [TRPO] iter = 2153000 dist_mean = 0.0688 dist_std = 0.1417 vf_loss = 0.0411 grad_norm = 3.6071 nat_grad_norm = 0.0628 cg_residual = 6.7322 step_size = 0.4764 reward = -0.0000 fps = 6 mse_loss = 0.2366 
2022-05-01 18:11:04.988623 - gail/main.py:164 - [TRPO] iter = 2154000 dist_mean = 0.0634 dist_std = 0.1420 vf_loss = 0.0484 grad_norm = 2.5859 nat_grad_norm = 0.0687 cg_residual = 1.1383 step_size = 0.5882 reward = -0.0000 fps = 6 mse_loss = 0.2831 
2022-05-01 18:11:14.644437 - gail/main.py:164 - [TRPO] iter = 2155000 dist_mean = 0.0485 dist_std = 0.1420 vf_loss = 0.0335 grad_norm = 3.4233 nat_grad_norm = 0.0637 cg_residual = 2.6522 step_size = 0.5547 reward = 0.0000 fps = 5 mse_loss = 0.2688 
2022-05-01 18:11:14.860139 - gail/main.py:191 - [Discriminator] iter = 2155000 loss = -0.2377 grad_norm = 3.6131 grad_penalty = 0.0422 regularization = 0.0000 true_logits = -0.0062 fake_logits = -0.2861 true_prob = 0.4878 fake_prob = 0.4430 
2022-05-01 18:13:22.420271 - gail/main.py:132 - [Evaluate] iter = 2155000 episode={ returns = 3602.3115 lengths = 1000 } discounted_episode={ returns = 2221.9337 lengths = 1000 } 
2022-05-01 18:13:31.605801 - gail/main.py:164 - [TRPO] iter = 2156000 dist_mean = 0.0700 dist_std = 0.1423 vf_loss = 0.0398 grad_norm = 2.9872 nat_grad_norm = 0.0657 cg_residual = 2.3859 step_size = 0.4793 reward = 0.0000 fps = 7 mse_loss = 0.2511 
2022-05-01 18:13:40.663847 - gail/main.py:164 - [TRPO] iter = 2157000 dist_mean = 0.0727 dist_std = 0.1421 vf_loss = 0.0313 grad_norm = 3.4935 nat_grad_norm = 0.0710 cg_residual = 2.3186 step_size = 0.4594 reward = 0.0000 fps = 6 mse_loss = 0.2598 
2022-05-01 18:13:50.425882 - gail/main.py:164 - [TRPO] iter = 2158000 dist_mean = 0.0803 dist_std = 0.1419 vf_loss = 0.0388 grad_norm = 2.7412 nat_grad_norm = 0.0670 cg_residual = 6.4915 step_size = 0.6037 reward = -0.0000 fps = 6 mse_loss = 0.2621 
2022-05-01 18:13:59.689539 - gail/main.py:164 - [TRPO] iter = 2159000 dist_mean = 0.0728 dist_std = 0.1418 vf_loss = 0.0518 grad_norm = 4.8795 nat_grad_norm = 0.0663 cg_residual = 5.7617 step_size = 0.5288 reward = -0.0000 fps = 6 mse_loss = 0.2809 
2022-05-01 18:14:08.996762 - gail/main.py:164 - [TRPO] iter = 2160000 dist_mean = 0.0866 dist_std = 0.1415 vf_loss = 0.0613 grad_norm = 4.0966 nat_grad_norm = 0.0615 cg_residual = 6.7861 step_size = 0.4913 reward = 0.0000 fps = 5 mse_loss = 0.2642 
2022-05-01 18:14:09.255398 - gail/main.py:191 - [Discriminator] iter = 2160000 loss = -0.3729 grad_norm = 3.6633 grad_penalty = 0.0477 regularization = 0.0000 true_logits = 0.0774 fake_logits = -0.3432 true_prob = 0.5014 fake_prob = 0.4327 
2022-05-01 18:16:18.354898 - gail/main.py:132 - [Evaluate] iter = 2160000 episode={ returns = 3611.3869 lengths = 1000 } discounted_episode={ returns = 2233.5228 lengths = 1000 } 
2022-05-01 18:16:27.862068 - gail/main.py:164 - [TRPO] iter = 2161000 dist_mean = 0.0885 dist_std = 0.1412 vf_loss = 0.0276 grad_norm = 3.7715 nat_grad_norm = 0.0616 cg_residual = 2.0906 step_size = 0.5086 reward = 0.0000 fps = 7 mse_loss = 0.2711 
2022-05-01 18:16:37.274037 - gail/main.py:164 - [TRPO] iter = 2162000 dist_mean = 0.1078 dist_std = 0.1408 vf_loss = 0.0342 grad_norm = 2.9255 nat_grad_norm = 0.0649 cg_residual = 2.8262 step_size = 0.5366 reward = 0.0000 fps = 6 mse_loss = 0.2720 
2022-05-01 18:16:46.459584 - gail/main.py:164 - [TRPO] iter = 2163000 dist_mean = 0.1138 dist_std = 0.1406 vf_loss = 0.0458 grad_norm = 1.7885 nat_grad_norm = 0.0560 cg_residual = 0.9126 step_size = 0.6817 reward = 0.0000 fps = 6 mse_loss = 0.2399 
2022-05-01 18:16:56.117248 - gail/main.py:164 - [TRPO] iter = 2164000 dist_mean = 0.0941 dist_std = 0.1407 vf_loss = 0.0150 grad_norm = 2.7014 nat_grad_norm = 0.0788 cg_residual = 2.9970 step_size = 0.4985 reward = -0.0000 fps = 5 mse_loss = 0.2779 
2022-05-01 18:17:05.869832 - gail/main.py:164 - [TRPO] iter = 2165000 dist_mean = 0.0613 dist_std = 0.1409 vf_loss = 0.0270 grad_norm = 4.3296 nat_grad_norm = 0.0745 cg_residual = 1.4234 step_size = 0.5197 reward = 0.0000 fps = 5 mse_loss = 0.2707 
2022-05-01 18:17:06.091423 - gail/main.py:191 - [Discriminator] iter = 2165000 loss = -0.3416 grad_norm = 3.5152 grad_penalty = 0.0424 regularization = 0.0000 true_logits = 0.0057 fake_logits = -0.3782 true_prob = 0.4873 fake_prob = 0.4239 
2022-05-01 18:19:12.210018 - gail/main.py:132 - [Evaluate] iter = 2165000 episode={ returns = 3587.4748 lengths = 1000 } discounted_episode={ returns = 2213.2322 lengths = 1000 } 
2022-05-01 18:19:21.491142 - gail/main.py:164 - [TRPO] iter = 2166000 dist_mean = 0.1006 dist_std = 0.1408 vf_loss = 0.0235 grad_norm = 3.3887 nat_grad_norm = 0.0926 cg_residual = 5.4495 step_size = 0.4411 reward = 0.0000 fps = 7 mse_loss = 0.2705 
2022-05-01 18:19:31.111312 - gail/main.py:164 - [TRPO] iter = 2167000 dist_mean = 0.0896 dist_std = 0.1408 vf_loss = 0.0297 grad_norm = 2.2503 nat_grad_norm = 0.0506 cg_residual = 3.5273 step_size = 0.6673 reward = -0.0000 fps = 6 mse_loss = 0.2649 
2022-05-01 18:19:40.600366 - gail/main.py:164 - [TRPO] iter = 2168000 dist_mean = 0.1050 dist_std = 0.1410 vf_loss = 0.0203 grad_norm = 2.1420 nat_grad_norm = 0.0650 cg_residual = 1.2244 step_size = 0.5696 reward = -0.0000 fps = 6 mse_loss = 0.2720 
2022-05-01 18:19:50.150889 - gail/main.py:164 - [TRPO] iter = 2169000 dist_mean = 0.1015 dist_std = 0.1414 vf_loss = 0.0368 grad_norm = 4.1107 nat_grad_norm = 0.0702 cg_residual = 1.5166 step_size = 0.5536 reward = -0.0000 fps = 6 mse_loss = 0.2979 
2022-05-01 18:19:59.413546 - gail/main.py:164 - [TRPO] iter = 2170000 dist_mean = 0.1153 dist_std = 0.1416 vf_loss = 0.0212 grad_norm = 4.3140 nat_grad_norm = 0.0646 cg_residual = 6.6256 step_size = 0.5516 reward = -0.0000 fps = 5 mse_loss = 0.2785 
2022-05-01 18:19:59.627975 - gail/main.py:191 - [Discriminator] iter = 2170000 loss = -0.3149 grad_norm = 4.5691 grad_penalty = 0.0462 regularization = 0.0000 true_logits = -0.0784 fake_logits = -0.4395 true_prob = 0.4698 fake_prob = 0.4140 
2022-05-01 18:22:07.753771 - gail/main.py:132 - [Evaluate] iter = 2170000 episode={ returns = 3605.3491 lengths = 1000 } discounted_episode={ returns = 2225.7104 lengths = 1000 } 
2022-05-01 18:22:17.362576 - gail/main.py:164 - [TRPO] iter = 2171000 dist_mean = 0.0811 dist_std = 0.1414 vf_loss = 0.0158 grad_norm = 3.8093 nat_grad_norm = 0.0615 cg_residual = 1.4558 step_size = 0.6085 reward = 0.0000 fps = 7 mse_loss = 0.2995 
2022-05-01 18:22:26.882480 - gail/main.py:164 - [TRPO] iter = 2172000 dist_mean = 0.1012 dist_std = 0.1417 vf_loss = 0.0241 grad_norm = 2.6400 nat_grad_norm = 0.0866 cg_residual = 1.8299 step_size = 0.4400 reward = -0.0000 fps = 6 mse_loss = 0.2613 
2022-05-01 18:22:36.712918 - gail/main.py:164 - [TRPO] iter = 2173000 dist_mean = 0.0889 dist_std = 0.1418 vf_loss = 0.0436 grad_norm = 3.7060 nat_grad_norm = 0.0622 cg_residual = 5.6367 step_size = 0.5431 reward = 0.0000 fps = 6 mse_loss = 0.2678 
2022-05-01 18:22:46.423451 - gail/main.py:164 - [TRPO] iter = 2174000 dist_mean = 0.0914 dist_std = 0.1419 vf_loss = 0.0277 grad_norm = 2.8221 nat_grad_norm = 0.0968 cg_residual = 2.0138 step_size = 0.4336 reward = -0.0000 fps = 5 mse_loss = 0.2792 
2022-05-01 18:22:56.055061 - gail/main.py:164 - [TRPO] iter = 2175000 dist_mean = 0.0934 dist_std = 0.1418 vf_loss = 0.0131 grad_norm = 3.4631 nat_grad_norm = 0.0699 cg_residual = 1.1197 step_size = 0.4797 reward = 0.0000 fps = 5 mse_loss = 0.2663 
2022-05-01 18:22:56.319120 - gail/main.py:191 - [Discriminator] iter = 2175000 loss = -0.4751 grad_norm = 3.2234 grad_penalty = 0.0489 regularization = 0.0000 true_logits = 0.0671 fake_logits = -0.4570 true_prob = 0.4942 fake_prob = 0.4080 
2022-05-01 18:25:08.167568 - gail/main.py:132 - [Evaluate] iter = 2175000 episode={ returns = 3572.7043 lengths = 1000 } discounted_episode={ returns = 2211.7612 lengths = 1000 } 
2022-05-01 18:25:18.396363 - gail/main.py:164 - [TRPO] iter = 2176000 dist_mean = 0.0600 dist_std = 0.1417 vf_loss = 0.0134 grad_norm = 4.2589 nat_grad_norm = 0.0968 cg_residual = 6.2967 step_size = 0.4265 reward = -0.0000 fps = 7 mse_loss = 0.2757 
2022-05-01 18:25:28.091267 - gail/main.py:164 - [TRPO] iter = 2177000 dist_mean = 0.0769 dist_std = 0.1416 vf_loss = 0.0497 grad_norm = 3.9747 nat_grad_norm = 0.0557 cg_residual = 2.0258 step_size = 0.5810 reward = -0.0000 fps = 6 mse_loss = 0.2798 
2022-05-01 18:25:38.018709 - gail/main.py:164 - [TRPO] iter = 2178000 dist_mean = 0.0772 dist_std = 0.1413 vf_loss = 0.0329 grad_norm = 3.5162 nat_grad_norm = 0.0784 cg_residual = 1.5418 step_size = 0.4525 reward = 0.0000 fps = 6 mse_loss = 0.3358 
2022-05-01 18:25:48.127766 - gail/main.py:164 - [TRPO] iter = 2179000 dist_mean = 0.0779 dist_std = 0.1413 vf_loss = 0.0190 grad_norm = 2.5245 nat_grad_norm = 0.0717 cg_residual = 1.5193 step_size = 0.5403 reward = 0.0000 fps = 5 mse_loss = 0.2937 
2022-05-01 18:25:57.741256 - gail/main.py:164 - [TRPO] iter = 2180000 dist_mean = 0.0608 dist_std = 0.1408 vf_loss = 0.0402 grad_norm = 5.0301 nat_grad_norm = 0.0710 cg_residual = 2.3084 step_size = 0.4114 reward = 0.0000 fps = 5 mse_loss = 0.2565 
2022-05-01 18:25:57.994426 - gail/main.py:191 - [Discriminator] iter = 2180000 loss = -0.4017 grad_norm = 3.2982 grad_penalty = 0.0470 regularization = 0.0000 true_logits = 0.0176 fake_logits = -0.4311 true_prob = 0.4886 fake_prob = 0.4135 
2022-05-01 18:28:05.735888 - gail/main.py:132 - [Evaluate] iter = 2180000 episode={ returns = 3533.9848 lengths = 1000 } discounted_episode={ returns = 2198.0843 lengths = 1000 } 
2022-05-01 18:28:15.366218 - gail/main.py:164 - [TRPO] iter = 2181000 dist_mean = 0.0478 dist_std = 0.1407 vf_loss = 0.0335 grad_norm = 2.2978 nat_grad_norm = 0.0828 cg_residual = 2.4898 step_size = 0.5078 reward = 0.0000 fps = 7 mse_loss = 0.2708 
2022-05-01 18:28:24.825343 - gail/main.py:164 - [TRPO] iter = 2182000 dist_mean = 0.0543 dist_std = 0.1411 vf_loss = 0.0457 grad_norm = 3.4457 nat_grad_norm = 0.0683 cg_residual = 1.0047 step_size = 0.5025 reward = -0.0000 fps = 6 mse_loss = 0.2673 
2022-05-01 18:28:34.017578 - gail/main.py:164 - [TRPO] iter = 2183000 dist_mean = 0.0316 dist_std = 0.1411 vf_loss = 0.0244 grad_norm = 3.7039 nat_grad_norm = 0.0951 cg_residual = 1.9026 step_size = 0.3706 reward = -0.0000 fps = 6 mse_loss = 0.2705 
2022-05-01 18:28:43.706441 - gail/main.py:164 - [TRPO] iter = 2184000 dist_mean = 0.0384 dist_std = 0.1413 vf_loss = 0.0191 grad_norm = 3.0361 nat_grad_norm = 0.0710 cg_residual = 1.6348 step_size = 0.5029 reward = 0.0000 fps = 6 mse_loss = 0.2673 
2022-05-01 18:28:53.024886 - gail/main.py:164 - [TRPO] iter = 2185000 dist_mean = 0.0516 dist_std = 0.1414 vf_loss = 0.0401 grad_norm = 2.5160 nat_grad_norm = 0.0624 cg_residual = 1.9959 step_size = 0.5513 reward = -0.0000 fps = 5 mse_loss = 0.2876 
2022-05-01 18:28:53.279484 - gail/main.py:191 - [Discriminator] iter = 2185000 loss = -0.3935 grad_norm = 3.4205 grad_penalty = 0.0490 regularization = 0.0000 true_logits = 0.0034 fake_logits = -0.4391 true_prob = 0.4823 fake_prob = 0.4135 
2022-05-01 18:30:58.723186 - gail/main.py:132 - [Evaluate] iter = 2185000 episode={ returns = 3475.3103 lengths = 1000 } discounted_episode={ returns = 2176.0373 lengths = 1000 } 
2022-05-01 18:31:07.888538 - gail/main.py:164 - [TRPO] iter = 2186000 dist_mean = 0.0297 dist_std = 0.1412 vf_loss = 0.0304 grad_norm = 3.0339 nat_grad_norm = 0.0894 cg_residual = 3.5013 step_size = 0.4642 reward = -0.0000 fps = 7 mse_loss = 0.2871 
2022-05-01 18:31:17.490873 - gail/main.py:164 - [TRPO] iter = 2187000 dist_mean = 0.0572 dist_std = 0.1416 vf_loss = 0.0236 grad_norm = 2.3551 nat_grad_norm = 0.0957 cg_residual = 3.0069 step_size = 0.4153 reward = 0.0000 fps = 6 mse_loss = 0.2875 
2022-05-01 18:31:26.724507 - gail/main.py:164 - [TRPO] iter = 2188000 dist_mean = 0.0419 dist_std = 0.1416 vf_loss = 0.0267 grad_norm = 3.8619 nat_grad_norm = 0.0791 cg_residual = 10.1003 step_size = 0.4758 reward = 0.0000 fps = 6 mse_loss = 0.2894 
2022-05-01 18:31:35.904055 - gail/main.py:164 - [TRPO] iter = 2189000 dist_mean = 0.0590 dist_std = 0.1415 vf_loss = 0.0187 grad_norm = 2.7615 nat_grad_norm = 0.0799 cg_residual = 1.4877 step_size = 0.4836 reward = 0.0000 fps = 6 mse_loss = 0.2711 
2022-05-01 18:31:45.395652 - gail/main.py:164 - [TRPO] iter = 2190000 dist_mean = 0.0383 dist_std = 0.1417 vf_loss = 0.0207 grad_norm = 3.5343 nat_grad_norm = 0.0692 cg_residual = 6.2459 step_size = 0.4871 reward = -0.0000 fps = 5 mse_loss = 0.2568 
2022-05-01 18:31:45.639553 - gail/main.py:191 - [Discriminator] iter = 2190000 loss = -0.3161 grad_norm = 4.7270 grad_penalty = 0.0556 regularization = 0.0000 true_logits = 0.0142 fake_logits = -0.3575 true_prob = 0.4840 fake_prob = 0.4237 
2022-05-01 18:33:48.921043 - gail/main.py:132 - [Evaluate] iter = 2190000 episode={ returns = 3495.1081 lengths = 1000 } discounted_episode={ returns = 2152.2165 lengths = 1000 } 
2022-05-01 18:33:58.357304 - gail/main.py:164 - [TRPO] iter = 2191000 dist_mean = 0.0291 dist_std = 0.1417 vf_loss = 0.0193 grad_norm = 2.6864 nat_grad_norm = 0.0727 cg_residual = 1.3973 step_size = 0.5095 reward = -0.0000 fps = 7 mse_loss = 0.2803 
2022-05-01 18:34:07.869974 - gail/main.py:164 - [TRPO] iter = 2192000 dist_mean = 0.0378 dist_std = 0.1415 vf_loss = 0.0172 grad_norm = 4.4937 nat_grad_norm = 0.0558 cg_residual = 1.0780 step_size = 0.5053 reward = -0.0000 fps = 7 mse_loss = 0.2654 
2022-05-01 18:34:17.232893 - gail/main.py:164 - [TRPO] iter = 2193000 dist_mean = 0.0194 dist_std = 0.1417 vf_loss = 0.0259 grad_norm = 3.6982 nat_grad_norm = 0.0691 cg_residual = 3.7474 step_size = 0.5058 reward = 0.0000 fps = 6 mse_loss = 0.2868 
2022-05-01 18:34:26.857430 - gail/main.py:164 - [TRPO] iter = 2194000 dist_mean = 0.0104 dist_std = 0.1420 vf_loss = 0.0254 grad_norm = 4.4188 nat_grad_norm = 0.0729 cg_residual = 10.9594 step_size = 0.4718 reward = 0.0000 fps = 6 mse_loss = 0.2643 
2022-05-01 18:34:36.280715 - gail/main.py:164 - [TRPO] iter = 2195000 dist_mean = 0.0175 dist_std = 0.1420 vf_loss = 0.0216 grad_norm = 3.0545 nat_grad_norm = 0.0761 cg_residual = 2.5110 step_size = 0.4968 reward = -0.0000 fps = 5 mse_loss = 0.2519 
2022-05-01 18:34:36.517398 - gail/main.py:191 - [Discriminator] iter = 2195000 loss = -0.3474 grad_norm = 3.4123 grad_penalty = 0.0450 regularization = 0.0000 true_logits = 0.0858 fake_logits = -0.3065 true_prob = 0.4972 fake_prob = 0.4300 
2022-05-01 18:36:41.729511 - gail/main.py:132 - [Evaluate] iter = 2195000 episode={ returns = 3535.5096 lengths = 1000 } discounted_episode={ returns = 2196.2520 lengths = 1000 } 
2022-05-01 18:36:51.521975 - gail/main.py:164 - [TRPO] iter = 2196000 dist_mean = 0.0101 dist_std = 0.1421 vf_loss = 0.0227 grad_norm = 4.6877 nat_grad_norm = 0.0981 cg_residual = 2.5510 step_size = 0.3949 reward = 0.0000 fps = 7 mse_loss = 0.2814 
2022-05-01 18:37:00.966560 - gail/main.py:164 - [TRPO] iter = 2197000 dist_mean = 0.0344 dist_std = 0.1423 vf_loss = 0.0162 grad_norm = 3.4917 nat_grad_norm = 0.0839 cg_residual = 10.1572 step_size = 0.3893 reward = -0.0000 fps = 6 mse_loss = 0.2726 
2022-05-01 18:37:10.332658 - gail/main.py:164 - [TRPO] iter = 2198000 dist_mean = 0.0320 dist_std = 0.1421 vf_loss = 0.0396 grad_norm = 3.3131 nat_grad_norm = 0.0911 cg_residual = 2.2938 step_size = 0.3925 reward = -0.0000 fps = 6 mse_loss = 0.2717 
2022-05-01 18:37:19.686428 - gail/main.py:164 - [TRPO] iter = 2199000 dist_mean = 0.0103 dist_std = 0.1420 vf_loss = 0.0278 grad_norm = 4.0690 nat_grad_norm = 0.0821 cg_residual = 4.7425 step_size = 0.4811 reward = 0.0000 fps = 6 mse_loss = 0.2879 
2022-05-01 18:37:29.053842 - gail/main.py:164 - [TRPO] iter = 2200000 dist_mean = 0.0082 dist_std = 0.1423 vf_loss = 0.0493 grad_norm = 2.9197 nat_grad_norm = 0.0870 cg_residual = 7.7158 step_size = 0.4355 reward = 0.0000 fps = 5 mse_loss = 0.2982 
2022-05-01 18:37:29.340177 - gail/main.py:191 - [Discriminator] iter = 2200000 loss = -0.2260 grad_norm = 3.8982 grad_penalty = 0.0482 regularization = 0.0000 true_logits = 0.0592 fake_logits = -0.2149 true_prob = 0.4943 fake_prob = 0.4497 
2022-05-01 18:39:32.471457 - gail/main.py:132 - [Evaluate] iter = 2200000 episode={ returns = 3557.6630 lengths = 1000 } discounted_episode={ returns = 2207.9581 lengths = 1000 } 
2022-05-01 18:39:41.603399 - gail/main.py:164 - [TRPO] iter = 2201000 dist_mean = 0.0220 dist_std = 0.1423 vf_loss = 0.0223 grad_norm = 4.4200 nat_grad_norm = 0.0838 cg_residual = 6.4095 step_size = 0.4067 reward = -0.0000 fps = 7 mse_loss = 0.2772 
2022-05-01 18:39:50.964783 - gail/main.py:164 - [TRPO] iter = 2202000 dist_mean = 0.0219 dist_std = 0.1422 vf_loss = 0.0177 grad_norm = 3.4187 nat_grad_norm = 0.0713 cg_residual = 5.2909 step_size = 0.4822 reward = -0.0000 fps = 7 mse_loss = 0.2697 
2022-05-01 18:40:00.217249 - gail/main.py:164 - [TRPO] iter = 2203000 dist_mean = 0.0286 dist_std = 0.1424 vf_loss = 0.0294 grad_norm = 4.0923 nat_grad_norm = 0.0644 cg_residual = 2.8213 step_size = 0.4776 reward = 0.0000 fps = 6 mse_loss = 0.2839 
2022-05-01 18:40:09.774282 - gail/main.py:164 - [TRPO] iter = 2204000 dist_mean = 0.0306 dist_std = 0.1423 vf_loss = 0.0252 grad_norm = 3.3087 nat_grad_norm = 0.1049 cg_residual = 2.2665 step_size = 0.3803 reward = 0.0000 fps = 6 mse_loss = 0.2843 
2022-05-01 18:40:19.140574 - gail/main.py:164 - [TRPO] iter = 2205000 dist_mean = 0.0163 dist_std = 0.1423 vf_loss = 0.0404 grad_norm = 3.9729 nat_grad_norm = 0.0822 cg_residual = 3.3626 step_size = 0.4719 reward = 0.0000 fps = 5 mse_loss = 0.2621 
2022-05-01 18:40:19.342440 - gail/main.py:191 - [Discriminator] iter = 2205000 loss = -0.3449 grad_norm = 3.3691 grad_penalty = 0.0440 regularization = 0.0000 true_logits = 0.1811 fake_logits = -0.2078 true_prob = 0.5234 fake_prob = 0.4519 
2022-05-01 18:42:27.705221 - gail/main.py:132 - [Evaluate] iter = 2205000 episode={ returns = 3543.9450 lengths = 1000 } discounted_episode={ returns = 2204.9717 lengths = 1000 } 
2022-05-01 18:42:37.314284 - gail/main.py:164 - [TRPO] iter = 2206000 dist_mean = 0.0306 dist_std = 0.1422 vf_loss = 0.0164 grad_norm = 6.0503 nat_grad_norm = 0.0814 cg_residual = 1.9809 step_size = 0.3712 reward = 0.0000 fps = 7 mse_loss = 0.2935 
2022-05-01 18:42:46.473850 - gail/main.py:164 - [TRPO] iter = 2207000 dist_mean = 0.0252 dist_std = 0.1420 vf_loss = 0.0297 grad_norm = 3.5008 nat_grad_norm = 0.1004 cg_residual = 2.6433 step_size = 0.4062 reward = -0.0000 fps = 6 mse_loss = 0.2813 
2022-05-01 18:42:55.673786 - gail/main.py:164 - [TRPO] iter = 2208000 dist_mean = 0.0345 dist_std = 0.1418 vf_loss = 0.0111 grad_norm = 2.9571 nat_grad_norm = 0.1354 cg_residual = 2.8224 step_size = 0.3160 reward = -0.0000 fps = 6 mse_loss = 0.2815 
2022-05-01 18:43:04.876390 - gail/main.py:164 - [TRPO] iter = 2209000 dist_mean = 0.0415 dist_std = 0.1420 vf_loss = 0.0170 grad_norm = 3.7110 nat_grad_norm = 0.0927 cg_residual = 1.8093 step_size = 0.3865 reward = 0.0000 fps = 6 mse_loss = 0.2959 
2022-05-01 18:43:14.415069 - gail/main.py:164 - [TRPO] iter = 2210000 dist_mean = 0.0056 dist_std = 0.1418 vf_loss = 0.0164 grad_norm = 4.9297 nat_grad_norm = 0.1020 cg_residual = 2.6924 step_size = 0.3356 reward = 0.0000 fps = 5 mse_loss = 0.2603 
2022-05-01 18:43:14.630187 - gail/main.py:191 - [Discriminator] iter = 2210000 loss = -0.2824 grad_norm = 3.5597 grad_penalty = 0.0512 regularization = 0.0000 true_logits = 0.1184 fake_logits = -0.2152 true_prob = 0.5125 fake_prob = 0.4522 
2022-05-01 18:45:20.524031 - gail/main.py:132 - [Evaluate] iter = 2210000 episode={ returns = 3542.9909 lengths = 1000 } discounted_episode={ returns = 2194.9335 lengths = 1000 } 
2022-05-01 18:45:29.467633 - gail/main.py:164 - [TRPO] iter = 2211000 dist_mean = 0.0201 dist_std = 0.1418 vf_loss = 0.0287 grad_norm = 6.0573 nat_grad_norm = 0.0709 cg_residual = 4.1454 step_size = 0.4443 reward = -0.0000 fps = 7 mse_loss = 0.2588 
2022-05-01 18:45:38.679053 - gail/main.py:164 - [TRPO] iter = 2212000 dist_mean = 0.0099 dist_std = 0.1419 vf_loss = 0.0196 grad_norm = 2.9148 nat_grad_norm = 0.1093 cg_residual = 2.2325 step_size = 0.4186 reward = 0.0000 fps = 6 mse_loss = 0.2918 
2022-05-01 18:45:48.186878 - gail/main.py:164 - [TRPO] iter = 2213000 dist_mean = 0.0178 dist_std = 0.1421 vf_loss = 0.0180 grad_norm = 5.9199 nat_grad_norm = 0.0931 cg_residual = 15.6518 step_size = 0.3823 reward = 0.0000 fps = 6 mse_loss = 0.2879 
2022-05-01 18:45:57.565320 - gail/main.py:164 - [TRPO] iter = 2214000 dist_mean = 0.0187 dist_std = 0.1422 vf_loss = 0.0196 grad_norm = 2.9021 nat_grad_norm = 0.0927 cg_residual = 1.9068 step_size = 0.4593 reward = 0.0000 fps = 6 mse_loss = 0.2657 
2022-05-01 18:46:07.110905 - gail/main.py:164 - [TRPO] iter = 2215000 dist_mean = 0.0194 dist_std = 0.1427 vf_loss = 0.0373 grad_norm = 3.0448 nat_grad_norm = 0.0615 cg_residual = 0.8325 step_size = 0.5558 reward = 0.0000 fps = 5 mse_loss = 0.2807 
2022-05-01 18:46:07.355991 - gail/main.py:191 - [Discriminator] iter = 2215000 loss = -0.2609 grad_norm = 3.4177 grad_penalty = 0.0478 regularization = 0.0000 true_logits = 0.0790 fake_logits = -0.2297 true_prob = 0.5065 fake_prob = 0.4503 
2022-05-01 18:48:13.572814 - gail/main.py:132 - [Evaluate] iter = 2215000 episode={ returns = 3573.6685 lengths = 1000 } discounted_episode={ returns = 2211.4012 lengths = 1000 } 
2022-05-01 18:48:23.318225 - gail/main.py:164 - [TRPO] iter = 2216000 dist_mean = 0.0193 dist_std = 0.1429 vf_loss = 0.0438 grad_norm = 4.5834 nat_grad_norm = 0.1116 cg_residual = 1.3539 step_size = 0.2908 reward = -0.0000 fps = 7 mse_loss = 0.2851 
2022-05-01 18:48:33.110706 - gail/main.py:164 - [TRPO] iter = 2217000 dist_mean = 0.0245 dist_std = 0.1427 vf_loss = 0.0221 grad_norm = 3.5204 nat_grad_norm = 0.0932 cg_residual = 1.8905 step_size = 0.3661 reward = -0.0000 fps = 6 mse_loss = 0.3003 
2022-05-01 18:48:42.435998 - gail/main.py:164 - [TRPO] iter = 2218000 dist_mean = 0.0237 dist_std = 0.1427 vf_loss = 0.0395 grad_norm = 3.5420 nat_grad_norm = 0.0905 cg_residual = 3.0855 step_size = 0.4752 reward = 0.0000 fps = 6 mse_loss = 0.2838 
2022-05-01 18:48:52.150472 - gail/main.py:164 - [TRPO] iter = 2219000 dist_mean = 0.0448 dist_std = 0.1427 vf_loss = 0.0468 grad_norm = 4.4554 nat_grad_norm = 0.0647 cg_residual = 2.5836 step_size = 0.4728 reward = 0.0000 fps = 6 mse_loss = 0.2723 
2022-05-01 18:49:01.805155 - gail/main.py:164 - [TRPO] iter = 2220000 dist_mean = 0.0296 dist_std = 0.1427 vf_loss = 0.0183 grad_norm = 6.6867 nat_grad_norm = 0.0797 cg_residual = 1.0415 step_size = 0.4402 reward = 0.0000 fps = 5 mse_loss = 0.2865 
2022-05-01 18:49:02.088550 - gail/main.py:191 - [Discriminator] iter = 2220000 loss = -0.2854 grad_norm = 3.5740 grad_penalty = 0.0473 regularization = 0.0000 true_logits = 0.0889 fake_logits = -0.2438 true_prob = 0.5104 fake_prob = 0.4496 
2022-05-01 18:51:09.917404 - gail/main.py:132 - [Evaluate] iter = 2220000 episode={ returns = 3609.3482 lengths = 1000 } discounted_episode={ returns = 2235.0816 lengths = 1000 } 
2022-05-01 18:51:19.745596 - gail/main.py:164 - [TRPO] iter = 2221000 dist_mean = 0.0657 dist_std = 0.1427 vf_loss = 0.0145 grad_norm = 2.6839 nat_grad_norm = 0.0922 cg_residual = 1.3950 step_size = 0.4464 reward = -0.0000 fps = 7 mse_loss = 0.2625 
2022-05-01 18:51:29.920348 - gail/main.py:164 - [TRPO] iter = 2222000 dist_mean = 0.0448 dist_std = 0.1432 vf_loss = 0.0222 grad_norm = 3.9871 nat_grad_norm = 0.0838 cg_residual = 2.0103 step_size = 0.4306 reward = 0.0000 fps = 6 mse_loss = 0.3009 
2022-05-01 18:51:39.435074 - gail/main.py:164 - [TRPO] iter = 2223000 dist_mean = 0.0445 dist_std = 0.1431 vf_loss = 0.0186 grad_norm = 3.1024 nat_grad_norm = 0.0701 cg_residual = 1.0931 step_size = 0.4834 reward = -0.0000 fps = 6 mse_loss = 0.2719 
2022-05-01 18:51:48.811781 - gail/main.py:164 - [TRPO] iter = 2224000 dist_mean = 0.0377 dist_std = 0.1433 vf_loss = 0.0192 grad_norm = 4.5090 nat_grad_norm = 0.0871 cg_residual = 0.9883 step_size = 0.4595 reward = 0.0000 fps = 5 mse_loss = 0.2917 
2022-05-01 18:51:58.209311 - gail/main.py:164 - [TRPO] iter = 2225000 dist_mean = 0.0607 dist_std = 0.1435 vf_loss = 0.0274 grad_norm = 3.1970 nat_grad_norm = 0.0811 cg_residual = 1.6465 step_size = 0.5061 reward = -0.0000 fps = 5 mse_loss = 0.2722 
2022-05-01 18:51:58.421789 - gail/main.py:191 - [Discriminator] iter = 2225000 loss = -0.2337 grad_norm = 2.7430 grad_penalty = 0.0452 regularization = 0.0000 true_logits = 0.0385 fake_logits = -0.2405 true_prob = 0.5006 fake_prob = 0.4495 
2022-05-01 18:54:05.101926 - gail/main.py:132 - [Evaluate] iter = 2225000 episode={ returns = 3622.0663 lengths = 1000 } discounted_episode={ returns = 2240.9465 lengths = 1000 } 
2022-05-01 18:54:14.471962 - gail/main.py:164 - [TRPO] iter = 2226000 dist_mean = 0.0423 dist_std = 0.1436 vf_loss = 0.0355 grad_norm = 3.3681 nat_grad_norm = 0.0872 cg_residual = 1.4526 step_size = 0.4551 reward = 0.0000 fps = 7 mse_loss = 0.3033 
2022-05-01 18:54:23.650012 - gail/main.py:164 - [TRPO] iter = 2227000 dist_mean = 0.0468 dist_std = 0.1438 vf_loss = 0.0142 grad_norm = 3.2335 nat_grad_norm = 0.0808 cg_residual = 1.1856 step_size = 0.4832 reward = 0.0000 fps = 6 mse_loss = 0.2886 
2022-05-01 18:54:32.915257 - gail/main.py:164 - [TRPO] iter = 2228000 dist_mean = 0.0625 dist_std = 0.1441 vf_loss = 0.0363 grad_norm = 3.2346 nat_grad_norm = 0.0903 cg_residual = 2.7443 step_size = 0.4045 reward = 0.0000 fps = 6 mse_loss = 0.2830 
2022-05-01 18:54:42.256323 - gail/main.py:164 - [TRPO] iter = 2229000 dist_mean = 0.0637 dist_std = 0.1445 vf_loss = 0.0294 grad_norm = 2.2315 nat_grad_norm = 0.0820 cg_residual = 0.8188 step_size = 0.4535 reward = -0.0000 fps = 6 mse_loss = 0.2679 
2022-05-01 18:54:51.677397 - gail/main.py:164 - [TRPO] iter = 2230000 dist_mean = 0.0598 dist_std = 0.1441 vf_loss = 0.0298 grad_norm = 3.3601 nat_grad_norm = 0.0934 cg_residual = 1.9780 step_size = 0.3876 reward = 0.0000 fps = 5 mse_loss = 0.2754 
2022-05-01 18:54:51.888011 - gail/main.py:191 - [Discriminator] iter = 2230000 loss = -0.2473 grad_norm = 3.9784 grad_penalty = 0.0470 regularization = 0.0000 true_logits = 0.0561 fake_logits = -0.2383 true_prob = 0.5047 fake_prob = 0.4488 
2022-05-01 18:56:59.565862 - gail/main.py:132 - [Evaluate] iter = 2230000 episode={ returns = 3622.3632 lengths = 1000 } discounted_episode={ returns = 2231.8952 lengths = 1000 } 
2022-05-01 18:57:09.356989 - gail/main.py:164 - [TRPO] iter = 2231000 dist_mean = 0.0675 dist_std = 0.1442 vf_loss = 0.0394 grad_norm = 4.5694 nat_grad_norm = 0.0885 cg_residual = 1.8237 step_size = 0.4435 reward = -0.0000 fps = 7 mse_loss = 0.2813 
2022-05-01 18:57:18.720165 - gail/main.py:164 - [TRPO] iter = 2232000 dist_mean = 0.0415 dist_std = 0.1445 vf_loss = 0.0343 grad_norm = 3.0573 nat_grad_norm = 0.0984 cg_residual = 1.8379 step_size = 0.4158 reward = -0.0000 fps = 6 mse_loss = 0.3096 
2022-05-01 18:57:27.523208 - gail/main.py:164 - [TRPO] iter = 2233000 dist_mean = 0.0409 dist_std = 0.1448 vf_loss = 0.0226 grad_norm = 5.1364 nat_grad_norm = 0.1094 cg_residual = 1.7866 step_size = 0.3509 reward = -0.0000 fps = 6 mse_loss = 0.3093 
2022-05-01 18:57:37.009948 - gail/main.py:164 - [TRPO] iter = 2234000 dist_mean = 0.0526 dist_std = 0.1446 vf_loss = 0.0111 grad_norm = 4.3347 nat_grad_norm = 0.0784 cg_residual = 1.4964 step_size = 0.4561 reward = 0.0000 fps = 6 mse_loss = 0.2818 
2022-05-01 18:57:46.400581 - gail/main.py:164 - [TRPO] iter = 2235000 dist_mean = 0.0548 dist_std = 0.1446 vf_loss = 0.0281 grad_norm = 2.4008 nat_grad_norm = 0.0988 cg_residual = 2.9535 step_size = 0.4437 reward = 0.0000 fps = 5 mse_loss = 0.2848 
2022-05-01 18:57:46.658367 - gail/main.py:191 - [Discriminator] iter = 2235000 loss = -0.2564 grad_norm = 4.0492 grad_penalty = 0.0499 regularization = 0.0000 true_logits = 0.0342 fake_logits = -0.2722 true_prob = 0.5011 fake_prob = 0.4441 
2022-05-01 18:59:52.457987 - gail/main.py:132 - [Evaluate] iter = 2235000 episode={ returns = 3601.8701 lengths = 1000 } discounted_episode={ returns = 2228.0821 lengths = 1000 } 
2022-05-01 19:00:01.798230 - gail/main.py:164 - [TRPO] iter = 2236000 dist_mean = 0.0436 dist_std = 0.1449 vf_loss = 0.0192 grad_norm = 3.1713 nat_grad_norm = 0.0806 cg_residual = 1.1530 step_size = 0.4804 reward = 0.0000 fps = 7 mse_loss = 0.3442 
2022-05-01 19:00:11.494750 - gail/main.py:164 - [TRPO] iter = 2237000 dist_mean = 0.0468 dist_std = 0.1448 vf_loss = 0.0311 grad_norm = 3.0911 nat_grad_norm = 0.0713 cg_residual = 1.0308 step_size = 0.5043 reward = -0.0000 fps = 6 mse_loss = 0.2727 
2022-05-01 19:00:20.616787 - gail/main.py:164 - [TRPO] iter = 2238000 dist_mean = 0.0460 dist_std = 0.1447 vf_loss = 0.0416 grad_norm = 4.1524 nat_grad_norm = 0.0661 cg_residual = 1.4021 step_size = 0.4534 reward = -0.0000 fps = 6 mse_loss = 0.2781 
2022-05-01 19:00:29.662979 - gail/main.py:164 - [TRPO] iter = 2239000 dist_mean = 0.0434 dist_std = 0.1447 vf_loss = 0.0228 grad_norm = 5.5093 nat_grad_norm = 0.0772 cg_residual = 0.6445 step_size = 0.4229 reward = 0.0000 fps = 6 mse_loss = 0.2864 
2022-05-01 19:00:38.780857 - gail/main.py:164 - [TRPO] iter = 2240000 dist_mean = 0.0595 dist_std = 0.1451 vf_loss = 0.0369 grad_norm = 4.2146 nat_grad_norm = 0.0632 cg_residual = 0.9095 step_size = 0.5696 reward = 0.0000 fps = 5 mse_loss = 0.2727 
2022-05-01 19:00:38.961135 - gail/main.py:191 - [Discriminator] iter = 2240000 loss = -0.1299 grad_norm = 4.7932 grad_penalty = 0.0488 regularization = 0.0000 true_logits = -0.1200 fake_logits = -0.2987 true_prob = 0.4674 fake_prob = 0.4413 
2022-05-01 19:02:45.861748 - gail/main.py:132 - [Evaluate] iter = 2240000 episode={ returns = 3600.7836 lengths = 1000 } discounted_episode={ returns = 2226.2580 lengths = 1000 } 
2022-05-01 19:02:55.265798 - gail/main.py:164 - [TRPO] iter = 2241000 dist_mean = 0.0556 dist_std = 0.1453 vf_loss = 0.0215 grad_norm = 3.2289 nat_grad_norm = 0.0963 cg_residual = 1.5810 step_size = 0.4084 reward = -0.0000 fps = 7 mse_loss = 0.3230 
2022-05-01 19:03:04.723002 - gail/main.py:164 - [TRPO] iter = 2242000 dist_mean = 0.0760 dist_std = 0.1450 vf_loss = 0.0311 grad_norm = 5.1023 nat_grad_norm = 0.0627 cg_residual = 1.1959 step_size = 0.4721 reward = -0.0000 fps = 6 mse_loss = 0.3012 
2022-05-01 19:03:14.327037 - gail/main.py:164 - [TRPO] iter = 2243000 dist_mean = 0.0102 dist_std = 0.1451 vf_loss = 0.0322 grad_norm = 3.6226 nat_grad_norm = 0.0735 cg_residual = 4.7395 step_size = 0.4869 reward = 0.0000 fps = 6 mse_loss = 0.3164 
2022-05-01 19:03:23.638479 - gail/main.py:164 - [TRPO] iter = 2244000 dist_mean = 0.0444 dist_std = 0.1449 vf_loss = 0.0291 grad_norm = 4.0684 nat_grad_norm = 0.0757 cg_residual = 0.9603 step_size = 0.4974 reward = -0.0000 fps = 6 mse_loss = 0.3026 
2022-05-01 19:03:33.220324 - gail/main.py:164 - [TRPO] iter = 2245000 dist_mean = 0.0247 dist_std = 0.1446 vf_loss = 0.0112 grad_norm = 3.0828 nat_grad_norm = 0.0927 cg_residual = 1.5104 step_size = 0.4225 reward = 0.0000 fps = 5 mse_loss = 0.2941 
2022-05-01 19:03:33.471355 - gail/main.py:191 - [Discriminator] iter = 2245000 loss = -0.1812 grad_norm = 4.1358 grad_penalty = 0.0540 regularization = 0.0000 true_logits = -0.2319 fake_logits = -0.4671 true_prob = 0.4454 fake_prob = 0.4050 
2022-05-01 19:05:39.778395 - gail/main.py:132 - [Evaluate] iter = 2245000 episode={ returns = 3610.3572 lengths = 1000 } discounted_episode={ returns = 2226.3519 lengths = 1000 } 
2022-05-01 19:05:49.471265 - gail/main.py:164 - [TRPO] iter = 2246000 dist_mean = 0.0245 dist_std = 0.1449 vf_loss = 0.0174 grad_norm = 3.5734 nat_grad_norm = 0.0820 cg_residual = 1.5599 step_size = 0.4876 reward = -0.0000 fps = 7 mse_loss = 0.3282 
2022-05-01 19:05:58.885503 - gail/main.py:164 - [TRPO] iter = 2247000 dist_mean = 0.0221 dist_std = 0.1450 vf_loss = 0.0116 grad_norm = 4.8771 nat_grad_norm = 0.0806 cg_residual = 1.4336 step_size = 0.4460 reward = 0.0000 fps = 6 mse_loss = 0.3189 
2022-05-01 19:06:08.311202 - gail/main.py:164 - [TRPO] iter = 2248000 dist_mean = 0.0065 dist_std = 0.1449 vf_loss = 0.0278 grad_norm = 2.6120 nat_grad_norm = 0.0886 cg_residual = 1.4840 step_size = 0.4609 reward = 0.0000 fps = 6 mse_loss = 0.2895 
2022-05-01 19:06:17.518524 - gail/main.py:164 - [TRPO] iter = 2249000 dist_mean = -0.0005 dist_std = 0.1450 vf_loss = 0.0257 grad_norm = 3.6957 nat_grad_norm = 0.0683 cg_residual = 1.5595 step_size = 0.4790 reward = 0.0000 fps = 6 mse_loss = 0.3085 
2022-05-01 19:06:26.946462 - gail/main.py:164 - [TRPO] iter = 2250000 dist_mean = 0.0249 dist_std = 0.1454 vf_loss = 0.0181 grad_norm = 3.0814 nat_grad_norm = 0.1432 cg_residual = 4.2249 step_size = 0.3073 reward = 0.0000 fps = 5 mse_loss = 0.2899 
2022-05-01 19:06:27.201228 - gail/main.py:191 - [Discriminator] iter = 2250000 loss = -0.3375 grad_norm = 3.8015 grad_penalty = 0.0544 regularization = 0.0000 true_logits = -0.4759 fake_logits = -0.8677 true_prob = 0.3962 fake_prob = 0.3265 
2022-05-01 19:08:34.514952 - gail/main.py:132 - [Evaluate] iter = 2250000 episode={ returns = 3605.2668 lengths = 1000 } discounted_episode={ returns = 2228.2836 lengths = 1000 } 
2022-05-01 19:08:44.203249 - gail/main.py:164 - [TRPO] iter = 2251000 dist_mean = 0.0112 dist_std = 0.1453 vf_loss = 0.0209 grad_norm = 3.1640 nat_grad_norm = 0.0915 cg_residual = 1.6298 step_size = 0.4405 reward = -0.0000 fps = 7 mse_loss = 0.3217 
2022-05-01 19:08:53.653193 - gail/main.py:164 - [TRPO] iter = 2252000 dist_mean = -0.0029 dist_std = 0.1450 vf_loss = 0.0213 grad_norm = 4.7137 nat_grad_norm = 0.1039 cg_residual = 2.3778 step_size = 0.3862 reward = 0.0000 fps = 6 mse_loss = 0.3287 
2022-05-01 19:09:03.113077 - gail/main.py:164 - [TRPO] iter = 2253000 dist_mean = -0.0016 dist_std = 0.1448 vf_loss = 0.0237 grad_norm = 3.5218 nat_grad_norm = 0.0794 cg_residual = 0.9683 step_size = 0.4561 reward = 0.0000 fps = 6 mse_loss = 0.2658 
2022-05-01 19:09:12.462346 - gail/main.py:164 - [TRPO] iter = 2254000 dist_mean = 0.0159 dist_std = 0.1447 vf_loss = 0.0134 grad_norm = 2.8438 nat_grad_norm = 0.0764 cg_residual = 1.0953 step_size = 0.4719 reward = -0.0000 fps = 6 mse_loss = 0.2843 
2022-05-01 19:09:21.648240 - gail/main.py:164 - [TRPO] iter = 2255000 dist_mean = 0.0037 dist_std = 0.1448 vf_loss = 0.0135 grad_norm = 6.1348 nat_grad_norm = 0.0852 cg_residual = 1.9181 step_size = 0.3915 reward = 0.0000 fps = 5 mse_loss = 0.2720 
2022-05-01 19:09:21.869090 - gail/main.py:191 - [Discriminator] iter = 2255000 loss = -0.2574 grad_norm = 4.1076 grad_penalty = 0.0538 regularization = 0.0000 true_logits = -0.7757 fake_logits = -1.0869 true_prob = 0.3382 fake_prob = 0.2797 
2022-05-01 19:11:28.147551 - gail/main.py:132 - [Evaluate] iter = 2255000 episode={ returns = 3544.3960 lengths = 1000 } discounted_episode={ returns = 2188.7804 lengths = 1000 } 
2022-05-01 19:11:37.708592 - gail/main.py:164 - [TRPO] iter = 2256000 dist_mean = 0.0085 dist_std = 0.1449 vf_loss = 0.0410 grad_norm = 4.0828 nat_grad_norm = 0.0817 cg_residual = 1.5482 step_size = 0.4608 reward = -0.0000 fps = 7 mse_loss = 0.2955 
2022-05-01 19:11:47.134622 - gail/main.py:164 - [TRPO] iter = 2257000 dist_mean = -0.0023 dist_std = 0.1449 vf_loss = 0.0352 grad_norm = 3.0101 nat_grad_norm = 0.0886 cg_residual = 1.1018 step_size = 0.5068 reward = -0.0000 fps = 6 mse_loss = 0.2962 
2022-05-01 19:11:56.293128 - gail/main.py:164 - [TRPO] iter = 2258000 dist_mean = -0.0003 dist_std = 0.1450 vf_loss = 0.0173 grad_norm = 4.4335 nat_grad_norm = 0.0993 cg_residual = 2.9691 step_size = 0.3640 reward = -0.0000 fps = 6 mse_loss = 0.2879 
2022-05-01 19:12:05.875817 - gail/main.py:164 - [TRPO] iter = 2259000 dist_mean = 0.0152 dist_std = 0.1450 vf_loss = 0.0382 grad_norm = 6.6499 nat_grad_norm = 0.1312 cg_residual = 5.6030 step_size = 0.2850 reward = -0.0000 fps = 6 mse_loss = 0.2939 
2022-05-01 19:12:15.440822 - gail/main.py:164 - [TRPO] iter = 2260000 dist_mean = 0.0053 dist_std = 0.1449 vf_loss = 0.0159 grad_norm = 3.5765 nat_grad_norm = 0.0748 cg_residual = 4.8403 step_size = 0.4844 reward = 0.0000 fps = 5 mse_loss = 0.2781 
2022-05-01 19:12:15.672734 - gail/main.py:191 - [Discriminator] iter = 2260000 loss = -0.2805 grad_norm = 4.5775 grad_penalty = 0.0543 regularization = 0.0000 true_logits = -0.9527 fake_logits = -1.2875 true_prob = 0.3017 fake_prob = 0.2395 
2022-05-01 19:14:22.012931 - gail/main.py:132 - [Evaluate] iter = 2260000 episode={ returns = 3507.8690 lengths = 1000 } discounted_episode={ returns = 2185.1798 lengths = 1000 } 
2022-05-01 19:14:31.326947 - gail/main.py:164 - [TRPO] iter = 2261000 dist_mean = -0.0027 dist_std = 0.1448 vf_loss = 0.0265 grad_norm = 3.5939 nat_grad_norm = 0.1428 cg_residual = 4.7930 step_size = 0.3072 reward = -0.0000 fps = 7 mse_loss = 0.3047 
2022-05-01 19:14:40.856780 - gail/main.py:164 - [TRPO] iter = 2262000 dist_mean = 0.0196 dist_std = 0.1450 vf_loss = 0.0239 grad_norm = 2.0880 nat_grad_norm = 0.1039 cg_residual = 1.6974 step_size = 0.4103 reward = 0.0000 fps = 6 mse_loss = 0.3062 
2022-05-01 19:14:50.489461 - gail/main.py:164 - [TRPO] iter = 2263000 dist_mean = 0.0174 dist_std = 0.1455 vf_loss = 0.0342 grad_norm = 6.7454 nat_grad_norm = 0.1160 cg_residual = 2.1736 step_size = 0.3084 reward = 0.0000 fps = 6 mse_loss = 0.2864 
2022-05-01 19:14:59.827783 - gail/main.py:164 - [TRPO] iter = 2264000 dist_mean = -0.0096 dist_std = 0.1455 vf_loss = 0.0240 grad_norm = 2.4100 nat_grad_norm = 0.0889 cg_residual = 2.2856 step_size = 0.4298 reward = 0.0000 fps = 6 mse_loss = 0.2791 
2022-05-01 19:15:09.435685 - gail/main.py:164 - [TRPO] iter = 2265000 dist_mean = 0.0008 dist_std = 0.1455 vf_loss = 0.0252 grad_norm = 5.5836 nat_grad_norm = 0.1630 cg_residual = 3.0231 step_size = 0.2557 reward = -0.0000 fps = 5 mse_loss = 0.2831 
2022-05-01 19:15:09.650498 - gail/main.py:191 - [Discriminator] iter = 2265000 loss = -0.3150 grad_norm = 5.2381 grad_penalty = 0.0598 regularization = 0.0000 true_logits = -0.9831 fake_logits = -1.3579 true_prob = 0.2957 fake_prob = 0.2267 
2022-05-01 19:17:16.964187 - gail/main.py:132 - [Evaluate] iter = 2265000 episode={ returns = 3490.7204 lengths = 1000 } discounted_episode={ returns = 2169.5543 lengths = 1000 } 
2022-05-01 19:17:26.479731 - gail/main.py:164 - [TRPO] iter = 2266000 dist_mean = -0.0031 dist_std = 0.1456 vf_loss = 0.0399 grad_norm = 4.4045 nat_grad_norm = 0.0910 cg_residual = 5.0240 step_size = 0.4444 reward = -0.0000 fps = 7 mse_loss = 0.2833 
2022-05-01 19:17:35.806045 - gail/main.py:164 - [TRPO] iter = 2267000 dist_mean = 0.0038 dist_std = 0.1453 vf_loss = 0.0349 grad_norm = 3.3958 nat_grad_norm = 0.0943 cg_residual = 7.4910 step_size = 0.4570 reward = -0.0000 fps = 6 mse_loss = 0.2518 
2022-05-01 19:17:45.070649 - gail/main.py:164 - [TRPO] iter = 2268000 dist_mean = 0.0088 dist_std = 0.1453 vf_loss = 0.0457 grad_norm = 5.2887 nat_grad_norm = 0.0689 cg_residual = 7.4123 step_size = 0.4775 reward = 0.0000 fps = 6 mse_loss = 0.2923 
2022-05-01 19:17:54.674071 - gail/main.py:164 - [TRPO] iter = 2269000 dist_mean = 0.0088 dist_std = 0.1454 vf_loss = 0.0203 grad_norm = 3.9282 nat_grad_norm = 0.1227 cg_residual = 3.8529 step_size = 0.3018 reward = -0.0000 fps = 6 mse_loss = 0.2964 
2022-05-01 19:18:03.954800 - gail/main.py:164 - [TRPO] iter = 2270000 dist_mean = -0.0064 dist_std = 0.1452 vf_loss = 0.0254 grad_norm = 4.1277 nat_grad_norm = 0.0887 cg_residual = 3.4773 step_size = 0.4357 reward = 0.0000 fps = 5 mse_loss = 0.2585 
2022-05-01 19:18:04.227846 - gail/main.py:191 - [Discriminator] iter = 2270000 loss = -0.3019 grad_norm = 5.2377 grad_penalty = 0.0663 regularization = 0.0000 true_logits = -0.9937 fake_logits = -1.3619 true_prob = 0.2900 fake_prob = 0.2241 
2022-05-01 19:20:10.108566 - gail/main.py:132 - [Evaluate] iter = 2270000 episode={ returns = 3486.8077 lengths = 1000 } discounted_episode={ returns = 2160.5927 lengths = 997 } 
2022-05-01 19:20:19.740573 - gail/main.py:164 - [TRPO] iter = 2271000 dist_mean = 0.0085 dist_std = 0.1450 vf_loss = 0.0394 grad_norm = 3.6545 nat_grad_norm = 0.0881 cg_residual = 8.7128 step_size = 0.4941 reward = 0.0000 fps = 7 mse_loss = 0.2825 
2022-05-01 19:20:28.881097 - gail/main.py:164 - [TRPO] iter = 2272000 dist_mean = -0.0093 dist_std = 0.1448 vf_loss = 0.0328 grad_norm = 4.6754 nat_grad_norm = 0.0913 cg_residual = 1.0929 step_size = 0.4190 reward = 0.0000 fps = 6 mse_loss = 0.2962 
2022-05-01 19:20:38.475777 - gail/main.py:164 - [TRPO] iter = 2273000 dist_mean = 0.0045 dist_std = 0.1452 vf_loss = 0.0238 grad_norm = 3.7540 nat_grad_norm = 0.0678 cg_residual = 2.5473 step_size = 0.4911 reward = -0.0000 fps = 6 mse_loss = 0.2709 
2022-05-01 19:20:47.977733 - gail/main.py:164 - [TRPO] iter = 2274000 dist_mean = -0.0078 dist_std = 0.1456 vf_loss = 0.0320 grad_norm = 3.9336 nat_grad_norm = 0.0862 cg_residual = 5.6200 step_size = 0.4668 reward = -0.0000 fps = 6 mse_loss = 0.2793 
2022-05-01 19:20:57.691176 - gail/main.py:164 - [TRPO] iter = 2275000 dist_mean = -0.0013 dist_std = 0.1455 vf_loss = 0.0216 grad_norm = 3.2858 nat_grad_norm = 0.0965 cg_residual = 2.5650 step_size = 0.3871 reward = -0.0000 fps = 5 mse_loss = 0.2774 
2022-05-01 19:20:57.958373 - gail/main.py:191 - [Discriminator] iter = 2275000 loss = -0.2388 grad_norm = 4.9861 grad_penalty = 0.0584 regularization = 0.0000 true_logits = -1.0245 fake_logits = -1.3217 true_prob = 0.2869 fake_prob = 0.2310 
2022-05-01 19:23:06.597559 - gail/main.py:132 - [Evaluate] iter = 2275000 episode={ returns = 3506.7134 lengths = 1000 } discounted_episode={ returns = 2174.3255 lengths = 1000 } 
2022-05-01 19:23:16.151978 - gail/main.py:164 - [TRPO] iter = 2276000 dist_mean = -0.0155 dist_std = 0.1456 vf_loss = 0.0269 grad_norm = 2.8835 nat_grad_norm = 0.0920 cg_residual = 1.9681 step_size = 0.4220 reward = 0.0000 fps = 7 mse_loss = 0.3089 
2022-05-01 19:23:25.528079 - gail/main.py:164 - [TRPO] iter = 2277000 dist_mean = 0.0270 dist_std = 0.1456 vf_loss = 0.0993 grad_norm = 2.7759 nat_grad_norm = 0.0833 cg_residual = 1.2114 step_size = 0.4740 reward = -0.0000 fps = 6 mse_loss = 0.3081 
2022-05-01 19:23:34.734105 - gail/main.py:164 - [TRPO] iter = 2278000 dist_mean = 0.0194 dist_std = 0.1457 vf_loss = 0.0266 grad_norm = 7.3858 nat_grad_norm = 0.0825 cg_residual = 7.7164 step_size = 0.4224 reward = 0.0000 fps = 6 mse_loss = 0.2867 
2022-05-01 19:23:44.064955 - gail/main.py:164 - [TRPO] iter = 2279000 dist_mean = 0.0084 dist_std = 0.1454 vf_loss = 0.0291 grad_norm = 5.4634 nat_grad_norm = 0.0798 cg_residual = 9.6026 step_size = 0.4014 reward = 0.0000 fps = 6 mse_loss = 0.2959 
2022-05-01 19:23:53.658065 - gail/main.py:164 - [TRPO] iter = 2280000 dist_mean = 0.0013 dist_std = 0.1454 vf_loss = 0.0220 grad_norm = 4.1810 nat_grad_norm = 0.0967 cg_residual = 6.7652 step_size = 0.4092 reward = 0.0000 fps = 5 mse_loss = 0.2869 
2022-05-01 19:23:53.894521 - gail/main.py:191 - [Discriminator] iter = 2280000 loss = -0.2637 grad_norm = 3.6533 grad_penalty = 0.0542 regularization = 0.0000 true_logits = -0.8882 fake_logits = -1.2061 true_prob = 0.3126 fake_prob = 0.2496 
2022-05-01 19:25:51.147113 - gail/main.py:132 - [Evaluate] iter = 2280000 episode={ returns = 3404.7863 lengths = 961 } discounted_episode={ returns = 1970.0588 lengths = 841 } 
2022-05-01 19:26:00.747524 - gail/main.py:164 - [TRPO] iter = 2281000 dist_mean = -0.0149 dist_std = 0.1454 vf_loss = 0.0275 grad_norm = 3.5980 nat_grad_norm = 0.0879 cg_residual = 3.2749 step_size = 0.4245 reward = -0.0000 fps = 7 mse_loss = 0.2787 
2022-05-01 19:26:10.414907 - gail/main.py:164 - [TRPO] iter = 2282000 dist_mean = -0.0096 dist_std = 0.1453 vf_loss = 0.1360 grad_norm = 4.0487 nat_grad_norm = 0.1054 cg_residual = 2.7169 step_size = 0.3625 reward = -0.0000 fps = 7 mse_loss = 0.2647 
2022-05-01 19:26:20.083799 - gail/main.py:164 - [TRPO] iter = 2283000 dist_mean = -0.0335 dist_std = 0.1448 vf_loss = 0.0257 grad_norm = 2.8150 nat_grad_norm = 0.1017 cg_residual = 2.0798 step_size = 0.3686 reward = 0.0000 fps = 6 mse_loss = 0.3237 
2022-05-01 19:26:29.944029 - gail/main.py:164 - [TRPO] iter = 2284000 dist_mean = 0.0109 dist_std = 0.1449 vf_loss = 0.0264 grad_norm = 4.5606 nat_grad_norm = 0.0936 cg_residual = 1.4906 step_size = 0.3800 reward = 0.0000 fps = 6 mse_loss = 0.3038 
2022-05-01 19:26:39.777740 - gail/main.py:164 - [TRPO] iter = 2285000 dist_mean = -0.0110 dist_std = 0.1450 vf_loss = 0.0291 grad_norm = 5.8462 nat_grad_norm = 0.0892 cg_residual = 8.7158 step_size = 0.3731 reward = 0.0000 fps = 6 mse_loss = 0.2820 
2022-05-01 19:26:39.989999 - gail/main.py:191 - [Discriminator] iter = 2285000 loss = -0.3539 grad_norm = 3.3369 grad_penalty = 0.0567 regularization = 0.0000 true_logits = -0.7064 fake_logits = -1.1170 true_prob = 0.3479 fake_prob = 0.2663 
2022-05-01 19:28:29.178778 - gail/main.py:132 - [Evaluate] iter = 2285000 episode={ returns = 2982.9858 lengths = 837 } discounted_episode={ returns = 1916.0253 lengths = 819 } 
2022-05-01 19:28:38.627397 - gail/main.py:164 - [TRPO] iter = 2286000 dist_mean = -0.0046 dist_std = 0.1450 vf_loss = 0.0263 grad_norm = 3.6719 nat_grad_norm = 0.0987 cg_residual = 2.4878 step_size = 0.4283 reward = 0.0000 fps = 8 mse_loss = 0.2968 
2022-05-01 19:28:48.073101 - gail/main.py:164 - [TRPO] iter = 2287000 dist_mean = 0.0102 dist_std = 0.1452 vf_loss = 0.0243 grad_norm = 4.1554 nat_grad_norm = 0.0793 cg_residual = 1.2155 step_size = 0.3997 reward = 0.0000 fps = 7 mse_loss = 0.2585 
2022-05-01 19:28:57.561001 - gail/main.py:164 - [TRPO] iter = 2288000 dist_mean = -0.0098 dist_std = 0.1453 vf_loss = 0.0157 grad_norm = 2.2028 nat_grad_norm = 0.1103 cg_residual = 3.0125 step_size = 0.4296 reward = -0.0000 fps = 7 mse_loss = 0.2664 
2022-05-01 19:29:07.149646 - gail/main.py:164 - [TRPO] iter = 2289000 dist_mean = 0.0367 dist_std = 0.1455 vf_loss = 0.0676 grad_norm = 4.2139 nat_grad_norm = 0.0780 cg_residual = 0.9865 step_size = 0.4922 reward = -0.0000 fps = 6 mse_loss = 0.2917 
2022-05-01 19:29:16.590360 - gail/main.py:164 - [TRPO] iter = 2290000 dist_mean = 0.0255 dist_std = 0.1452 vf_loss = 0.0230 grad_norm = 4.7158 nat_grad_norm = 0.0892 cg_residual = 17.5911 step_size = 0.4577 reward = -0.0000 fps = 6 mse_loss = 0.3084 
2022-05-01 19:29:16.838255 - gail/main.py:191 - [Discriminator] iter = 2290000 loss = -0.2502 grad_norm = 3.8105 grad_penalty = 0.0576 regularization = 0.0000 true_logits = -0.6553 fake_logits = -0.9631 true_prob = 0.3601 fake_prob = 0.2981 
2022-05-01 19:31:23.894296 - gail/main.py:132 - [Evaluate] iter = 2290000 episode={ returns = 3483.5853 lengths = 990 } discounted_episode={ returns = 2167.5459 lengths = 1000 } 
2022-05-01 19:31:33.155972 - gail/main.py:164 - [TRPO] iter = 2291000 dist_mean = 0.0421 dist_std = 0.1449 vf_loss = 0.0190 grad_norm = 6.0949 nat_grad_norm = 0.0936 cg_residual = 1.1364 step_size = 0.4373 reward = -0.0000 fps = 7 mse_loss = 0.2629 
2022-05-01 19:31:42.666620 - gail/main.py:164 - [TRPO] iter = 2292000 dist_mean = 0.0292 dist_std = 0.1449 vf_loss = 0.0153 grad_norm = 4.9745 nat_grad_norm = 0.0685 cg_residual = 1.1318 step_size = 0.4791 reward = -0.0000 fps = 6 mse_loss = 0.2860 
2022-05-01 19:31:51.762007 - gail/main.py:164 - [TRPO] iter = 2293000 dist_mean = 0.0116 dist_std = 0.1448 vf_loss = 0.0213 grad_norm = 4.1636 nat_grad_norm = 0.0899 cg_residual = 1.0040 step_size = 0.3984 reward = 0.0000 fps = 6 mse_loss = 0.2507 
2022-05-01 19:32:01.030397 - gail/main.py:164 - [TRPO] iter = 2294000 dist_mean = 0.0091 dist_std = 0.1449 vf_loss = 0.0351 grad_norm = 3.2096 nat_grad_norm = 0.1065 cg_residual = 1.5405 step_size = 0.3883 reward = 0.0000 fps = 6 mse_loss = 0.3220 
2022-05-01 19:32:10.608804 - gail/main.py:164 - [TRPO] iter = 2295000 dist_mean = 0.0165 dist_std = 0.1447 vf_loss = 0.0448 grad_norm = 3.9680 nat_grad_norm = 0.0927 cg_residual = 2.0880 step_size = 0.4356 reward = 0.0000 fps = 5 mse_loss = 0.2885 
2022-05-01 19:32:10.845696 - gail/main.py:191 - [Discriminator] iter = 2295000 loss = -0.3043 grad_norm = 4.0080 grad_penalty = 0.0546 regularization = 0.0000 true_logits = -0.6088 fake_logits = -0.9678 true_prob = 0.3682 fake_prob = 0.2926 
2022-05-01 19:34:19.912494 - gail/main.py:132 - [Evaluate] iter = 2295000 episode={ returns = 3538.0859 lengths = 1000 } discounted_episode={ returns = 2180.7972 lengths = 1000 } 
2022-05-01 19:34:29.143626 - gail/main.py:164 - [TRPO] iter = 2296000 dist_mean = 0.0044 dist_std = 0.1450 vf_loss = 0.0168 grad_norm = 2.7102 nat_grad_norm = 0.0936 cg_residual = 2.2776 step_size = 0.4392 reward = -0.0000 fps = 7 mse_loss = 0.2774 
2022-05-01 19:34:38.686513 - gail/main.py:164 - [TRPO] iter = 2297000 dist_mean = 0.0069 dist_std = 0.1452 vf_loss = 0.0294 grad_norm = 4.0594 nat_grad_norm = 0.0956 cg_residual = 3.7789 step_size = 0.4287 reward = 0.0000 fps = 6 mse_loss = 0.3114 
2022-05-01 19:34:48.298617 - gail/main.py:164 - [TRPO] iter = 2298000 dist_mean = 0.0287 dist_std = 0.1456 vf_loss = 0.0200 grad_norm = 2.6029 nat_grad_norm = 0.0986 cg_residual = 1.2375 step_size = 0.4250 reward = 0.0000 fps = 6 mse_loss = 0.2525 
2022-05-01 19:34:57.845952 - gail/main.py:164 - [TRPO] iter = 2299000 dist_mean = 0.0461 dist_std = 0.1459 vf_loss = 0.0192 grad_norm = 3.5719 nat_grad_norm = 0.0786 cg_residual = 1.4926 step_size = 0.4827 reward = 0.0000 fps = 5 mse_loss = 0.2989 
2022-05-01 19:35:07.376827 - gail/main.py:164 - [TRPO] iter = 2300000 dist_mean = 0.0430 dist_std = 0.1459 vf_loss = 0.0288 grad_norm = 4.4244 nat_grad_norm = 0.0793 cg_residual = 2.7194 step_size = 0.4900 reward = -0.0000 fps = 5 mse_loss = 0.2798 
2022-05-01 19:35:07.600333 - gail/main.py:191 - [Discriminator] iter = 2300000 loss = -0.3055 grad_norm = 3.5035 grad_penalty = 0.0555 regularization = 0.0000 true_logits = -0.5020 fake_logits = -0.8631 true_prob = 0.3896 fake_prob = 0.3142 
2022-05-01 19:37:16.878544 - gail/main.py:132 - [Evaluate] iter = 2300000 episode={ returns = 3534.5190 lengths = 1000 } discounted_episode={ returns = 2181.2423 lengths = 1000 } 
2022-05-01 19:37:25.826121 - gail/main.py:164 - [TRPO] iter = 2301000 dist_mean = 0.0239 dist_std = 0.1455 vf_loss = 0.0169 grad_norm = 4.4838 nat_grad_norm = 0.1055 cg_residual = 5.7014 step_size = 0.3746 reward = 0.0000 fps = 7 mse_loss = 0.2659 
2022-05-01 19:37:34.960850 - gail/main.py:164 - [TRPO] iter = 2302000 dist_mean = 0.0611 dist_std = 0.1455 vf_loss = 0.0162 grad_norm = 3.4856 nat_grad_norm = 0.0914 cg_residual = 1.7305 step_size = 0.4016 reward = -0.0000 fps = 6 mse_loss = 0.2746 
2022-05-01 19:37:44.383950 - gail/main.py:164 - [TRPO] iter = 2303000 dist_mean = 0.0490 dist_std = 0.1454 vf_loss = 0.0226 grad_norm = 3.6587 nat_grad_norm = 0.1067 cg_residual = 1.4760 step_size = 0.3652 reward = 0.0000 fps = 6 mse_loss = 0.3072 
2022-05-01 19:37:53.763772 - gail/main.py:164 - [TRPO] iter = 2304000 dist_mean = 0.0576 dist_std = 0.1455 vf_loss = 0.0386 grad_norm = 2.9289 nat_grad_norm = 0.0801 cg_residual = 1.1005 step_size = 0.4525 reward = 0.0000 fps = 6 mse_loss = 0.2677 
2022-05-01 19:38:03.146845 - gail/main.py:164 - [TRPO] iter = 2305000 dist_mean = 0.0816 dist_std = 0.1450 vf_loss = 0.0255 grad_norm = 3.4156 nat_grad_norm = 0.0563 cg_residual = 0.5013 step_size = 0.5133 reward = 0.0000 fps = 5 mse_loss = 0.2791 
2022-05-01 19:38:03.417892 - gail/main.py:191 - [Discriminator] iter = 2305000 loss = -0.3040 grad_norm = 3.6477 grad_penalty = 0.0605 regularization = 0.0000 true_logits = -0.4130 fake_logits = -0.7775 true_prob = 0.4083 fake_prob = 0.3315 
2022-05-01 19:40:10.376988 - gail/main.py:132 - [Evaluate] iter = 2305000 episode={ returns = 3545.6777 lengths = 1000 } discounted_episode={ returns = 2198.4797 lengths = 1000 } 
2022-05-01 19:40:19.877264 - gail/main.py:164 - [TRPO] iter = 2306000 dist_mean = 0.0792 dist_std = 0.1452 vf_loss = 0.0156 grad_norm = 4.1358 nat_grad_norm = 0.0898 cg_residual = 1.8031 step_size = 0.4220 reward = 0.0000 fps = 7 mse_loss = 0.2791 
2022-05-01 19:40:29.463912 - gail/main.py:164 - [TRPO] iter = 2307000 dist_mean = 0.0626 dist_std = 0.1452 vf_loss = 0.0259 grad_norm = 4.5029 nat_grad_norm = 0.0800 cg_residual = 2.4537 step_size = 0.4282 reward = -0.0000 fps = 6 mse_loss = 0.2447 
2022-05-01 19:40:38.894768 - gail/main.py:164 - [TRPO] iter = 2308000 dist_mean = 0.0892 dist_std = 0.1450 vf_loss = 0.0306 grad_norm = 3.8175 nat_grad_norm = 0.0664 cg_residual = 0.9281 step_size = 0.5168 reward = -0.0000 fps = 6 mse_loss = 0.2677 
2022-05-01 19:40:48.425159 - gail/main.py:164 - [TRPO] iter = 2309000 dist_mean = 0.0717 dist_std = 0.1451 vf_loss = 0.0310 grad_norm = 3.8118 nat_grad_norm = 0.0700 cg_residual = 0.9189 step_size = 0.4901 reward = -0.0000 fps = 6 mse_loss = 0.2596 
2022-05-01 19:40:57.852666 - gail/main.py:164 - [TRPO] iter = 2310000 dist_mean = 0.0737 dist_std = 0.1449 vf_loss = 0.0132 grad_norm = 3.8077 nat_grad_norm = 0.0808 cg_residual = 0.9024 step_size = 0.4476 reward = 0.0000 fps = 5 mse_loss = 0.2453 
2022-05-01 19:40:58.097923 - gail/main.py:191 - [Discriminator] iter = 2310000 loss = -0.2371 grad_norm = 4.8337 grad_penalty = 0.0625 regularization = 0.0000 true_logits = -0.3670 fake_logits = -0.6666 true_prob = 0.4184 fake_prob = 0.3555 
2022-05-01 19:43:04.230721 - gail/main.py:132 - [Evaluate] iter = 2310000 episode={ returns = 3569.1359 lengths = 1000 } discounted_episode={ returns = 2210.1576 lengths = 1000 } 
2022-05-01 19:43:13.916495 - gail/main.py:164 - [TRPO] iter = 2311000 dist_mean = 0.0491 dist_std = 0.1448 vf_loss = 0.0229 grad_norm = 4.3990 nat_grad_norm = 0.0751 cg_residual = 0.8013 step_size = 0.4487 reward = -0.0000 fps = 7 mse_loss = 0.2794 
2022-05-01 19:43:23.171041 - gail/main.py:164 - [TRPO] iter = 2312000 dist_mean = 0.0634 dist_std = 0.1447 vf_loss = 0.0183 grad_norm = 4.2793 nat_grad_norm = 0.1032 cg_residual = 1.6555 step_size = 0.3884 reward = 0.0000 fps = 6 mse_loss = 0.2681 
2022-05-01 19:43:32.716491 - gail/main.py:164 - [TRPO] iter = 2313000 dist_mean = 0.0620 dist_std = 0.1449 vf_loss = 0.0285 grad_norm = 3.3748 nat_grad_norm = 0.0828 cg_residual = 2.4550 step_size = 0.4920 reward = -0.0000 fps = 6 mse_loss = 0.2787 
2022-05-01 19:43:42.010818 - gail/main.py:164 - [TRPO] iter = 2314000 dist_mean = 0.0481 dist_std = 0.1451 vf_loss = 0.0359 grad_norm = 4.7134 nat_grad_norm = 0.0774 cg_residual = 1.7615 step_size = 0.4552 reward = -0.0000 fps = 6 mse_loss = 0.2694 
2022-05-01 19:43:51.692137 - gail/main.py:164 - [TRPO] iter = 2315000 dist_mean = 0.0640 dist_std = 0.1455 vf_loss = 0.0461 grad_norm = 3.8291 nat_grad_norm = 0.0596 cg_residual = 0.9398 step_size = 0.5621 reward = -0.0000 fps = 5 mse_loss = 0.2958 
2022-05-01 19:43:51.961480 - gail/main.py:191 - [Discriminator] iter = 2315000 loss = -0.2170 grad_norm = 5.2891 grad_penalty = 0.0653 regularization = 0.0000 true_logits = -0.4309 fake_logits = -0.7132 true_prob = 0.4037 fake_prob = 0.3453 
2022-05-01 19:45:55.145590 - gail/main.py:132 - [Evaluate] iter = 2315000 episode={ returns = 3526.4034 lengths = 1000 } discounted_episode={ returns = 2125.5246 lengths = 961 } 
2022-05-01 19:46:04.398725 - gail/main.py:164 - [TRPO] iter = 2316000 dist_mean = 0.0497 dist_std = 0.1455 vf_loss = 0.0103 grad_norm = 3.2309 nat_grad_norm = 0.0887 cg_residual = 0.9047 step_size = 0.4427 reward = 0.0000 fps = 7 mse_loss = 0.2681 
2022-05-01 19:46:13.418257 - gail/main.py:164 - [TRPO] iter = 2317000 dist_mean = 0.0607 dist_std = 0.1453 vf_loss = 0.0429 grad_norm = 4.1733 nat_grad_norm = 0.0857 cg_residual = 2.1980 step_size = 0.3896 reward = -0.0000 fps = 7 mse_loss = 0.2608 
2022-05-01 19:46:22.522844 - gail/main.py:164 - [TRPO] iter = 2318000 dist_mean = 0.0431 dist_std = 0.1452 vf_loss = 0.0242 grad_norm = 2.9393 nat_grad_norm = 0.0863 cg_residual = 1.8468 step_size = 0.4372 reward = 0.0000 fps = 6 mse_loss = 0.2517 
2022-05-01 19:46:31.936291 - gail/main.py:164 - [TRPO] iter = 2319000 dist_mean = 0.0212 dist_std = 0.1454 vf_loss = 0.0161 grad_norm = 3.8520 nat_grad_norm = 0.0693 cg_residual = 1.3767 step_size = 0.4835 reward = -0.0000 fps = 6 mse_loss = 0.2432 
2022-05-01 19:46:41.301862 - gail/main.py:164 - [TRPO] iter = 2320000 dist_mean = 0.0442 dist_std = 0.1456 vf_loss = 0.0171 grad_norm = 2.5306 nat_grad_norm = 0.0875 cg_residual = 1.1450 step_size = 0.4180 reward = -0.0000 fps = 5 mse_loss = 0.2972 
2022-05-01 19:46:41.536591 - gail/main.py:191 - [Discriminator] iter = 2320000 loss = -0.2175 grad_norm = 5.1403 grad_penalty = 0.0548 regularization = 0.0000 true_logits = -0.5855 fake_logits = -0.8578 true_prob = 0.3704 fake_prob = 0.3149 
2022-05-01 19:48:45.772428 - gail/main.py:132 - [Evaluate] iter = 2320000 episode={ returns = 3552.3820 lengths = 1000 } discounted_episode={ returns = 2203.8593 lengths = 1000 } 
2022-05-01 19:48:54.913698 - gail/main.py:164 - [TRPO] iter = 2321000 dist_mean = 0.0397 dist_std = 0.1456 vf_loss = 0.0204 grad_norm = 2.5394 nat_grad_norm = 0.0811 cg_residual = 1.6117 step_size = 0.4773 reward = -0.0000 fps = 7 mse_loss = 0.2788 
2022-05-01 19:49:04.275425 - gail/main.py:164 - [TRPO] iter = 2322000 dist_mean = 0.0026 dist_std = 0.1454 vf_loss = 0.0426 grad_norm = 4.4847 nat_grad_norm = 0.0889 cg_residual = 2.8311 step_size = 0.3981 reward = 0.0000 fps = 7 mse_loss = 0.2944 
2022-05-01 19:49:13.792527 - gail/main.py:164 - [TRPO] iter = 2323000 dist_mean = 0.0074 dist_std = 0.1454 vf_loss = 0.0324 grad_norm = 3.1206 nat_grad_norm = 0.1091 cg_residual = 2.5100 step_size = 0.4139 reward = 0.0000 fps = 6 mse_loss = 0.2778 
2022-05-01 19:49:23.154941 - gail/main.py:164 - [TRPO] iter = 2324000 dist_mean = 0.0337 dist_std = 0.1456 vf_loss = 0.0189 grad_norm = 5.5905 nat_grad_norm = 0.0915 cg_residual = 2.4345 step_size = 0.3644 reward = 0.0000 fps = 6 mse_loss = 0.2527 
2022-05-01 19:49:32.295566 - gail/main.py:164 - [TRPO] iter = 2325000 dist_mean = 0.0239 dist_std = 0.1455 vf_loss = 0.0267 grad_norm = 8.6159 nat_grad_norm = 0.1038 cg_residual = 2.7549 step_size = 0.2925 reward = -0.0000 fps = 5 mse_loss = 0.2461 
2022-05-01 19:49:32.514384 - gail/main.py:191 - [Discriminator] iter = 2325000 loss = -0.2621 grad_norm = 3.8816 grad_penalty = 0.0480 regularization = 0.0000 true_logits = -0.6753 fake_logits = -0.9854 true_prob = 0.3488 fake_prob = 0.2868 
2022-05-01 19:51:37.804168 - gail/main.py:132 - [Evaluate] iter = 2325000 episode={ returns = 3522.2482 lengths = 1000 } discounted_episode={ returns = 2189.8166 lengths = 1000 } 
2022-05-01 19:51:47.302042 - gail/main.py:164 - [TRPO] iter = 2326000 dist_mean = 0.0190 dist_std = 0.1454 vf_loss = 0.0180 grad_norm = 3.9207 nat_grad_norm = 0.0945 cg_residual = 5.8530 step_size = 0.4232 reward = 0.0000 fps = 7 mse_loss = 0.2638 
2022-05-01 19:51:56.678906 - gail/main.py:164 - [TRPO] iter = 2327000 dist_mean = 0.0125 dist_std = 0.1453 vf_loss = 0.0249 grad_norm = 5.7177 nat_grad_norm = 0.0711 cg_residual = 1.7610 step_size = 0.4075 reward = 0.0000 fps = 6 mse_loss = 0.2803 
2022-05-01 19:52:06.104656 - gail/main.py:164 - [TRPO] iter = 2328000 dist_mean = 0.0303 dist_std = 0.1454 vf_loss = 0.0219 grad_norm = 4.5307 nat_grad_norm = 0.0918 cg_residual = 11.5047 step_size = 0.4024 reward = 0.0000 fps = 6 mse_loss = 0.2304 
2022-05-01 19:52:15.441958 - gail/main.py:164 - [TRPO] iter = 2329000 dist_mean = 0.0065 dist_std = 0.1454 vf_loss = 0.0347 grad_norm = 2.8650 nat_grad_norm = 0.0820 cg_residual = 1.5552 step_size = 0.4564 reward = 0.0000 fps = 6 mse_loss = 0.2511 
2022-05-01 19:52:24.370263 - gail/main.py:164 - [TRPO] iter = 2330000 dist_mean = -0.0136 dist_std = 0.1455 vf_loss = 0.0329 grad_norm = 5.7665 nat_grad_norm = 0.0879 cg_residual = 11.1165 step_size = 0.3759 reward = -0.0000 fps = 5 mse_loss = 0.2563 
2022-05-01 19:52:24.652773 - gail/main.py:191 - [Discriminator] iter = 2330000 loss = -0.2189 grad_norm = 4.6482 grad_penalty = 0.0524 regularization = 0.0000 true_logits = -0.7298 fake_logits = -1.0012 true_prob = 0.3391 fake_prob = 0.2828 
2022-05-01 19:54:20.576837 - gail/main.py:132 - [Evaluate] iter = 2330000 episode={ returns = 3458.3575 lengths = 970 } discounted_episode={ returns = 2082.8040 lengths = 922 } 
2022-05-01 19:54:29.668086 - gail/main.py:164 - [TRPO] iter = 2331000 dist_mean = 0.0161 dist_std = 0.1456 vf_loss = 0.0204 grad_norm = 6.5480 nat_grad_norm = 0.0733 cg_residual = 3.7077 step_size = 0.4158 reward = -0.0000 fps = 8 mse_loss = 0.2361 
2022-05-01 19:54:38.843936 - gail/main.py:164 - [TRPO] iter = 2332000 dist_mean = -0.0151 dist_std = 0.1459 vf_loss = 0.0171 grad_norm = 3.2274 nat_grad_norm = 0.0996 cg_residual = 2.1449 step_size = 0.3988 reward = -0.0000 fps = 7 mse_loss = 0.2553 
2022-05-01 19:54:48.078336 - gail/main.py:164 - [TRPO] iter = 2333000 dist_mean = -0.0031 dist_std = 0.1457 vf_loss = 0.0121 grad_norm = 4.5578 nat_grad_norm = 0.1207 cg_residual = 4.0718 step_size = 0.3042 reward = -0.0000 fps = 6 mse_loss = 0.2395 
2022-05-01 19:54:57.258121 - gail/main.py:164 - [TRPO] iter = 2334000 dist_mean = -0.0041 dist_std = 0.1458 vf_loss = 0.0160 grad_norm = 3.5956 nat_grad_norm = 0.0959 cg_residual = 2.6112 step_size = 0.3787 reward = -0.0000 fps = 6 mse_loss = 0.2459 
2022-05-01 19:55:06.564517 - gail/main.py:164 - [TRPO] iter = 2335000 dist_mean = 0.0225 dist_std = 0.1462 vf_loss = 0.0155 grad_norm = 3.6628 nat_grad_norm = 0.0715 cg_residual = 12.6547 step_size = 0.4730 reward = 0.0000 fps = 6 mse_loss = 0.2601 
2022-05-01 19:55:06.780346 - gail/main.py:191 - [Discriminator] iter = 2335000 loss = -0.2965 grad_norm = 3.5070 grad_penalty = 0.0490 regularization = 0.0000 true_logits = -0.6127 fake_logits = -0.9583 true_prob = 0.3639 fake_prob = 0.2939 
2022-05-01 19:56:28.449111 - gail/main.py:132 - [Evaluate] iter = 2335000 episode={ returns = 2112.8352 lengths = 596 } discounted_episode={ returns = 1757.1602 lengths = 727 } 
2022-05-01 19:56:37.811243 - gail/main.py:164 - [TRPO] iter = 2336000 dist_mean = 0.0039 dist_std = 0.1461 vf_loss = 0.0120 grad_norm = 3.7773 nat_grad_norm = 0.0902 cg_residual = 1.2238 step_size = 0.4467 reward = 0.0000 fps = 10 mse_loss = 0.2452 
2022-05-01 19:56:47.526334 - gail/main.py:164 - [TRPO] iter = 2337000 dist_mean = 0.0140 dist_std = 0.1463 vf_loss = 0.0141 grad_norm = 4.7653 nat_grad_norm = 0.0864 cg_residual = 6.3727 step_size = 0.4552 reward = 0.0000 fps = 9 mse_loss = 0.2067 
2022-05-01 19:56:57.387909 - gail/main.py:164 - [TRPO] iter = 2338000 dist_mean = 0.0114 dist_std = 0.1466 vf_loss = 0.0101 grad_norm = 2.5492 nat_grad_norm = 0.1008 cg_residual = 2.0644 step_size = 0.4037 reward = -0.0000 fps = 9 mse_loss = 0.2528 
2022-05-01 19:57:06.937176 - gail/main.py:164 - [TRPO] iter = 2339000 dist_mean = -0.0119 dist_std = 0.1462 vf_loss = 0.0160 grad_norm = 4.3702 nat_grad_norm = 0.0833 cg_residual = 1.8428 step_size = 0.3921 reward = 0.0000 fps = 8 mse_loss = 0.2168 
2022-05-01 19:57:16.320001 - gail/main.py:164 - [TRPO] iter = 2340000 dist_mean = -0.0123 dist_std = 0.1463 vf_loss = 0.0192 grad_norm = 3.7836 nat_grad_norm = 0.0894 cg_residual = 3.6136 step_size = 0.4457 reward = -0.0000 fps = 7 mse_loss = 0.2358 
2022-05-01 19:57:16.529798 - gail/main.py:191 - [Discriminator] iter = 2340000 loss = -0.2902 grad_norm = 3.6249 grad_penalty = 0.0545 regularization = 0.0000 true_logits = -0.6270 fake_logits = -0.9717 true_prob = 0.3644 fake_prob = 0.2953 
2022-05-01 19:59:08.284595 - gail/main.py:132 - [Evaluate] iter = 2340000 episode={ returns = 3299.8693 lengths = 926 } discounted_episode={ returns = 2040.5719 lengths = 888 } 
2022-05-01 19:59:17.841649 - gail/main.py:164 - [TRPO] iter = 2341000 dist_mean = -0.0025 dist_std = 0.1460 vf_loss = 0.0119 grad_norm = 3.2726 nat_grad_norm = 0.0941 cg_residual = 1.0929 step_size = 0.4201 reward = -0.0000 fps = 8 mse_loss = 0.2665 
2022-05-01 19:59:27.410884 - gail/main.py:164 - [TRPO] iter = 2342000 dist_mean = 0.0057 dist_std = 0.1458 vf_loss = 0.0218 grad_norm = 3.2748 nat_grad_norm = 0.0850 cg_residual = 2.6900 step_size = 0.4543 reward = 0.0000 fps = 7 mse_loss = 0.2259 
2022-05-01 19:59:37.117680 - gail/main.py:164 - [TRPO] iter = 2343000 dist_mean = 0.0106 dist_std = 0.1456 vf_loss = 0.0363 grad_norm = 3.9796 nat_grad_norm = 0.1035 cg_residual = 9.6247 step_size = 0.4091 reward = 0.0000 fps = 7 mse_loss = 0.2720 
2022-05-01 19:59:46.775186 - gail/main.py:164 - [TRPO] iter = 2344000 dist_mean = 0.0027 dist_std = 0.1455 vf_loss = 0.0163 grad_norm = 4.3412 nat_grad_norm = 0.0729 cg_residual = 6.8709 step_size = 0.4341 reward = -0.0000 fps = 6 mse_loss = 0.2452 
2022-05-01 19:59:55.919140 - gail/main.py:164 - [TRPO] iter = 2345000 dist_mean = -0.0238 dist_std = 0.1454 vf_loss = 0.0166 grad_norm = 4.6936 nat_grad_norm = 0.0819 cg_residual = 5.2885 step_size = 0.4277 reward = -0.0000 fps = 6 mse_loss = 0.2455 
2022-05-01 19:59:56.137893 - gail/main.py:191 - [Discriminator] iter = 2345000 loss = -0.4228 grad_norm = 3.8334 grad_penalty = 0.0720 regularization = 0.0000 true_logits = -0.5184 fake_logits = -1.0132 true_prob = 0.3879 fake_prob = 0.2885 
2022-05-01 20:01:59.344857 - gail/main.py:132 - [Evaluate] iter = 2345000 episode={ returns = 3571.1941 lengths = 1000 } discounted_episode={ returns = 2174.5442 lengths = 976 } 
2022-05-01 20:02:08.935020 - gail/main.py:164 - [TRPO] iter = 2346000 dist_mean = 0.0126 dist_std = 0.1450 vf_loss = 0.0257 grad_norm = 5.0135 nat_grad_norm = 0.0818 cg_residual = 1.2753 step_size = 0.3731 reward = 0.0000 fps = 7 mse_loss = 0.2287 
2022-05-01 20:02:18.732285 - gail/main.py:164 - [TRPO] iter = 2347000 dist_mean = 0.0119 dist_std = 0.1450 vf_loss = 0.0263 grad_norm = 3.8640 nat_grad_norm = 0.0942 cg_residual = 2.3225 step_size = 0.4113 reward = 0.0000 fps = 7 mse_loss = 0.2572 
2022-05-01 20:02:28.262597 - gail/main.py:164 - [TRPO] iter = 2348000 dist_mean = -0.0042 dist_std = 0.1452 vf_loss = 0.0274 grad_norm = 4.4013 nat_grad_norm = 0.0883 cg_residual = 1.9898 step_size = 0.4350 reward = 0.0000 fps = 6 mse_loss = 0.2166 
2022-05-01 20:02:37.928705 - gail/main.py:164 - [TRPO] iter = 2349000 dist_mean = 0.0181 dist_std = 0.1453 vf_loss = 0.0216 grad_norm = 5.0073 nat_grad_norm = 0.0812 cg_residual = 1.5859 step_size = 0.3835 reward = -0.0000 fps = 6 mse_loss = 0.2398 
2022-05-01 20:02:47.613186 - gail/main.py:164 - [TRPO] iter = 2350000 dist_mean = -0.0133 dist_std = 0.1453 vf_loss = 0.0161 grad_norm = 3.4696 nat_grad_norm = 0.0764 cg_residual = 5.9247 step_size = 0.4096 reward = 0.0000 fps = 5 mse_loss = 0.2312 
2022-05-01 20:02:47.846861 - gail/main.py:191 - [Discriminator] iter = 2350000 loss = -0.2695 grad_norm = 4.4302 grad_penalty = 0.0690 regularization = 0.0000 true_logits = -0.5237 fake_logits = -0.8623 true_prob = 0.3867 fake_prob = 0.3180 
2022-05-01 20:04:55.497970 - gail/main.py:132 - [Evaluate] iter = 2350000 episode={ returns = 3593.0099 lengths = 1000 } discounted_episode={ returns = 2221.0570 lengths = 1000 } 
2022-05-01 20:05:05.115834 - gail/main.py:164 - [TRPO] iter = 2351000 dist_mean = 0.0005 dist_std = 0.1451 vf_loss = 0.0223 grad_norm = 4.2281 nat_grad_norm = 0.1016 cg_residual = 2.4697 step_size = 0.3539 reward = -0.0000 fps = 7 mse_loss = 0.2353 
2022-05-01 20:05:14.828925 - gail/main.py:164 - [TRPO] iter = 2352000 dist_mean = 0.0311 dist_std = 0.1452 vf_loss = 0.0143 grad_norm = 3.9513 nat_grad_norm = 0.0734 cg_residual = 2.5600 step_size = 0.4545 reward = -0.0000 fps = 6 mse_loss = 0.2479 
2022-05-01 20:05:24.396746 - gail/main.py:164 - [TRPO] iter = 2353000 dist_mean = 0.0249 dist_std = 0.1453 vf_loss = 0.0649 grad_norm = 4.4760 nat_grad_norm = 0.1505 cg_residual = 7.0929 step_size = 0.2712 reward = 0.0000 fps = 6 mse_loss = 0.2450 
2022-05-01 20:05:34.282446 - gail/main.py:164 - [TRPO] iter = 2354000 dist_mean = 0.0174 dist_std = 0.1454 vf_loss = 0.0661 grad_norm = 3.6162 nat_grad_norm = 0.0755 cg_residual = 3.6114 step_size = 0.4437 reward = -0.0000 fps = 6 mse_loss = 0.2631 
2022-05-01 20:05:44.016978 - gail/main.py:164 - [TRPO] iter = 2355000 dist_mean = 0.0294 dist_std = 0.1455 vf_loss = 0.0779 grad_norm = 4.9682 nat_grad_norm = 0.0701 cg_residual = 1.4504 step_size = 0.3805 reward = 0.0000 fps = 5 mse_loss = 0.2133 
2022-05-01 20:05:44.227954 - gail/main.py:191 - [Discriminator] iter = 2355000 loss = -0.3407 grad_norm = 6.1473 grad_penalty = 0.0597 regularization = 0.0000 true_logits = -0.5691 fake_logits = -0.9695 true_prob = 0.3781 fake_prob = 0.3119 
2022-05-01 20:05:46.037268 - gail/main.py:132 - [Evaluate] iter = 2355000 episode={ returns = 10.8419 lengths = 12 } discounted_episode={ returns = 10.7991 lengths = 12 } 
2022-05-01 20:05:55.724648 - gail/main.py:164 - [TRPO] iter = 2356000 dist_mean = 0.0265 dist_std = 0.1455 vf_loss = 0.0126 grad_norm = 3.3123 nat_grad_norm = 0.1069 cg_residual = 13.7139 step_size = 0.3533 reward = -0.0000 fps = 87 mse_loss = 0.2557 
2022-05-01 20:06:05.602257 - gail/main.py:164 - [TRPO] iter = 2357000 dist_mean = 0.1715 dist_std = 0.1456 vf_loss = 0.1586 grad_norm = 7.4429 nat_grad_norm = 0.0719 cg_residual = 1.1094 step_size = 0.3639 reward = -0.0000 fps = 46 mse_loss = 0.2540 
2022-05-01 20:06:15.588564 - gail/main.py:164 - [TRPO] iter = 2358000 dist_mean = 0.2140 dist_std = 0.1456 vf_loss = 0.1691 grad_norm = 9.9739 nat_grad_norm = 0.0417 cg_residual = 0.7497 step_size = 0.6014 reward = 0.0000 fps = 31 mse_loss = 0.2550 
2022-05-01 20:06:25.340510 - gail/main.py:164 - [TRPO] iter = 2359000 dist_mean = 0.2092 dist_std = 0.1459 vf_loss = 0.1712 grad_norm = 9.7685 nat_grad_norm = 0.0243 cg_residual = 0.2079 step_size = 0.5330 reward = -0.0000 fps = 24 mse_loss = 0.2568 
2022-05-01 20:06:35.444329 - gail/main.py:164 - [TRPO] iter = 2360000 dist_mean = 0.2110 dist_std = 0.1458 vf_loss = 0.0648 grad_norm = 10.8626 nat_grad_norm = 0.0267 cg_residual = 1.0318 step_size = 0.4831 reward = 0.0000 fps = 19 mse_loss = 0.2490 
2022-05-01 20:06:35.709726 - gail/main.py:191 - [Discriminator] iter = 2360000 loss = -5.1819 grad_norm = 23.6889 grad_penalty = 0.7924 regularization = 0.0000 true_logits = -0.8288 fake_logits = -6.8031 true_prob = 0.3456 fake_prob = 0.0079 
2022-05-01 20:06:37.079493 - gail/main.py:132 - [Evaluate] iter = 2360000 episode={ returns = 7.9810 lengths = 10 } discounted_episode={ returns = 7.9523 lengths = 10 } 
2022-05-01 20:06:46.981597 - gail/main.py:164 - [TRPO] iter = 2361000 dist_mean = 0.2060 dist_std = 0.1459 vf_loss = 0.0154 grad_norm = 5.3420 nat_grad_norm = 0.0495 cg_residual = 2.3809 step_size = 0.8025 reward = 0.0000 fps = 88 mse_loss = 0.2487 
2022-05-01 20:06:57.075952 - gail/main.py:164 - [TRPO] iter = 2362000 dist_mean = 0.2008 dist_std = 0.1459 vf_loss = 0.0131 grad_norm = 9.5701 nat_grad_norm = 0.0354 cg_residual = 0.3620 step_size = 0.5592 reward = 0.0000 fps = 46 mse_loss = 0.2319 
2022-05-01 20:07:07.181450 - gail/main.py:164 - [TRPO] iter = 2363000 dist_mean = 0.1993 dist_std = 0.1464 vf_loss = 0.0153 grad_norm = 11.8070 nat_grad_norm = 0.0512 cg_residual = 0.5262 step_size = 0.4325 reward = -0.0000 fps = 31 mse_loss = 0.2498 
2022-05-01 20:07:17.104076 - gail/main.py:164 - [TRPO] iter = 2364000 dist_mean = 0.1976 dist_std = 0.1466 vf_loss = 0.0143 grad_norm = 12.1141 nat_grad_norm = 0.0374 cg_residual = 0.3320 step_size = 0.4703 reward = 0.0000 fps = 24 mse_loss = 0.2502 
2022-05-01 20:07:26.671508 - gail/main.py:164 - [TRPO] iter = 2365000 dist_mean = 0.1985 dist_std = 0.1469 vf_loss = 0.0129 grad_norm = 10.0682 nat_grad_norm = 0.0480 cg_residual = 0.1189 step_size = 0.5314 reward = 0.0000 fps = 19 mse_loss = 0.2389 
2022-05-01 20:07:26.884209 - gail/main.py:191 - [Discriminator] iter = 2365000 loss = -7.9587 grad_norm = 16.5774 grad_penalty = 1.0152 regularization = 0.0000 true_logits = -0.2638 fake_logits = -9.2377 true_prob = 0.4476 fake_prob = 0.0056 
2022-05-01 20:07:28.321410 - gail/main.py:132 - [Evaluate] iter = 2365000 episode={ returns = 9.5553 lengths = 11 } discounted_episode={ returns = 9.4714 lengths = 11 } 
2022-05-01 20:07:38.298535 - gail/main.py:164 - [TRPO] iter = 2366000 dist_mean = 0.1907 dist_std = 0.1471 vf_loss = 0.0177 grad_norm = 9.5825 nat_grad_norm = 0.0339 cg_residual = 0.9412 step_size = 0.5023 reward = -0.0000 fps = 87 mse_loss = 0.2654 
2022-05-01 20:07:48.414057 - gail/main.py:164 - [TRPO] iter = 2367000 dist_mean = 0.1810 dist_std = 0.1470 vf_loss = 0.0179 grad_norm = 13.5927 nat_grad_norm = 0.0313 cg_residual = 1.8970 step_size = 0.4574 reward = 0.0000 fps = 46 mse_loss = 0.2289 
2022-05-01 20:07:58.465116 - gail/main.py:164 - [TRPO] iter = 2368000 dist_mean = 0.1777 dist_std = 0.1471 vf_loss = 0.0185 grad_norm = 16.8878 nat_grad_norm = 0.0361 cg_residual = 2.6862 step_size = 0.3779 reward = 0.0000 fps = 31 mse_loss = 0.2601 
2022-05-01 20:08:08.530861 - gail/main.py:164 - [TRPO] iter = 2369000 dist_mean = 0.1775 dist_std = 0.1471 vf_loss = 0.0243 grad_norm = 13.2651 nat_grad_norm = 0.0483 cg_residual = 4.8520 step_size = 0.3702 reward = 0.0000 fps = 24 mse_loss = 0.2619 
2022-05-01 20:08:18.667407 - gail/main.py:164 - [TRPO] iter = 2370000 dist_mean = 0.1724 dist_std = 0.1472 vf_loss = 0.0594 grad_norm = 9.0705 nat_grad_norm = 0.0982 cg_residual = 11.8009 step_size = 0.3185 reward = 0.0000 fps = 19 mse_loss = 0.2531 
2022-05-01 20:08:18.896585 - gail/main.py:191 - [Discriminator] iter = 2370000 loss = -8.6163 grad_norm = 11.5696 grad_penalty = 1.4541 regularization = 0.0000 true_logits = -0.3109 fake_logits = -10.3813 true_prob = 0.4567 fake_prob = 0.0034 
2022-05-01 20:08:20.450263 - gail/main.py:132 - [Evaluate] iter = 2370000 episode={ returns = 10.4932 lengths = 11 } discounted_episode={ returns = 10.4263 lengths = 11 } 
2022-05-01 20:08:30.478135 - gail/main.py:164 - [TRPO] iter = 2371000 dist_mean = 0.1642 dist_std = 0.1475 vf_loss = 0.0292 grad_norm = 10.6578 nat_grad_norm = 0.0367 cg_residual = 1.4270 step_size = 0.4422 reward = -0.0000 fps = 86 mse_loss = 0.2597 
2022-05-01 20:08:40.477789 - gail/main.py:164 - [TRPO] iter = 2372000 dist_mean = 0.1708 dist_std = 0.1478 vf_loss = 0.0231 grad_norm = 10.3025 nat_grad_norm = 0.0666 cg_residual = 1.1316 step_size = 0.4668 reward = 0.0000 fps = 46 mse_loss = 0.2714 
2022-05-01 20:08:49.976376 - gail/main.py:164 - [TRPO] iter = 2373000 dist_mean = 0.0672 dist_std = 0.1481 vf_loss = 0.0412 grad_norm = 3.2994 nat_grad_norm = 0.1013 cg_residual = 2.1982 step_size = 0.3575 reward = 0.0000 fps = 32 mse_loss = 0.2618 
2022-05-01 20:08:59.900174 - gail/main.py:164 - [TRPO] iter = 2374000 dist_mean = 0.1438 dist_std = 0.1486 vf_loss = 0.0752 grad_norm = 5.1616 nat_grad_norm = 0.1467 cg_residual = 35.6217 step_size = 0.3304 reward = -0.0000 fps = 24 mse_loss = 0.2566 
2022-05-01 20:09:09.673565 - gail/main.py:164 - [TRPO] iter = 2375000 dist_mean = 0.1574 dist_std = 0.1483 vf_loss = 0.0442 grad_norm = 5.3073 nat_grad_norm = 0.0407 cg_residual = 0.6087 step_size = 0.6770 reward = -0.0000 fps = 19 mse_loss = 0.2916 
2022-05-01 20:09:09.881269 - gail/main.py:191 - [Discriminator] iter = 2375000 loss = -9.1126 grad_norm = 8.7835 grad_penalty = 1.4886 regularization = 0.0000 true_logits = -0.1124 fake_logits = -10.7136 true_prob = 0.4719 fake_prob = 0.0027 
2022-05-01 20:09:11.441762 - gail/main.py:132 - [Evaluate] iter = 2375000 episode={ returns = 11.4362 lengths = 11 } discounted_episode={ returns = 11.2371 lengths = 11 } 
2022-05-01 20:09:21.098052 - gail/main.py:164 - [TRPO] iter = 2376000 dist_mean = 0.1136 dist_std = 0.1483 vf_loss = 0.2765 grad_norm = 4.6813 nat_grad_norm = 0.0589 cg_residual = 1.5373 step_size = 0.4856 reward = -0.0000 fps = 89 mse_loss = 0.2599 
2022-05-01 20:09:30.384397 - gail/main.py:164 - [TRPO] iter = 2377000 dist_mean = 0.0882 dist_std = 0.1484 vf_loss = 0.3619 grad_norm = 2.6392 nat_grad_norm = 0.0869 cg_residual = 1.0706 step_size = 0.4628 reward = 0.0000 fps = 48 mse_loss = 0.2412 
2022-05-01 20:09:40.346635 - gail/main.py:164 - [TRPO] iter = 2378000 dist_mean = 0.1196 dist_std = 0.1487 vf_loss = 2.0967 grad_norm = 5.3791 nat_grad_norm = 0.0904 cg_residual = 1.1341 step_size = 0.3526 reward = -0.0000 fps = 32 mse_loss = 0.2911 
2022-05-01 20:09:50.175672 - gail/main.py:164 - [TRPO] iter = 2379000 dist_mean = 0.0104 dist_std = 0.1485 vf_loss = 0.2837 grad_norm = 3.3792 nat_grad_norm = 0.0866 cg_residual = 2.6269 step_size = 0.4223 reward = -0.0000 fps = 24 mse_loss = 0.2658 
2022-05-01 20:09:59.484695 - gail/main.py:164 - [TRPO] iter = 2380000 dist_mean = 0.0691 dist_std = 0.1487 vf_loss = 0.1017 grad_norm = 3.8420 nat_grad_norm = 0.0937 cg_residual = 2.9377 step_size = 0.3732 reward = 0.0000 fps = 20 mse_loss = 0.2572 
2022-05-01 20:09:59.706481 - gail/main.py:191 - [Discriminator] iter = 2380000 loss = 0.4373 grad_norm = 7.1858 grad_penalty = 0.4310 regularization = 0.0000 true_logits = -0.1920 fake_logits = -0.1857 true_prob = 0.4683 fake_prob = 0.4605 
2022-05-01 20:10:16.926225 - gail/main.py:132 - [Evaluate] iter = 2380000 episode={ returns = 50.2222 lengths = 29 } discounted_episode={ returns = 484.8060 lengths = 241 } 
2022-05-01 20:10:26.597271 - gail/main.py:164 - [TRPO] iter = 2381000 dist_mean = 0.1157 dist_std = 0.1487 vf_loss = 0.7452 grad_norm = 3.9233 nat_grad_norm = 0.0723 cg_residual = 12.4807 step_size = 0.4508 reward = 0.0000 fps = 37 mse_loss = 0.2692 
2022-05-01 20:10:36.288518 - gail/main.py:164 - [TRPO] iter = 2382000 dist_mean = 0.0700 dist_std = 0.1488 vf_loss = 0.0799 grad_norm = 3.7839 nat_grad_norm = 0.1145 cg_residual = 9.2413 step_size = 0.3351 reward = -0.0000 fps = 27 mse_loss = 0.2653 
2022-05-01 20:10:45.751808 - gail/main.py:164 - [TRPO] iter = 2383000 dist_mean = 0.0737 dist_std = 0.1488 vf_loss = 0.1278 grad_norm = 4.1585 nat_grad_norm = 0.1037 cg_residual = 4.6045 step_size = 0.3462 reward = 0.0000 fps = 21 mse_loss = 0.2735 
2022-05-01 20:10:55.327101 - gail/main.py:164 - [TRPO] iter = 2384000 dist_mean = 0.0740 dist_std = 0.1487 vf_loss = 0.0684 grad_norm = 3.5603 nat_grad_norm = 0.0983 cg_residual = 2.6725 step_size = 0.3753 reward = -0.0000 fps = 17 mse_loss = 0.2648 
2022-05-01 20:11:04.987735 - gail/main.py:164 - [TRPO] iter = 2385000 dist_mean = 0.0753 dist_std = 0.1487 vf_loss = 0.2979 grad_norm = 3.5378 nat_grad_norm = 0.1057 cg_residual = 3.1314 step_size = 0.3588 reward = -0.0000 fps = 15 mse_loss = 0.2862 
2022-05-01 20:11:05.235846 - gail/main.py:191 - [Discriminator] iter = 2385000 loss = -0.2897 grad_norm = 6.0885 grad_penalty = 0.0916 regularization = 0.0000 true_logits = -0.6128 fake_logits = -0.9941 true_prob = 0.4322 fake_prob = 0.4086 
2022-05-01 20:12:21.535328 - gail/main.py:132 - [Evaluate] iter = 2385000 episode={ returns = 2225.8302 lengths = 689 } discounted_episode={ returns = 971.4947 lengths = 498 } 
2022-05-01 20:12:31.302447 - gail/main.py:164 - [TRPO] iter = 2386000 dist_mean = 0.0781 dist_std = 0.1487 vf_loss = 0.0583 grad_norm = 4.8982 nat_grad_norm = 0.1185 cg_residual = 3.7354 step_size = 0.3210 reward = 0.0000 fps = 11 mse_loss = 0.2554 
2022-05-01 20:12:40.790012 - gail/main.py:164 - [TRPO] iter = 2387000 dist_mean = 0.0538 dist_std = 0.1486 vf_loss = 0.0865 grad_norm = 3.1672 nat_grad_norm = 0.0856 cg_residual = 2.5341 step_size = 0.4399 reward = 0.0000 fps = 10 mse_loss = 0.2589 
2022-05-01 20:12:50.313548 - gail/main.py:164 - [TRPO] iter = 2388000 dist_mean = 0.0794 dist_std = 0.1485 vf_loss = 0.0328 grad_norm = 3.6976 nat_grad_norm = 0.1099 cg_residual = 1.8191 step_size = 0.3509 reward = 0.0000 fps = 9 mse_loss = 0.2651 
2022-05-01 20:13:00.326404 - gail/main.py:164 - [TRPO] iter = 2389000 dist_mean = 0.0762 dist_std = 0.1484 vf_loss = 0.0474 grad_norm = 4.2795 nat_grad_norm = 0.1066 cg_residual = 12.2357 step_size = 0.3577 reward = -0.0000 fps = 8 mse_loss = 0.3133 
2022-05-01 20:13:09.639283 - gail/main.py:164 - [TRPO] iter = 2390000 dist_mean = 0.0750 dist_std = 0.1484 vf_loss = 0.0700 grad_norm = 5.4393 nat_grad_norm = 0.1414 cg_residual = 3.3399 step_size = 0.2465 reward = -0.0000 fps = 8 mse_loss = 0.2815 
2022-05-01 20:13:09.848787 - gail/main.py:191 - [Discriminator] iter = 2390000 loss = -0.1106 grad_norm = 3.5327 grad_penalty = 0.0920 regularization = 0.0000 true_logits = -1.2950 fake_logits = -1.4976 true_prob = 0.3659 fake_prob = 0.3616 
2022-05-01 20:13:19.646090 - gail/main.py:132 - [Evaluate] iter = 2390000 episode={ returns = 110.9628 lengths = 57 } discounted_episode={ returns = 162.9683 lengths = 86 } 
2022-05-01 20:13:29.377519 - gail/main.py:164 - [TRPO] iter = 2391000 dist_mean = 0.0812 dist_std = 0.1483 vf_loss = 0.0536 grad_norm = 4.5666 nat_grad_norm = 0.1286 cg_residual = 16.3705 step_size = 0.3270 reward = -0.0000 fps = 51 mse_loss = 0.2909 
2022-05-01 20:13:38.859893 - gail/main.py:164 - [TRPO] iter = 2392000 dist_mean = 0.0625 dist_std = 0.1480 vf_loss = 0.1602 grad_norm = 5.2418 nat_grad_norm = 0.0973 cg_residual = 8.6599 step_size = 0.3674 reward = 0.0000 fps = 34 mse_loss = 0.2935 
2022-05-01 20:13:48.373864 - gail/main.py:164 - [TRPO] iter = 2393000 dist_mean = 0.0781 dist_std = 0.1477 vf_loss = 0.0492 grad_norm = 3.5433 nat_grad_norm = 0.0745 cg_residual = 2.3955 step_size = 0.4406 reward = -0.0000 fps = 25 mse_loss = 0.2707 
2022-05-01 20:13:58.168808 - gail/main.py:164 - [TRPO] iter = 2394000 dist_mean = 0.0863 dist_std = 0.1478 vf_loss = 0.0472 grad_norm = 3.9303 nat_grad_norm = 0.0685 cg_residual = 1.4278 step_size = 0.5344 reward = -0.0000 fps = 20 mse_loss = 0.2844 
2022-05-01 20:14:08.013952 - gail/main.py:164 - [TRPO] iter = 2395000 dist_mean = 0.0588 dist_std = 0.1479 vf_loss = 0.0497 grad_norm = 5.2587 nat_grad_norm = 0.1272 cg_residual = 3.9181 step_size = 0.3037 reward = 0.0000 fps = 17 mse_loss = 0.2836 
2022-05-01 20:14:08.232242 - gail/main.py:191 - [Discriminator] iter = 2395000 loss = -1.1264 grad_norm = 3.7245 grad_penalty = 0.1016 regularization = 0.0000 true_logits = -1.2898 fake_logits = -2.5179 true_prob = 0.3743 fake_prob = 0.2979 
2022-05-01 20:14:09.731336 - gail/main.py:132 - [Evaluate] iter = 2395000 episode={ returns = 9.2915 lengths = 10 } discounted_episode={ returns = 9.3833 lengths = 10 } 
2022-05-01 20:14:19.133002 - gail/main.py:164 - [TRPO] iter = 2396000 dist_mean = 0.0827 dist_std = 0.1478 vf_loss = 0.2756 grad_norm = 3.8596 nat_grad_norm = 0.0689 cg_residual = 1.5648 step_size = 0.4552 reward = 0.0000 fps = 91 mse_loss = 0.2683 
2022-05-01 20:14:28.510752 - gail/main.py:164 - [TRPO] iter = 2397000 dist_mean = 0.0784 dist_std = 0.1479 vf_loss = 0.0508 grad_norm = 3.2812 nat_grad_norm = 0.0964 cg_residual = 4.7675 step_size = 0.4160 reward = 0.0000 fps = 49 mse_loss = 0.2599 
2022-05-01 20:14:38.413808 - gail/main.py:164 - [TRPO] iter = 2398000 dist_mean = 0.0928 dist_std = 0.1479 vf_loss = 0.0249 grad_norm = 3.7497 nat_grad_norm = 0.1119 cg_residual = 10.1532 step_size = 0.3817 reward = 0.0000 fps = 33 mse_loss = 0.3053 
2022-05-01 20:14:48.334145 - gail/main.py:164 - [TRPO] iter = 2399000 dist_mean = 0.0887 dist_std = 0.1481 vf_loss = 0.4386 grad_norm = 5.1696 nat_grad_norm = 0.0510 cg_residual = 1.6198 step_size = 0.5334 reward = -0.0000 fps = 24 mse_loss = 0.2736 
2022-05-01 20:14:57.607145 - gail/main.py:164 - [TRPO] iter = 2400000 dist_mean = 0.0761 dist_std = 0.1480 vf_loss = 0.0900 grad_norm = 3.0092 nat_grad_norm = 0.0683 cg_residual = 0.8627 step_size = 0.5236 reward = 0.0000 fps = 20 mse_loss = 0.2637 
2022-05-01 20:14:57.859469 - gail/main.py:191 - [Discriminator] iter = 2400000 loss = -1.0768 grad_norm = 3.4587 grad_penalty = 0.1227 regularization = 0.0000 true_logits = -1.6542 fake_logits = -2.8537 true_prob = 0.3383 fake_prob = 0.2760 
2022-05-01 20:14:59.203931 - gail/main.py:132 - [Evaluate] iter = 2400000 episode={ returns = 8.7096 lengths = 9 } discounted_episode={ returns = 8.8776 lengths = 9 } 
2022-05-01 20:15:09.326178 - gail/main.py:164 - [TRPO] iter = 2401000 dist_mean = 0.0939 dist_std = 0.1476 vf_loss = 0.5178 grad_norm = 3.0399 nat_grad_norm = 0.0870 cg_residual = 3.2064 step_size = 0.3897 reward = -0.0000 fps = 87 mse_loss = 0.2938 
2022-05-01 20:15:19.063963 - gail/main.py:164 - [TRPO] iter = 2402000 dist_mean = 0.0944 dist_std = 0.1476 vf_loss = 0.2764 grad_norm = 2.8104 nat_grad_norm = 0.0835 cg_residual = 1.4100 step_size = 0.4315 reward = 0.0000 fps = 47 mse_loss = 0.3152 
2022-05-01 20:15:28.533748 - gail/main.py:164 - [TRPO] iter = 2403000 dist_mean = 0.0801 dist_std = 0.1474 vf_loss = 0.1175 grad_norm = 2.7298 nat_grad_norm = 0.0719 cg_residual = 4.1910 step_size = 0.4887 reward = -0.0000 fps = 32 mse_loss = 0.2995 
2022-05-01 20:15:38.387494 - gail/main.py:164 - [TRPO] iter = 2404000 dist_mean = 0.1136 dist_std = 0.1475 vf_loss = 0.0577 grad_norm = 4.0009 nat_grad_norm = 0.1020 cg_residual = 2.4825 step_size = 0.3451 reward = -0.0000 fps = 24 mse_loss = 0.3306 
2022-05-01 20:15:48.162478 - gail/main.py:164 - [TRPO] iter = 2405000 dist_mean = 0.1041 dist_std = 0.1474 vf_loss = 0.4161 grad_norm = 4.6987 nat_grad_norm = 0.0717 cg_residual = 2.0943 step_size = 0.4332 reward = -0.0000 fps = 19 mse_loss = 0.3139 
2022-05-01 20:15:48.373502 - gail/main.py:191 - [Discriminator] iter = 2405000 loss = -2.7113 grad_norm = 3.9766 grad_penalty = 0.2940 regularization = 0.0000 true_logits = -1.8627 fake_logits = -4.8680 true_prob = 0.3057 fake_prob = 0.1644 
2022-05-01 20:15:49.712312 - gail/main.py:132 - [Evaluate] iter = 2405000 episode={ returns = 9.0834 lengths = 9 } discounted_episode={ returns = 8.7921 lengths = 9 } 
2022-05-01 20:15:59.201307 - gail/main.py:164 - [TRPO] iter = 2406000 dist_mean = 0.0777 dist_std = 0.1474 vf_loss = 0.2934 grad_norm = 2.7008 nat_grad_norm = 0.0674 cg_residual = 4.2638 step_size = 0.4906 reward = -0.0000 fps = 92 mse_loss = 0.3148 
2022-05-01 20:16:08.645448 - gail/main.py:164 - [TRPO] iter = 2407000 dist_mean = 0.0471 dist_std = 0.1474 vf_loss = 0.2112 grad_norm = 2.9276 nat_grad_norm = 0.0626 cg_residual = 1.0958 step_size = 0.5591 reward = 0.0000 fps = 49 mse_loss = 0.3383 
2022-05-01 20:16:17.998995 - gail/main.py:164 - [TRPO] iter = 2408000 dist_mean = 0.0746 dist_std = 0.1476 vf_loss = 0.7072 grad_norm = 2.9291 nat_grad_norm = 0.0612 cg_residual = 1.2462 step_size = 0.5146 reward = 0.0000 fps = 33 mse_loss = 0.3455 
2022-05-01 20:16:27.401176 - gail/main.py:164 - [TRPO] iter = 2409000 dist_mean = 0.1024 dist_std = 0.1476 vf_loss = 1.0066 grad_norm = 4.9947 nat_grad_norm = 0.1320 cg_residual = 4.1837 step_size = 0.2701 reward = -0.0000 fps = 25 mse_loss = 0.3034 
2022-05-01 20:16:36.999640 - gail/main.py:164 - [TRPO] iter = 2410000 dist_mean = 0.0515 dist_std = 0.1476 vf_loss = 0.2241 grad_norm = 2.6720 nat_grad_norm = 0.1172 cg_residual = 3.3953 step_size = 0.3453 reward = -0.0000 fps = 20 mse_loss = 0.2951 
2022-05-01 20:16:37.195490 - gail/main.py:191 - [Discriminator] iter = 2410000 loss = -0.6540 grad_norm = 3.4838 grad_penalty = 0.1633 regularization = 0.0000 true_logits = -1.6706 fake_logits = -2.4879 true_prob = 0.3125 fake_prob = 0.2329 
2022-05-01 20:17:57.527730 - gail/main.py:132 - [Evaluate] iter = 2410000 episode={ returns = 2161.7617 lengths = 626 } discounted_episode={ returns = 1300.0121 lengths = 640 } 
2022-05-01 20:18:07.191101 - gail/main.py:164 - [TRPO] iter = 2411000 dist_mean = 0.0597 dist_std = 0.1480 vf_loss = 0.5662 grad_norm = 3.9481 nat_grad_norm = 0.0799 cg_residual = 6.1366 step_size = 0.4617 reward = -0.0000 fps = 11 mse_loss = 0.3245 
2022-05-01 20:18:17.042824 - gail/main.py:164 - [TRPO] iter = 2412000 dist_mean = 0.0663 dist_std = 0.1479 vf_loss = 0.0958 grad_norm = 3.5572 nat_grad_norm = 0.1219 cg_residual = 3.1543 step_size = 0.3361 reward = 0.0000 fps = 10 mse_loss = 0.3436 
2022-05-01 20:18:26.493403 - gail/main.py:164 - [TRPO] iter = 2413000 dist_mean = 0.0808 dist_std = 0.1481 vf_loss = 0.0533 grad_norm = 4.2481 nat_grad_norm = 0.1235 cg_residual = 9.6057 step_size = 0.3342 reward = -0.0000 fps = 9 mse_loss = 0.3076 
2022-05-01 20:18:36.112070 - gail/main.py:164 - [TRPO] iter = 2414000 dist_mean = 0.0524 dist_std = 0.1479 vf_loss = 0.2109 grad_norm = 3.1634 nat_grad_norm = 0.0598 cg_residual = 1.0453 step_size = 0.5259 reward = -0.0000 fps = 8 mse_loss = 0.3138 
2022-05-01 20:18:45.590478 - gail/main.py:164 - [TRPO] iter = 2415000 dist_mean = 0.0541 dist_std = 0.1479 vf_loss = 0.0479 grad_norm = 3.2757 nat_grad_norm = 0.0888 cg_residual = 3.1622 step_size = 0.4402 reward = 0.0000 fps = 7 mse_loss = 0.3270 
2022-05-01 20:18:45.810467 - gail/main.py:191 - [Discriminator] iter = 2415000 loss = -0.3306 grad_norm = 3.6653 grad_penalty = 0.0973 regularization = 0.0000 true_logits = -1.7425 fake_logits = -2.1705 true_prob = 0.2876 fake_prob = 0.2402 
