2022-05-01 03:46:07.682520 - utils/flags.py:257 - log_dir = logs/gail_w-Hopper-v2-200-2022-05-01-03-46-07
2022-05-01 03:46:14.941661 - gail/utils/replay_buffer.py:86 - Load dataset from /content/drive/MyDrive/project_2022_05_01/dataset/sac/Hopper-v2
2022-05-01 03:46:23.701264 - gail/main.py:75 - Expert Reward 3582.436530
2022-05-01 03:46:24.089326 - gail/main.py:79 - Original dataset size 3000
2022-05-01 03:46:24.131198 - gail/main.py:81 - Subsampled dataset size 3000
2022-05-01 03:46:24.137673 - gail/main.py:82 - np random: 864 random : 786
2022-05-01 03:46:24.138357 - gail/main.py:86 - Sampled obs: 0.4652, acs: 0.0749
2022-05-01 03:46:25.460704 - lunzi/nn/flat_param.py:17 - Enabling flattening... ['GaussianMLPPolicy_1/log_std:0', 'GaussianMLPPolicy_1/Variable:0', 'GaussianMLPPolicy_1/Variable_1:0', 'GaussianMLPPolicy_1/Variable_2:0', 'GaussianMLPPolicy_1/Variable_3:0', 'GaussianMLPPolicy_1/Variable_4:0', 'GaussianMLPPolicy_1/Variable_5:0']
2022-05-01 03:46:37.126606 - gail/discriminator/discriminator.py:30 - Use predefined normalization.
2022-05-01 03:46:37.141924 - gail/discriminator/discriminator.py:33 - Normalizer loc:[[ 1.3966653  -0.06165453 -0.19472611 -0.4584401   0.18350822  2.5732448
   0.00400542 -0.00549955 -0.04755233 -0.02386179  0.00759995]] 
 scale:[[0.16755195 0.05883223 0.15990146 0.34682125 0.5992658  0.6461788
  1.5187451  0.8811966  2.0685835  3.6282625  5.862049  ]]
2022-05-01 03:46:43.437732 - gail/discriminator/discriminator.py:67 - Discriminator uses Wasserstein distance.
2022-05-01 03:46:43.446383 - gail/discriminator/discriminator.py:68 - [<tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable:0' shape=(14, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_2:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_3:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_4:0' shape=(100, 1) dtype=float32_ref>, <tf.Variable 'Discriminator_1/BinaryClassifier_1/Variable_5:0' shape=(1,) dtype=float32_ref>]
2022-05-01 03:46:43.447684 - gail/discriminator/discriminator.py:69 - Use gradient penalty regularization (coef = 10.000000)
2022-05-01 03:46:44.663828 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions_mean]
2022-05-01 03:47:09.304523 - gail/main.py:132 - [Evaluate] iter = 0 episode={ returns = 151.7944 lengths = 165 } discounted_episode={ returns = 145.6909 lengths = 173 } 
2022-05-01 03:47:09.305390 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states] => [actions]
2022-05-01 03:47:22.179451 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [fake_states fake_actions] => [scaled_neural_reward]
2022-05-01 03:47:22.498801 - lunzi/nn/module.py:71 - [MLPVFunction] is making TensorFlow callables, key = [states] => [values]
2022-05-01 03:47:23.069272 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [] => [sync_old]
2022-05-01 03:47:23.339357 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss flat_grad dist_std mean_kl dist_mean]
2022-05-01 03:47:25.167452 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states tangents actions] => [hessian_vec_prod]
2022-05-01 03:47:28.601644 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [] => [get_flat]
2022-05-01 03:47:28.976852 - lunzi/nn/module.py:71 - [FlatParam] is making TensorFlow callables, key = [feed_flat] => [set_flat]
2022-05-01 03:47:29.312798 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states actions advantages ent_coef] => [loss mean_kl]
2022-05-01 03:47:29.916987 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [train_vf vf_loss]
2022-05-01 03:47:30.992636 - lunzi/nn/module.py:71 - [TRPO] is making TensorFlow callables, key = [states returns] => [vf_loss]
2022-05-01 03:47:31.419426 - lunzi/nn/module.py:71 - [GaussianMLPPolicy] is making TensorFlow callables, key = [states actions_] => [mse_loss]
2022-05-01 03:47:31.791615 - gail/main.py:164 - [TRPO] iter = 1000 dist_mean = -0.0000 dist_std = 1.0000 vf_loss = 0.2514 grad_norm = 0.3047 nat_grad_norm = 0.3393 cg_residual = 0.0000 step_size = 0.4765 reward = 0.0000 fps = 21 mse_loss = 0.3253 
2022-05-01 03:47:41.876312 - gail/main.py:164 - [TRPO] iter = 2000 dist_mean = 0.0570 dist_std = 1.0017 vf_loss = 0.3318 grad_norm = 0.3617 nat_grad_norm = 0.4168 cg_residual = 0.0000 step_size = 0.4072 reward = -0.0000 fps = 17 mse_loss = 0.3659 
2022-05-01 03:47:51.849932 - gail/main.py:164 - [TRPO] iter = 3000 dist_mean = 0.1010 dist_std = 0.9916 vf_loss = 0.2525 grad_norm = 0.3418 nat_grad_norm = 0.3390 cg_residual = 0.0000 step_size = 0.4626 reward = 0.0000 fps = 14 mse_loss = 0.3793 
2022-05-01 03:48:02.118618 - gail/main.py:164 - [TRPO] iter = 4000 dist_mean = 0.1515 dist_std = 0.9764 vf_loss = 0.3282 grad_norm = 0.2820 nat_grad_norm = 0.3051 cg_residual = 0.0000 step_size = 0.5470 reward = 0.0000 fps = 12 mse_loss = 0.3545 
2022-05-01 03:48:12.260092 - gail/main.py:164 - [TRPO] iter = 5000 dist_mean = 0.1659 dist_std = 0.9587 vf_loss = 0.3746 grad_norm = 0.2795 nat_grad_norm = 0.3719 cg_residual = 0.0000 step_size = 0.6178 reward = -0.0000 fps = 11 mse_loss = 0.4274 
2022-05-01 03:48:12.262822 - lunzi/nn/module.py:71 - [Discriminator] is making TensorFlow callables, key = [true_states true_actions fake_states fake_actions true_masks] => [train loss true_logits fake_logits true_prob fake_prob grad_norm grad_penalty regularization]
2022-05-01 03:48:15.301730 - gail/main.py:191 - [Discriminator] iter = 5000 loss = 1.5168 grad_norm = 13.1276 grad_penalty = 1.5373 regularization = 0.0000 true_logits = -0.2267 fake_logits = -0.2472 true_prob = 0.4439 fake_prob = 0.4387 
2022-05-01 03:48:30.700836 - gail/main.py:132 - [Evaluate] iter = 5000 episode={ returns = 212.3676 lengths = 110 } discounted_episode={ returns = 202.3702 lengths = 111 } 
2022-05-01 03:48:40.583698 - gail/main.py:164 - [TRPO] iter = 6000 dist_mean = 0.2075 dist_std = 0.9529 vf_loss = 0.3781 grad_norm = 0.3119 nat_grad_norm = 0.3829 cg_residual = 0.0000 step_size = 0.5587 reward = -0.0000 fps = 39 mse_loss = 0.4183 
2022-05-01 03:48:50.828217 - gail/main.py:164 - [TRPO] iter = 7000 dist_mean = 0.1994 dist_std = 0.9398 vf_loss = 0.4616 grad_norm = 0.3044 nat_grad_norm = 0.4053 cg_residual = 0.0000 step_size = 0.5058 reward = 0.0000 fps = 28 mse_loss = 0.4898 
2022-05-01 03:49:00.881364 - gail/main.py:164 - [TRPO] iter = 8000 dist_mean = 0.2148 dist_std = 0.9394 vf_loss = 0.3368 grad_norm = 0.3283 nat_grad_norm = 0.2875 cg_residual = 0.0000 step_size = 0.6729 reward = -0.0000 fps = 21 mse_loss = 0.4930 
2022-05-01 03:49:11.638615 - gail/main.py:164 - [TRPO] iter = 9000 dist_mean = 0.2162 dist_std = 0.9513 vf_loss = 0.4786 grad_norm = 0.3392 nat_grad_norm = 0.3608 cg_residual = 0.0000 step_size = 0.5537 reward = 0.0000 fps = 17 mse_loss = 0.5917 
2022-05-01 03:49:21.649566 - gail/main.py:164 - [TRPO] iter = 10000 dist_mean = 0.2444 dist_std = 0.9428 vf_loss = 0.5202 grad_norm = 0.3483 nat_grad_norm = 0.3780 cg_residual = 0.0000 step_size = 0.5376 reward = 0.0000 fps = 15 mse_loss = 0.5879 
2022-05-01 03:49:21.862132 - gail/main.py:191 - [Discriminator] iter = 10000 loss = 1.1704 grad_norm = 11.8895 grad_penalty = 1.2207 regularization = 0.0000 true_logits = -0.2148 fake_logits = -0.2651 true_prob = 0.4468 fake_prob = 0.4343 
2022-05-01 03:49:38.221538 - gail/main.py:132 - [Evaluate] iter = 10000 episode={ returns = 212.8082 lengths = 102 } discounted_episode={ returns = 200.6754 lengths = 102 } 
2022-05-01 03:49:48.264323 - gail/main.py:164 - [TRPO] iter = 11000 dist_mean = 0.2024 dist_std = 0.9360 vf_loss = 0.3845 grad_norm = 0.4211 nat_grad_norm = 0.3646 cg_residual = 0.0000 step_size = 0.5535 reward = 0.0000 fps = 37 mse_loss = 0.5727 
2022-05-01 03:49:58.522455 - gail/main.py:164 - [TRPO] iter = 12000 dist_mean = 0.2217 dist_std = 0.9275 vf_loss = 0.2595 grad_norm = 0.3887 nat_grad_norm = 0.3703 cg_residual = 0.0001 step_size = 0.5170 reward = -0.0000 fps = 27 mse_loss = 0.6381 
2022-05-01 03:50:08.481833 - gail/main.py:164 - [TRPO] iter = 13000 dist_mean = 0.2337 dist_std = 0.9121 vf_loss = 0.2238 grad_norm = 0.3463 nat_grad_norm = 0.3473 cg_residual = 0.0001 step_size = 0.5510 reward = -0.0000 fps = 21 mse_loss = 0.6358 
2022-05-01 03:50:18.711356 - gail/main.py:164 - [TRPO] iter = 14000 dist_mean = 0.2426 dist_std = 0.8983 vf_loss = 0.2523 grad_norm = 0.5260 nat_grad_norm = 0.3942 cg_residual = 0.0001 step_size = 0.4924 reward = -0.0000 fps = 17 mse_loss = 0.7499 
2022-05-01 03:50:28.909337 - gail/main.py:164 - [TRPO] iter = 15000 dist_mean = 0.2465 dist_std = 0.8921 vf_loss = 0.1436 grad_norm = 0.2911 nat_grad_norm = 0.3420 cg_residual = 0.0002 step_size = 0.6209 reward = -0.0000 fps = 14 mse_loss = 0.7096 
2022-05-01 03:50:29.143929 - gail/main.py:191 - [Discriminator] iter = 15000 loss = 0.6835 grad_norm = 7.6770 grad_penalty = 0.7604 regularization = 0.0000 true_logits = -0.1851 fake_logits = -0.2620 true_prob = 0.4542 fake_prob = 0.4351 
2022-05-01 03:50:40.262780 - gail/main.py:132 - [Evaluate] iter = 15000 episode={ returns = 161.0191 lengths = 75 } discounted_episode={ returns = 152.9673 lengths = 75 } 
2022-05-01 03:50:50.287858 - gail/main.py:164 - [TRPO] iter = 16000 dist_mean = 0.2401 dist_std = 0.8846 vf_loss = 0.1853 grad_norm = 0.3829 nat_grad_norm = 0.3046 cg_residual = 0.0001 step_size = 0.5675 reward = 0.0000 fps = 47 mse_loss = 0.6826 
2022-05-01 03:51:00.541553 - gail/main.py:164 - [TRPO] iter = 17000 dist_mean = 0.2297 dist_std = 0.8747 vf_loss = 0.1778 grad_norm = 0.4627 nat_grad_norm = 0.3369 cg_residual = 0.0001 step_size = 0.4879 reward = -0.0000 fps = 31 mse_loss = 0.7060 
2022-05-01 03:51:10.981559 - gail/main.py:164 - [TRPO] iter = 18000 dist_mean = 0.2597 dist_std = 0.8582 vf_loss = 0.1047 grad_norm = 0.5352 nat_grad_norm = 0.3479 cg_residual = 0.0003 step_size = 0.4337 reward = -0.0000 fps = 23 mse_loss = 0.6793 
2022-05-01 03:51:21.335886 - gail/main.py:164 - [TRPO] iter = 19000 dist_mean = 0.2600 dist_std = 0.8371 vf_loss = 0.0950 grad_norm = 0.6222 nat_grad_norm = 0.3721 cg_residual = 0.0004 step_size = 0.4368 reward = -0.0000 fps = 19 mse_loss = 0.8148 
2022-05-01 03:51:31.253697 - gail/main.py:164 - [TRPO] iter = 20000 dist_mean = 0.2576 dist_std = 0.8208 vf_loss = 0.1245 grad_norm = 0.3521 nat_grad_norm = 0.2963 cg_residual = 0.0003 step_size = 0.6167 reward = -0.0000 fps = 16 mse_loss = 0.8999 
2022-05-01 03:51:31.480646 - gail/main.py:191 - [Discriminator] iter = 20000 loss = 0.4287 grad_norm = 5.8603 grad_penalty = 0.5898 regularization = 0.0000 true_logits = -0.1465 fake_logits = -0.3077 true_prob = 0.4637 fake_prob = 0.4241 
2022-05-01 03:51:41.555378 - gail/main.py:132 - [Evaluate] iter = 20000 episode={ returns = 153.1253 lengths = 72 } discounted_episode={ returns = 147.1495 lengths = 72 } 
2022-05-01 03:51:51.293817 - gail/main.py:164 - [TRPO] iter = 21000 dist_mean = 0.2546 dist_std = 0.8003 vf_loss = 0.0816 grad_norm = 0.3401 nat_grad_norm = 0.3279 cg_residual = 0.0007 step_size = 0.6027 reward = -0.0000 fps = 50 mse_loss = 1.0657 
2022-05-01 03:52:01.380283 - gail/main.py:164 - [TRPO] iter = 22000 dist_mean = 0.2619 dist_std = 0.7909 vf_loss = 0.0749 grad_norm = 0.4559 nat_grad_norm = 0.3566 cg_residual = 0.0003 step_size = 0.4960 reward = -0.0000 fps = 33 mse_loss = 1.0854 
2022-05-01 03:52:11.674762 - gail/main.py:164 - [TRPO] iter = 23000 dist_mean = 0.2524 dist_std = 0.7798 vf_loss = 0.0624 grad_norm = 0.5559 nat_grad_norm = 0.4038 cg_residual = 0.0007 step_size = 0.4526 reward = -0.0000 fps = 24 mse_loss = 1.1793 
2022-05-01 03:52:21.926476 - gail/main.py:164 - [TRPO] iter = 24000 dist_mean = 0.2169 dist_std = 0.7673 vf_loss = 0.0474 grad_norm = 0.5407 nat_grad_norm = 0.3083 cg_residual = 0.0013 step_size = 0.5416 reward = 0.0000 fps = 19 mse_loss = 1.3262 
2022-05-01 03:52:31.978582 - gail/main.py:164 - [TRPO] iter = 25000 dist_mean = 0.2116 dist_std = 0.7547 vf_loss = 0.0457 grad_norm = 0.6488 nat_grad_norm = 0.3911 cg_residual = 0.0014 step_size = 0.4613 reward = 0.0000 fps = 16 mse_loss = 1.4017 
2022-05-01 03:52:32.222322 - gail/main.py:191 - [Discriminator] iter = 25000 loss = 0.2078 grad_norm = 5.5341 grad_penalty = 0.4737 regularization = 0.0000 true_logits = -0.1286 fake_logits = -0.3945 true_prob = 0.4682 fake_prob = 0.4032 
2022-05-01 03:52:42.503872 - gail/main.py:132 - [Evaluate] iter = 25000 episode={ returns = 153.8679 lengths = 72 } discounted_episode={ returns = 146.0307 lengths = 71 } 
2022-05-01 03:52:53.441909 - gail/main.py:164 - [TRPO] iter = 26000 dist_mean = 0.2161 dist_std = 0.7391 vf_loss = 0.0630 grad_norm = 0.4271 nat_grad_norm = 0.2777 cg_residual = 0.0007 step_size = 0.6152 reward = 0.0000 fps = 47 mse_loss = 1.4350 
2022-05-01 03:53:03.871132 - gail/main.py:164 - [TRPO] iter = 27000 dist_mean = 0.2084 dist_std = 0.7253 vf_loss = 0.0497 grad_norm = 0.6803 nat_grad_norm = 0.2888 cg_residual = 0.0014 step_size = 0.4643 reward = -0.0000 fps = 31 mse_loss = 1.5251 
2022-05-01 03:53:14.202379 - gail/main.py:164 - [TRPO] iter = 28000 dist_mean = 0.2087 dist_std = 0.7139 vf_loss = 0.0388 grad_norm = 0.4950 nat_grad_norm = 0.2855 cg_residual = 0.0010 step_size = 0.5375 reward = -0.0000 fps = 23 mse_loss = 1.4160 
2022-05-01 03:53:24.210685 - gail/main.py:164 - [TRPO] iter = 29000 dist_mean = 0.2069 dist_std = 0.7001 vf_loss = 0.0444 grad_norm = 0.4668 nat_grad_norm = 0.3251 cg_residual = 0.0022 step_size = 0.5294 reward = -0.0000 fps = 19 mse_loss = 1.6157 
2022-05-01 03:53:34.335867 - gail/main.py:164 - [TRPO] iter = 30000 dist_mean = 0.2157 dist_std = 0.6889 vf_loss = 0.0370 grad_norm = 0.7086 nat_grad_norm = 0.2933 cg_residual = 0.0014 step_size = 0.5617 reward = -0.0000 fps = 16 mse_loss = 1.3377 
2022-05-01 03:53:34.562576 - gail/main.py:191 - [Discriminator] iter = 30000 loss = 0.0885 grad_norm = 4.7540 grad_penalty = 0.4905 regularization = 0.0000 true_logits = -0.1086 fake_logits = -0.5106 true_prob = 0.4733 fake_prob = 0.3759 
2022-05-01 03:53:44.941883 - gail/main.py:132 - [Evaluate] iter = 30000 episode={ returns = 168.7301 lengths = 76 } discounted_episode={ returns = 161.2596 lengths = 76 } 
2022-05-01 03:53:55.181148 - gail/main.py:164 - [TRPO] iter = 31000 dist_mean = 0.2210 dist_std = 0.6774 vf_loss = 0.0396 grad_norm = 0.4748 nat_grad_norm = 0.3499 cg_residual = 0.0026 step_size = 0.5431 reward = -0.0000 fps = 48 mse_loss = 1.6500 
2022-05-01 03:54:05.378269 - gail/main.py:164 - [TRPO] iter = 32000 dist_mean = 0.2180 dist_std = 0.6679 vf_loss = 0.0303 grad_norm = 0.3382 nat_grad_norm = 0.3611 cg_residual = 0.0043 step_size = 0.6061 reward = 0.0000 fps = 32 mse_loss = 1.7674 
2022-05-01 03:54:15.614016 - gail/main.py:164 - [TRPO] iter = 33000 dist_mean = 0.2430 dist_std = 0.6570 vf_loss = 0.0307 grad_norm = 0.5008 nat_grad_norm = 0.2930 cg_residual = 0.0044 step_size = 0.5799 reward = -0.0000 fps = 24 mse_loss = 1.8825 
2022-05-01 03:54:25.760276 - gail/main.py:164 - [TRPO] iter = 34000 dist_mean = 0.2202 dist_std = 0.6462 vf_loss = 0.0278 grad_norm = 0.8372 nat_grad_norm = 0.3862 cg_residual = 0.0016 step_size = 0.4746 reward = -0.0000 fps = 19 mse_loss = 1.7751 
2022-05-01 03:54:36.557144 - gail/main.py:164 - [TRPO] iter = 35000 dist_mean = 0.2430 dist_std = 0.6324 vf_loss = 0.0416 grad_norm = 0.6303 nat_grad_norm = 0.3440 cg_residual = 0.0050 step_size = 0.4594 reward = -0.0000 fps = 16 mse_loss = 1.9655 
2022-05-01 03:54:36.815948 - gail/main.py:191 - [Discriminator] iter = 35000 loss = -0.1819 grad_norm = 5.0269 grad_penalty = 0.3975 regularization = 0.0000 true_logits = -0.0707 fake_logits = -0.6501 true_prob = 0.4827 fake_prob = 0.3443 
2022-05-01 03:54:48.201849 - gail/main.py:132 - [Evaluate] iter = 35000 episode={ returns = 178.9480 lengths = 79 } discounted_episode={ returns = 170.5732 lengths = 80 } 
2022-05-01 03:54:58.339355 - gail/main.py:164 - [TRPO] iter = 36000 dist_mean = 0.2185 dist_std = 0.6144 vf_loss = 0.0426 grad_norm = 0.5767 nat_grad_norm = 0.2864 cg_residual = 0.0068 step_size = 0.5740 reward = 0.0000 fps = 46 mse_loss = 1.8598 
2022-05-01 03:55:08.681769 - gail/main.py:164 - [TRPO] iter = 37000 dist_mean = 0.2305 dist_std = 0.6106 vf_loss = 0.0274 grad_norm = 0.5409 nat_grad_norm = 0.2256 cg_residual = 0.0045 step_size = 0.7322 reward = 0.0000 fps = 31 mse_loss = 2.0004 
2022-05-01 03:55:18.764052 - gail/main.py:164 - [TRPO] iter = 38000 dist_mean = 0.2334 dist_std = 0.6035 vf_loss = 0.0275 grad_norm = 0.6156 nat_grad_norm = 0.2720 cg_residual = 0.0068 step_size = 0.6182 reward = -0.0000 fps = 23 mse_loss = 1.9397 
2022-05-01 03:55:28.666190 - gail/main.py:164 - [TRPO] iter = 39000 dist_mean = 0.2409 dist_std = 0.5936 vf_loss = 0.0352 grad_norm = 0.6344 nat_grad_norm = 0.3120 cg_residual = 0.0096 step_size = 0.5074 reward = -0.0000 fps = 19 mse_loss = 2.2066 
2022-05-01 03:55:38.541244 - gail/main.py:164 - [TRPO] iter = 40000 dist_mean = 0.2229 dist_std = 0.5828 vf_loss = 0.0425 grad_norm = 1.1112 nat_grad_norm = 0.3028 cg_residual = 0.0144 step_size = 0.4340 reward = 0.0000 fps = 16 mse_loss = 2.1608 
2022-05-01 03:55:38.776517 - gail/main.py:191 - [Discriminator] iter = 40000 loss = -0.3754 grad_norm = 4.6474 grad_penalty = 0.3579 regularization = 0.0000 true_logits = -0.0730 fake_logits = -0.8063 true_prob = 0.4827 fake_prob = 0.3108 
2022-05-01 03:55:50.358114 - gail/main.py:132 - [Evaluate] iter = 40000 episode={ returns = 188.3188 lengths = 82 } discounted_episode={ returns = 178.7377 lengths = 82 } 
2022-05-01 03:56:00.614604 - gail/main.py:164 - [TRPO] iter = 41000 dist_mean = 0.2527 dist_std = 0.5805 vf_loss = 0.0591 grad_norm = 1.0113 nat_grad_norm = 0.3906 cg_residual = 0.0219 step_size = 0.4112 reward = -0.0000 fps = 45 mse_loss = 2.0609 
2022-05-01 03:56:10.654215 - gail/main.py:164 - [TRPO] iter = 42000 dist_mean = 0.2517 dist_std = 0.5725 vf_loss = 0.0329 grad_norm = 1.3250 nat_grad_norm = 0.2565 cg_residual = 0.0193 step_size = 0.4606 reward = 0.0000 fps = 31 mse_loss = 2.0416 
2022-05-01 03:56:20.539180 - gail/main.py:164 - [TRPO] iter = 43000 dist_mean = 0.2236 dist_std = 0.5694 vf_loss = 0.0373 grad_norm = 0.9769 nat_grad_norm = 0.2827 cg_residual = 0.0222 step_size = 0.4950 reward = 0.0000 fps = 23 mse_loss = 2.1162 
2022-05-01 03:56:30.440156 - gail/main.py:164 - [TRPO] iter = 44000 dist_mean = 0.2498 dist_std = 0.5628 vf_loss = 0.0569 grad_norm = 0.9561 nat_grad_norm = 0.3039 cg_residual = 0.0206 step_size = 0.4438 reward = 0.0000 fps = 19 mse_loss = 1.9802 
2022-05-01 03:56:40.647075 - gail/main.py:164 - [TRPO] iter = 45000 dist_mean = 0.2500 dist_std = 0.5589 vf_loss = 0.0764 grad_norm = 1.3121 nat_grad_norm = 0.2965 cg_residual = 0.1598 step_size = 0.4001 reward = 0.0000 fps = 16 mse_loss = 2.1202 
2022-05-01 03:56:40.887764 - gail/main.py:191 - [Discriminator] iter = 45000 loss = -0.5014 grad_norm = 5.3969 grad_penalty = 0.4041 regularization = 0.0000 true_logits = -0.0674 fake_logits = -0.9730 true_prob = 0.4846 fake_prob = 0.2773 
2022-05-01 03:56:53.921818 - gail/main.py:132 - [Evaluate] iter = 45000 episode={ returns = 228.4450 lengths = 93 } discounted_episode={ returns = 215.7860 lengths = 93 } 
2022-05-01 03:57:04.004590 - gail/main.py:164 - [TRPO] iter = 46000 dist_mean = 0.2408 dist_std = 0.5421 vf_loss = 0.0961 grad_norm = 0.9073 nat_grad_norm = 0.3034 cg_residual = 0.0599 step_size = 0.4660 reward = -0.0000 fps = 43 mse_loss = 2.1771 
2022-05-01 03:57:14.116837 - gail/main.py:164 - [TRPO] iter = 47000 dist_mean = 0.2307 dist_std = 0.5323 vf_loss = 0.0813 grad_norm = 1.1788 nat_grad_norm = 0.3070 cg_residual = 0.1519 step_size = 0.4358 reward = -0.0000 fps = 30 mse_loss = 2.4385 
2022-05-01 03:57:23.993153 - gail/main.py:164 - [TRPO] iter = 48000 dist_mean = 0.2356 dist_std = 0.5257 vf_loss = 0.0821 grad_norm = 1.7966 nat_grad_norm = 0.1543 cg_residual = 0.0138 step_size = 0.4782 reward = -0.0000 fps = 23 mse_loss = 2.5261 
2022-05-01 03:57:34.049556 - gail/main.py:164 - [TRPO] iter = 49000 dist_mean = 0.2278 dist_std = 0.5192 vf_loss = 0.0935 grad_norm = 0.6800 nat_grad_norm = 0.2164 cg_residual = 0.0195 step_size = 0.6233 reward = 0.0000 fps = 18 mse_loss = 2.5083 
2022-05-01 03:57:44.096979 - gail/main.py:164 - [TRPO] iter = 50000 dist_mean = 0.2236 dist_std = 0.5106 vf_loss = 0.0674 grad_norm = 2.0542 nat_grad_norm = 0.2181 cg_residual = 0.0162 step_size = 0.4966 reward = 0.0000 fps = 15 mse_loss = 2.3254 
2022-05-01 03:57:44.328071 - gail/main.py:191 - [Discriminator] iter = 50000 loss = -0.7892 grad_norm = 4.8551 grad_penalty = 0.3042 regularization = 0.0000 true_logits = -0.0780 fake_logits = -1.1714 true_prob = 0.4826 fake_prob = 0.2405 
2022-05-01 03:57:58.768875 - gail/main.py:132 - [Evaluate] iter = 50000 episode={ returns = 273.4873 lengths = 105 } discounted_episode={ returns = 257.0266 lengths = 105 } 
2022-05-01 03:58:09.134573 - gail/main.py:164 - [TRPO] iter = 51000 dist_mean = 0.2185 dist_std = 0.5107 vf_loss = 0.0535 grad_norm = 1.1895 nat_grad_norm = 0.1894 cg_residual = 0.0785 step_size = 0.6168 reward = 0.0000 fps = 40 mse_loss = 2.3745 
2022-05-01 03:58:19.498176 - gail/main.py:164 - [TRPO] iter = 52000 dist_mean = 0.1907 dist_std = 0.5016 vf_loss = 0.0699 grad_norm = 1.5002 nat_grad_norm = 0.2637 cg_residual = 0.1411 step_size = 0.4600 reward = 0.0000 fps = 28 mse_loss = 2.4158 
2022-05-01 03:58:29.748540 - gail/main.py:164 - [TRPO] iter = 53000 dist_mean = 0.1964 dist_std = 0.4992 vf_loss = 0.0497 grad_norm = 1.4924 nat_grad_norm = 0.2350 cg_residual = 0.1668 step_size = 0.4621 reward = -0.0000 fps = 22 mse_loss = 2.4063 
2022-05-01 03:58:39.758610 - gail/main.py:164 - [TRPO] iter = 54000 dist_mean = 0.1900 dist_std = 0.5016 vf_loss = 0.0876 grad_norm = 1.6810 nat_grad_norm = 0.2406 cg_residual = 0.1943 step_size = 0.4595 reward = 0.0000 fps = 18 mse_loss = 2.4085 
2022-05-01 03:58:49.971691 - gail/main.py:164 - [TRPO] iter = 55000 dist_mean = 0.1785 dist_std = 0.4928 vf_loss = 0.0570 grad_norm = 1.1739 nat_grad_norm = 0.2178 cg_residual = 0.0797 step_size = 0.4953 reward = -0.0000 fps = 15 mse_loss = 2.5626 
2022-05-01 03:58:50.199213 - gail/main.py:191 - [Discriminator] iter = 55000 loss = -0.9878 grad_norm = 4.5380 grad_penalty = 0.3026 regularization = 0.0000 true_logits = -0.0851 fake_logits = -1.3755 true_prob = 0.4820 fake_prob = 0.2069 
2022-05-01 03:59:04.626124 - gail/main.py:132 - [Evaluate] iter = 55000 episode={ returns = 280.1474 lengths = 106 } discounted_episode={ returns = 262.2095 lengths = 106 } 
2022-05-01 03:59:14.695349 - gail/main.py:164 - [TRPO] iter = 56000 dist_mean = 0.1675 dist_std = 0.4882 vf_loss = 0.0706 grad_norm = 1.3384 nat_grad_norm = 0.2313 cg_residual = 0.0632 step_size = 0.4206 reward = -0.0000 fps = 40 mse_loss = 2.7840 
2022-05-01 03:59:24.436224 - gail/main.py:164 - [TRPO] iter = 57000 dist_mean = 0.1427 dist_std = 0.4929 vf_loss = 0.0640 grad_norm = 1.7590 nat_grad_norm = 0.1948 cg_residual = 0.0271 step_size = 0.5349 reward = 0.0000 fps = 29 mse_loss = 2.7256 
2022-05-01 03:59:34.374555 - gail/main.py:164 - [TRPO] iter = 58000 dist_mean = 0.1375 dist_std = 0.4913 vf_loss = 0.0492 grad_norm = 1.2789 nat_grad_norm = 0.1731 cg_residual = 0.0170 step_size = 0.5792 reward = -0.0000 fps = 22 mse_loss = 2.7290 
2022-05-01 03:59:45.369413 - gail/main.py:164 - [TRPO] iter = 59000 dist_mean = 0.1492 dist_std = 0.4854 vf_loss = 0.0363 grad_norm = 1.5275 nat_grad_norm = 0.1562 cg_residual = 0.0674 step_size = 0.5299 reward = -0.0000 fps = 18 mse_loss = 3.0274 
2022-05-01 03:59:56.483630 - gail/main.py:164 - [TRPO] iter = 60000 dist_mean = 0.1431 dist_std = 0.4800 vf_loss = 0.0801 grad_norm = 2.0231 nat_grad_norm = 0.2449 cg_residual = 0.0657 step_size = 0.4097 reward = 0.0000 fps = 15 mse_loss = 2.8003 
2022-05-01 03:59:56.721495 - gail/main.py:191 - [Discriminator] iter = 60000 loss = -1.1247 grad_norm = 3.9528 grad_penalty = 0.2389 regularization = 0.0000 true_logits = -0.1336 fake_logits = -1.4972 true_prob = 0.4722 fake_prob = 0.1909 
2022-05-01 04:00:12.072755 - gail/main.py:132 - [Evaluate] iter = 60000 episode={ returns = 296.8597 lengths = 110 } discounted_episode={ returns = 277.4976 lengths = 110 } 
2022-05-01 04:00:22.091995 - gail/main.py:164 - [TRPO] iter = 61000 dist_mean = 0.1408 dist_std = 0.4777 vf_loss = 0.0780 grad_norm = 1.4258 nat_grad_norm = 0.2117 cg_residual = 0.0972 step_size = 0.5012 reward = -0.0000 fps = 39 mse_loss = 3.0652 
2022-05-01 04:00:31.966683 - gail/main.py:164 - [TRPO] iter = 62000 dist_mean = 0.1114 dist_std = 0.4780 vf_loss = 0.0939 grad_norm = 1.6172 nat_grad_norm = 0.2715 cg_residual = 0.0495 step_size = 0.4307 reward = 0.0000 fps = 28 mse_loss = 2.9979 
2022-05-01 04:00:41.992323 - gail/main.py:164 - [TRPO] iter = 63000 dist_mean = 0.1009 dist_std = 0.4763 vf_loss = 0.1083 grad_norm = 1.8980 nat_grad_norm = 0.2702 cg_residual = 0.1000 step_size = 0.4619 reward = 0.0000 fps = 22 mse_loss = 3.0236 
2022-05-01 04:00:52.150469 - gail/main.py:164 - [TRPO] iter = 64000 dist_mean = 0.1047 dist_std = 0.4771 vf_loss = 0.2964 grad_norm = 1.3264 nat_grad_norm = 0.2294 cg_residual = 0.0459 step_size = 0.5197 reward = 0.0000 fps = 18 mse_loss = 3.0359 
2022-05-01 04:01:02.232593 - gail/main.py:164 - [TRPO] iter = 65000 dist_mean = 0.0947 dist_std = 0.4672 vf_loss = 0.0861 grad_norm = 1.7770 nat_grad_norm = 0.2412 cg_residual = 0.0520 step_size = 0.4152 reward = -0.0000 fps = 15 mse_loss = 2.9317 
2022-05-01 04:01:02.485473 - gail/main.py:191 - [Discriminator] iter = 65000 loss = -1.2371 grad_norm = 3.8355 grad_penalty = 0.2452 regularization = 0.0000 true_logits = -0.1188 fake_logits = -1.6011 true_prob = 0.4760 fake_prob = 0.1806 
2022-05-01 04:01:18.401755 - gail/main.py:132 - [Evaluate] iter = 65000 episode={ returns = 322.6136 lengths = 116 } discounted_episode={ returns = 301.5691 lengths = 117 } 
2022-05-01 04:01:28.634459 - gail/main.py:164 - [TRPO] iter = 66000 dist_mean = 0.0985 dist_std = 0.4645 vf_loss = 0.2331 grad_norm = 0.7872 nat_grad_norm = 0.2349 cg_residual = 0.0450 step_size = 0.5809 reward = 0.0000 fps = 38 mse_loss = 2.9233 
2022-05-01 04:01:39.049736 - gail/main.py:164 - [TRPO] iter = 67000 dist_mean = 0.0972 dist_std = 0.4588 vf_loss = 0.0909 grad_norm = 1.2415 nat_grad_norm = 0.2520 cg_residual = 0.0317 step_size = 0.4936 reward = -0.0000 fps = 27 mse_loss = 2.7975 
2022-05-01 04:01:49.350112 - gail/main.py:164 - [TRPO] iter = 68000 dist_mean = 0.0818 dist_std = 0.4586 vf_loss = 0.1276 grad_norm = 1.3105 nat_grad_norm = 0.3066 cg_residual = 0.0368 step_size = 0.4834 reward = 0.0000 fps = 21 mse_loss = 2.9674 
2022-05-01 04:01:59.336283 - gail/main.py:164 - [TRPO] iter = 69000 dist_mean = 0.0581 dist_std = 0.4548 vf_loss = 0.1321 grad_norm = 1.2837 nat_grad_norm = 0.2552 cg_residual = 0.0461 step_size = 0.5058 reward = -0.0000 fps = 17 mse_loss = 2.9436 
2022-05-01 04:02:09.668777 - gail/main.py:164 - [TRPO] iter = 70000 dist_mean = 0.0757 dist_std = 0.4497 vf_loss = 0.4501 grad_norm = 1.4352 nat_grad_norm = 0.2159 cg_residual = 0.0547 step_size = 0.4811 reward = 0.0000 fps = 14 mse_loss = 2.9160 
2022-05-01 04:02:09.922280 - gail/main.py:191 - [Discriminator] iter = 70000 loss = -1.2172 grad_norm = 4.2470 grad_penalty = 0.2621 regularization = 0.0000 true_logits = -0.0920 fake_logits = -1.5713 true_prob = 0.4835 fake_prob = 0.1895 
2022-05-01 04:02:28.270452 - gail/main.py:132 - [Evaluate] iter = 70000 episode={ returns = 385.2023 lengths = 133 } discounted_episode={ returns = 355.7662 lengths = 132 } 
2022-05-01 04:02:38.568996 - gail/main.py:164 - [TRPO] iter = 71000 dist_mean = 0.0700 dist_std = 0.4469 vf_loss = 0.2197 grad_norm = 1.7565 nat_grad_norm = 0.2380 cg_residual = 0.0550 step_size = 0.4324 reward = -0.0000 fps = 34 mse_loss = 2.7425 
2022-05-01 04:02:49.140188 - gail/main.py:164 - [TRPO] iter = 72000 dist_mean = 0.0631 dist_std = 0.4477 vf_loss = 0.1655 grad_norm = 1.0537 nat_grad_norm = 0.2534 cg_residual = 0.0491 step_size = 0.4758 reward = -0.0000 fps = 25 mse_loss = 2.8479 
2022-05-01 04:02:58.579090 - gail/main.py:164 - [TRPO] iter = 73000 dist_mean = 0.0659 dist_std = 0.4539 vf_loss = 0.1057 grad_norm = 1.2827 nat_grad_norm = 0.2832 cg_residual = 0.0440 step_size = 0.4273 reward = 0.0000 fps = 20 mse_loss = 2.5173 
2022-05-01 04:03:08.594765 - gail/main.py:164 - [TRPO] iter = 74000 dist_mean = 0.0585 dist_std = 0.4558 vf_loss = 0.1236 grad_norm = 1.6594 nat_grad_norm = 0.2917 cg_residual = 0.0726 step_size = 0.4417 reward = 0.0000 fps = 17 mse_loss = 2.6133 
2022-05-01 04:03:18.659461 - gail/main.py:164 - [TRPO] iter = 75000 dist_mean = 0.0878 dist_std = 0.4483 vf_loss = 0.2034 grad_norm = 1.6760 nat_grad_norm = 0.2158 cg_residual = 0.0372 step_size = 0.4285 reward = -0.0000 fps = 14 mse_loss = 2.5863 
2022-05-01 04:03:18.893430 - gail/main.py:191 - [Discriminator] iter = 75000 loss = -1.1804 grad_norm = 3.3069 grad_penalty = 0.2101 regularization = 0.0000 true_logits = -0.0950 fake_logits = -1.4855 true_prob = 0.4822 fake_prob = 0.2032 
2022-05-01 04:03:38.045468 - gail/main.py:132 - [Evaluate] iter = 75000 episode={ returns = 420.5960 lengths = 141 } discounted_episode={ returns = 387.0149 lengths = 141 } 
2022-05-01 04:03:48.121905 - gail/main.py:164 - [TRPO] iter = 76000 dist_mean = 0.0670 dist_std = 0.4440 vf_loss = 0.1400 grad_norm = 1.3782 nat_grad_norm = 0.1745 cg_residual = 0.0463 step_size = 0.5825 reward = 0.0000 fps = 34 mse_loss = 2.7753 
2022-05-01 04:03:58.014049 - gail/main.py:164 - [TRPO] iter = 77000 dist_mean = 0.0640 dist_std = 0.4390 vf_loss = 0.1903 grad_norm = 1.4852 nat_grad_norm = 0.2349 cg_residual = 0.0829 step_size = 0.4212 reward = 0.0000 fps = 25 mse_loss = 2.8986 
2022-05-01 04:04:07.783558 - gail/main.py:164 - [TRPO] iter = 78000 dist_mean = 0.0720 dist_std = 0.4368 vf_loss = 0.0938 grad_norm = 1.2145 nat_grad_norm = 0.2462 cg_residual = 0.0299 step_size = 0.5108 reward = -0.0000 fps = 20 mse_loss = 2.7654 
2022-05-01 04:04:17.617600 - gail/main.py:164 - [TRPO] iter = 79000 dist_mean = 0.0762 dist_std = 0.4338 vf_loss = 0.2085 grad_norm = 1.1960 nat_grad_norm = 0.2719 cg_residual = 0.0609 step_size = 0.4559 reward = 0.0000 fps = 17 mse_loss = 2.8264 
2022-05-01 04:04:27.529188 - gail/main.py:164 - [TRPO] iter = 80000 dist_mean = 0.0752 dist_std = 0.4277 vf_loss = 0.0685 grad_norm = 0.9194 nat_grad_norm = 0.1971 cg_residual = 0.0397 step_size = 0.5515 reward = -0.0000 fps = 14 mse_loss = 2.8672 
2022-05-01 04:04:27.712286 - gail/main.py:191 - [Discriminator] iter = 80000 loss = -1.1039 grad_norm = 4.2925 grad_penalty = 0.2313 regularization = 0.0000 true_logits = -0.0987 fake_logits = -1.4340 true_prob = 0.4832 fake_prob = 0.2154 
2022-05-01 04:04:48.083764 - gail/main.py:132 - [Evaluate] iter = 80000 episode={ returns = 446.7966 lengths = 146 } discounted_episode={ returns = 409.3175 lengths = 146 } 
2022-05-01 04:04:58.049394 - gail/main.py:164 - [TRPO] iter = 81000 dist_mean = 0.0747 dist_std = 0.4348 vf_loss = 0.1205 grad_norm = 1.4399 nat_grad_norm = 0.2035 cg_residual = 0.0441 step_size = 0.5073 reward = 0.0000 fps = 32 mse_loss = 3.0597 
2022-05-01 04:05:08.311410 - gail/main.py:164 - [TRPO] iter = 82000 dist_mean = 0.0534 dist_std = 0.4378 vf_loss = 0.0899 grad_norm = 1.3230 nat_grad_norm = 0.2534 cg_residual = 0.0910 step_size = 0.4925 reward = 0.0000 fps = 24 mse_loss = 3.0369 
2022-05-01 04:05:18.261431 - gail/main.py:164 - [TRPO] iter = 83000 dist_mean = 0.0632 dist_std = 0.4323 vf_loss = 0.1514 grad_norm = 1.3764 nat_grad_norm = 0.1841 cg_residual = 0.0540 step_size = 0.4596 reward = -0.0000 fps = 19 mse_loss = 3.0683 
2022-05-01 04:05:27.744185 - gail/main.py:164 - [TRPO] iter = 84000 dist_mean = 0.0818 dist_std = 0.4293 vf_loss = 0.1943 grad_norm = 1.6611 nat_grad_norm = 0.2152 cg_residual = 0.0604 step_size = 0.4350 reward = -0.0000 fps = 16 mse_loss = 3.0643 
2022-05-01 04:05:37.713040 - gail/main.py:164 - [TRPO] iter = 85000 dist_mean = 0.0390 dist_std = 0.4270 vf_loss = 0.1238 grad_norm = 1.6380 nat_grad_norm = 0.1887 cg_residual = 0.1048 step_size = 0.4829 reward = 0.0000 fps = 14 mse_loss = 3.1601 
2022-05-01 04:05:37.918403 - gail/main.py:191 - [Discriminator] iter = 85000 loss = -1.0619 grad_norm = 3.5435 grad_penalty = 0.2290 regularization = 0.0000 true_logits = -0.0498 fake_logits = -1.3407 true_prob = 0.4953 fake_prob = 0.2304 
2022-05-01 04:05:58.622559 - gail/main.py:132 - [Evaluate] iter = 85000 episode={ returns = 489.1695 lengths = 156 } discounted_episode={ returns = 446.8715 lengths = 156 } 
2022-05-01 04:06:08.210822 - gail/main.py:164 - [TRPO] iter = 86000 dist_mean = 0.0530 dist_std = 0.4270 vf_loss = 0.1631 grad_norm = 0.8289 nat_grad_norm = 0.2725 cg_residual = 0.1346 step_size = 0.4502 reward = -0.0000 fps = 33 mse_loss = 3.3124 
2022-05-01 04:06:18.079267 - gail/main.py:164 - [TRPO] iter = 87000 dist_mean = 0.0640 dist_std = 0.4236 vf_loss = 0.1320 grad_norm = 1.3159 nat_grad_norm = 0.2064 cg_residual = 0.0701 step_size = 0.4928 reward = -0.0000 fps = 24 mse_loss = 3.1796 
2022-05-01 04:06:27.515110 - gail/main.py:164 - [TRPO] iter = 88000 dist_mean = 0.0324 dist_std = 0.4193 vf_loss = 0.1328 grad_norm = 1.9559 nat_grad_norm = 0.2172 cg_residual = 0.0746 step_size = 0.4551 reward = 0.0000 fps = 20 mse_loss = 3.2045 
2022-05-01 04:06:37.592959 - gail/main.py:164 - [TRPO] iter = 89000 dist_mean = 0.0376 dist_std = 0.4119 vf_loss = 0.2111 grad_norm = 1.9071 nat_grad_norm = 0.1963 cg_residual = 0.1099 step_size = 0.4301 reward = -0.0000 fps = 16 mse_loss = 3.0586 
2022-05-01 04:06:47.432929 - gail/main.py:164 - [TRPO] iter = 90000 dist_mean = 0.0264 dist_std = 0.4042 vf_loss = 0.1739 grad_norm = 0.9686 nat_grad_norm = 0.2341 cg_residual = 0.1516 step_size = 0.4833 reward = -0.0000 fps = 14 mse_loss = 3.3042 
2022-05-01 04:06:47.658479 - gail/main.py:191 - [Discriminator] iter = 90000 loss = -1.0847 grad_norm = 3.6597 grad_penalty = 0.2296 regularization = 0.0000 true_logits = -0.0102 fake_logits = -1.3244 true_prob = 0.5046 fake_prob = 0.2339 
2022-05-01 04:07:10.758230 - gail/main.py:132 - [Evaluate] iter = 90000 episode={ returns = 565.1124 lengths = 172 } discounted_episode={ returns = 509.7540 lengths = 171 } 
2022-05-01 04:07:20.285683 - gail/main.py:164 - [TRPO] iter = 91000 dist_mean = 0.0433 dist_std = 0.4021 vf_loss = 0.1296 grad_norm = 1.6057 nat_grad_norm = 0.1957 cg_residual = 0.0914 step_size = 0.4499 reward = -0.0000 fps = 30 mse_loss = 3.2798 
2022-05-01 04:07:30.162202 - gail/main.py:164 - [TRPO] iter = 92000 dist_mean = 0.0371 dist_std = 0.3971 vf_loss = 0.1151 grad_norm = 1.3428 nat_grad_norm = 0.2050 cg_residual = 0.1518 step_size = 0.4857 reward = 0.0000 fps = 23 mse_loss = 3.2919 
2022-05-01 04:07:39.805112 - gail/main.py:164 - [TRPO] iter = 93000 dist_mean = 0.0259 dist_std = 0.3948 vf_loss = 0.1956 grad_norm = 1.4083 nat_grad_norm = 0.1951 cg_residual = 0.1331 step_size = 0.5602 reward = -0.0000 fps = 19 mse_loss = 3.4708 
2022-05-01 04:07:49.235495 - gail/main.py:164 - [TRPO] iter = 94000 dist_mean = 0.0332 dist_std = 0.3959 vf_loss = 0.1364 grad_norm = 0.8921 nat_grad_norm = 0.1669 cg_residual = 0.0618 step_size = 0.5845 reward = 0.0000 fps = 16 mse_loss = 3.2153 
2022-05-01 04:07:58.971279 - gail/main.py:164 - [TRPO] iter = 95000 dist_mean = 0.0279 dist_std = 0.3905 vf_loss = 0.1036 grad_norm = 0.8569 nat_grad_norm = 0.1953 cg_residual = 0.0615 step_size = 0.6003 reward = 0.0000 fps = 14 mse_loss = 3.4262 
2022-05-01 04:07:59.207210 - gail/main.py:191 - [Discriminator] iter = 95000 loss = -1.0466 grad_norm = 3.2259 grad_penalty = 0.2165 regularization = 0.0000 true_logits = -0.0374 fake_logits = -1.3005 true_prob = 0.4974 fake_prob = 0.2385 
2022-05-01 04:08:23.447317 - gail/main.py:132 - [Evaluate] iter = 95000 episode={ returns = 590.7464 lengths = 180 } discounted_episode={ returns = 529.0757 lengths = 180 } 
2022-05-01 04:08:33.172826 - gail/main.py:164 - [TRPO] iter = 96000 dist_mean = 0.0219 dist_std = 0.3920 vf_loss = 0.1354 grad_norm = 1.2914 nat_grad_norm = 0.1865 cg_residual = 0.0782 step_size = 0.5124 reward = -0.0000 fps = 29 mse_loss = 3.2155 
2022-05-01 04:08:43.007234 - gail/main.py:164 - [TRPO] iter = 97000 dist_mean = 0.0469 dist_std = 0.3891 vf_loss = 0.1924 grad_norm = 0.9757 nat_grad_norm = 0.2048 cg_residual = 0.1079 step_size = 0.5699 reward = 0.0000 fps = 22 mse_loss = 3.1138 
2022-05-01 04:08:52.877012 - gail/main.py:164 - [TRPO] iter = 98000 dist_mean = 0.0433 dist_std = 0.3908 vf_loss = 0.1417 grad_norm = 1.6025 nat_grad_norm = 0.2102 cg_residual = 0.1146 step_size = 0.4571 reward = 0.0000 fps = 18 mse_loss = 3.1402 
2022-05-01 04:09:02.606476 - gail/main.py:164 - [TRPO] iter = 99000 dist_mean = 0.0109 dist_std = 0.3923 vf_loss = 0.1152 grad_norm = 1.3206 nat_grad_norm = 0.1965 cg_residual = 0.0866 step_size = 0.4861 reward = 0.0000 fps = 15 mse_loss = 3.3943 
2022-05-01 04:09:12.073010 - gail/main.py:164 - [TRPO] iter = 100000 dist_mean = 0.0729 dist_std = 0.3872 vf_loss = 0.3682 grad_norm = 0.8963 nat_grad_norm = 0.3297 cg_residual = 0.3708 step_size = 0.3811 reward = -0.0000 fps = 13 mse_loss = 3.4061 
2022-05-01 04:09:12.284123 - gail/main.py:191 - [Discriminator] iter = 100000 loss = -1.1378 grad_norm = 3.5641 grad_penalty = 0.2230 regularization = 0.0000 true_logits = 0.0141 fake_logits = -1.3467 true_prob = 0.5094 fake_prob = 0.2347 
2022-05-01 04:09:37.439330 - gail/main.py:132 - [Evaluate] iter = 100000 episode={ returns = 601.5393 lengths = 187 } discounted_episode={ returns = 538.5613 lengths = 187 } 
2022-05-01 04:09:47.116740 - gail/main.py:164 - [TRPO] iter = 101000 dist_mean = 0.0827 dist_std = 0.3844 vf_loss = 0.1751 grad_norm = 1.4658 nat_grad_norm = 0.1841 cg_residual = 0.1088 step_size = 0.4919 reward = -0.0000 fps = 28 mse_loss = 3.3466 
2022-05-01 04:09:58.365609 - gail/main.py:164 - [TRPO] iter = 102000 dist_mean = 0.0747 dist_std = 0.3803 vf_loss = 0.1616 grad_norm = 1.7255 nat_grad_norm = 0.2328 cg_residual = 0.1546 step_size = 0.4278 reward = 0.0000 fps = 21 mse_loss = 3.3915 
2022-05-01 04:10:08.679897 - gail/main.py:164 - [TRPO] iter = 103000 dist_mean = 0.1458 dist_std = 0.3768 vf_loss = 0.3321 grad_norm = 1.3053 nat_grad_norm = 0.2852 cg_residual = 0.2040 step_size = 0.3903 reward = 0.0000 fps = 17 mse_loss = 3.2889 
2022-05-01 04:10:18.779371 - gail/main.py:164 - [TRPO] iter = 104000 dist_mean = 0.1024 dist_std = 0.3780 vf_loss = 0.3023 grad_norm = 1.3630 nat_grad_norm = 0.2192 cg_residual = 0.1459 step_size = 0.4295 reward = 0.0000 fps = 15 mse_loss = 3.2908 
2022-05-01 04:10:28.603901 - gail/main.py:164 - [TRPO] iter = 105000 dist_mean = 0.1134 dist_std = 0.3741 vf_loss = 0.3408 grad_norm = 1.2135 nat_grad_norm = 0.2717 cg_residual = 0.2301 step_size = 0.4081 reward = -0.0000 fps = 13 mse_loss = 3.1349 
2022-05-01 04:10:28.818494 - gail/main.py:191 - [Discriminator] iter = 105000 loss = -1.1513 grad_norm = 2.9474 grad_penalty = 0.2085 regularization = 0.0000 true_logits = 0.0450 fake_logits = -1.3148 true_prob = 0.5159 fake_prob = 0.2456 
2022-05-01 04:10:53.279170 - gail/main.py:132 - [Evaluate] iter = 105000 episode={ returns = 598.8091 lengths = 186 } discounted_episode={ returns = 536.9512 lengths = 186 } 
2022-05-01 04:11:03.022432 - gail/main.py:164 - [TRPO] iter = 106000 dist_mean = 0.1449 dist_std = 0.3743 vf_loss = 0.3015 grad_norm = 1.5878 nat_grad_norm = 0.1998 cg_residual = 0.1251 step_size = 0.4199 reward = 0.0000 fps = 29 mse_loss = 3.2706 
2022-05-01 04:11:12.925301 - gail/main.py:164 - [TRPO] iter = 107000 dist_mean = 0.1608 dist_std = 0.3764 vf_loss = 0.3527 grad_norm = 1.2431 nat_grad_norm = 0.1672 cg_residual = 0.0508 step_size = 0.5727 reward = -0.0000 fps = 22 mse_loss = 3.2873 
2022-05-01 04:11:22.798862 - gail/main.py:164 - [TRPO] iter = 108000 dist_mean = 0.1842 dist_std = 0.3821 vf_loss = 1.4001 grad_norm = 1.7347 nat_grad_norm = 0.2043 cg_residual = 0.1271 step_size = 0.4503 reward = 0.0000 fps = 18 mse_loss = 3.5168 
2022-05-01 04:11:32.620893 - gail/main.py:164 - [TRPO] iter = 109000 dist_mean = 0.2236 dist_std = 0.3791 vf_loss = 0.1176 grad_norm = 1.4958 nat_grad_norm = 0.2597 cg_residual = 0.1933 step_size = 0.4022 reward = -0.0000 fps = 15 mse_loss = 3.1843 
2022-05-01 04:11:42.409834 - gail/main.py:164 - [TRPO] iter = 110000 dist_mean = 0.2460 dist_std = 0.3760 vf_loss = 0.2284 grad_norm = 1.1424 nat_grad_norm = 0.2000 cg_residual = 0.0981 step_size = 0.5272 reward = 0.0000 fps = 13 mse_loss = 3.2832 
2022-05-01 04:11:42.652726 - gail/main.py:191 - [Discriminator] iter = 110000 loss = -0.9907 grad_norm = 3.5527 grad_penalty = 0.2219 regularization = 0.0000 true_logits = 0.0347 fake_logits = -1.1779 true_prob = 0.5152 fake_prob = 0.2725 
2022-05-01 04:12:07.176069 - gail/main.py:132 - [Evaluate] iter = 110000 episode={ returns = 574.5230 lengths = 183 } discounted_episode={ returns = 482.0370 lengths = 174 } 
2022-05-01 04:12:17.042719 - gail/main.py:164 - [TRPO] iter = 111000 dist_mean = 0.2035 dist_std = 0.3757 vf_loss = 0.0947 grad_norm = 1.4689 nat_grad_norm = 0.1892 cg_residual = 0.1469 step_size = 0.5248 reward = -0.0000 fps = 29 mse_loss = 3.2295 
2022-05-01 04:12:26.700700 - gail/main.py:164 - [TRPO] iter = 112000 dist_mean = 0.2316 dist_std = 0.3795 vf_loss = 0.1385 grad_norm = 1.0378 nat_grad_norm = 0.2615 cg_residual = 0.1815 step_size = 0.4265 reward = 0.0000 fps = 22 mse_loss = 3.2761 
2022-05-01 04:12:36.588660 - gail/main.py:164 - [TRPO] iter = 113000 dist_mean = 0.2940 dist_std = 0.3756 vf_loss = 0.0676 grad_norm = 1.2337 nat_grad_norm = 0.1969 cg_residual = 0.0614 step_size = 0.5034 reward = 0.0000 fps = 18 mse_loss = 3.4739 
2022-05-01 04:12:46.426762 - gail/main.py:164 - [TRPO] iter = 114000 dist_mean = 0.2178 dist_std = 0.3801 vf_loss = 0.2940 grad_norm = 1.7610 nat_grad_norm = 0.3150 cg_residual = 0.1434 step_size = 0.3195 reward = -0.0000 fps = 15 mse_loss = 3.1360 
2022-05-01 04:12:56.039977 - gail/main.py:164 - [TRPO] iter = 115000 dist_mean = 0.2895 dist_std = 0.3816 vf_loss = 0.1741 grad_norm = 0.9408 nat_grad_norm = 0.2486 cg_residual = 0.1644 step_size = 0.4370 reward = -0.0000 fps = 13 mse_loss = 3.1377 
2022-05-01 04:12:56.318547 - gail/main.py:191 - [Discriminator] iter = 115000 loss = -1.0971 grad_norm = 2.9583 grad_penalty = 0.1679 regularization = 0.0000 true_logits = 0.0335 fake_logits = -1.2314 true_prob = 0.5124 fake_prob = 0.2592 
2022-05-01 04:13:24.242143 - gail/main.py:132 - [Evaluate] iter = 115000 episode={ returns = 675.6225 lengths = 207 } discounted_episode={ returns = 599.2977 lengths = 208 } 
2022-05-01 04:13:34.051639 - gail/main.py:164 - [TRPO] iter = 116000 dist_mean = 0.2659 dist_std = 0.3825 vf_loss = 0.1039 grad_norm = 0.8112 nat_grad_norm = 0.2527 cg_residual = 0.0831 step_size = 0.5119 reward = 0.0000 fps = 26 mse_loss = 3.0996 
2022-05-01 04:13:43.825019 - gail/main.py:164 - [TRPO] iter = 117000 dist_mean = 0.2318 dist_std = 0.3777 vf_loss = 0.1077 grad_norm = 0.9390 nat_grad_norm = 0.2561 cg_residual = 0.1426 step_size = 0.4598 reward = -0.0000 fps = 21 mse_loss = 3.3365 
2022-05-01 04:13:53.988165 - gail/main.py:164 - [TRPO] iter = 118000 dist_mean = 0.2576 dist_std = 0.3769 vf_loss = 0.1436 grad_norm = 1.2882 nat_grad_norm = 0.1770 cg_residual = 0.1317 step_size = 0.4819 reward = 0.0000 fps = 17 mse_loss = 3.1337 
2022-05-01 04:14:04.073886 - gail/main.py:164 - [TRPO] iter = 119000 dist_mean = 0.2467 dist_std = 0.3764 vf_loss = 0.1063 grad_norm = 1.7116 nat_grad_norm = 0.2607 cg_residual = 0.1807 step_size = 0.3818 reward = -0.0000 fps = 14 mse_loss = 3.3928 
2022-05-01 04:14:14.035615 - gail/main.py:164 - [TRPO] iter = 120000 dist_mean = 0.2325 dist_std = 0.3738 vf_loss = 0.0704 grad_norm = 1.6296 nat_grad_norm = 0.2773 cg_residual = 0.1682 step_size = 0.3889 reward = -0.0000 fps = 12 mse_loss = 3.1097 
2022-05-01 04:14:14.259006 - gail/main.py:191 - [Discriminator] iter = 120000 loss = -1.2068 grad_norm = 3.2183 grad_penalty = 0.1793 regularization = 0.0000 true_logits = 0.1289 fake_logits = -1.2572 true_prob = 0.5324 fake_prob = 0.2519 
2022-05-01 04:14:45.209523 - gail/main.py:132 - [Evaluate] iter = 120000 episode={ returns = 746.6133 lengths = 225 } discounted_episode={ returns = 653.7002 lengths = 225 } 
2022-05-01 04:14:54.805372 - gail/main.py:164 - [TRPO] iter = 121000 dist_mean = 0.3142 dist_std = 0.3730 vf_loss = 0.1238 grad_norm = 1.4168 nat_grad_norm = 0.2162 cg_residual = 0.1404 step_size = 0.4291 reward = 0.0000 fps = 24 mse_loss = 3.3204 
2022-05-01 04:15:04.515769 - gail/main.py:164 - [TRPO] iter = 122000 dist_mean = 0.2729 dist_std = 0.3722 vf_loss = 0.1165 grad_norm = 0.8175 nat_grad_norm = 0.1906 cg_residual = 0.1018 step_size = 0.5626 reward = -0.0000 fps = 19 mse_loss = 3.1886 
2022-05-01 04:15:14.441998 - gail/main.py:164 - [TRPO] iter = 123000 dist_mean = 0.3020 dist_std = 0.3733 vf_loss = 0.1288 grad_norm = 1.0987 nat_grad_norm = 0.2519 cg_residual = 0.2140 step_size = 0.3933 reward = 0.0000 fps = 16 mse_loss = 3.3029 
2022-05-01 04:15:23.982196 - gail/main.py:164 - [TRPO] iter = 124000 dist_mean = 0.2901 dist_std = 0.3730 vf_loss = 0.1021 grad_norm = 1.3223 nat_grad_norm = 0.2335 cg_residual = 0.2149 step_size = 0.4473 reward = -0.0000 fps = 14 mse_loss = 3.3112 
2022-05-01 04:15:33.773339 - gail/main.py:164 - [TRPO] iter = 125000 dist_mean = 0.2657 dist_std = 0.3748 vf_loss = 0.1072 grad_norm = 1.7105 nat_grad_norm = 0.2849 cg_residual = 0.1696 step_size = 0.3647 reward = -0.0000 fps = 12 mse_loss = 3.1103 
2022-05-01 04:15:34.027833 - gail/main.py:191 - [Discriminator] iter = 125000 loss = -1.2396 grad_norm = 2.6272 grad_penalty = 0.1394 regularization = 0.0000 true_logits = 0.0466 fake_logits = -1.3324 true_prob = 0.5132 fake_prob = 0.2379 
2022-05-01 04:16:04.877227 - gail/main.py:132 - [Evaluate] iter = 125000 episode={ returns = 722.3963 lengths = 219 } discounted_episode={ returns = 633.8975 lengths = 218 } 
2022-05-01 04:16:14.897823 - gail/main.py:164 - [TRPO] iter = 126000 dist_mean = 0.2657 dist_std = 0.3734 vf_loss = 0.0878 grad_norm = 1.7021 nat_grad_norm = 0.2029 cg_residual = 0.1663 step_size = 0.4576 reward = 0.0000 fps = 24 mse_loss = 2.9483 
2022-05-01 04:16:25.141506 - gail/main.py:164 - [TRPO] iter = 127000 dist_mean = 0.2725 dist_std = 0.3728 vf_loss = 0.1443 grad_norm = 1.0535 nat_grad_norm = 0.2438 cg_residual = 0.1113 step_size = 0.4613 reward = 0.0000 fps = 19 mse_loss = 3.0875 
2022-05-01 04:16:36.463213 - gail/main.py:164 - [TRPO] iter = 128000 dist_mean = 0.2523 dist_std = 0.3716 vf_loss = 0.0725 grad_norm = 1.3207 nat_grad_norm = 0.3264 cg_residual = 0.4098 step_size = 0.3857 reward = -0.0000 fps = 16 mse_loss = 3.3163 
2022-05-01 04:16:46.906691 - gail/main.py:164 - [TRPO] iter = 129000 dist_mean = 0.2430 dist_std = 0.3705 vf_loss = 0.4897 grad_norm = 1.7387 nat_grad_norm = 0.2098 cg_residual = 0.2025 step_size = 0.4062 reward = 0.0000 fps = 13 mse_loss = 3.2279 
2022-05-01 04:16:57.899058 - gail/main.py:164 - [TRPO] iter = 130000 dist_mean = 0.2569 dist_std = 0.3658 vf_loss = 0.1310 grad_norm = 1.2135 nat_grad_norm = 0.2053 cg_residual = 0.2212 step_size = 0.4841 reward = -0.0000 fps = 11 mse_loss = 3.1094 
2022-05-01 04:16:58.153121 - gail/main.py:191 - [Discriminator] iter = 130000 loss = -1.1349 grad_norm = 2.4831 grad_penalty = 0.1592 regularization = 0.0000 true_logits = 0.0368 fake_logits = -1.2573 true_prob = 0.5121 fake_prob = 0.2504 
2022-05-01 04:17:31.156801 - gail/main.py:132 - [Evaluate] iter = 130000 episode={ returns = 729.6759 lengths = 222 } discounted_episode={ returns = 639.8160 lengths = 222 } 
2022-05-01 04:17:41.778796 - gail/main.py:164 - [TRPO] iter = 131000 dist_mean = 0.2553 dist_std = 0.3672 vf_loss = 0.2077 grad_norm = 1.2426 nat_grad_norm = 0.2779 cg_residual = 0.2272 step_size = 0.4172 reward = 0.0000 fps = 22 mse_loss = 3.2864 
2022-05-01 04:17:52.532984 - gail/main.py:164 - [TRPO] iter = 132000 dist_mean = 0.2715 dist_std = 0.3668 vf_loss = 0.0966 grad_norm = 1.6389 nat_grad_norm = 0.2406 cg_residual = 0.3516 step_size = 0.3970 reward = 0.0000 fps = 18 mse_loss = 3.0328 
2022-05-01 04:18:03.623325 - gail/main.py:164 - [TRPO] iter = 133000 dist_mean = 0.2429 dist_std = 0.3634 vf_loss = 0.2282 grad_norm = 0.7525 nat_grad_norm = 0.1921 cg_residual = 0.2143 step_size = 0.5323 reward = -0.0000 fps = 15 mse_loss = 3.0233 
2022-05-01 04:18:14.551212 - gail/main.py:164 - [TRPO] iter = 134000 dist_mean = 0.2580 dist_std = 0.3623 vf_loss = 0.0967 grad_norm = 1.4904 nat_grad_norm = 0.3114 cg_residual = 0.2350 step_size = 0.3568 reward = -0.0000 fps = 13 mse_loss = 2.9603 
2022-05-01 04:18:25.701246 - gail/main.py:164 - [TRPO] iter = 135000 dist_mean = 0.2560 dist_std = 0.3618 vf_loss = 0.1068 grad_norm = 1.3625 nat_grad_norm = 0.2374 cg_residual = 0.1848 step_size = 0.4542 reward = 0.0000 fps = 11 mse_loss = 3.1115 
2022-05-01 04:18:26.009612 - gail/main.py:191 - [Discriminator] iter = 135000 loss = -1.2147 grad_norm = 2.6620 grad_penalty = 0.1442 regularization = 0.0000 true_logits = 0.0325 fake_logits = -1.3265 true_prob = 0.5118 fake_prob = 0.2389 
2022-05-01 04:19:00.283376 - gail/main.py:132 - [Evaluate] iter = 135000 episode={ returns = 760.7500 lengths = 227 } discounted_episode={ returns = 664.8757 lengths = 227 } 
2022-05-01 04:19:11.102025 - gail/main.py:164 - [TRPO] iter = 136000 dist_mean = 0.2485 dist_std = 0.3607 vf_loss = 0.1428 grad_norm = 1.9499 nat_grad_norm = 0.3006 cg_residual = 0.3477 step_size = 0.2887 reward = -0.0000 fps = 22 mse_loss = 2.9965 
2022-05-01 04:19:21.943188 - gail/main.py:164 - [TRPO] iter = 137000 dist_mean = 0.2461 dist_std = 0.3575 vf_loss = 0.2821 grad_norm = 1.2028 nat_grad_norm = 0.1888 cg_residual = 0.2688 step_size = 0.5123 reward = 0.0000 fps = 17 mse_loss = 3.0293 
2022-05-01 04:19:32.851692 - gail/main.py:164 - [TRPO] iter = 138000 dist_mean = 0.3162 dist_std = 0.3596 vf_loss = 0.1757 grad_norm = 1.0165 nat_grad_norm = 0.1882 cg_residual = 0.1745 step_size = 0.5335 reward = 0.0000 fps = 14 mse_loss = 3.1796 
2022-05-01 04:19:43.869512 - gail/main.py:164 - [TRPO] iter = 139000 dist_mean = 0.2749 dist_std = 0.3570 vf_loss = 0.1307 grad_norm = 1.3920 nat_grad_norm = 0.2282 cg_residual = 0.1592 step_size = 0.4429 reward = 0.0000 fps = 12 mse_loss = 3.2826 
2022-05-01 04:19:54.501828 - gail/main.py:164 - [TRPO] iter = 140000 dist_mean = 0.2808 dist_std = 0.3574 vf_loss = 0.2575 grad_norm = 1.0896 nat_grad_norm = 0.1760 cg_residual = 0.0872 step_size = 0.5575 reward = 0.0000 fps = 11 mse_loss = 3.1712 
2022-05-01 04:19:54.772866 - gail/main.py:191 - [Discriminator] iter = 140000 loss = -1.1862 grad_norm = 2.5250 grad_penalty = 0.1347 regularization = 0.0000 true_logits = -0.0038 fake_logits = -1.3246 true_prob = 0.5035 fake_prob = 0.2413 
2022-05-01 04:20:33.790072 - gail/main.py:132 - [Evaluate] iter = 140000 episode={ returns = 881.9614 lengths = 259 } discounted_episode={ returns = 773.0629 lengths = 261 } 
2022-05-01 04:20:43.929116 - gail/main.py:164 - [TRPO] iter = 141000 dist_mean = 0.2103 dist_std = 0.3583 vf_loss = 0.2194 grad_norm = 1.6572 nat_grad_norm = 0.2688 cg_residual = 0.2219 step_size = 0.3894 reward = 0.0000 fps = 20 mse_loss = 3.1562 
2022-05-01 04:20:54.389306 - gail/main.py:164 - [TRPO] iter = 142000 dist_mean = 0.2345 dist_std = 0.3571 vf_loss = 0.2162 grad_norm = 1.2625 nat_grad_norm = 0.1898 cg_residual = 0.1245 step_size = 0.4768 reward = -0.0000 fps = 16 mse_loss = 3.1473 
2022-05-01 04:21:04.807921 - gail/main.py:164 - [TRPO] iter = 143000 dist_mean = 0.1685 dist_std = 0.3605 vf_loss = 0.0759 grad_norm = 1.3944 nat_grad_norm = 0.2962 cg_residual = 0.2079 step_size = 0.3359 reward = -0.0000 fps = 14 mse_loss = 3.1720 
2022-05-01 04:21:15.024739 - gail/main.py:164 - [TRPO] iter = 144000 dist_mean = 0.2512 dist_std = 0.3588 vf_loss = 0.0828 grad_norm = 1.6913 nat_grad_norm = 0.2159 cg_residual = 0.1969 step_size = 0.4102 reward = 0.0000 fps = 12 mse_loss = 3.0736 
2022-05-01 04:21:25.219472 - gail/main.py:164 - [TRPO] iter = 145000 dist_mean = 0.2202 dist_std = 0.3585 vf_loss = 0.1144 grad_norm = 1.2848 nat_grad_norm = 0.1844 cg_residual = 0.2700 step_size = 0.5114 reward = -0.0000 fps = 11 mse_loss = 3.0671 
2022-05-01 04:21:25.438670 - gail/main.py:191 - [Discriminator] iter = 145000 loss = -1.2330 grad_norm = 2.3606 grad_penalty = 0.1307 regularization = 0.0000 true_logits = -0.0028 fake_logits = -1.3665 true_prob = 0.5038 fake_prob = 0.2341 
2022-05-01 04:22:02.215794 - gail/main.py:132 - [Evaluate] iter = 145000 episode={ returns = 889.6034 lengths = 262 } discounted_episode={ returns = 764.3366 lengths = 262 } 
2022-05-01 04:22:12.550284 - gail/main.py:164 - [TRPO] iter = 146000 dist_mean = 0.2348 dist_std = 0.3572 vf_loss = 0.1512 grad_norm = 1.3315 nat_grad_norm = 0.2045 cg_residual = 0.1755 step_size = 0.4258 reward = 0.0000 fps = 21 mse_loss = 2.8237 
2022-05-01 04:22:22.656526 - gail/main.py:164 - [TRPO] iter = 147000 dist_mean = 0.1915 dist_std = 0.3551 vf_loss = 0.0474 grad_norm = 1.0644 nat_grad_norm = 0.2147 cg_residual = 0.1579 step_size = 0.4234 reward = 0.0000 fps = 17 mse_loss = 2.9061 
2022-05-01 04:22:32.763133 - gail/main.py:164 - [TRPO] iter = 148000 dist_mean = 0.2182 dist_std = 0.3522 vf_loss = 0.1116 grad_norm = 1.5747 nat_grad_norm = 0.2808 cg_residual = 0.2878 step_size = 0.3354 reward = 0.0000 fps = 14 mse_loss = 2.9236 
2022-05-01 04:22:43.324071 - gail/main.py:164 - [TRPO] iter = 149000 dist_mean = 0.1581 dist_std = 0.3522 vf_loss = 0.1050 grad_norm = 1.6723 nat_grad_norm = 0.2490 cg_residual = 0.1893 step_size = 0.3774 reward = -0.0000 fps = 12 mse_loss = 3.0690 
2022-05-01 04:22:53.584499 - gail/main.py:164 - [TRPO] iter = 150000 dist_mean = 0.2501 dist_std = 0.3534 vf_loss = 0.0634 grad_norm = 0.7199 nat_grad_norm = 0.2168 cg_residual = 0.0767 step_size = 0.5271 reward = 0.0000 fps = 11 mse_loss = 3.1396 
2022-05-01 04:22:53.851375 - gail/main.py:191 - [Discriminator] iter = 150000 loss = -1.2612 grad_norm = 2.5932 grad_penalty = 0.1369 regularization = 0.0000 true_logits = -0.0065 fake_logits = -1.4046 true_prob = 0.5022 fake_prob = 0.2266 
2022-05-01 04:23:28.430885 - gail/main.py:132 - [Evaluate] iter = 150000 episode={ returns = 885.7394 lengths = 253 } discounted_episode={ returns = 766.7447 lengths = 254 } 
2022-05-01 04:23:38.547914 - gail/main.py:164 - [TRPO] iter = 151000 dist_mean = 0.2505 dist_std = 0.3550 vf_loss = 0.0696 grad_norm = 1.5129 nat_grad_norm = 0.2500 cg_residual = 0.2240 step_size = 0.4244 reward = -0.0000 fps = 22 mse_loss = 3.0500 
2022-05-01 04:23:48.631612 - gail/main.py:164 - [TRPO] iter = 152000 dist_mean = 0.1377 dist_std = 0.3496 vf_loss = 0.0591 grad_norm = 1.1618 nat_grad_norm = 0.2235 cg_residual = 0.1837 step_size = 0.4354 reward = 0.0000 fps = 18 mse_loss = 2.7977 
2022-05-01 04:23:58.832903 - gail/main.py:164 - [TRPO] iter = 153000 dist_mean = 0.1753 dist_std = 0.3484 vf_loss = 0.0532 grad_norm = 1.5385 nat_grad_norm = 0.1850 cg_residual = 0.1550 step_size = 0.4485 reward = -0.0000 fps = 15 mse_loss = 2.9187 
2022-05-01 04:24:08.901425 - gail/main.py:164 - [TRPO] iter = 154000 dist_mean = 0.1844 dist_std = 0.3484 vf_loss = 0.0795 grad_norm = 1.9210 nat_grad_norm = 0.1863 cg_residual = 0.0985 step_size = 0.4286 reward = -0.0000 fps = 13 mse_loss = 3.1533 
2022-05-01 04:24:19.010178 - gail/main.py:164 - [TRPO] iter = 155000 dist_mean = 0.1807 dist_std = 0.3519 vf_loss = 0.1661 grad_norm = 1.4602 nat_grad_norm = 0.2780 cg_residual = 0.1567 step_size = 0.3926 reward = -0.0000 fps = 11 mse_loss = 3.0386 
2022-05-01 04:24:19.232154 - gail/main.py:191 - [Discriminator] iter = 155000 loss = -1.4239 grad_norm = 2.5708 grad_penalty = 0.1517 regularization = 0.0000 true_logits = 0.0566 fake_logits = -1.5189 true_prob = 0.5170 fake_prob = 0.2108 
2022-05-01 04:24:55.610629 - gail/main.py:132 - [Evaluate] iter = 155000 episode={ returns = 902.5382 lengths = 262 } discounted_episode={ returns = 774.9057 lengths = 261 } 
2022-05-01 04:25:06.177805 - gail/main.py:164 - [TRPO] iter = 156000 dist_mean = 0.1588 dist_std = 0.3545 vf_loss = 0.0814 grad_norm = 1.9911 nat_grad_norm = 0.2652 cg_residual = 0.1363 step_size = 0.3734 reward = -0.0000 fps = 21 mse_loss = 2.9444 
2022-05-01 04:25:15.846638 - gail/main.py:164 - [TRPO] iter = 157000 dist_mean = 0.2057 dist_std = 0.3523 vf_loss = 0.0603 grad_norm = 0.9811 nat_grad_norm = 0.2682 cg_residual = 0.1236 step_size = 0.4411 reward = -0.0000 fps = 17 mse_loss = 3.0756 
2022-05-01 04:25:25.875905 - gail/main.py:164 - [TRPO] iter = 158000 dist_mean = 0.1313 dist_std = 0.3526 vf_loss = 0.1073 grad_norm = 1.6031 nat_grad_norm = 0.2030 cg_residual = 0.1151 step_size = 0.4281 reward = 0.0000 fps = 15 mse_loss = 2.7360 
2022-05-01 04:25:35.951534 - gail/main.py:164 - [TRPO] iter = 159000 dist_mean = 0.1537 dist_std = 0.3521 vf_loss = 0.0696 grad_norm = 1.5904 nat_grad_norm = 0.1771 cg_residual = 0.1326 step_size = 0.4733 reward = -0.0000 fps = 13 mse_loss = 2.7873 
2022-05-01 04:25:46.164544 - gail/main.py:164 - [TRPO] iter = 160000 dist_mean = 0.1509 dist_std = 0.3488 vf_loss = 0.0582 grad_norm = 1.1807 nat_grad_norm = 0.2134 cg_residual = 0.1069 step_size = 0.4722 reward = -0.0000 fps = 11 mse_loss = 2.6060 
2022-05-01 04:25:46.375900 - gail/main.py:191 - [Discriminator] iter = 160000 loss = -1.3059 grad_norm = 2.7300 grad_penalty = 0.1432 regularization = 0.0000 true_logits = 0.0126 fake_logits = -1.4364 true_prob = 0.5067 fake_prob = 0.2252 
2022-05-01 04:26:18.580423 - gail/main.py:132 - [Evaluate] iter = 160000 episode={ returns = 736.7626 lengths = 232 } discounted_episode={ returns = 645.7000 lengths = 232 } 
2022-05-01 04:26:28.675443 - gail/main.py:164 - [TRPO] iter = 161000 dist_mean = 0.1124 dist_std = 0.3455 vf_loss = 0.1143 grad_norm = 1.4388 nat_grad_norm = 0.2254 cg_residual = 0.1663 step_size = 0.4322 reward = 0.0000 fps = 23 mse_loss = 2.7044 
2022-05-01 04:26:39.071883 - gail/main.py:164 - [TRPO] iter = 162000 dist_mean = 0.1099 dist_std = 0.3477 vf_loss = 0.1327 grad_norm = 2.0325 nat_grad_norm = 0.2864 cg_residual = 0.1875 step_size = 0.3430 reward = 0.0000 fps = 18 mse_loss = 2.5077 
2022-05-01 04:26:49.355311 - gail/main.py:164 - [TRPO] iter = 163000 dist_mean = 0.1708 dist_std = 0.3506 vf_loss = 0.0429 grad_norm = 1.5923 nat_grad_norm = 0.2045 cg_residual = 0.1340 step_size = 0.4422 reward = 0.0000 fps = 15 mse_loss = 2.7193 
2022-05-01 04:26:59.297652 - gail/main.py:164 - [TRPO] iter = 164000 dist_mean = 0.1229 dist_std = 0.3523 vf_loss = 0.0378 grad_norm = 0.9585 nat_grad_norm = 0.2566 cg_residual = 0.1119 step_size = 0.4742 reward = 0.0000 fps = 13 mse_loss = 2.7264 
2022-05-01 04:27:09.258754 - gail/main.py:164 - [TRPO] iter = 165000 dist_mean = 0.1104 dist_std = 0.3471 vf_loss = 0.1311 grad_norm = 1.1289 nat_grad_norm = 0.1874 cg_residual = 0.1193 step_size = 0.5522 reward = -0.0000 fps = 12 mse_loss = 2.7110 
2022-05-01 04:27:09.488694 - gail/main.py:191 - [Discriminator] iter = 165000 loss = -1.3914 grad_norm = 2.3520 grad_penalty = 0.1335 regularization = 0.0000 true_logits = 0.0910 fake_logits = -1.4339 true_prob = 0.5236 fake_prob = 0.2248 
2022-05-01 04:27:53.083818 - gail/main.py:132 - [Evaluate] iter = 165000 episode={ returns = 1151.1768 lengths = 329 } discounted_episode={ returns = 945.7328 lengths = 326 } 
2022-05-01 04:28:03.050168 - gail/main.py:164 - [TRPO] iter = 166000 dist_mean = 0.1712 dist_std = 0.3518 vf_loss = 0.0468 grad_norm = 1.3626 nat_grad_norm = 0.1633 cg_residual = 0.0645 step_size = 0.5118 reward = 0.0000 fps = 18 mse_loss = 2.6525 
2022-05-01 04:28:13.016335 - gail/main.py:164 - [TRPO] iter = 167000 dist_mean = 0.1742 dist_std = 0.3540 vf_loss = 0.0545 grad_norm = 1.6284 nat_grad_norm = 0.2867 cg_residual = 0.4055 step_size = 0.3347 reward = -0.0000 fps = 15 mse_loss = 2.8944 
2022-05-01 04:28:22.688139 - gail/main.py:164 - [TRPO] iter = 168000 dist_mean = 0.1731 dist_std = 0.3521 vf_loss = 0.1451 grad_norm = 1.3112 nat_grad_norm = 0.2266 cg_residual = 0.2158 step_size = 0.4349 reward = -0.0000 fps = 13 mse_loss = 2.6839 
2022-05-01 04:28:32.423242 - gail/main.py:164 - [TRPO] iter = 169000 dist_mean = 0.1338 dist_std = 0.3505 vf_loss = 0.0785 grad_norm = 0.9140 nat_grad_norm = 0.1919 cg_residual = 0.1594 step_size = 0.4983 reward = -0.0000 fps = 12 mse_loss = 2.7256 
2022-05-01 04:28:42.211070 - gail/main.py:164 - [TRPO] iter = 170000 dist_mean = 0.1749 dist_std = 0.3518 vf_loss = 0.0316 grad_norm = 1.0140 nat_grad_norm = 0.2000 cg_residual = 0.1685 step_size = 0.5369 reward = 0.0000 fps = 10 mse_loss = 2.7848 
2022-05-01 04:28:42.465580 - gail/main.py:191 - [Discriminator] iter = 170000 loss = -1.2604 grad_norm = 2.3432 grad_penalty = 0.1230 regularization = 0.0000 true_logits = 0.0403 fake_logits = -1.3431 true_prob = 0.5132 fake_prob = 0.2454 
2022-05-01 04:29:28.203101 - gail/main.py:132 - [Evaluate] iter = 170000 episode={ returns = 1167.9946 lengths = 334 } discounted_episode={ returns = 974.1406 lengths = 335 } 
2022-05-01 04:29:38.570146 - gail/main.py:164 - [TRPO] iter = 171000 dist_mean = 0.1739 dist_std = 0.3522 vf_loss = 0.0583 grad_norm = 2.3492 nat_grad_norm = 0.2525 cg_residual = 0.2737 step_size = 0.3354 reward = -0.0000 fps = 17 mse_loss = 2.5496 
2022-05-01 04:29:48.803992 - gail/main.py:164 - [TRPO] iter = 172000 dist_mean = 0.1525 dist_std = 0.3513 vf_loss = 0.0739 grad_norm = 1.0959 nat_grad_norm = 0.2280 cg_residual = 0.0695 step_size = 0.4474 reward = -0.0000 fps = 15 mse_loss = 2.4624 
2022-05-01 04:29:59.713424 - gail/main.py:164 - [TRPO] iter = 173000 dist_mean = 0.1097 dist_std = 0.3458 vf_loss = 0.0522 grad_norm = 1.4378 nat_grad_norm = 0.2332 cg_residual = 0.1681 step_size = 0.4487 reward = -0.0000 fps = 12 mse_loss = 2.5544 
2022-05-01 04:30:10.228168 - gail/main.py:164 - [TRPO] iter = 174000 dist_mean = 0.1312 dist_std = 0.3469 vf_loss = 0.0586 grad_norm = 1.3933 nat_grad_norm = 0.2063 cg_residual = 0.1784 step_size = 0.4568 reward = 0.0000 fps = 11 mse_loss = 2.3561 
2022-05-01 04:30:20.243097 - gail/main.py:164 - [TRPO] iter = 175000 dist_mean = 0.1131 dist_std = 0.3451 vf_loss = 0.0342 grad_norm = 1.6669 nat_grad_norm = 0.2400 cg_residual = 0.3428 step_size = 0.3620 reward = 0.0000 fps = 10 mse_loss = 2.5282 
2022-05-01 04:30:20.515617 - gail/main.py:191 - [Discriminator] iter = 175000 loss = -1.3636 grad_norm = 2.2497 grad_penalty = 0.1321 regularization = 0.0000 true_logits = 0.0899 fake_logits = -1.4058 true_prob = 0.5242 fake_prob = 0.2339 
2022-05-01 04:30:52.264109 - gail/main.py:132 - [Evaluate] iter = 175000 episode={ returns = 711.7054 lengths = 229 } discounted_episode={ returns = 622.6739 lengths = 227 } 
2022-05-01 04:31:02.013602 - gail/main.py:164 - [TRPO] iter = 176000 dist_mean = 0.1446 dist_std = 0.3452 vf_loss = 0.0293 grad_norm = 0.8784 nat_grad_norm = 0.1332 cg_residual = 0.0868 step_size = 0.6514 reward = -0.0000 fps = 24 mse_loss = 2.4514 
2022-05-01 04:31:11.888559 - gail/main.py:164 - [TRPO] iter = 177000 dist_mean = 0.1883 dist_std = 0.3464 vf_loss = 0.0381 grad_norm = 1.5984 nat_grad_norm = 0.1808 cg_residual = 0.1090 step_size = 0.4611 reward = 0.0000 fps = 19 mse_loss = 2.5645 
2022-05-01 04:31:21.966047 - gail/main.py:164 - [TRPO] iter = 178000 dist_mean = 0.1083 dist_std = 0.3461 vf_loss = 0.0367 grad_norm = 1.5917 nat_grad_norm = 0.2743 cg_residual = 0.2171 step_size = 0.3987 reward = -0.0000 fps = 16 mse_loss = 2.6739 
2022-05-01 04:31:31.912038 - gail/main.py:164 - [TRPO] iter = 179000 dist_mean = 0.1460 dist_std = 0.3468 vf_loss = 0.1028 grad_norm = 1.9916 nat_grad_norm = 0.2494 cg_residual = 0.1852 step_size = 0.3918 reward = 0.0000 fps = 14 mse_loss = 2.8355 
2022-05-01 04:31:42.006237 - gail/main.py:164 - [TRPO] iter = 180000 dist_mean = 0.0975 dist_std = 0.3479 vf_loss = 0.0529 grad_norm = 1.3346 nat_grad_norm = 0.2325 cg_residual = 0.1275 step_size = 0.4631 reward = -0.0000 fps = 12 mse_loss = 2.6065 
2022-05-01 04:31:42.245868 - gail/main.py:191 - [Discriminator] iter = 180000 loss = -1.4781 grad_norm = 2.3107 grad_penalty = 0.1304 regularization = 0.0000 true_logits = 0.1678 fake_logits = -1.4407 true_prob = 0.5414 fake_prob = 0.2266 
2022-05-01 04:32:03.127365 - gail/main.py:132 - [Evaluate] iter = 180000 episode={ returns = 422.8399 lengths = 151 } discounted_episode={ returns = 389.5409 lengths = 151 } 
2022-05-01 04:32:13.083097 - gail/main.py:164 - [TRPO] iter = 181000 dist_mean = 0.0795 dist_std = 0.3487 vf_loss = 0.0509 grad_norm = 1.3139 nat_grad_norm = 0.1997 cg_residual = 0.1503 step_size = 0.4771 reward = 0.0000 fps = 32 mse_loss = 2.6339 
2022-05-01 04:32:23.081690 - gail/main.py:164 - [TRPO] iter = 182000 dist_mean = 0.1039 dist_std = 0.3478 vf_loss = 0.0553 grad_norm = 0.7504 nat_grad_norm = 0.2488 cg_residual = 0.1716 step_size = 0.5032 reward = -0.0000 fps = 24 mse_loss = 2.4970 
2022-05-01 04:32:33.245785 - gail/main.py:164 - [TRPO] iter = 183000 dist_mean = 0.0811 dist_std = 0.3427 vf_loss = 0.0468 grad_norm = 1.5244 nat_grad_norm = 0.2389 cg_residual = 0.0950 step_size = 0.4489 reward = -0.0000 fps = 19 mse_loss = 2.6304 
2022-05-01 04:32:43.514898 - gail/main.py:164 - [TRPO] iter = 184000 dist_mean = 0.0700 dist_std = 0.3383 vf_loss = 0.0273 grad_norm = 0.9842 nat_grad_norm = 0.1643 cg_residual = 0.0742 step_size = 0.6124 reward = 0.0000 fps = 16 mse_loss = 2.7828 
2022-05-01 04:32:53.786675 - gail/main.py:164 - [TRPO] iter = 185000 dist_mean = 0.0820 dist_std = 0.3395 vf_loss = 0.0353 grad_norm = 1.6912 nat_grad_norm = 0.1585 cg_residual = 0.1309 step_size = 0.4959 reward = 0.0000 fps = 13 mse_loss = 2.6934 
2022-05-01 04:32:54.032504 - gail/main.py:191 - [Discriminator] iter = 185000 loss = -1.3181 grad_norm = 2.7066 grad_penalty = 0.1390 regularization = 0.0000 true_logits = 0.1806 fake_logits = -1.2765 true_prob = 0.5428 fake_prob = 0.2572 
2022-05-01 04:33:14.322946 - gail/main.py:132 - [Evaluate] iter = 185000 episode={ returns = 403.7922 lengths = 146 } discounted_episode={ returns = 371.0495 lengths = 146 } 
2022-05-01 04:33:24.567192 - gail/main.py:164 - [TRPO] iter = 186000 dist_mean = 0.0873 dist_std = 0.3362 vf_loss = 0.0781 grad_norm = 1.6334 nat_grad_norm = 0.2260 cg_residual = 0.1431 step_size = 0.4139 reward = -0.0000 fps = 32 mse_loss = 2.6204 
2022-05-01 04:33:34.726623 - gail/main.py:164 - [TRPO] iter = 187000 dist_mean = 0.0537 dist_std = 0.3372 vf_loss = 0.0467 grad_norm = 1.2473 nat_grad_norm = 0.2465 cg_residual = 0.3564 step_size = 0.4039 reward = -0.0000 fps = 24 mse_loss = 2.9747 
2022-05-01 04:33:44.858984 - gail/main.py:164 - [TRPO] iter = 188000 dist_mean = 0.0900 dist_std = 0.3357 vf_loss = 0.0229 grad_norm = 1.0047 nat_grad_norm = 0.1681 cg_residual = 0.1495 step_size = 0.5731 reward = 0.0000 fps = 19 mse_loss = 2.7360 
2022-05-01 04:33:54.895665 - gail/main.py:164 - [TRPO] iter = 189000 dist_mean = 0.0694 dist_std = 0.3360 vf_loss = 0.0544 grad_norm = 1.4595 nat_grad_norm = 0.2248 cg_residual = 0.2322 step_size = 0.4745 reward = -0.0000 fps = 16 mse_loss = 2.9491 
2022-05-01 04:34:04.953301 - gail/main.py:164 - [TRPO] iter = 190000 dist_mean = 0.0765 dist_std = 0.3360 vf_loss = 0.0479 grad_norm = 1.0742 nat_grad_norm = 0.1576 cg_residual = 0.0905 step_size = 0.5904 reward = 0.0000 fps = 14 mse_loss = 3.0855 
2022-05-01 04:34:05.187062 - gail/main.py:191 - [Discriminator] iter = 190000 loss = -1.4142 grad_norm = 2.5815 grad_penalty = 0.1320 regularization = 0.0000 true_logits = 0.2838 fake_logits = -1.2625 true_prob = 0.5634 fake_prob = 0.2580 
2022-05-01 04:34:25.290024 - gail/main.py:132 - [Evaluate] iter = 190000 episode={ returns = 400.1715 lengths = 145 } discounted_episode={ returns = 367.7479 lengths = 145 } 
2022-05-01 04:34:35.469419 - gail/main.py:164 - [TRPO] iter = 191000 dist_mean = 0.1083 dist_std = 0.3361 vf_loss = 0.0849 grad_norm = 1.3803 nat_grad_norm = 0.2257 cg_residual = 0.1551 step_size = 0.4470 reward = 0.0000 fps = 33 mse_loss = 2.9893 
2022-05-01 04:34:45.580668 - gail/main.py:164 - [TRPO] iter = 192000 dist_mean = 0.0897 dist_std = 0.3331 vf_loss = 0.0330 grad_norm = 1.1751 nat_grad_norm = 0.2127 cg_residual = 0.0955 step_size = 0.5090 reward = -0.0000 fps = 24 mse_loss = 3.1641 
2022-05-01 04:34:55.536139 - gail/main.py:164 - [TRPO] iter = 193000 dist_mean = 0.0773 dist_std = 0.3323 vf_loss = 0.0664 grad_norm = 1.1219 nat_grad_norm = 0.1658 cg_residual = 0.0854 step_size = 0.6060 reward = -0.0000 fps = 19 mse_loss = 3.0782 
2022-05-01 04:35:05.293405 - gail/main.py:164 - [TRPO] iter = 194000 dist_mean = 0.0714 dist_std = 0.3328 vf_loss = 0.0208 grad_norm = 1.0975 nat_grad_norm = 0.2798 cg_residual = 0.2614 step_size = 0.4408 reward = -0.0000 fps = 16 mse_loss = 2.8583 
2022-05-01 04:35:15.432690 - gail/main.py:164 - [TRPO] iter = 195000 dist_mean = 0.0703 dist_std = 0.3301 vf_loss = 0.0413 grad_norm = 1.4075 nat_grad_norm = 0.1759 cg_residual = 0.0883 step_size = 0.4857 reward = -0.0000 fps = 14 mse_loss = 2.9161 
2022-05-01 04:35:15.654911 - gail/main.py:191 - [Discriminator] iter = 195000 loss = -1.5076 grad_norm = 2.2570 grad_penalty = 0.1297 regularization = 0.0000 true_logits = 0.4534 fake_logits = -1.1840 true_prob = 0.5967 fake_prob = 0.2730 
2022-05-01 04:35:36.429261 - gail/main.py:132 - [Evaluate] iter = 195000 episode={ returns = 410.4582 lengths = 145 } discounted_episode={ returns = 377.3955 lengths = 145 } 
2022-05-01 04:35:46.613995 - gail/main.py:164 - [TRPO] iter = 196000 dist_mean = 0.0385 dist_std = 0.3320 vf_loss = 0.1018 grad_norm = 1.1973 nat_grad_norm = 0.2400 cg_residual = 0.4445 step_size = 0.4359 reward = -0.0000 fps = 32 mse_loss = 2.9867 
2022-05-01 04:35:56.817671 - gail/main.py:164 - [TRPO] iter = 197000 dist_mean = 0.0788 dist_std = 0.3296 vf_loss = 0.1030 grad_norm = 1.2768 nat_grad_norm = 0.1599 cg_residual = 0.1481 step_size = 0.4909 reward = 0.0000 fps = 24 mse_loss = 3.2182 
2022-05-01 04:36:06.620558 - gail/main.py:164 - [TRPO] iter = 198000 dist_mean = 0.0441 dist_std = 0.3300 vf_loss = 0.0418 grad_norm = 2.3311 nat_grad_norm = 0.3582 cg_residual = 0.6241 step_size = 0.2510 reward = -0.0000 fps = 19 mse_loss = 2.7391 
2022-05-01 04:36:16.634066 - gail/main.py:164 - [TRPO] iter = 199000 dist_mean = 0.0494 dist_std = 0.3271 vf_loss = 0.0327 grad_norm = 0.9654 nat_grad_norm = 0.1564 cg_residual = 0.0986 step_size = 0.5887 reward = -0.0000 fps = 16 mse_loss = 2.7993 
2022-05-01 04:36:26.556322 - gail/main.py:164 - [TRPO] iter = 200000 dist_mean = 0.0754 dist_std = 0.3289 vf_loss = 0.1333 grad_norm = 1.6443 nat_grad_norm = 0.1661 cg_residual = 0.0906 step_size = 0.5057 reward = -0.0000 fps = 14 mse_loss = 3.0941 
2022-05-01 04:36:26.783768 - gail/main.py:191 - [Discriminator] iter = 200000 loss = -1.4556 grad_norm = 2.3315 grad_penalty = 0.1187 regularization = 0.0000 true_logits = 0.4491 fake_logits = -1.1252 true_prob = 0.5926 fake_prob = 0.2838 
2022-05-01 04:36:47.403327 - gail/main.py:132 - [Evaluate] iter = 200000 episode={ returns = 406.2262 lengths = 146 } discounted_episode={ returns = 373.8958 lengths = 146 } 
2022-05-01 04:36:57.833793 - gail/main.py:164 - [TRPO] iter = 201000 dist_mean = 0.0515 dist_std = 0.3223 vf_loss = 0.1643 grad_norm = 1.3492 nat_grad_norm = 0.2028 cg_residual = 0.1917 step_size = 0.4631 reward = -0.0000 fps = 32 mse_loss = 2.9155 
2022-05-01 04:37:08.019530 - gail/main.py:164 - [TRPO] iter = 202000 dist_mean = 0.0544 dist_std = 0.3255 vf_loss = 0.0319 grad_norm = 1.0427 nat_grad_norm = 0.1342 cg_residual = 0.0966 step_size = 0.5960 reward = -0.0000 fps = 24 mse_loss = 2.9729 
2022-05-01 04:37:17.911618 - gail/main.py:164 - [TRPO] iter = 203000 dist_mean = 0.0123 dist_std = 0.3258 vf_loss = 0.0743 grad_norm = 0.8894 nat_grad_norm = 0.2049 cg_residual = 0.1977 step_size = 0.4846 reward = -0.0000 fps = 19 mse_loss = 2.9455 
2022-05-01 04:37:28.017203 - gail/main.py:164 - [TRPO] iter = 204000 dist_mean = 0.0851 dist_std = 0.3275 vf_loss = 0.1468 grad_norm = 1.3591 nat_grad_norm = 0.2404 cg_residual = 0.1737 step_size = 0.4521 reward = -0.0000 fps = 16 mse_loss = 3.0144 
2022-05-01 04:37:38.297057 - gail/main.py:164 - [TRPO] iter = 205000 dist_mean = 0.0340 dist_std = 0.3240 vf_loss = 0.0607 grad_norm = 1.1248 nat_grad_norm = 0.1916 cg_residual = 0.1778 step_size = 0.5463 reward = 0.0000 fps = 13 mse_loss = 2.8977 
2022-05-01 04:37:38.544538 - gail/main.py:191 - [Discriminator] iter = 205000 loss = -1.5117 grad_norm = 2.1236 grad_penalty = 0.1172 regularization = 0.0000 true_logits = 0.5972 fake_logits = -1.0317 true_prob = 0.6231 fake_prob = 0.3014 
2022-05-01 04:37:58.311043 - gail/main.py:132 - [Evaluate] iter = 205000 episode={ returns = 403.3046 lengths = 143 } discounted_episode={ returns = 371.9227 lengths = 143 } 
2022-05-01 04:38:08.372276 - gail/main.py:164 - [TRPO] iter = 206000 dist_mean = 0.0280 dist_std = 0.3204 vf_loss = 0.1420 grad_norm = 2.0801 nat_grad_norm = 0.2079 cg_residual = 0.1664 step_size = 0.4093 reward = 0.0000 fps = 33 mse_loss = 2.7897 
2022-05-01 04:38:18.351776 - gail/main.py:164 - [TRPO] iter = 207000 dist_mean = 0.0466 dist_std = 0.3198 vf_loss = 0.0368 grad_norm = 1.5646 nat_grad_norm = 0.2305 cg_residual = 0.2387 step_size = 0.4536 reward = 0.0000 fps = 25 mse_loss = 2.8855 
2022-05-01 04:38:28.240743 - gail/main.py:164 - [TRPO] iter = 208000 dist_mean = 0.0433 dist_std = 0.3165 vf_loss = 0.0943 grad_norm = 1.7896 nat_grad_norm = 0.2576 cg_residual = 0.2745 step_size = 0.3325 reward = -0.0000 fps = 20 mse_loss = 3.0079 
2022-05-01 04:38:38.073222 - gail/main.py:164 - [TRPO] iter = 209000 dist_mean = 0.0584 dist_std = 0.3178 vf_loss = 0.0415 grad_norm = 1.2958 nat_grad_norm = 0.1606 cg_residual = 0.1128 step_size = 0.5088 reward = 0.0000 fps = 16 mse_loss = 2.7674 
2022-05-01 04:38:48.199901 - gail/main.py:164 - [TRPO] iter = 210000 dist_mean = 0.0790 dist_std = 0.3172 vf_loss = 0.1254 grad_norm = 1.2609 nat_grad_norm = 0.2516 cg_residual = 0.2622 step_size = 0.4142 reward = 0.0000 fps = 14 mse_loss = 3.0093 
2022-05-01 04:38:48.432303 - gail/main.py:191 - [Discriminator] iter = 210000 loss = -1.5284 grad_norm = 2.5233 grad_penalty = 0.1149 regularization = 0.0000 true_logits = 0.6658 fake_logits = -0.9776 true_prob = 0.6319 fake_prob = 0.3115 
2022-05-01 04:39:07.749192 - gail/main.py:132 - [Evaluate] iter = 210000 episode={ returns = 391.5699 lengths = 139 } discounted_episode={ returns = 360.1502 lengths = 138 } 
2022-05-01 04:39:17.409321 - gail/main.py:164 - [TRPO] iter = 211000 dist_mean = 0.0809 dist_std = 0.3135 vf_loss = 0.0481 grad_norm = 1.4738 nat_grad_norm = 0.1180 cg_residual = 0.0967 step_size = 0.5083 reward = 0.0000 fps = 34 mse_loss = 2.8214 
2022-05-01 04:39:27.620756 - gail/main.py:164 - [TRPO] iter = 212000 dist_mean = 0.1058 dist_std = 0.3139 vf_loss = 0.0754 grad_norm = 1.4170 nat_grad_norm = 0.1838 cg_residual = 0.1535 step_size = 0.4660 reward = -0.0000 fps = 25 mse_loss = 2.7830 
2022-05-01 04:39:37.977343 - gail/main.py:164 - [TRPO] iter = 213000 dist_mean = 0.0533 dist_std = 0.3133 vf_loss = 0.0553 grad_norm = 1.9480 nat_grad_norm = 0.1442 cg_residual = 0.1361 step_size = 0.4882 reward = -0.0000 fps = 20 mse_loss = 2.8167 
2022-05-01 04:39:47.706902 - gail/main.py:164 - [TRPO] iter = 214000 dist_mean = 0.1229 dist_std = 0.3090 vf_loss = 0.0755 grad_norm = 1.3049 nat_grad_norm = 0.1698 cg_residual = 0.1104 step_size = 0.5409 reward = 0.0000 fps = 16 mse_loss = 2.8956 
2022-05-01 04:39:58.034609 - gail/main.py:164 - [TRPO] iter = 215000 dist_mean = 0.1119 dist_std = 0.3046 vf_loss = 0.1826 grad_norm = 1.7030 nat_grad_norm = 0.1663 cg_residual = 0.2707 step_size = 0.4628 reward = -0.0000 fps = 14 mse_loss = 3.0757 
2022-05-01 04:39:58.255891 - gail/main.py:191 - [Discriminator] iter = 215000 loss = -1.4608 grad_norm = 2.5886 grad_penalty = 0.1187 regularization = 0.0000 true_logits = 0.6577 fake_logits = -0.9217 true_prob = 0.6287 fake_prob = 0.3256 
2022-05-01 04:40:20.887879 - gail/main.py:132 - [Evaluate] iter = 215000 episode={ returns = 504.1630 lengths = 162 } discounted_episode={ returns = 460.4552 lengths = 163 } 
2022-05-01 04:40:31.065845 - gail/main.py:164 - [TRPO] iter = 216000 dist_mean = 0.1218 dist_std = 0.3030 vf_loss = 0.2445 grad_norm = 1.7538 nat_grad_norm = 0.2160 cg_residual = 0.2483 step_size = 0.4678 reward = -0.0000 fps = 30 mse_loss = 3.0343 
2022-05-01 04:40:41.085830 - gail/main.py:164 - [TRPO] iter = 217000 dist_mean = 0.1248 dist_std = 0.3020 vf_loss = 0.0578 grad_norm = 1.7068 nat_grad_norm = 0.1144 cg_residual = 0.1676 step_size = 0.5930 reward = 0.0000 fps = 23 mse_loss = 3.1282 
2022-05-01 04:40:51.167646 - gail/main.py:164 - [TRPO] iter = 218000 dist_mean = 0.1134 dist_std = 0.3001 vf_loss = 0.0944 grad_norm = 1.3377 nat_grad_norm = 0.1634 cg_residual = 0.3799 step_size = 0.5263 reward = 0.0000 fps = 18 mse_loss = 2.9326 
2022-05-01 04:41:01.664346 - gail/main.py:164 - [TRPO] iter = 219000 dist_mean = 0.1095 dist_std = 0.3002 vf_loss = 0.0567 grad_norm = 1.7445 nat_grad_norm = 0.1825 cg_residual = 0.1829 step_size = 0.4203 reward = 0.0000 fps = 15 mse_loss = 3.1430 
2022-05-01 04:41:11.954514 - gail/main.py:164 - [TRPO] iter = 220000 dist_mean = 0.1205 dist_std = 0.3009 vf_loss = 0.0433 grad_norm = 1.5194 nat_grad_norm = 0.1823 cg_residual = 0.2248 step_size = 0.4840 reward = 0.0000 fps = 13 mse_loss = 3.1880 
2022-05-01 04:41:12.162808 - gail/main.py:191 - [Discriminator] iter = 220000 loss = -1.3579 grad_norm = 2.3153 grad_penalty = 0.0970 regularization = 0.0000 true_logits = 0.5924 fake_logits = -0.8625 true_prob = 0.6180 fake_prob = 0.3361 
2022-05-01 04:41:36.258096 - gail/main.py:132 - [Evaluate] iter = 220000 episode={ returns = 550.6297 lengths = 172 } discounted_episode={ returns = 498.0501 lengths = 172 } 
2022-05-01 04:41:46.176045 - gail/main.py:164 - [TRPO] iter = 221000 dist_mean = 0.0850 dist_std = 0.3026 vf_loss = 0.0499 grad_norm = 1.3900 nat_grad_norm = 0.1394 cg_residual = 0.1267 step_size = 0.5082 reward = 0.0000 fps = 29 mse_loss = 3.0509 
2022-05-01 04:41:56.161577 - gail/main.py:164 - [TRPO] iter = 222000 dist_mean = 0.1378 dist_std = 0.3005 vf_loss = 0.2252 grad_norm = 1.1772 nat_grad_norm = 0.2203 cg_residual = 0.2710 step_size = 0.4107 reward = -0.0000 fps = 22 mse_loss = 3.0556 
2022-05-01 04:42:06.176233 - gail/main.py:164 - [TRPO] iter = 223000 dist_mean = 0.1017 dist_std = 0.2976 vf_loss = 0.1262 grad_norm = 1.7918 nat_grad_norm = 0.2199 cg_residual = 0.4132 step_size = 0.4237 reward = 0.0000 fps = 18 mse_loss = 3.1216 
2022-05-01 04:42:16.676182 - gail/main.py:164 - [TRPO] iter = 224000 dist_mean = 0.1000 dist_std = 0.2963 vf_loss = 0.0689 grad_norm = 1.5613 nat_grad_norm = 0.1563 cg_residual = 0.1242 step_size = 0.5474 reward = 0.0000 fps = 15 mse_loss = 3.2803 
2022-05-01 04:42:26.656744 - gail/main.py:164 - [TRPO] iter = 225000 dist_mean = 0.0977 dist_std = 0.2917 vf_loss = 0.0639 grad_norm = 1.4485 nat_grad_norm = 0.2227 cg_residual = 0.2289 step_size = 0.4041 reward = 0.0000 fps = 13 mse_loss = 3.1520 
2022-05-01 04:42:26.940893 - gail/main.py:191 - [Discriminator] iter = 225000 loss = -1.3522 grad_norm = 2.4724 grad_penalty = 0.1016 regularization = 0.0000 true_logits = 0.5406 fake_logits = -0.9132 true_prob = 0.6046 fake_prob = 0.3286 
2022-05-01 04:42:51.755836 - gail/main.py:132 - [Evaluate] iter = 225000 episode={ returns = 556.9513 lengths = 173 } discounted_episode={ returns = 501.8932 lengths = 173 } 
2022-05-01 04:43:01.849004 - gail/main.py:164 - [TRPO] iter = 226000 dist_mean = 0.0991 dist_std = 0.2888 vf_loss = 0.0574 grad_norm = 1.4582 nat_grad_norm = 0.1765 cg_residual = 0.2462 step_size = 0.4370 reward = 0.0000 fps = 28 mse_loss = 3.1269 
2022-05-01 04:43:12.265525 - gail/main.py:164 - [TRPO] iter = 227000 dist_mean = 0.1345 dist_std = 0.2870 vf_loss = 0.0922 grad_norm = 1.3476 nat_grad_norm = 0.1509 cg_residual = 0.1959 step_size = 0.5050 reward = -0.0000 fps = 22 mse_loss = 3.1363 
2022-05-01 04:43:22.551261 - gail/main.py:164 - [TRPO] iter = 228000 dist_mean = 0.1541 dist_std = 0.2861 vf_loss = 0.1306 grad_norm = 2.1143 nat_grad_norm = 0.1208 cg_residual = 0.1300 step_size = 0.5389 reward = 0.0000 fps = 17 mse_loss = 3.2332 
2022-05-01 04:43:33.144098 - gail/main.py:164 - [TRPO] iter = 229000 dist_mean = 0.1233 dist_std = 0.2849 vf_loss = 0.1036 grad_norm = 1.7996 nat_grad_norm = 0.1235 cg_residual = 0.2686 step_size = 0.5342 reward = 0.0000 fps = 15 mse_loss = 3.0516 
2022-05-01 04:43:43.380266 - gail/main.py:164 - [TRPO] iter = 230000 dist_mean = 0.1064 dist_std = 0.2825 vf_loss = 0.0638 grad_norm = 2.1393 nat_grad_norm = 0.1768 cg_residual = 0.1849 step_size = 0.4861 reward = -0.0000 fps = 13 mse_loss = 3.4666 
2022-05-01 04:43:43.624078 - gail/main.py:191 - [Discriminator] iter = 230000 loss = -1.3744 grad_norm = 2.1247 grad_penalty = 0.0989 regularization = 0.0000 true_logits = 0.6358 fake_logits = -0.8375 true_prob = 0.6246 fake_prob = 0.3439 
2022-05-01 04:44:08.050036 - gail/main.py:132 - [Evaluate] iter = 230000 episode={ returns = 555.7395 lengths = 173 } discounted_episode={ returns = 502.5630 lengths = 174 } 
2022-05-01 04:44:18.276905 - gail/main.py:164 - [TRPO] iter = 231000 dist_mean = 0.0922 dist_std = 0.2780 vf_loss = 0.0415 grad_norm = 1.5033 nat_grad_norm = 0.1485 cg_residual = 0.1959 step_size = 0.5277 reward = 0.0000 fps = 28 mse_loss = 3.3034 
2022-05-01 04:44:28.390439 - gail/main.py:164 - [TRPO] iter = 232000 dist_mean = 0.1532 dist_std = 0.2755 vf_loss = 0.1580 grad_norm = 2.1631 nat_grad_norm = 0.1290 cg_residual = 0.2376 step_size = 0.4920 reward = 0.0000 fps = 22 mse_loss = 3.1365 
2022-05-01 04:44:38.592064 - gail/main.py:164 - [TRPO] iter = 233000 dist_mean = 0.1268 dist_std = 0.2749 vf_loss = 0.0262 grad_norm = 1.4792 nat_grad_norm = 0.1467 cg_residual = 0.2039 step_size = 0.5641 reward = -0.0000 fps = 18 mse_loss = 2.9093 
2022-05-01 04:44:49.095015 - gail/main.py:164 - [TRPO] iter = 234000 dist_mean = 0.1358 dist_std = 0.2754 vf_loss = 0.1130 grad_norm = 1.7716 nat_grad_norm = 0.1311 cg_residual = 0.2348 step_size = 0.5690 reward = 0.0000 fps = 15 mse_loss = 2.9606 
2022-05-01 04:44:59.294557 - gail/main.py:164 - [TRPO] iter = 235000 dist_mean = 0.1255 dist_std = 0.2757 vf_loss = 0.0407 grad_norm = 1.7339 nat_grad_norm = 0.1808 cg_residual = 0.3813 step_size = 0.4311 reward = -0.0000 fps = 13 mse_loss = 2.9554 
2022-05-01 04:44:59.520103 - gail/main.py:191 - [Discriminator] iter = 235000 loss = -1.3929 grad_norm = 2.2894 grad_penalty = 0.1028 regularization = 0.0000 true_logits = 0.6236 fake_logits = -0.8720 true_prob = 0.6199 fake_prob = 0.3387 
2022-05-01 04:45:23.768396 - gail/main.py:132 - [Evaluate] iter = 235000 episode={ returns = 554.1548 lengths = 174 } discounted_episode={ returns = 500.2640 lengths = 174 } 
2022-05-01 04:45:33.923790 - gail/main.py:164 - [TRPO] iter = 236000 dist_mean = 0.1369 dist_std = 0.2768 vf_loss = 0.0560 grad_norm = 1.9049 nat_grad_norm = 0.1636 cg_residual = 0.2659 step_size = 0.4414 reward = 0.0000 fps = 29 mse_loss = 3.0588 
2022-05-01 04:45:44.079231 - gail/main.py:164 - [TRPO] iter = 237000 dist_mean = 0.1125 dist_std = 0.2767 vf_loss = 0.0489 grad_norm = 1.5868 nat_grad_norm = 0.1616 cg_residual = 0.3238 step_size = 0.4714 reward = -0.0000 fps = 22 mse_loss = 2.9118 
2022-05-01 04:45:53.992604 - gail/main.py:164 - [TRPO] iter = 238000 dist_mean = 0.1377 dist_std = 0.2757 vf_loss = 0.1318 grad_norm = 1.2647 nat_grad_norm = 0.1561 cg_residual = 0.1590 step_size = 0.5801 reward = 0.0000 fps = 18 mse_loss = 3.1512 
2022-05-01 04:46:04.204833 - gail/main.py:164 - [TRPO] iter = 239000 dist_mean = 0.1435 dist_std = 0.2783 vf_loss = 0.1234 grad_norm = 1.7290 nat_grad_norm = 0.1587 cg_residual = 0.1780 step_size = 0.4704 reward = 0.0000 fps = 15 mse_loss = 2.9842 
2022-05-01 04:46:14.324745 - gail/main.py:164 - [TRPO] iter = 240000 dist_mean = 0.1372 dist_std = 0.2741 vf_loss = 0.0759 grad_norm = 1.8199 nat_grad_norm = 0.1382 cg_residual = 0.2280 step_size = 0.5023 reward = -0.0000 fps = 13 mse_loss = 2.9503 
2022-05-01 04:46:14.566637 - gail/main.py:191 - [Discriminator] iter = 240000 loss = -1.3165 grad_norm = 2.3297 grad_penalty = 0.0939 regularization = 0.0000 true_logits = 0.6061 fake_logits = -0.8043 true_prob = 0.6147 fake_prob = 0.3494 
2022-05-01 04:46:38.056380 - gail/main.py:132 - [Evaluate] iter = 240000 episode={ returns = 551.2053 lengths = 174 } discounted_episode={ returns = 497.8098 lengths = 174 } 
2022-05-01 04:46:48.103536 - gail/main.py:164 - [TRPO] iter = 241000 dist_mean = 0.1498 dist_std = 0.2732 vf_loss = 0.0495 grad_norm = 2.8919 nat_grad_norm = 0.1997 cg_residual = 0.3699 step_size = 0.3501 reward = -0.0000 fps = 29 mse_loss = 3.0703 
2022-05-01 04:46:58.272641 - gail/main.py:164 - [TRPO] iter = 242000 dist_mean = 0.1395 dist_std = 0.2708 vf_loss = 0.0665 grad_norm = 1.4102 nat_grad_norm = 0.1684 cg_residual = 0.4692 step_size = 0.4786 reward = 0.0000 fps = 22 mse_loss = 3.1702 
2022-05-01 04:47:08.537653 - gail/main.py:164 - [TRPO] iter = 243000 dist_mean = 0.1139 dist_std = 0.2715 vf_loss = 0.0686 grad_norm = 1.4439 nat_grad_norm = 0.1224 cg_residual = 0.2371 step_size = 0.6352 reward = -0.0000 fps = 18 mse_loss = 2.9082 
2022-05-01 04:47:18.209855 - gail/main.py:164 - [TRPO] iter = 244000 dist_mean = 0.1201 dist_std = 0.2741 vf_loss = 0.0409 grad_norm = 1.7304 nat_grad_norm = 0.1968 cg_residual = 0.3900 step_size = 0.4248 reward = -0.0000 fps = 15 mse_loss = 2.9989 
2022-05-01 04:47:27.977935 - gail/main.py:164 - [TRPO] iter = 245000 dist_mean = 0.1270 dist_std = 0.2725 vf_loss = 0.0649 grad_norm = 1.7516 nat_grad_norm = 0.1508 cg_residual = 0.2914 step_size = 0.5246 reward = -0.0000 fps = 13 mse_loss = 2.9894 
2022-05-01 04:47:28.199884 - gail/main.py:191 - [Discriminator] iter = 245000 loss = -1.3615 grad_norm = 2.7847 grad_penalty = 0.1040 regularization = 0.0000 true_logits = 0.5815 fake_logits = -0.8840 true_prob = 0.6137 fake_prob = 0.3356 
2022-05-01 04:47:52.621596 - gail/main.py:132 - [Evaluate] iter = 245000 episode={ returns = 562.4112 lengths = 180 } discounted_episode={ returns = 507.6547 lengths = 180 } 
2022-05-01 04:48:02.493438 - gail/main.py:164 - [TRPO] iter = 246000 dist_mean = 0.1445 dist_std = 0.2733 vf_loss = 0.0708 grad_norm = 1.2180 nat_grad_norm = 0.1545 cg_residual = 0.2934 step_size = 0.5104 reward = -0.0000 fps = 29 mse_loss = 2.9163 
2022-05-01 04:48:12.460347 - gail/main.py:164 - [TRPO] iter = 247000 dist_mean = 0.1193 dist_std = 0.2742 vf_loss = 0.1038 grad_norm = 2.7150 nat_grad_norm = 0.1370 cg_residual = 0.3126 step_size = 0.4087 reward = -0.0000 fps = 22 mse_loss = 3.0383 
2022-05-01 04:48:22.363786 - gail/main.py:164 - [TRPO] iter = 248000 dist_mean = 0.1557 dist_std = 0.2740 vf_loss = 0.1433 grad_norm = 2.0432 nat_grad_norm = 0.1447 cg_residual = 0.4094 step_size = 0.4564 reward = -0.0000 fps = 18 mse_loss = 2.8389 
2022-05-01 04:48:32.485367 - gail/main.py:164 - [TRPO] iter = 249000 dist_mean = 0.1185 dist_std = 0.2731 vf_loss = 0.2027 grad_norm = 1.3720 nat_grad_norm = 0.1355 cg_residual = 0.2054 step_size = 0.6070 reward = -0.0000 fps = 15 mse_loss = 3.0779 
2022-05-01 04:48:42.592584 - gail/main.py:164 - [TRPO] iter = 250000 dist_mean = 0.1345 dist_std = 0.2738 vf_loss = 0.1387 grad_norm = 1.4742 nat_grad_norm = 0.1546 cg_residual = 0.3308 step_size = 0.5171 reward = -0.0000 fps = 13 mse_loss = 2.8325 
2022-05-01 04:48:42.825071 - gail/main.py:191 - [Discriminator] iter = 250000 loss = -1.3170 grad_norm = 2.8559 grad_penalty = 0.1032 regularization = 0.0000 true_logits = 0.5108 fake_logits = -0.9093 true_prob = 0.6005 fake_prob = 0.3301 
2022-05-01 04:49:11.301176 - gail/main.py:132 - [Evaluate] iter = 250000 episode={ returns = 681.9338 lengths = 209 } discounted_episode={ returns = 588.2090 lengths = 204 } 
2022-05-01 04:49:20.812818 - gail/main.py:164 - [TRPO] iter = 251000 dist_mean = 0.1102 dist_std = 0.2748 vf_loss = 0.0840 grad_norm = 2.2632 nat_grad_norm = 0.2015 cg_residual = 0.5538 step_size = 0.4217 reward = 0.0000 fps = 26 mse_loss = 2.9290 
2022-05-01 04:49:30.979565 - gail/main.py:164 - [TRPO] iter = 252000 dist_mean = 0.1309 dist_std = 0.2714 vf_loss = 0.3038 grad_norm = 1.6990 nat_grad_norm = 0.1780 cg_residual = 0.5695 step_size = 0.4381 reward = 0.0000 fps = 20 mse_loss = 2.9609 
2022-05-01 04:49:40.805838 - gail/main.py:164 - [TRPO] iter = 253000 dist_mean = 0.1324 dist_std = 0.2707 vf_loss = 0.1538 grad_norm = 1.9127 nat_grad_norm = 0.1269 cg_residual = 0.3255 step_size = 0.5079 reward = 0.0000 fps = 17 mse_loss = 2.9542 
2022-05-01 04:49:50.609902 - gail/main.py:164 - [TRPO] iter = 254000 dist_mean = 0.1604 dist_std = 0.2698 vf_loss = 0.0641 grad_norm = 1.5906 nat_grad_norm = 0.2192 cg_residual = 0.8135 step_size = 0.4396 reward = 0.0000 fps = 14 mse_loss = 3.0038 
2022-05-01 04:50:00.480155 - gail/main.py:164 - [TRPO] iter = 255000 dist_mean = 0.1250 dist_std = 0.2692 vf_loss = 0.0827 grad_norm = 1.6942 nat_grad_norm = 0.1513 cg_residual = 0.4581 step_size = 0.5018 reward = 0.0000 fps = 12 mse_loss = 2.6784 
2022-05-01 04:50:00.691348 - gail/main.py:191 - [Discriminator] iter = 255000 loss = -1.2275 grad_norm = 2.2487 grad_penalty = 0.0921 regularization = 0.0000 true_logits = 0.6144 fake_logits = -0.7052 true_prob = 0.6222 fake_prob = 0.3698 
2022-05-01 04:50:25.520046 - gail/main.py:132 - [Evaluate] iter = 255000 episode={ returns = 549.3826 lengths = 177 } discounted_episode={ returns = 503.3261 lengths = 179 } 
2022-05-01 04:50:35.765496 - gail/main.py:164 - [TRPO] iter = 256000 dist_mean = 0.1174 dist_std = 0.2691 vf_loss = 0.0972 grad_norm = 1.5590 nat_grad_norm = 0.1746 cg_residual = 0.3194 step_size = 0.4760 reward = 0.0000 fps = 28 mse_loss = 3.0910 
2022-05-01 04:50:45.856179 - gail/main.py:164 - [TRPO] iter = 257000 dist_mean = 0.1247 dist_std = 0.2676 vf_loss = 0.0396 grad_norm = 1.7937 nat_grad_norm = 0.1283 cg_residual = 0.2330 step_size = 0.5392 reward = -0.0000 fps = 22 mse_loss = 2.9046 
2022-05-01 04:50:56.140362 - gail/main.py:164 - [TRPO] iter = 258000 dist_mean = 0.1236 dist_std = 0.2666 vf_loss = 0.0956 grad_norm = 1.7509 nat_grad_norm = 0.1744 cg_residual = 0.2774 step_size = 0.4606 reward = -0.0000 fps = 18 mse_loss = 3.0358 
2022-05-01 04:51:06.254760 - gail/main.py:164 - [TRPO] iter = 259000 dist_mean = 0.1556 dist_std = 0.2676 vf_loss = 0.2349 grad_norm = 2.2273 nat_grad_norm = 0.1725 cg_residual = 0.4180 step_size = 0.4261 reward = -0.0000 fps = 15 mse_loss = 2.9096 
2022-05-01 04:51:16.327347 - gail/main.py:164 - [TRPO] iter = 260000 dist_mean = 0.1566 dist_std = 0.2676 vf_loss = 0.0901 grad_norm = 1.3675 nat_grad_norm = 0.1190 cg_residual = 0.1872 step_size = 0.5528 reward = 0.0000 fps = 13 mse_loss = 3.0558 
2022-05-01 04:51:16.541703 - gail/main.py:191 - [Discriminator] iter = 260000 loss = -1.2760 grad_norm = 1.9873 grad_penalty = 0.0969 regularization = 0.0000 true_logits = 0.5501 fake_logits = -0.8228 true_prob = 0.6065 fake_prob = 0.3492 
2022-05-01 04:51:41.416174 - gail/main.py:132 - [Evaluate] iter = 260000 episode={ returns = 583.0023 lengths = 185 } discounted_episode={ returns = 523.2349 lengths = 186 } 
2022-05-01 04:51:51.081936 - gail/main.py:164 - [TRPO] iter = 261000 dist_mean = 0.1382 dist_std = 0.2681 vf_loss = 0.0640 grad_norm = 1.9391 nat_grad_norm = 0.1676 cg_residual = 0.3908 step_size = 0.4499 reward = -0.0000 fps = 28 mse_loss = 3.1191 
2022-05-01 04:52:00.682265 - gail/main.py:164 - [TRPO] iter = 262000 dist_mean = 0.1535 dist_std = 0.2653 vf_loss = 0.0485 grad_norm = 1.6564 nat_grad_norm = 0.1192 cg_residual = 0.1785 step_size = 0.5599 reward = -0.0000 fps = 22 mse_loss = 3.0388 
2022-05-01 04:52:10.555672 - gail/main.py:164 - [TRPO] iter = 263000 dist_mean = 0.1362 dist_std = 0.2639 vf_loss = 0.0405 grad_norm = 1.8696 nat_grad_norm = 0.1538 cg_residual = 0.3346 step_size = 0.4360 reward = -0.0000 fps = 18 mse_loss = 2.8190 
2022-05-01 04:52:20.471519 - gail/main.py:164 - [TRPO] iter = 264000 dist_mean = 0.1138 dist_std = 0.2666 vf_loss = 0.0546 grad_norm = 1.5472 nat_grad_norm = 0.1782 cg_residual = 0.4501 step_size = 0.4897 reward = 0.0000 fps = 15 mse_loss = 2.9162 
2022-05-01 04:52:30.448245 - gail/main.py:164 - [TRPO] iter = 265000 dist_mean = 0.1430 dist_std = 0.2663 vf_loss = 0.0706 grad_norm = 1.6532 nat_grad_norm = 0.1426 cg_residual = 0.2211 step_size = 0.5085 reward = -0.0000 fps = 13 mse_loss = 2.9919 
2022-05-01 04:52:30.648171 - gail/main.py:191 - [Discriminator] iter = 265000 loss = -1.1351 grad_norm = 2.3213 grad_penalty = 0.0919 regularization = 0.0000 true_logits = 0.5361 fake_logits = -0.6909 true_prob = 0.6042 fake_prob = 0.3717 
2022-05-01 04:52:56.050747 - gail/main.py:132 - [Evaluate] iter = 265000 episode={ returns = 567.9071 lengths = 187 } discounted_episode={ returns = 511.2219 lengths = 187 } 
2022-05-01 04:53:06.142973 - gail/main.py:164 - [TRPO] iter = 266000 dist_mean = 0.1625 dist_std = 0.2630 vf_loss = 0.0738 grad_norm = 1.6089 nat_grad_norm = 0.1311 cg_residual = 0.3177 step_size = 0.5170 reward = 0.0000 fps = 28 mse_loss = 3.1009 
2022-05-01 04:53:16.420701 - gail/main.py:164 - [TRPO] iter = 267000 dist_mean = 0.2096 dist_std = 0.2656 vf_loss = 0.0693 grad_norm = 1.7252 nat_grad_norm = 0.1774 cg_residual = 0.4316 step_size = 0.3907 reward = -0.0000 fps = 21 mse_loss = 2.9353 
2022-05-01 04:53:26.266560 - gail/main.py:164 - [TRPO] iter = 268000 dist_mean = 0.1535 dist_std = 0.2642 vf_loss = 0.1075 grad_norm = 1.7022 nat_grad_norm = 0.1505 cg_residual = 0.3319 step_size = 0.4707 reward = -0.0000 fps = 17 mse_loss = 2.8119 
2022-05-01 04:53:36.271424 - gail/main.py:164 - [TRPO] iter = 269000 dist_mean = 0.1463 dist_std = 0.2625 vf_loss = 0.4164 grad_norm = 2.0095 nat_grad_norm = 0.1525 cg_residual = 0.3259 step_size = 0.4684 reward = 0.0000 fps = 15 mse_loss = 2.7918 
2022-05-01 04:53:46.021070 - gail/main.py:164 - [TRPO] iter = 270000 dist_mean = 0.1803 dist_std = 0.2628 vf_loss = 0.3099 grad_norm = 3.0166 nat_grad_norm = 0.3191 cg_residual = 1.3670 step_size = 0.2518 reward = -0.0000 fps = 13 mse_loss = 2.8058 
2022-05-01 04:53:46.242445 - gail/main.py:191 - [Discriminator] iter = 270000 loss = -1.3626 grad_norm = 3.1362 grad_penalty = 0.0966 regularization = 0.0000 true_logits = 0.6092 fake_logits = -0.8500 true_prob = 0.6195 fake_prob = 0.3442 
2022-05-01 04:54:12.830608 - gail/main.py:132 - [Evaluate] iter = 270000 episode={ returns = 608.8795 lengths = 194 } discounted_episode={ returns = 543.7444 lengths = 194 } 
2022-05-01 04:54:22.894055 - gail/main.py:164 - [TRPO] iter = 271000 dist_mean = 0.1510 dist_std = 0.2610 vf_loss = 0.1164 grad_norm = 1.6478 nat_grad_norm = 0.1692 cg_residual = 0.3403 step_size = 0.5208 reward = 0.0000 fps = 27 mse_loss = 2.9063 
2022-05-01 04:54:33.165807 - gail/main.py:164 - [TRPO] iter = 272000 dist_mean = 0.1505 dist_std = 0.2592 vf_loss = 0.0919 grad_norm = 1.7837 nat_grad_norm = 0.1122 cg_residual = 0.4476 step_size = 0.5525 reward = -0.0000 fps = 21 mse_loss = 2.6570 
2022-05-01 04:54:43.430845 - gail/main.py:164 - [TRPO] iter = 273000 dist_mean = 0.1921 dist_std = 0.2595 vf_loss = 0.0451 grad_norm = 2.0032 nat_grad_norm = 0.1882 cg_residual = 0.7807 step_size = 0.3809 reward = 0.0000 fps = 17 mse_loss = 2.7574 
2022-05-01 04:54:53.419573 - gail/main.py:164 - [TRPO] iter = 274000 dist_mean = 0.1727 dist_std = 0.2590 vf_loss = 0.0352 grad_norm = 2.8675 nat_grad_norm = 0.1889 cg_residual = 0.5201 step_size = 0.3872 reward = -0.0000 fps = 14 mse_loss = 2.6791 
2022-05-01 04:55:03.121903 - gail/main.py:164 - [TRPO] iter = 275000 dist_mean = 0.2160 dist_std = 0.2594 vf_loss = 0.0536 grad_norm = 2.7253 nat_grad_norm = 0.1874 cg_residual = 0.5152 step_size = 0.3226 reward = 0.0000 fps = 13 mse_loss = 2.8016 
2022-05-01 04:55:03.376742 - gail/main.py:191 - [Discriminator] iter = 275000 loss = -1.5894 grad_norm = 2.3684 grad_penalty = 0.1174 regularization = 0.0000 true_logits = 0.6348 fake_logits = -1.0720 true_prob = 0.6222 fake_prob = 0.3088 
2022-05-01 04:55:25.943609 - gail/main.py:132 - [Evaluate] iter = 275000 episode={ returns = 532.2326 lengths = 167 } discounted_episode={ returns = 476.7861 lengths = 168 } 
2022-05-01 04:55:35.926928 - gail/main.py:164 - [TRPO] iter = 276000 dist_mean = 0.1565 dist_std = 0.2589 vf_loss = 0.0522 grad_norm = 1.9379 nat_grad_norm = 0.1453 cg_residual = 0.6009 step_size = 0.4510 reward = 0.0000 fps = 30 mse_loss = 2.7153 
2022-05-01 04:55:45.786442 - gail/main.py:164 - [TRPO] iter = 277000 dist_mean = 0.1430 dist_std = 0.2574 vf_loss = 0.0880 grad_norm = 1.3358 nat_grad_norm = 0.1705 cg_residual = 0.5354 step_size = 0.5433 reward = 0.0000 fps = 23 mse_loss = 2.6743 
2022-05-01 04:55:55.968014 - gail/main.py:164 - [TRPO] iter = 278000 dist_mean = 0.1771 dist_std = 0.2578 vf_loss = 0.1265 grad_norm = 1.9297 nat_grad_norm = 0.1586 cg_residual = 0.7654 step_size = 0.3855 reward = -0.0000 fps = 19 mse_loss = 2.8217 
2022-05-01 04:56:05.791193 - gail/main.py:164 - [TRPO] iter = 279000 dist_mean = 0.2043 dist_std = 0.2565 vf_loss = 0.1863 grad_norm = 1.7391 nat_grad_norm = 0.1367 cg_residual = 0.8027 step_size = 0.5136 reward = 0.0000 fps = 16 mse_loss = 2.6396 
2022-05-01 04:56:15.399682 - gail/main.py:164 - [TRPO] iter = 280000 dist_mean = 0.1908 dist_std = 0.2552 vf_loss = 0.1739 grad_norm = 1.9909 nat_grad_norm = 0.1409 cg_residual = 0.3669 step_size = 0.4723 reward = -0.0000 fps = 13 mse_loss = 2.8414 
2022-05-01 04:56:15.574070 - gail/main.py:191 - [Discriminator] iter = 280000 loss = -1.5454 grad_norm = 2.4603 grad_penalty = 0.1171 regularization = 0.0000 true_logits = 0.6665 fake_logits = -0.9960 true_prob = 0.6327 fake_prob = 0.3225 
2022-05-01 04:56:41.978844 - gail/main.py:132 - [Evaluate] iter = 280000 episode={ returns = 661.8604 lengths = 200 } discounted_episode={ returns = 555.2365 lengths = 193 } 
2022-05-01 04:56:52.169760 - gail/main.py:164 - [TRPO] iter = 281000 dist_mean = 0.1493 dist_std = 0.2559 vf_loss = 0.1011 grad_norm = 2.5156 nat_grad_norm = 0.1216 cg_residual = 0.4283 step_size = 0.4796 reward = -0.0000 fps = 27 mse_loss = 2.7456 
2022-05-01 04:57:02.226021 - gail/main.py:164 - [TRPO] iter = 282000 dist_mean = 0.1076 dist_std = 0.2567 vf_loss = 0.1243 grad_norm = 2.4382 nat_grad_norm = 0.1538 cg_residual = 0.2718 step_size = 0.4527 reward = -0.0000 fps = 21 mse_loss = 2.6050 
2022-05-01 04:57:12.298340 - gail/main.py:164 - [TRPO] iter = 283000 dist_mean = 0.1599 dist_std = 0.2564 vf_loss = 1.0396 grad_norm = 2.3644 nat_grad_norm = 0.1604 cg_residual = 0.4620 step_size = 0.3870 reward = 0.0000 fps = 17 mse_loss = 2.7263 
2022-05-01 04:57:22.103325 - gail/main.py:164 - [TRPO] iter = 284000 dist_mean = 0.0642 dist_std = 0.2550 vf_loss = 0.0508 grad_norm = 1.9895 nat_grad_norm = 0.1806 cg_residual = 0.6001 step_size = 0.4738 reward = -0.0000 fps = 15 mse_loss = 2.9709 
2022-05-01 04:57:32.138394 - gail/main.py:164 - [TRPO] iter = 285000 dist_mean = 0.1402 dist_std = 0.2526 vf_loss = 0.0863 grad_norm = 1.7009 nat_grad_norm = 0.1608 cg_residual = 0.6509 step_size = 0.4721 reward = -0.0000 fps = 13 mse_loss = 2.9663 
2022-05-01 04:57:32.391559 - gail/main.py:191 - [Discriminator] iter = 285000 loss = -1.4145 grad_norm = 2.2079 grad_penalty = 0.1066 regularization = 0.0000 true_logits = 0.6299 fake_logits = -0.8912 true_prob = 0.6240 fake_prob = 0.3463 
2022-05-01 04:58:01.932395 - gail/main.py:132 - [Evaluate] iter = 285000 episode={ returns = 752.9788 lengths = 224 } discounted_episode={ returns = 643.7138 lengths = 220 } 
2022-05-01 04:58:11.959461 - gail/main.py:164 - [TRPO] iter = 286000 dist_mean = 0.0781 dist_std = 0.2512 vf_loss = 0.1167 grad_norm = 2.7137 nat_grad_norm = 0.2234 cg_residual = 0.6627 step_size = 0.3630 reward = 0.0000 fps = 25 mse_loss = 2.9185 
2022-05-01 04:58:21.992609 - gail/main.py:164 - [TRPO] iter = 287000 dist_mean = 0.1132 dist_std = 0.2503 vf_loss = 0.0563 grad_norm = 1.8829 nat_grad_norm = 0.1674 cg_residual = 0.3849 step_size = 0.4326 reward = -0.0000 fps = 20 mse_loss = 2.7000 
2022-05-01 04:58:31.734029 - gail/main.py:164 - [TRPO] iter = 288000 dist_mean = 0.0864 dist_std = 0.2516 vf_loss = 0.0578 grad_norm = 2.8222 nat_grad_norm = 0.1596 cg_residual = 0.7513 step_size = 0.4379 reward = 0.0000 fps = 16 mse_loss = 2.7580 
2022-05-01 04:58:41.584550 - gail/main.py:164 - [TRPO] iter = 289000 dist_mean = 0.0841 dist_std = 0.2528 vf_loss = 0.0595 grad_norm = 1.9242 nat_grad_norm = 0.1535 cg_residual = 0.3652 step_size = 0.4518 reward = -0.0000 fps = 14 mse_loss = 2.8745 
2022-05-01 04:58:51.560447 - gail/main.py:164 - [TRPO] iter = 290000 dist_mean = 0.0968 dist_std = 0.2527 vf_loss = 0.0877 grad_norm = 1.8473 nat_grad_norm = 0.1302 cg_residual = 0.3579 step_size = 0.5160 reward = 0.0000 fps = 12 mse_loss = 2.6876 
2022-05-01 04:58:51.752794 - gail/main.py:191 - [Discriminator] iter = 290000 loss = -1.3514 grad_norm = 1.7879 grad_penalty = 0.0871 regularization = 0.0000 true_logits = 0.6574 fake_logits = -0.7811 true_prob = 0.6327 fake_prob = 0.3604 
2022-05-01 04:59:21.124869 - gail/main.py:132 - [Evaluate] iter = 290000 episode={ returns = 739.6494 lengths = 221 } discounted_episode={ returns = 649.0982 lengths = 221 } 
2022-05-01 04:59:31.015409 - gail/main.py:164 - [TRPO] iter = 291000 dist_mean = 0.1142 dist_std = 0.2516 vf_loss = 0.0466 grad_norm = 2.0125 nat_grad_norm = 0.1688 cg_residual = 0.3735 step_size = 0.4147 reward = -0.0000 fps = 25 mse_loss = 2.8362 
2022-05-01 04:59:40.657443 - gail/main.py:164 - [TRPO] iter = 292000 dist_mean = 0.0747 dist_std = 0.2523 vf_loss = 0.0692 grad_norm = 1.9554 nat_grad_norm = 0.1480 cg_residual = 0.3188 step_size = 0.4740 reward = 0.0000 fps = 20 mse_loss = 2.9378 
2022-05-01 04:59:50.383010 - gail/main.py:164 - [TRPO] iter = 293000 dist_mean = 0.0603 dist_std = 0.2508 vf_loss = 0.0325 grad_norm = 1.6216 nat_grad_norm = 0.1580 cg_residual = 0.4183 step_size = 0.4983 reward = 0.0000 fps = 17 mse_loss = 2.8798 
2022-05-01 04:59:59.765957 - gail/main.py:164 - [TRPO] iter = 294000 dist_mean = 0.0796 dist_std = 0.2510 vf_loss = 0.0717 grad_norm = 2.4912 nat_grad_norm = 0.1502 cg_residual = 0.3907 step_size = 0.4698 reward = -0.0000 fps = 14 mse_loss = 2.9778 
2022-05-01 05:00:09.828459 - gail/main.py:164 - [TRPO] iter = 295000 dist_mean = 0.0892 dist_std = 0.2509 vf_loss = 0.0365 grad_norm = 1.8768 nat_grad_norm = 0.1234 cg_residual = 0.2877 step_size = 0.5199 reward = 0.0000 fps = 12 mse_loss = 3.0139 
2022-05-01 05:00:10.075610 - gail/main.py:191 - [Discriminator] iter = 295000 loss = -1.1260 grad_norm = 2.5559 grad_penalty = 0.0924 regularization = 0.0000 true_logits = 0.6077 fake_logits = -0.6106 true_prob = 0.6199 fake_prob = 0.3927 
2022-05-01 05:00:45.160072 - gail/main.py:132 - [Evaluate] iter = 295000 episode={ returns = 848.4552 lengths = 254 } discounted_episode={ returns = 767.2833 lengths = 264 } 
2022-05-01 05:00:54.950250 - gail/main.py:164 - [TRPO] iter = 296000 dist_mean = 0.1040 dist_std = 0.2517 vf_loss = 0.0407 grad_norm = 1.6918 nat_grad_norm = 0.1352 cg_residual = 0.3036 step_size = 0.5052 reward = -0.0000 fps = 22 mse_loss = 2.9769 
2022-05-01 05:01:05.031692 - gail/main.py:164 - [TRPO] iter = 297000 dist_mean = 0.1286 dist_std = 0.2488 vf_loss = 0.0456 grad_norm = 2.0072 nat_grad_norm = 0.1446 cg_residual = 0.5404 step_size = 0.4206 reward = -0.0000 fps = 18 mse_loss = 2.8623 
2022-05-01 05:01:15.095829 - gail/main.py:164 - [TRPO] iter = 298000 dist_mean = 0.0765 dist_std = 0.2490 vf_loss = 0.1092 grad_norm = 2.3085 nat_grad_norm = 0.1753 cg_residual = 0.7022 step_size = 0.3964 reward = 0.0000 fps = 15 mse_loss = 3.0284 
2022-05-01 05:01:25.439060 - gail/main.py:164 - [TRPO] iter = 299000 dist_mean = 0.1104 dist_std = 0.2483 vf_loss = 0.0553 grad_norm = 1.7546 nat_grad_norm = 0.1284 cg_residual = 0.4253 step_size = 0.5385 reward = -0.0000 fps = 13 mse_loss = 2.7868 
2022-05-01 05:01:35.354675 - gail/main.py:164 - [TRPO] iter = 300000 dist_mean = 0.1392 dist_std = 0.2495 vf_loss = 0.1027 grad_norm = 1.3067 nat_grad_norm = 0.1139 cg_residual = 0.2272 step_size = 0.6355 reward = 0.0000 fps = 11 mse_loss = 2.8628 
2022-05-01 05:01:35.606420 - gail/main.py:191 - [Discriminator] iter = 300000 loss = -1.3113 grad_norm = 2.7794 grad_penalty = 0.0981 regularization = 0.0000 true_logits = 0.6167 fake_logits = -0.7927 true_prob = 0.6213 fake_prob = 0.3579 
2022-05-01 05:02:03.882706 - gail/main.py:132 - [Evaluate] iter = 300000 episode={ returns = 753.6617 lengths = 229 } discounted_episode={ returns = 560.1482 lengths = 199 } 
2022-05-01 05:02:13.700138 - gail/main.py:164 - [TRPO] iter = 301000 dist_mean = 0.0984 dist_std = 0.2487 vf_loss = 0.0782 grad_norm = 2.0884 nat_grad_norm = 0.1189 cg_residual = 0.4912 step_size = 0.5227 reward = 0.0000 fps = 26 mse_loss = 2.7666 
2022-05-01 05:02:23.480563 - gail/main.py:164 - [TRPO] iter = 302000 dist_mean = 0.0957 dist_std = 0.2473 vf_loss = 0.0425 grad_norm = 2.2239 nat_grad_norm = 0.1425 cg_residual = 0.5668 step_size = 0.4342 reward = 0.0000 fps = 20 mse_loss = 2.7078 
2022-05-01 05:02:33.436918 - gail/main.py:164 - [TRPO] iter = 303000 dist_mean = 0.1318 dist_std = 0.2489 vf_loss = 0.1269 grad_norm = 2.2211 nat_grad_norm = 0.1208 cg_residual = 0.7745 step_size = 0.5113 reward = -0.0000 fps = 17 mse_loss = 2.6588 
2022-05-01 05:02:43.349172 - gail/main.py:164 - [TRPO] iter = 304000 dist_mean = 0.0933 dist_std = 0.2495 vf_loss = 0.0803 grad_norm = 2.0762 nat_grad_norm = 0.1362 cg_residual = 0.6602 step_size = 0.4474 reward = -0.0000 fps = 14 mse_loss = 2.7881 
2022-05-01 05:02:53.169126 - gail/main.py:164 - [TRPO] iter = 305000 dist_mean = 0.0844 dist_std = 0.2487 vf_loss = 0.2108 grad_norm = 2.2694 nat_grad_norm = 0.1165 cg_residual = 0.2905 step_size = 0.5416 reward = 0.0000 fps = 12 mse_loss = 2.7911 
2022-05-01 05:02:53.401656 - gail/main.py:191 - [Discriminator] iter = 305000 loss = -1.2407 grad_norm = 2.4243 grad_penalty = 0.1006 regularization = 0.0000 true_logits = 0.6671 fake_logits = -0.6742 true_prob = 0.6293 fake_prob = 0.3828 
2022-05-01 05:03:24.682559 - gail/main.py:132 - [Evaluate] iter = 305000 episode={ returns = 747.0978 lengths = 224 } discounted_episode={ returns = 708.6714 lengths = 246 } 
2022-05-01 05:03:34.495397 - gail/main.py:164 - [TRPO] iter = 306000 dist_mean = 0.0660 dist_std = 0.2481 vf_loss = 0.0896 grad_norm = 1.3247 nat_grad_norm = 0.1459 cg_residual = 0.2965 step_size = 0.5251 reward = -0.0000 fps = 24 mse_loss = 2.6647 
2022-05-01 05:03:44.404413 - gail/main.py:164 - [TRPO] iter = 307000 dist_mean = 0.0869 dist_std = 0.2495 vf_loss = 0.2971 grad_norm = 2.5127 nat_grad_norm = 0.1385 cg_residual = 0.4138 step_size = 0.4056 reward = -0.0000 fps = 19 mse_loss = 2.7123 
2022-05-01 05:03:54.611147 - gail/main.py:164 - [TRPO] iter = 308000 dist_mean = 0.1251 dist_std = 0.2486 vf_loss = 0.1080 grad_norm = 1.7636 nat_grad_norm = 0.1350 cg_residual = 0.4169 step_size = 0.5054 reward = 0.0000 fps = 16 mse_loss = 2.8102 
2022-05-01 05:04:04.947118 - gail/main.py:164 - [TRPO] iter = 309000 dist_mean = 0.0971 dist_std = 0.2474 vf_loss = 0.0424 grad_norm = 1.8266 nat_grad_norm = 0.1095 cg_residual = 0.3939 step_size = 0.5676 reward = -0.0000 fps = 13 mse_loss = 2.7802 
2022-05-01 05:04:14.700993 - gail/main.py:164 - [TRPO] iter = 310000 dist_mean = 0.0981 dist_std = 0.2462 vf_loss = 0.1082 grad_norm = 1.7074 nat_grad_norm = 0.1429 cg_residual = 0.6212 step_size = 0.4431 reward = -0.0000 fps = 12 mse_loss = 2.7022 
2022-05-01 05:04:14.883199 - gail/main.py:191 - [Discriminator] iter = 310000 loss = -1.2685 grad_norm = 2.6186 grad_penalty = 0.1025 regularization = 0.0000 true_logits = 0.6465 fake_logits = -0.7244 true_prob = 0.6280 fake_prob = 0.3755 
2022-05-01 05:04:47.556548 - gail/main.py:132 - [Evaluate] iter = 310000 episode={ returns = 831.9968 lengths = 245 } discounted_episode={ returns = 713.0859 lengths = 243 } 
2022-05-01 05:04:57.487346 - gail/main.py:164 - [TRPO] iter = 311000 dist_mean = 0.1290 dist_std = 0.2470 vf_loss = 0.1615 grad_norm = 2.7923 nat_grad_norm = 0.1021 cg_residual = 0.2302 step_size = 0.4790 reward = 0.0000 fps = 23 mse_loss = 2.7338 
2022-05-01 05:05:07.426119 - gail/main.py:164 - [TRPO] iter = 312000 dist_mean = 0.0799 dist_std = 0.2464 vf_loss = 0.1992 grad_norm = 2.6828 nat_grad_norm = 0.1063 cg_residual = 0.2895 step_size = 0.5022 reward = -0.0000 fps = 19 mse_loss = 2.7268 
2022-05-01 05:05:17.176181 - gail/main.py:164 - [TRPO] iter = 313000 dist_mean = 0.0969 dist_std = 0.2448 vf_loss = 0.1587 grad_norm = 2.4708 nat_grad_norm = 0.1387 cg_residual = 0.4279 step_size = 0.4354 reward = 0.0000 fps = 16 mse_loss = 2.8600 
2022-05-01 05:05:26.910435 - gail/main.py:164 - [TRPO] iter = 314000 dist_mean = 0.0699 dist_std = 0.2429 vf_loss = 0.2263 grad_norm = 2.4532 nat_grad_norm = 0.1974 cg_residual = 0.8297 step_size = 0.3710 reward = 0.0000 fps = 13 mse_loss = 2.8971 
2022-05-01 05:05:36.609228 - gail/main.py:164 - [TRPO] iter = 315000 dist_mean = 0.0528 dist_std = 0.2412 vf_loss = 0.1030 grad_norm = 1.8115 nat_grad_norm = 0.1173 cg_residual = 0.3275 step_size = 0.5461 reward = -0.0000 fps = 12 mse_loss = 2.7842 
2022-05-01 05:05:36.834717 - gail/main.py:191 - [Discriminator] iter = 315000 loss = -1.1520 grad_norm = 2.5786 grad_penalty = 0.0884 regularization = 0.0000 true_logits = 0.7668 fake_logits = -0.4736 true_prob = 0.6472 fake_prob = 0.4165 
2022-05-01 05:06:14.606684 - gail/main.py:132 - [Evaluate] iter = 315000 episode={ returns = 929.1585 lengths = 273 } discounted_episode={ returns = 784.8177 lengths = 268 } 
2022-05-01 05:06:24.628406 - gail/main.py:164 - [TRPO] iter = 316000 dist_mean = 0.0511 dist_std = 0.2407 vf_loss = 0.0685 grad_norm = 2.4983 nat_grad_norm = 0.1535 cg_residual = 0.2612 step_size = 0.4340 reward = 0.0000 fps = 20 mse_loss = 2.8978 
2022-05-01 05:06:34.875609 - gail/main.py:164 - [TRPO] iter = 317000 dist_mean = 0.0930 dist_std = 0.2397 vf_loss = 0.0908 grad_norm = 2.1650 nat_grad_norm = 0.1480 cg_residual = 0.6823 step_size = 0.4552 reward = 0.0000 fps = 17 mse_loss = 2.8229 
2022-05-01 05:06:44.713697 - gail/main.py:164 - [TRPO] iter = 318000 dist_mean = 0.1054 dist_std = 0.2404 vf_loss = 0.0640 grad_norm = 2.5416 nat_grad_norm = 0.1319 cg_residual = 0.4564 step_size = 0.5380 reward = 0.0000 fps = 14 mse_loss = 2.8243 
2022-05-01 05:06:54.706520 - gail/main.py:164 - [TRPO] iter = 319000 dist_mean = 0.0912 dist_std = 0.2405 vf_loss = 0.0373 grad_norm = 2.7029 nat_grad_norm = 0.1289 cg_residual = 0.4931 step_size = 0.4521 reward = 0.0000 fps = 12 mse_loss = 2.8840 
2022-05-01 05:07:04.609002 - gail/main.py:164 - [TRPO] iter = 320000 dist_mean = 0.0422 dist_std = 0.2432 vf_loss = 0.0454 grad_norm = 2.1334 nat_grad_norm = 0.1421 cg_residual = 0.5454 step_size = 0.4498 reward = 0.0000 fps = 11 mse_loss = 2.7045 
2022-05-01 05:07:04.837453 - gail/main.py:191 - [Discriminator] iter = 320000 loss = -1.1543 grad_norm = 2.5813 grad_penalty = 0.0884 regularization = 0.0000 true_logits = 0.7507 fake_logits = -0.4920 true_prob = 0.6441 fake_prob = 0.4147 
2022-05-01 05:07:40.903244 - gail/main.py:132 - [Evaluate] iter = 320000 episode={ returns = 862.8393 lengths = 253 } discounted_episode={ returns = 809.0906 lengths = 278 } 
2022-05-01 05:07:50.730305 - gail/main.py:164 - [TRPO] iter = 321000 dist_mean = 0.0591 dist_std = 0.2427 vf_loss = 0.0704 grad_norm = 1.8177 nat_grad_norm = 0.0921 cg_residual = 0.4868 step_size = 0.5970 reward = -0.0000 fps = 21 mse_loss = 3.0055 
2022-05-01 05:08:00.494336 - gail/main.py:164 - [TRPO] iter = 322000 dist_mean = 0.0576 dist_std = 0.2411 vf_loss = 0.0501 grad_norm = 2.3513 nat_grad_norm = 0.1548 cg_residual = 0.4565 step_size = 0.4157 reward = -0.0000 fps = 17 mse_loss = 2.7478 
2022-05-01 05:08:10.401615 - gail/main.py:164 - [TRPO] iter = 323000 dist_mean = 0.0831 dist_std = 0.2411 vf_loss = 0.0344 grad_norm = 1.9400 nat_grad_norm = 0.1030 cg_residual = 0.2140 step_size = 0.5902 reward = -0.0000 fps = 15 mse_loss = 2.7956 
2022-05-01 05:08:20.169099 - gail/main.py:164 - [TRPO] iter = 324000 dist_mean = 0.1099 dist_std = 0.2416 vf_loss = 0.0539 grad_norm = 1.8882 nat_grad_norm = 0.1222 cg_residual = 0.4203 step_size = 0.5219 reward = -0.0000 fps = 13 mse_loss = 2.8613 
2022-05-01 05:08:30.327829 - gail/main.py:164 - [TRPO] iter = 325000 dist_mean = 0.1498 dist_std = 0.2424 vf_loss = 0.0421 grad_norm = 1.7199 nat_grad_norm = 0.1661 cg_residual = 0.5863 step_size = 0.4476 reward = -0.0000 fps = 11 mse_loss = 2.6644 
2022-05-01 05:08:30.524219 - gail/main.py:191 - [Discriminator] iter = 325000 loss = -1.3548 grad_norm = 2.5384 grad_penalty = 0.0945 regularization = 0.0000 true_logits = 0.7306 fake_logits = -0.7187 true_prob = 0.6375 fake_prob = 0.3783 
2022-05-01 05:09:03.451030 - gail/main.py:132 - [Evaluate] iter = 325000 episode={ returns = 883.7874 lengths = 257 } discounted_episode={ returns = 677.5000 lengths = 230 } 
2022-05-01 05:09:13.319046 - gail/main.py:164 - [TRPO] iter = 326000 dist_mean = 0.0796 dist_std = 0.2403 vf_loss = 0.0318 grad_norm = 1.9636 nat_grad_norm = 0.1235 cg_residual = 0.3366 step_size = 0.5240 reward = -0.0000 fps = 23 mse_loss = 2.9489 
2022-05-01 05:09:23.228322 - gail/main.py:164 - [TRPO] iter = 327000 dist_mean = 0.1065 dist_std = 0.2398 vf_loss = 0.0462 grad_norm = 1.7000 nat_grad_norm = 0.1314 cg_residual = 0.3979 step_size = 0.4674 reward = 0.0000 fps = 18 mse_loss = 2.6822 
2022-05-01 05:09:32.663134 - gail/main.py:164 - [TRPO] iter = 328000 dist_mean = 0.1186 dist_std = 0.2420 vf_loss = 0.0686 grad_norm = 1.6519 nat_grad_norm = 0.1893 cg_residual = 1.1415 step_size = 0.4195 reward = 0.0000 fps = 16 mse_loss = 2.7738 
2022-05-01 05:09:42.790104 - gail/main.py:164 - [TRPO] iter = 329000 dist_mean = 0.1328 dist_std = 0.2410 vf_loss = 0.0561 grad_norm = 1.8172 nat_grad_norm = 0.1509 cg_residual = 0.5130 step_size = 0.5075 reward = -0.0000 fps = 13 mse_loss = 2.9335 
2022-05-01 05:09:52.352579 - gail/main.py:164 - [TRPO] iter = 330000 dist_mean = 0.1317 dist_std = 0.2411 vf_loss = 0.0424 grad_norm = 2.0175 nat_grad_norm = 0.1274 cg_residual = 0.4447 step_size = 0.4870 reward = 0.0000 fps = 12 mse_loss = 2.9306 
2022-05-01 05:09:52.594109 - gail/main.py:191 - [Discriminator] iter = 330000 loss = -1.0366 grad_norm = 2.9032 grad_penalty = 0.0954 regularization = 0.0000 true_logits = 0.6837 fake_logits = -0.4483 true_prob = 0.6324 fake_prob = 0.4244 
2022-05-01 05:10:31.077686 - gail/main.py:132 - [Evaluate] iter = 330000 episode={ returns = 885.5786 lengths = 260 } discounted_episode={ returns = 889.2669 lengths = 312 } 
2022-05-01 05:10:41.127508 - gail/main.py:164 - [TRPO] iter = 331000 dist_mean = 0.0990 dist_std = 0.2422 vf_loss = 0.0485 grad_norm = 2.0549 nat_grad_norm = 0.1241 cg_residual = 0.6547 step_size = 0.4731 reward = 0.0000 fps = 20 mse_loss = 2.6238 
2022-05-01 05:10:51.157862 - gail/main.py:164 - [TRPO] iter = 332000 dist_mean = 0.1480 dist_std = 0.2422 vf_loss = 0.1184 grad_norm = 2.7282 nat_grad_norm = 0.1550 cg_residual = 0.4206 step_size = 0.4395 reward = -0.0000 fps = 17 mse_loss = 2.8429 
2022-05-01 05:11:00.814405 - gail/main.py:164 - [TRPO] iter = 333000 dist_mean = 0.0589 dist_std = 0.2421 vf_loss = 0.0565 grad_norm = 2.8341 nat_grad_norm = 0.1447 cg_residual = 0.4994 step_size = 0.4693 reward = 0.0000 fps = 14 mse_loss = 2.8103 
2022-05-01 05:11:11.055203 - gail/main.py:164 - [TRPO] iter = 334000 dist_mean = 0.1116 dist_std = 0.2438 vf_loss = 0.0606 grad_norm = 2.3083 nat_grad_norm = 0.1400 cg_residual = 0.3912 step_size = 0.4199 reward = -0.0000 fps = 12 mse_loss = 2.9351 
2022-05-01 05:11:20.994688 - gail/main.py:164 - [TRPO] iter = 335000 dist_mean = 0.1609 dist_std = 0.2436 vf_loss = 0.0292 grad_norm = 3.0608 nat_grad_norm = 0.1299 cg_residual = 0.4767 step_size = 0.4359 reward = 0.0000 fps = 11 mse_loss = 2.7832 
2022-05-01 05:11:21.241212 - gail/main.py:191 - [Discriminator] iter = 335000 loss = -1.3879 grad_norm = 2.2885 grad_penalty = 0.1085 regularization = 0.0000 true_logits = 0.7374 fake_logits = -0.7590 true_prob = 0.6445 fake_prob = 0.3754 
2022-05-01 05:11:58.001598 - gail/main.py:132 - [Evaluate] iter = 335000 episode={ returns = 964.3167 lengths = 285 } discounted_episode={ returns = 771.1846 lengths = 264 } 
2022-05-01 05:12:07.843667 - gail/main.py:164 - [TRPO] iter = 336000 dist_mean = 0.0675 dist_std = 0.2449 vf_loss = 0.0517 grad_norm = 1.9713 nat_grad_norm = 0.1113 cg_residual = 0.2867 step_size = 0.5408 reward = 0.0000 fps = 21 mse_loss = 2.6442 
2022-05-01 05:12:17.766011 - gail/main.py:164 - [TRPO] iter = 337000 dist_mean = 0.0684 dist_std = 0.2422 vf_loss = 0.0322 grad_norm = 2.1562 nat_grad_norm = 0.1376 cg_residual = 0.5505 step_size = 0.4880 reward = -0.0000 fps = 17 mse_loss = 2.7440 
2022-05-01 05:12:27.690416 - gail/main.py:164 - [TRPO] iter = 338000 dist_mean = 0.0574 dist_std = 0.2415 vf_loss = 0.0620 grad_norm = 2.6146 nat_grad_norm = 0.1373 cg_residual = 0.7181 step_size = 0.4465 reward = -0.0000 fps = 15 mse_loss = 2.6728 
2022-05-01 05:12:37.595985 - gail/main.py:164 - [TRPO] iter = 339000 dist_mean = 0.0763 dist_std = 0.2401 vf_loss = 0.0459 grad_norm = 1.6426 nat_grad_norm = 0.1070 cg_residual = 0.2589 step_size = 0.5550 reward = 0.0000 fps = 13 mse_loss = 2.6207 
2022-05-01 05:12:46.950565 - gail/main.py:164 - [TRPO] iter = 340000 dist_mean = 0.0991 dist_std = 0.2380 vf_loss = 0.0454 grad_norm = 2.7796 nat_grad_norm = 0.1419 cg_residual = 0.8335 step_size = 0.4377 reward = -0.0000 fps = 11 mse_loss = 2.6985 
2022-05-01 05:12:47.223058 - gail/main.py:191 - [Discriminator] iter = 340000 loss = -1.0161 grad_norm = 2.3427 grad_penalty = 0.0942 regularization = 0.0000 true_logits = 0.6444 fake_logits = -0.4660 true_prob = 0.6258 fake_prob = 0.4228 
2022-05-01 05:13:30.025186 - gail/main.py:132 - [Evaluate] iter = 340000 episode={ returns = 1056.0790 lengths = 309 } discounted_episode={ returns = 920.3522 lengths = 321 } 
2022-05-01 05:13:39.887117 - gail/main.py:164 - [TRPO] iter = 341000 dist_mean = 0.0942 dist_std = 0.2360 vf_loss = 0.0487 grad_norm = 2.8400 nat_grad_norm = 0.1243 cg_residual = 0.5568 step_size = 0.4483 reward = 0.0000 fps = 18 mse_loss = 2.7280 
2022-05-01 05:13:49.913449 - gail/main.py:164 - [TRPO] iter = 342000 dist_mean = 0.0526 dist_std = 0.2362 vf_loss = 0.0454 grad_norm = 2.2755 nat_grad_norm = 0.1060 cg_residual = 0.5797 step_size = 0.5451 reward = -0.0000 fps = 15 mse_loss = 2.7693 
2022-05-01 05:13:59.672606 - gail/main.py:164 - [TRPO] iter = 343000 dist_mean = 0.1570 dist_std = 0.2363 vf_loss = 0.0686 grad_norm = 1.5219 nat_grad_norm = 0.1727 cg_residual = 0.8875 step_size = 0.4103 reward = -0.0000 fps = 13 mse_loss = 2.6923 
2022-05-01 05:14:09.580866 - gail/main.py:164 - [TRPO] iter = 344000 dist_mean = 0.1003 dist_std = 0.2368 vf_loss = 0.0725 grad_norm = 2.4755 nat_grad_norm = 0.1534 cg_residual = 0.4990 step_size = 0.4319 reward = 0.0000 fps = 12 mse_loss = 2.6923 
2022-05-01 05:14:19.458782 - gail/main.py:164 - [TRPO] iter = 345000 dist_mean = 0.0551 dist_std = 0.2350 vf_loss = 0.0537 grad_norm = 1.4954 nat_grad_norm = 0.1550 cg_residual = 0.5331 step_size = 0.4890 reward = -0.0000 fps = 10 mse_loss = 2.6659 
2022-05-01 05:14:19.667231 - gail/main.py:191 - [Discriminator] iter = 345000 loss = -1.0594 grad_norm = 2.2796 grad_penalty = 0.0782 regularization = 0.0000 true_logits = 0.7677 fake_logits = -0.3700 true_prob = 0.6519 fake_prob = 0.4381 
2022-05-01 05:15:05.418885 - gail/main.py:132 - [Evaluate] iter = 345000 episode={ returns = 1181.7478 lengths = 344 } discounted_episode={ returns = 942.5753 lengths = 332 } 
2022-05-01 05:15:15.338557 - gail/main.py:164 - [TRPO] iter = 346000 dist_mean = 0.0738 dist_std = 0.2339 vf_loss = 0.0455 grad_norm = 2.9519 nat_grad_norm = 0.1341 cg_residual = 0.6274 step_size = 0.4358 reward = -0.0000 fps = 17 mse_loss = 2.5030 
2022-05-01 05:15:25.225150 - gail/main.py:164 - [TRPO] iter = 347000 dist_mean = 0.0689 dist_std = 0.2322 vf_loss = 0.0516 grad_norm = 2.3675 nat_grad_norm = 0.1222 cg_residual = 0.8177 step_size = 0.4404 reward = 0.0000 fps = 15 mse_loss = 2.7519 
2022-05-01 05:15:35.068952 - gail/main.py:164 - [TRPO] iter = 348000 dist_mean = 0.0775 dist_std = 0.2321 vf_loss = 0.1502 grad_norm = 2.0552 nat_grad_norm = 0.1140 cg_residual = 0.9661 step_size = 0.5360 reward = -0.0000 fps = 13 mse_loss = 2.4494 
2022-05-01 05:15:44.853228 - gail/main.py:164 - [TRPO] iter = 349000 dist_mean = 0.0977 dist_std = 0.2325 vf_loss = 0.0797 grad_norm = 1.6861 nat_grad_norm = 0.1965 cg_residual = 1.1418 step_size = 0.3797 reward = 0.0000 fps = 11 mse_loss = 2.8536 
2022-05-01 05:15:54.980697 - gail/main.py:164 - [TRPO] iter = 350000 dist_mean = 0.0913 dist_std = 0.2317 vf_loss = 0.0611 grad_norm = 1.4487 nat_grad_norm = 0.1212 cg_residual = 0.4046 step_size = 0.5251 reward = -0.0000 fps = 10 mse_loss = 2.4693 
2022-05-01 05:15:55.165986 - gail/main.py:191 - [Discriminator] iter = 350000 loss = -1.1197 grad_norm = 2.5717 grad_penalty = 0.0942 regularization = 0.0000 true_logits = 0.7093 fake_logits = -0.5046 true_prob = 0.6362 fake_prob = 0.4173 
2022-05-01 05:16:39.195269 - gail/main.py:132 - [Evaluate] iter = 350000 episode={ returns = 1101.0470 lengths = 318 } discounted_episode={ returns = 976.4468 lengths = 342 } 
2022-05-01 05:16:48.948403 - gail/main.py:164 - [TRPO] iter = 351000 dist_mean = 0.0831 dist_std = 0.2309 vf_loss = 0.0533 grad_norm = 2.3777 nat_grad_norm = 0.1453 cg_residual = 0.7295 step_size = 0.4112 reward = 0.0000 fps = 18 mse_loss = 2.5742 
2022-05-01 05:16:58.978279 - gail/main.py:164 - [TRPO] iter = 352000 dist_mean = 0.0877 dist_std = 0.2305 vf_loss = 0.0504 grad_norm = 1.7483 nat_grad_norm = 0.1325 cg_residual = 0.3045 step_size = 0.5491 reward = 0.0000 fps = 15 mse_loss = 2.7461 
2022-05-01 05:17:08.898487 - gail/main.py:164 - [TRPO] iter = 353000 dist_mean = 0.1030 dist_std = 0.2303 vf_loss = 0.0392 grad_norm = 2.9486 nat_grad_norm = 0.1035 cg_residual = 0.6293 step_size = 0.4661 reward = 0.0000 fps = 13 mse_loss = 2.8111 
2022-05-01 05:17:18.654498 - gail/main.py:164 - [TRPO] iter = 354000 dist_mean = 0.1184 dist_std = 0.2308 vf_loss = 0.0287 grad_norm = 2.5844 nat_grad_norm = 0.1213 cg_residual = 0.4452 step_size = 0.5320 reward = 0.0000 fps = 11 mse_loss = 2.5895 
2022-05-01 05:17:28.168578 - gail/main.py:164 - [TRPO] iter = 355000 dist_mean = 0.0857 dist_std = 0.2302 vf_loss = 0.0291 grad_norm = 3.8417 nat_grad_norm = 0.1373 cg_residual = 0.9441 step_size = 0.3675 reward = 0.0000 fps = 10 mse_loss = 2.7658 
2022-05-01 05:17:28.376147 - gail/main.py:191 - [Discriminator] iter = 355000 loss = -0.8735 grad_norm = 3.6921 grad_penalty = 0.0788 regularization = 0.0000 true_logits = 0.7219 fake_logits = -0.2304 true_prob = 0.6377 fake_prob = 0.4660 
2022-05-01 05:18:03.893781 - gail/main.py:132 - [Evaluate] iter = 355000 episode={ returns = 705.9287 lengths = 213 } discounted_episode={ returns = 842.7160 lengths = 318 } 
2022-05-01 05:18:13.580687 - gail/main.py:164 - [TRPO] iter = 356000 dist_mean = 0.1288 dist_std = 0.2308 vf_loss = 0.0541 grad_norm = 1.3118 nat_grad_norm = 0.1600 cg_residual = 0.8229 step_size = 0.4635 reward = -0.0000 fps = 22 mse_loss = 2.8183 
2022-05-01 05:18:23.562753 - gail/main.py:164 - [TRPO] iter = 357000 dist_mean = 0.1066 dist_std = 0.2301 vf_loss = 0.0342 grad_norm = 2.4525 nat_grad_norm = 0.1428 cg_residual = 0.8393 step_size = 0.4032 reward = 0.0000 fps = 18 mse_loss = 2.5505 
2022-05-01 05:18:33.998014 - gail/main.py:164 - [TRPO] iter = 358000 dist_mean = 0.1224 dist_std = 0.2303 vf_loss = 0.0462 grad_norm = 2.1885 nat_grad_norm = 0.0957 cg_residual = 0.5693 step_size = 0.6017 reward = 0.0000 fps = 15 mse_loss = 2.5730 
2022-05-01 05:18:43.749031 - gail/main.py:164 - [TRPO] iter = 359000 dist_mean = 0.1771 dist_std = 0.2283 vf_loss = 0.0388 grad_norm = 2.2530 nat_grad_norm = 0.1642 cg_residual = 1.3331 step_size = 0.4035 reward = 0.0000 fps = 13 mse_loss = 2.6404 
2022-05-01 05:18:53.902455 - gail/main.py:164 - [TRPO] iter = 360000 dist_mean = 0.1321 dist_std = 0.2292 vf_loss = 0.0635 grad_norm = 2.0757 nat_grad_norm = 0.1483 cg_residual = 1.0104 step_size = 0.4378 reward = 0.0000 fps = 11 mse_loss = 2.6054 
2022-05-01 05:18:54.143074 - gail/main.py:191 - [Discriminator] iter = 360000 loss = -1.3390 grad_norm = 2.3853 grad_penalty = 0.1044 regularization = 0.0000 true_logits = 0.7461 fake_logits = -0.6972 true_prob = 0.6391 fake_prob = 0.3825 
2022-05-01 05:19:23.022354 - gail/main.py:132 - [Evaluate] iter = 360000 episode={ returns = 719.2073 lengths = 213 } discounted_episode={ returns = 595.2342 lengths = 212 } 
2022-05-01 05:19:32.745295 - gail/main.py:164 - [TRPO] iter = 361000 dist_mean = 0.0715 dist_std = 0.2287 vf_loss = 0.0556 grad_norm = 2.2721 nat_grad_norm = 0.0944 cg_residual = 0.5816 step_size = 0.5572 reward = -0.0000 fps = 25 mse_loss = 2.5110 
2022-05-01 05:19:42.647824 - gail/main.py:164 - [TRPO] iter = 362000 dist_mean = 0.1094 dist_std = 0.2284 vf_loss = 0.2692 grad_norm = 1.7808 nat_grad_norm = 0.1209 cg_residual = 0.7976 step_size = 0.4508 reward = -0.0000 fps = 20 mse_loss = 2.5368 
2022-05-01 05:19:53.085417 - gail/main.py:164 - [TRPO] iter = 363000 dist_mean = 0.1130 dist_std = 0.2271 vf_loss = 0.0414 grad_norm = 2.4318 nat_grad_norm = 0.1472 cg_residual = 1.0976 step_size = 0.4507 reward = -0.0000 fps = 16 mse_loss = 2.6602 
2022-05-01 05:20:03.639692 - gail/main.py:164 - [TRPO] iter = 364000 dist_mean = 0.1053 dist_std = 0.2268 vf_loss = 0.0537 grad_norm = 2.9040 nat_grad_norm = 0.1050 cg_residual = 0.5536 step_size = 0.4656 reward = -0.0000 fps = 14 mse_loss = 2.5757 
2022-05-01 05:20:13.997008 - gail/main.py:164 - [TRPO] iter = 365000 dist_mean = 0.0944 dist_std = 0.2263 vf_loss = 0.0454 grad_norm = 1.5147 nat_grad_norm = 0.0998 cg_residual = 0.6618 step_size = 0.5966 reward = -0.0000 fps = 12 mse_loss = 2.5106 
2022-05-01 05:20:14.247930 - gail/main.py:191 - [Discriminator] iter = 365000 loss = -0.8903 grad_norm = 2.3328 grad_penalty = 0.0868 regularization = 0.0000 true_logits = 0.7636 fake_logits = -0.2136 true_prob = 0.6465 fake_prob = 0.4701 
2022-05-01 05:20:54.923430 - gail/main.py:132 - [Evaluate] iter = 365000 episode={ returns = 1072.2071 lengths = 311 } discounted_episode={ returns = 684.9683 lengths = 243 } 
2022-05-01 05:21:06.090502 - gail/main.py:164 - [TRPO] iter = 366000 dist_mean = 0.0965 dist_std = 0.2254 vf_loss = 0.0232 grad_norm = 2.6647 nat_grad_norm = 0.1128 cg_residual = 0.7868 step_size = 0.4638 reward = 0.0000 fps = 19 mse_loss = 2.5178 
2022-05-01 05:21:18.041734 - gail/main.py:164 - [TRPO] iter = 367000 dist_mean = 0.1021 dist_std = 0.2253 vf_loss = 0.0248 grad_norm = 2.7524 nat_grad_norm = 0.1020 cg_residual = 0.6452 step_size = 0.4717 reward = 0.0000 fps = 15 mse_loss = 2.5189 
2022-05-01 05:21:29.766090 - gail/main.py:164 - [TRPO] iter = 368000 dist_mean = 0.1651 dist_std = 0.2243 vf_loss = 0.0360 grad_norm = 2.3454 nat_grad_norm = 0.1435 cg_residual = 0.9600 step_size = 0.3501 reward = 0.0000 fps = 13 mse_loss = 2.5496 
2022-05-01 05:21:41.276768 - gail/main.py:164 - [TRPO] iter = 369000 dist_mean = 0.1992 dist_std = 0.2237 vf_loss = 0.0524 grad_norm = 2.4382 nat_grad_norm = 0.1592 cg_residual = 1.9579 step_size = 0.3846 reward = -0.0000 fps = 11 mse_loss = 2.6194 
2022-05-01 05:21:52.611214 - gail/main.py:164 - [TRPO] iter = 370000 dist_mean = 0.1275 dist_std = 0.2228 vf_loss = 0.0449 grad_norm = 2.2907 nat_grad_norm = 0.1283 cg_residual = 0.9558 step_size = 0.4390 reward = 0.0000 fps = 10 mse_loss = 2.3887 
2022-05-01 05:21:52.875286 - gail/main.py:191 - [Discriminator] iter = 370000 loss = -0.9357 grad_norm = 2.2564 grad_penalty = 0.0849 regularization = 0.0000 true_logits = 0.7940 fake_logits = -0.2266 true_prob = 0.6508 fake_prob = 0.4607 
2022-05-01 05:22:43.154867 - gail/main.py:132 - [Evaluate] iter = 370000 episode={ returns = 1209.8311 lengths = 354 } discounted_episode={ returns = 771.7519 lengths = 274 } 
2022-05-01 05:22:54.925398 - gail/main.py:164 - [TRPO] iter = 371000 dist_mean = 0.1403 dist_std = 0.2229 vf_loss = 0.0292 grad_norm = 1.6771 nat_grad_norm = 0.1316 cg_residual = 1.1638 step_size = 0.4664 reward = 0.0000 fps = 16 mse_loss = 2.4953 
2022-05-01 05:23:05.745114 - gail/main.py:164 - [TRPO] iter = 372000 dist_mean = 0.0480 dist_std = 0.2234 vf_loss = 0.0339 grad_norm = 2.4816 nat_grad_norm = 0.1314 cg_residual = 1.5549 step_size = 0.4323 reward = -0.0000 fps = 13 mse_loss = 2.6688 
2022-05-01 05:23:15.967184 - gail/main.py:164 - [TRPO] iter = 373000 dist_mean = 0.0780 dist_std = 0.2218 vf_loss = 0.0275 grad_norm = 1.5890 nat_grad_norm = 0.1115 cg_residual = 0.6188 step_size = 0.5218 reward = 0.0000 fps = 12 mse_loss = 2.3435 
2022-05-01 05:23:26.018073 - gail/main.py:164 - [TRPO] iter = 374000 dist_mean = 0.0633 dist_std = 0.2225 vf_loss = 0.0627 grad_norm = 2.1892 nat_grad_norm = 0.1117 cg_residual = 1.0155 step_size = 0.4725 reward = -0.0000 fps = 10 mse_loss = 2.5106 
2022-05-01 05:23:36.087017 - gail/main.py:164 - [TRPO] iter = 375000 dist_mean = 0.1304 dist_std = 0.2219 vf_loss = 0.2274 grad_norm = 1.9218 nat_grad_norm = 0.1550 cg_residual = 0.7268 step_size = 0.4275 reward = 0.0000 fps = 9 mse_loss = 2.4908 
2022-05-01 05:23:36.306160 - gail/main.py:191 - [Discriminator] iter = 375000 loss = -1.3737 grad_norm = 2.6886 grad_penalty = 0.1116 regularization = 0.0000 true_logits = 0.7624 fake_logits = -0.7230 true_prob = 0.6438 fake_prob = 0.3677 
2022-05-01 05:24:30.431742 - gail/main.py:132 - [Evaluate] iter = 375000 episode={ returns = 1281.7277 lengths = 372 } discounted_episode={ returns = 1101.1369 lengths = 417 } 
2022-05-01 05:24:40.640687 - gail/main.py:164 - [TRPO] iter = 376000 dist_mean = 0.0755 dist_std = 0.2224 vf_loss = 0.0351 grad_norm = 2.5418 nat_grad_norm = 0.0893 cg_residual = 0.4711 step_size = 0.5568 reward = 0.0000 fps = 15 mse_loss = 2.4124 
2022-05-01 05:24:51.039925 - gail/main.py:164 - [TRPO] iter = 377000 dist_mean = 0.0352 dist_std = 0.2231 vf_loss = 0.0576 grad_norm = 1.7079 nat_grad_norm = 0.1067 cg_residual = 0.9963 step_size = 0.5571 reward = -0.0000 fps = 13 mse_loss = 2.3913 
2022-05-01 05:25:01.071246 - gail/main.py:164 - [TRPO] iter = 378000 dist_mean = 0.1471 dist_std = 0.2229 vf_loss = 0.0984 grad_norm = 2.6380 nat_grad_norm = 0.1553 cg_residual = 0.8882 step_size = 0.3472 reward = 0.0000 fps = 11 mse_loss = 2.5095 
2022-05-01 05:25:10.813186 - gail/main.py:164 - [TRPO] iter = 379000 dist_mean = 0.0972 dist_std = 0.2230 vf_loss = 0.0649 grad_norm = 2.1450 nat_grad_norm = 0.1235 cg_residual = 1.3734 step_size = 0.4418 reward = -0.0000 fps = 10 mse_loss = 2.4925 
2022-05-01 05:25:20.927348 - gail/main.py:164 - [TRPO] iter = 380000 dist_mean = 0.1352 dist_std = 0.2226 vf_loss = 0.0612 grad_norm = 2.5094 nat_grad_norm = 0.1127 cg_residual = 0.5292 step_size = 0.4534 reward = 0.0000 fps = 9 mse_loss = 2.5778 
2022-05-01 05:25:21.221027 - gail/main.py:191 - [Discriminator] iter = 380000 loss = -1.1899 grad_norm = 2.2925 grad_penalty = 0.0977 regularization = 0.0000 true_logits = 0.8619 fake_logits = -0.4257 true_prob = 0.6595 fake_prob = 0.4282 
2022-05-01 05:26:07.073881 - gail/main.py:132 - [Evaluate] iter = 380000 episode={ returns = 1068.8156 lengths = 316 } discounted_episode={ returns = 919.5175 lengths = 329 } 
2022-05-01 05:26:16.993796 - gail/main.py:164 - [TRPO] iter = 381000 dist_mean = 0.2172 dist_std = 0.2230 vf_loss = 0.0330 grad_norm = 1.8801 nat_grad_norm = 0.1394 cg_residual = 0.8332 step_size = 0.4182 reward = -0.0000 fps = 17 mse_loss = 2.6548 
2022-05-01 05:26:26.906025 - gail/main.py:164 - [TRPO] iter = 382000 dist_mean = 0.0933 dist_std = 0.2231 vf_loss = 0.0302 grad_norm = 3.3693 nat_grad_norm = 0.1644 cg_residual = 1.1346 step_size = 0.4054 reward = -0.0000 fps = 15 mse_loss = 2.3801 
2022-05-01 05:26:36.779768 - gail/main.py:164 - [TRPO] iter = 383000 dist_mean = 0.1175 dist_std = 0.2218 vf_loss = 0.0650 grad_norm = 2.7511 nat_grad_norm = 0.1258 cg_residual = 0.8472 step_size = 0.4308 reward = -0.0000 fps = 13 mse_loss = 2.3834 
2022-05-01 05:26:46.790880 - gail/main.py:164 - [TRPO] iter = 384000 dist_mean = 0.2368 dist_std = 0.2217 vf_loss = 0.0581 grad_norm = 2.8627 nat_grad_norm = 0.1312 cg_residual = 0.4361 step_size = 0.4204 reward = 0.0000 fps = 11 mse_loss = 2.5589 
2022-05-01 05:26:56.743417 - gail/main.py:164 - [TRPO] iter = 385000 dist_mean = 0.0998 dist_std = 0.2207 vf_loss = 0.0375 grad_norm = 2.0055 nat_grad_norm = 0.1022 cg_residual = 0.5302 step_size = 0.4986 reward = -0.0000 fps = 10 mse_loss = 2.3933 
2022-05-01 05:26:56.953521 - gail/main.py:191 - [Discriminator] iter = 385000 loss = -1.1474 grad_norm = 2.1354 grad_penalty = 0.0813 regularization = 0.0000 true_logits = 0.8274 fake_logits = -0.4013 true_prob = 0.6531 fake_prob = 0.4364 
2022-05-01 05:27:22.185551 - gail/main.py:132 - [Evaluate] iter = 385000 episode={ returns = 702.9042 lengths = 217 } discounted_episode={ returns = 407.1666 lengths = 148 } 
2022-05-01 05:27:32.189706 - gail/main.py:164 - [TRPO] iter = 386000 dist_mean = 0.0897 dist_std = 0.2203 vf_loss = 0.0282 grad_norm = 2.5633 nat_grad_norm = 0.1249 cg_residual = 0.5969 step_size = 0.4266 reward = 0.0000 fps = 28 mse_loss = 2.5557 
2022-05-01 05:27:41.771366 - gail/main.py:164 - [TRPO] iter = 387000 dist_mean = 0.1228 dist_std = 0.2194 vf_loss = 0.0390 grad_norm = 2.5920 nat_grad_norm = 0.1280 cg_residual = 1.0636 step_size = 0.4278 reward = -0.0000 fps = 22 mse_loss = 2.5553 
2022-05-01 05:27:51.444622 - gail/main.py:164 - [TRPO] iter = 388000 dist_mean = 0.1128 dist_std = 0.2203 vf_loss = 0.1235 grad_norm = 2.4032 nat_grad_norm = 0.1379 cg_residual = 1.1326 step_size = 0.4132 reward = 0.0000 fps = 18 mse_loss = 2.5102 
2022-05-01 05:28:01.436347 - gail/main.py:164 - [TRPO] iter = 389000 dist_mean = 0.1409 dist_std = 0.2199 vf_loss = 0.0359 grad_norm = 3.4127 nat_grad_norm = 0.1677 cg_residual = 1.4858 step_size = 0.3289 reward = -0.0000 fps = 15 mse_loss = 2.4399 
2022-05-01 05:28:11.309973 - gail/main.py:164 - [TRPO] iter = 390000 dist_mean = 0.0943 dist_std = 0.2203 vf_loss = 0.2714 grad_norm = 1.6079 nat_grad_norm = 0.1145 cg_residual = 0.5130 step_size = 0.5185 reward = -0.0000 fps = 13 mse_loss = 2.4591 
2022-05-01 05:28:11.541385 - gail/main.py:191 - [Discriminator] iter = 390000 loss = -1.3135 grad_norm = 2.2986 grad_penalty = 0.0981 regularization = 0.0000 true_logits = 0.8423 fake_logits = -0.5693 true_prob = 0.6614 fake_prob = 0.4042 
2022-05-01 05:28:56.330642 - gail/main.py:132 - [Evaluate] iter = 390000 episode={ returns = 1181.1479 lengths = 344 } discounted_episode={ returns = 957.1380 lengths = 336 } 
2022-05-01 05:29:06.030516 - gail/main.py:164 - [TRPO] iter = 391000 dist_mean = 0.0951 dist_std = 0.2188 vf_loss = 0.0397 grad_norm = 3.5262 nat_grad_norm = 0.1176 cg_residual = 0.3620 step_size = 0.4467 reward = -0.0000 fps = 18 mse_loss = 2.5096 
2022-05-01 05:29:15.651913 - gail/main.py:164 - [TRPO] iter = 392000 dist_mean = 0.1094 dist_std = 0.2189 vf_loss = 0.0587 grad_norm = 2.6808 nat_grad_norm = 0.0971 cg_residual = 0.4821 step_size = 0.5338 reward = 0.0000 fps = 15 mse_loss = 2.4621 
2022-05-01 05:29:25.221734 - gail/main.py:164 - [TRPO] iter = 393000 dist_mean = 0.0995 dist_std = 0.2193 vf_loss = 0.0569 grad_norm = 1.6111 nat_grad_norm = 0.1144 cg_residual = 0.7793 step_size = 0.5379 reward = 0.0000 fps = 13 mse_loss = 2.6192 
2022-05-01 05:29:34.926628 - gail/main.py:164 - [TRPO] iter = 394000 dist_mean = 0.0560 dist_std = 0.2182 vf_loss = 0.0425 grad_norm = 1.6506 nat_grad_norm = 0.1249 cg_residual = 0.8770 step_size = 0.5224 reward = -0.0000 fps = 11 mse_loss = 2.4922 
2022-05-01 05:29:44.510416 - gail/main.py:164 - [TRPO] iter = 395000 dist_mean = 0.0553 dist_std = 0.2176 vf_loss = 0.0298 grad_norm = 3.0645 nat_grad_norm = 0.1199 cg_residual = 0.6824 step_size = 0.4177 reward = 0.0000 fps = 10 mse_loss = 2.5801 
2022-05-01 05:29:44.725483 - gail/main.py:191 - [Discriminator] iter = 395000 loss = -0.7858 grad_norm = 2.2129 grad_penalty = 0.0705 regularization = 0.0000 true_logits = 0.7699 fake_logits = -0.0865 true_prob = 0.6457 fake_prob = 0.4919 
2022-05-01 05:30:54.133187 - gail/main.py:132 - [Evaluate] iter = 395000 episode={ returns = 1723.8970 lengths = 508 } discounted_episode={ returns = 1298.2071 lengths = 518 } 
2022-05-01 05:31:03.902539 - gail/main.py:164 - [TRPO] iter = 396000 dist_mean = 0.1111 dist_std = 0.2172 vf_loss = 0.0342 grad_norm = 1.6124 nat_grad_norm = 0.1192 cg_residual = 0.8482 step_size = 0.5402 reward = 0.0000 fps = 12 mse_loss = 2.5887 
2022-05-01 05:31:14.008362 - gail/main.py:164 - [TRPO] iter = 397000 dist_mean = 0.0808 dist_std = 0.2180 vf_loss = 0.0172 grad_norm = 2.6998 nat_grad_norm = 0.1105 cg_residual = 0.5509 step_size = 0.4662 reward = 0.0000 fps = 11 mse_loss = 2.4174 
2022-05-01 05:31:24.104498 - gail/main.py:164 - [TRPO] iter = 398000 dist_mean = 0.1147 dist_std = 0.2183 vf_loss = 0.0561 grad_norm = 2.9286 nat_grad_norm = 0.1264 cg_residual = 0.3252 step_size = 0.4471 reward = -0.0000 fps = 10 mse_loss = 2.4004 
2022-05-01 05:31:34.132660 - gail/main.py:164 - [TRPO] iter = 399000 dist_mean = 0.1241 dist_std = 0.2171 vf_loss = 0.0204 grad_norm = 1.9075 nat_grad_norm = 0.1209 cg_residual = 0.3428 step_size = 0.5093 reward = 0.0000 fps = 9 mse_loss = 2.5640 
2022-05-01 05:31:43.973060 - gail/main.py:164 - [TRPO] iter = 400000 dist_mean = 0.0355 dist_std = 0.2174 vf_loss = 0.0263 grad_norm = 2.5750 nat_grad_norm = 0.1152 cg_residual = 0.7768 step_size = 0.4741 reward = -0.0000 fps = 8 mse_loss = 2.4175 
2022-05-01 05:31:44.181393 - gail/main.py:191 - [Discriminator] iter = 400000 loss = -0.7739 grad_norm = 3.4228 grad_penalty = 0.0746 regularization = 0.0000 true_logits = 0.8655 fake_logits = 0.0171 true_prob = 0.6623 fake_prob = 0.5103 
2022-05-01 05:32:05.193336 - gail/main.py:132 - [Evaluate] iter = 400000 episode={ returns = 604.1562 lengths = 183 } discounted_episode={ returns = 323.4606 lengths = 122 } 
2022-05-01 05:32:15.148414 - gail/main.py:164 - [TRPO] iter = 401000 dist_mean = 0.0883 dist_std = 0.2172 vf_loss = 0.0242 grad_norm = 1.7586 nat_grad_norm = 0.1504 cg_residual = 0.7156 step_size = 0.4087 reward = -0.0000 fps = 32 mse_loss = 2.5956 
2022-05-01 05:32:25.072761 - gail/main.py:164 - [TRPO] iter = 402000 dist_mean = 0.0929 dist_std = 0.2168 vf_loss = 0.0220 grad_norm = 1.9095 nat_grad_norm = 0.1114 cg_residual = 0.5223 step_size = 0.5435 reward = 0.0000 fps = 24 mse_loss = 2.6661 
2022-05-01 05:32:34.804581 - gail/main.py:164 - [TRPO] iter = 403000 dist_mean = 0.0471 dist_std = 0.2172 vf_loss = 0.0198 grad_norm = 3.1558 nat_grad_norm = 0.1298 cg_residual = 1.1812 step_size = 0.4030 reward = 0.0000 fps = 19 mse_loss = 2.4451 
2022-05-01 05:32:44.702171 - gail/main.py:164 - [TRPO] iter = 404000 dist_mean = 0.1059 dist_std = 0.2164 vf_loss = 0.0279 grad_norm = 2.3546 nat_grad_norm = 0.1222 cg_residual = 0.5027 step_size = 0.4486 reward = 0.0000 fps = 16 mse_loss = 2.3881 
2022-05-01 05:32:54.900271 - gail/main.py:164 - [TRPO] iter = 405000 dist_mean = 0.1199 dist_std = 0.2151 vf_loss = 0.0334 grad_norm = 2.3656 nat_grad_norm = 0.1253 cg_residual = 0.6354 step_size = 0.4578 reward = 0.0000 fps = 14 mse_loss = 2.5642 
2022-05-01 05:32:55.088278 - gail/main.py:191 - [Discriminator] iter = 405000 loss = -1.0157 grad_norm = 2.4619 grad_penalty = 0.0851 regularization = 0.0000 true_logits = 0.8370 fake_logits = -0.2638 true_prob = 0.6592 fake_prob = 0.4564 
2022-05-01 05:33:28.966481 - gail/main.py:132 - [Evaluate] iter = 405000 episode={ returns = 1070.2917 lengths = 323 } discounted_episode={ returns = 443.0177 lengths = 166 } 
2022-05-01 05:33:38.890979 - gail/main.py:164 - [TRPO] iter = 406000 dist_mean = 0.0667 dist_std = 0.2157 vf_loss = 0.0304 grad_norm = 1.8833 nat_grad_norm = 0.1490 cg_residual = 0.8090 step_size = 0.4296 reward = 0.0000 fps = 22 mse_loss = 2.3695 
2022-05-01 05:33:48.909832 - gail/main.py:164 - [TRPO] iter = 407000 dist_mean = 0.0854 dist_std = 0.2152 vf_loss = 0.0317 grad_norm = 3.1172 nat_grad_norm = 0.1164 cg_residual = 1.0612 step_size = 0.4061 reward = 0.0000 fps = 18 mse_loss = 2.3936 
2022-05-01 05:33:58.840881 - gail/main.py:164 - [TRPO] iter = 408000 dist_mean = 0.0540 dist_std = 0.2149 vf_loss = 0.0351 grad_norm = 2.0241 nat_grad_norm = 0.1079 cg_residual = 0.4476 step_size = 0.5215 reward = -0.0000 fps = 15 mse_loss = 2.4521 
2022-05-01 05:34:09.009448 - gail/main.py:164 - [TRPO] iter = 409000 dist_mean = 0.1378 dist_std = 0.2143 vf_loss = 0.0197 grad_norm = 3.7632 nat_grad_norm = 0.1176 cg_residual = 0.9415 step_size = 0.4129 reward = -0.0000 fps = 13 mse_loss = 2.4980 
2022-05-01 05:34:19.010631 - gail/main.py:164 - [TRPO] iter = 410000 dist_mean = 0.0312 dist_std = 0.2136 vf_loss = 0.0314 grad_norm = 2.3439 nat_grad_norm = 0.0939 cg_residual = 0.5408 step_size = 0.4615 reward = -0.0000 fps = 11 mse_loss = 2.5716 
2022-05-01 05:34:19.254559 - gail/main.py:191 - [Discriminator] iter = 410000 loss = -0.8903 grad_norm = 2.3514 grad_penalty = 0.0901 regularization = 0.0000 true_logits = 0.8340 fake_logits = -0.1464 true_prob = 0.6614 fake_prob = 0.4848 
2022-05-01 05:35:06.970561 - gail/main.py:132 - [Evaluate] iter = 410000 episode={ returns = 1101.8829 lengths = 334 } discounted_episode={ returns = 983.9431 lengths = 389 } 
2022-05-01 05:35:17.076231 - gail/main.py:164 - [TRPO] iter = 411000 dist_mean = 0.0538 dist_std = 0.2138 vf_loss = 0.0457 grad_norm = 2.5801 nat_grad_norm = 0.1003 cg_residual = 0.6395 step_size = 0.4821 reward = -0.0000 fps = 17 mse_loss = 2.5675 
2022-05-01 05:35:26.699164 - gail/main.py:164 - [TRPO] iter = 412000 dist_mean = 0.0934 dist_std = 0.2133 vf_loss = 0.2364 grad_norm = 3.9733 nat_grad_norm = 0.1577 cg_residual = 0.7777 step_size = 0.3530 reward = -0.0000 fps = 14 mse_loss = 2.5800 
2022-05-01 05:35:36.847357 - gail/main.py:164 - [TRPO] iter = 413000 dist_mean = 0.0735 dist_std = 0.2120 vf_loss = 0.0501 grad_norm = 2.7263 nat_grad_norm = 0.1208 cg_residual = 0.8470 step_size = 0.4957 reward = 0.0000 fps = 12 mse_loss = 2.4695 
2022-05-01 05:35:46.748477 - gail/main.py:164 - [TRPO] iter = 414000 dist_mean = 0.0497 dist_std = 0.2114 vf_loss = 0.0453 grad_norm = 1.7563 nat_grad_norm = 0.1357 cg_residual = 1.3223 step_size = 0.4335 reward = 0.0000 fps = 11 mse_loss = 2.5394 
2022-05-01 05:35:56.731060 - gail/main.py:164 - [TRPO] iter = 415000 dist_mean = 0.0522 dist_std = 0.2112 vf_loss = 0.0418 grad_norm = 2.6632 nat_grad_norm = 0.1166 cg_residual = 0.6245 step_size = 0.4190 reward = 0.0000 fps = 10 mse_loss = 2.4754 
2022-05-01 05:35:56.953925 - gail/main.py:191 - [Discriminator] iter = 415000 loss = -0.5673 grad_norm = 2.5065 grad_penalty = 0.0726 regularization = 0.0000 true_logits = 0.7660 fake_logits = 0.1261 true_prob = 0.6469 fake_prob = 0.5339 
2022-05-01 05:36:07.817008 - gail/main.py:132 - [Evaluate] iter = 415000 episode={ returns = 283.0450 lengths = 93 } discounted_episode={ returns = 152.0814 lengths = 63 } 
2022-05-01 05:36:17.700053 - gail/main.py:164 - [TRPO] iter = 416000 dist_mean = 0.1459 dist_std = 0.2116 vf_loss = 0.0347 grad_norm = 2.3011 nat_grad_norm = 0.1086 cg_residual = 0.8706 step_size = 0.4851 reward = 0.0000 fps = 48 mse_loss = 2.5683 
2022-05-01 05:36:27.458936 - gail/main.py:164 - [TRPO] iter = 417000 dist_mean = 0.1773 dist_std = 0.2108 vf_loss = 0.0781 grad_norm = 2.5759 nat_grad_norm = 0.1050 cg_residual = 0.4420 step_size = 0.5398 reward = 0.0000 fps = 32 mse_loss = 2.5394 
2022-05-01 05:36:37.784695 - gail/main.py:164 - [TRPO] iter = 418000 dist_mean = 0.1034 dist_std = 0.2107 vf_loss = 0.3937 grad_norm = 2.0213 nat_grad_norm = 0.1410 cg_residual = 0.8843 step_size = 0.4287 reward = -0.0000 fps = 24 mse_loss = 2.5608 
2022-05-01 05:36:47.904124 - gail/main.py:164 - [TRPO] iter = 419000 dist_mean = 0.0930 dist_std = 0.2103 vf_loss = 0.1161 grad_norm = 2.2212 nat_grad_norm = 0.1313 cg_residual = 0.7953 step_size = 0.4651 reward = 0.0000 fps = 19 mse_loss = 2.5694 
2022-05-01 05:36:58.258642 - gail/main.py:164 - [TRPO] iter = 420000 dist_mean = 0.0546 dist_std = 0.2107 vf_loss = 0.0382 grad_norm = 3.1861 nat_grad_norm = 0.0988 cg_residual = 0.7626 step_size = 0.5323 reward = 0.0000 fps = 16 mse_loss = 2.7243 
2022-05-01 05:36:58.494039 - gail/main.py:191 - [Discriminator] iter = 420000 loss = -0.8033 grad_norm = 2.9534 grad_penalty = 0.0695 regularization = 0.0000 true_logits = 0.8526 fake_logits = -0.0202 true_prob = 0.6654 fake_prob = 0.5056 
2022-05-01 05:37:15.312678 - gail/main.py:132 - [Evaluate] iter = 420000 episode={ returns = 160.6572 lengths = 58 } discounted_episode={ returns = 454.3530 lengths = 198 } 
2022-05-01 05:37:25.125641 - gail/main.py:164 - [TRPO] iter = 421000 dist_mean = 0.1356 dist_std = 0.2110 vf_loss = 0.0965 grad_norm = 2.9332 nat_grad_norm = 0.1222 cg_residual = 1.2842 step_size = 0.4511 reward = -0.0000 fps = 37 mse_loss = 2.4299 
2022-05-01 05:37:35.440587 - gail/main.py:164 - [TRPO] iter = 422000 dist_mean = 0.0731 dist_std = 0.2099 vf_loss = 0.0681 grad_norm = 2.3581 nat_grad_norm = 0.0913 cg_residual = 0.4572 step_size = 0.5556 reward = -0.0000 fps = 27 mse_loss = 2.5360 
2022-05-01 05:37:45.416352 - gail/main.py:164 - [TRPO] iter = 423000 dist_mean = 0.0438 dist_std = 0.2096 vf_loss = 0.0439 grad_norm = 1.8681 nat_grad_norm = 0.1168 cg_residual = 1.1322 step_size = 0.4576 reward = 0.0000 fps = 21 mse_loss = 2.6363 
2022-05-01 05:37:55.528356 - gail/main.py:164 - [TRPO] iter = 424000 dist_mean = 0.0452 dist_std = 0.2092 vf_loss = 0.0535 grad_norm = 2.6671 nat_grad_norm = 0.1093 cg_residual = 1.0919 step_size = 0.4861 reward = -0.0000 fps = 17 mse_loss = 2.6665 
2022-05-01 05:38:05.597819 - gail/main.py:164 - [TRPO] iter = 425000 dist_mean = 0.0455 dist_std = 0.2093 vf_loss = 0.0602 grad_norm = 2.2126 nat_grad_norm = 0.1120 cg_residual = 0.8467 step_size = 0.4863 reward = 0.0000 fps = 14 mse_loss = 2.6793 
2022-05-01 05:38:05.806797 - gail/main.py:191 - [Discriminator] iter = 425000 loss = -0.6391 grad_norm = 2.4995 grad_penalty = 0.0659 regularization = 0.0000 true_logits = 0.7315 fake_logits = 0.0266 true_prob = 0.6443 fake_prob = 0.5109 
2022-05-01 05:38:55.717656 - gail/main.py:132 - [Evaluate] iter = 425000 episode={ returns = 1282.5721 lengths = 378 } discounted_episode={ returns = 1036.8096 lengths = 374 } 
2022-05-01 05:39:05.986680 - gail/main.py:164 - [TRPO] iter = 426000 dist_mean = 0.1230 dist_std = 0.2084 vf_loss = 0.1375 grad_norm = 1.9820 nat_grad_norm = 0.1033 cg_residual = 0.5928 step_size = 0.5114 reward = -0.0000 fps = 16 mse_loss = 2.6723 
2022-05-01 05:39:15.729889 - gail/main.py:164 - [TRPO] iter = 427000 dist_mean = 0.0716 dist_std = 0.2078 vf_loss = 0.0836 grad_norm = 2.3974 nat_grad_norm = 0.0943 cg_residual = 0.7083 step_size = 0.5167 reward = -0.0000 fps = 14 mse_loss = 2.5108 
2022-05-01 05:39:25.322979 - gail/main.py:164 - [TRPO] iter = 428000 dist_mean = 0.1264 dist_std = 0.2070 vf_loss = 0.0722 grad_norm = 2.4547 nat_grad_norm = 0.1091 cg_residual = 0.5853 step_size = 0.4992 reward = 0.0000 fps = 12 mse_loss = 2.5401 
2022-05-01 05:39:35.361158 - gail/main.py:164 - [TRPO] iter = 429000 dist_mean = 0.1099 dist_std = 0.2063 vf_loss = 0.0299 grad_norm = 3.6216 nat_grad_norm = 0.1891 cg_residual = 2.0502 step_size = 0.3499 reward = 0.0000 fps = 11 mse_loss = 2.5922 
2022-05-01 05:39:44.627375 - gail/main.py:164 - [TRPO] iter = 430000 dist_mean = 0.0625 dist_std = 0.2063 vf_loss = 0.0310 grad_norm = 2.2870 nat_grad_norm = 0.1308 cg_residual = 0.8444 step_size = 0.4134 reward = -0.0000 fps = 10 mse_loss = 2.5614 
2022-05-01 05:39:44.877329 - gail/main.py:191 - [Discriminator] iter = 430000 loss = -0.7053 grad_norm = 2.4051 grad_penalty = 0.0674 regularization = 0.0000 true_logits = 0.8374 fake_logits = 0.0647 true_prob = 0.6625 fake_prob = 0.5211 
2022-05-01 05:40:20.137594 - gail/main.py:132 - [Evaluate] iter = 430000 episode={ returns = 942.3365 lengths = 274 } discounted_episode={ returns = 707.3237 lengths = 261 } 
2022-05-01 05:40:30.023644 - gail/main.py:164 - [TRPO] iter = 431000 dist_mean = 0.0920 dist_std = 0.2062 vf_loss = 0.0239 grad_norm = 2.5349 nat_grad_norm = 0.0822 cg_residual = 0.7426 step_size = 0.5405 reward = -0.0000 fps = 22 mse_loss = 2.5775 
2022-05-01 05:40:40.296529 - gail/main.py:164 - [TRPO] iter = 432000 dist_mean = 0.1031 dist_std = 0.2065 vf_loss = 0.2130 grad_norm = 3.1305 nat_grad_norm = 0.0766 cg_residual = 0.4448 step_size = 0.5378 reward = -0.0000 fps = 18 mse_loss = 2.4621 
2022-05-01 05:40:50.169802 - gail/main.py:164 - [TRPO] iter = 433000 dist_mean = 0.0634 dist_std = 0.2061 vf_loss = 0.1050 grad_norm = 2.1071 nat_grad_norm = 0.1774 cg_residual = 1.8371 step_size = 0.3578 reward = 0.0000 fps = 15 mse_loss = 2.3843 
2022-05-01 05:41:00.302364 - gail/main.py:164 - [TRPO] iter = 434000 dist_mean = 0.0762 dist_std = 0.2063 vf_loss = 0.1015 grad_norm = 2.3128 nat_grad_norm = 0.1201 cg_residual = 0.8176 step_size = 0.4512 reward = 0.0000 fps = 13 mse_loss = 2.5332 
2022-05-01 05:41:10.332148 - gail/main.py:164 - [TRPO] iter = 435000 dist_mean = 0.1585 dist_std = 0.2059 vf_loss = 0.0829 grad_norm = 2.4220 nat_grad_norm = 0.1299 cg_residual = 1.1596 step_size = 0.3837 reward = 0.0000 fps = 11 mse_loss = 2.6361 
2022-05-01 05:41:10.566861 - gail/main.py:191 - [Discriminator] iter = 435000 loss = -1.0780 grad_norm = 2.8027 grad_penalty = 0.0920 regularization = 0.0000 true_logits = 0.7606 fake_logits = -0.4093 true_prob = 0.6520 fake_prob = 0.4357 
2022-05-01 05:41:18.403502 - gail/main.py:132 - [Evaluate] iter = 435000 episode={ returns = 39.0797 lengths = 23 } discounted_episode={ returns = 213.3914 lengths = 91 } 
2022-05-01 05:41:28.348553 - gail/main.py:164 - [TRPO] iter = 436000 dist_mean = 0.0980 dist_std = 0.2065 vf_loss = 0.0746 grad_norm = 2.0437 nat_grad_norm = 0.1260 cg_residual = 0.5256 step_size = 0.5280 reward = 0.0000 fps = 56 mse_loss = 2.3805 
2022-05-01 05:41:38.780542 - gail/main.py:164 - [TRPO] iter = 437000 dist_mean = 0.1885 dist_std = 0.2063 vf_loss = 0.0477 grad_norm = 3.5666 nat_grad_norm = 0.1592 cg_residual = 2.0787 step_size = 0.3106 reward = -0.0000 fps = 35 mse_loss = 2.5088 
2022-05-01 05:41:49.428862 - gail/main.py:164 - [TRPO] iter = 438000 dist_mean = 0.0812 dist_std = 0.2070 vf_loss = 0.0719 grad_norm = 2.9809 nat_grad_norm = 0.1159 cg_residual = 1.4088 step_size = 0.4417 reward = -0.0000 fps = 25 mse_loss = 2.4740 
2022-05-01 05:41:59.291558 - gail/main.py:164 - [TRPO] iter = 439000 dist_mean = 0.1153 dist_std = 0.2073 vf_loss = 0.0439 grad_norm = 2.0137 nat_grad_norm = 0.1243 cg_residual = 0.8162 step_size = 0.4775 reward = -0.0000 fps = 20 mse_loss = 2.4156 
2022-05-01 05:42:09.415820 - gail/main.py:164 - [TRPO] iter = 440000 dist_mean = 0.1464 dist_std = 0.2064 vf_loss = 0.0216 grad_norm = 2.3200 nat_grad_norm = 0.1183 cg_residual = 0.7302 step_size = 0.4672 reward = -0.0000 fps = 16 mse_loss = 2.4365 
2022-05-01 05:42:09.723511 - gail/main.py:191 - [Discriminator] iter = 440000 loss = -1.2371 grad_norm = 2.5738 grad_penalty = 0.1053 regularization = 0.0000 true_logits = 0.7563 fake_logits = -0.5861 true_prob = 0.6537 fake_prob = 0.4087 
2022-05-01 05:42:13.110388 - gail/main.py:132 - [Evaluate] iter = 440000 episode={ returns = 38.1947 lengths = 22 } discounted_episode={ returns = 37.6249 lengths = 22 } 
2022-05-01 05:42:23.177623 - gail/main.py:164 - [TRPO] iter = 441000 dist_mean = 0.1042 dist_std = 0.2072 vf_loss = 0.0435 grad_norm = 2.3061 nat_grad_norm = 0.1298 cg_residual = 1.4725 step_size = 0.3878 reward = 0.0000 fps = 74 mse_loss = 2.4166 
2022-05-01 05:42:33.597449 - gail/main.py:164 - [TRPO] iter = 442000 dist_mean = 0.3357 dist_std = 0.2071 vf_loss = 0.0506 grad_norm = 1.9211 nat_grad_norm = 0.1252 cg_residual = 0.7467 step_size = 0.4147 reward = -0.0000 fps = 41 mse_loss = 2.7044 
2022-05-01 05:42:44.121174 - gail/main.py:164 - [TRPO] iter = 443000 dist_mean = 0.1901 dist_std = 0.2064 vf_loss = 0.0527 grad_norm = 2.6149 nat_grad_norm = 0.1142 cg_residual = 0.7968 step_size = 0.4286 reward = 0.0000 fps = 29 mse_loss = 2.5449 
2022-05-01 05:42:54.503928 - gail/main.py:164 - [TRPO] iter = 444000 dist_mean = 0.2555 dist_std = 0.2065 vf_loss = 0.3797 grad_norm = 2.6447 nat_grad_norm = 0.0916 cg_residual = 0.6058 step_size = 0.4374 reward = -0.0000 fps = 22 mse_loss = 2.5055 
2022-05-01 05:43:04.684116 - gail/main.py:164 - [TRPO] iter = 445000 dist_mean = 0.0729 dist_std = 0.2065 vf_loss = 0.1839 grad_norm = 2.3569 nat_grad_norm = 0.1126 cg_residual = 0.7079 step_size = 0.5005 reward = 0.0000 fps = 18 mse_loss = 2.4523 
2022-05-01 05:43:04.918208 - gail/main.py:191 - [Discriminator] iter = 445000 loss = -1.0856 grad_norm = 3.1503 grad_penalty = 0.0972 regularization = 0.0000 true_logits = 0.6793 fake_logits = -0.5036 true_prob = 0.6380 fake_prob = 0.4280 
2022-05-01 05:43:08.273856 - gail/main.py:132 - [Evaluate] iter = 445000 episode={ returns = 37.8597 lengths = 22 } discounted_episode={ returns = 37.4213 lengths = 22 } 
2022-05-01 05:43:18.391578 - gail/main.py:164 - [TRPO] iter = 446000 dist_mean = 0.1007 dist_std = 0.2067 vf_loss = 0.9640 grad_norm = 2.9263 nat_grad_norm = 0.1238 cg_residual = 0.6335 step_size = 0.3787 reward = -0.0000 fps = 74 mse_loss = 2.4259 
2022-05-01 05:43:27.915623 - gail/main.py:164 - [TRPO] iter = 447000 dist_mean = 0.1921 dist_std = 0.2057 vf_loss = 0.4074 grad_norm = 3.1545 nat_grad_norm = 0.1736 cg_residual = 1.8196 step_size = 0.3389 reward = 0.0000 fps = 43 mse_loss = 2.5535 
2022-05-01 05:43:37.930241 - gail/main.py:164 - [TRPO] iter = 448000 dist_mean = 0.1858 dist_std = 0.2060 vf_loss = 0.2380 grad_norm = 2.4169 nat_grad_norm = 0.1406 cg_residual = 1.1723 step_size = 0.3823 reward = 0.0000 fps = 30 mse_loss = 2.7284 
2022-05-01 05:43:47.908344 - gail/main.py:164 - [TRPO] iter = 449000 dist_mean = 0.1661 dist_std = 0.2048 vf_loss = 0.1174 grad_norm = 1.8855 nat_grad_norm = 0.1343 cg_residual = 1.1502 step_size = 0.4451 reward = -0.0000 fps = 23 mse_loss = 2.4916 
2022-05-01 05:43:57.819933 - gail/main.py:164 - [TRPO] iter = 450000 dist_mean = 0.0539 dist_std = 0.2056 vf_loss = 0.0861 grad_norm = 2.2911 nat_grad_norm = 0.0972 cg_residual = 0.4338 step_size = 0.4517 reward = -0.0000 fps = 18 mse_loss = 2.4895 
2022-05-01 05:43:58.070413 - gail/main.py:191 - [Discriminator] iter = 450000 loss = -0.6399 grad_norm = 3.6221 grad_penalty = 0.0827 regularization = 0.0000 true_logits = 0.6788 fake_logits = -0.0438 true_prob = 0.6401 fake_prob = 0.4954 
2022-05-01 05:44:02.940325 - gail/main.py:132 - [Evaluate] iter = 450000 episode={ returns = 117.2119 lengths = 44 } discounted_episode={ returns = 39.9969 lengths = 23 } 
2022-05-01 05:44:13.072323 - gail/main.py:164 - [TRPO] iter = 451000 dist_mean = 0.1019 dist_std = 0.2057 vf_loss = 0.0515 grad_norm = 2.4645 nat_grad_norm = 0.1029 cg_residual = 1.0592 step_size = 0.4850 reward = -0.0000 fps = 66 mse_loss = 2.4753 
2022-05-01 05:44:22.937642 - gail/main.py:164 - [TRPO] iter = 452000 dist_mean = 0.0735 dist_std = 0.2046 vf_loss = 0.4027 grad_norm = 2.6668 nat_grad_norm = 0.1162 cg_residual = 0.5841 step_size = 0.4211 reward = -0.0000 fps = 40 mse_loss = 2.4247 
2022-05-01 05:44:32.900025 - gail/main.py:164 - [TRPO] iter = 453000 dist_mean = 0.0493 dist_std = 0.2043 vf_loss = 0.0847 grad_norm = 2.2165 nat_grad_norm = 0.1268 cg_residual = 0.6912 step_size = 0.4870 reward = -0.0000 fps = 28 mse_loss = 2.4080 
2022-05-01 05:44:43.023481 - gail/main.py:164 - [TRPO] iter = 454000 dist_mean = 0.1099 dist_std = 0.2037 vf_loss = 0.1137 grad_norm = 2.7979 nat_grad_norm = 0.1474 cg_residual = 1.1345 step_size = 0.3606 reward = 0.0000 fps = 22 mse_loss = 2.5438 
2022-05-01 05:44:52.951424 - gail/main.py:164 - [TRPO] iter = 455000 dist_mean = 0.1518 dist_std = 0.2036 vf_loss = 0.0675 grad_norm = 2.2031 nat_grad_norm = 0.1105 cg_residual = 0.5862 step_size = 0.4817 reward = -0.0000 fps = 18 mse_loss = 2.4603 
2022-05-01 05:44:53.159736 - gail/main.py:191 - [Discriminator] iter = 455000 loss = -1.0572 grad_norm = 2.6149 grad_penalty = 0.0806 regularization = 0.0000 true_logits = 0.7115 fake_logits = -0.4262 true_prob = 0.6411 fake_prob = 0.4250 
2022-05-01 05:45:40.434561 - gail/main.py:132 - [Evaluate] iter = 455000 episode={ returns = 1110.0031 lengths = 331 } discounted_episode={ returns = 1013.7176 lengths = 377 } 
2022-05-01 05:45:50.502707 - gail/main.py:164 - [TRPO] iter = 456000 dist_mean = 0.0312 dist_std = 0.2032 vf_loss = 0.0582 grad_norm = 2.6071 nat_grad_norm = 0.1169 cg_residual = 0.8266 step_size = 0.4388 reward = -0.0000 fps = 17 mse_loss = 2.5234 
2022-05-01 05:46:00.387351 - gail/main.py:164 - [TRPO] iter = 457000 dist_mean = 0.1724 dist_std = 0.2035 vf_loss = 0.0794 grad_norm = 2.5944 nat_grad_norm = 0.1609 cg_residual = 1.5821 step_size = 0.3868 reward = -0.0000 fps = 14 mse_loss = 2.5165 
2022-05-01 05:46:10.435537 - gail/main.py:164 - [TRPO] iter = 458000 dist_mean = 0.0599 dist_std = 0.2029 vf_loss = 0.0910 grad_norm = 2.4400 nat_grad_norm = 0.1162 cg_residual = 1.5784 step_size = 0.4571 reward = -0.0000 fps = 12 mse_loss = 2.4032 
2022-05-01 05:46:20.235420 - gail/main.py:164 - [TRPO] iter = 459000 dist_mean = 0.0525 dist_std = 0.2020 vf_loss = 0.0718 grad_norm = 2.2864 nat_grad_norm = 0.1370 cg_residual = 0.9399 step_size = 0.4371 reward = -0.0000 fps = 11 mse_loss = 2.3336 
2022-05-01 05:46:30.191419 - gail/main.py:164 - [TRPO] iter = 460000 dist_mean = 0.0563 dist_std = 0.2021 vf_loss = 0.0528 grad_norm = 2.2070 nat_grad_norm = 0.1060 cg_residual = 0.9343 step_size = 0.4643 reward = 0.0000 fps = 10 mse_loss = 2.3619 
2022-05-01 05:46:30.406949 - gail/main.py:191 - [Discriminator] iter = 460000 loss = -0.7602 grad_norm = 2.8273 grad_penalty = 0.0843 regularization = 0.0000 true_logits = 0.7186 fake_logits = -0.1260 true_prob = 0.6437 fake_prob = 0.4798 
2022-05-01 05:47:11.538711 - gail/main.py:132 - [Evaluate] iter = 460000 episode={ returns = 1040.9593 lengths = 324 } discounted_episode={ returns = 785.5243 lengths = 302 } 
2022-05-01 05:47:21.435825 - gail/main.py:164 - [TRPO] iter = 461000 dist_mean = 0.0345 dist_std = 0.2020 vf_loss = 0.0489 grad_norm = 1.7848 nat_grad_norm = 0.1221 cg_residual = 0.8301 step_size = 0.5089 reward = -0.0000 fps = 19 mse_loss = 2.3620 
2022-05-01 05:47:31.097995 - gail/main.py:164 - [TRPO] iter = 462000 dist_mean = 0.0318 dist_std = 0.2021 vf_loss = 0.0577 grad_norm = 2.4457 nat_grad_norm = 0.1602 cg_residual = 2.2398 step_size = 0.3527 reward = -0.0000 fps = 16 mse_loss = 2.5122 
2022-05-01 05:47:41.198670 - gail/main.py:164 - [TRPO] iter = 463000 dist_mean = 0.0529 dist_std = 0.2017 vf_loss = 0.2024 grad_norm = 2.3512 nat_grad_norm = 0.0915 cg_residual = 0.8723 step_size = 0.4940 reward = -0.0000 fps = 14 mse_loss = 2.6033 
2022-05-01 05:47:50.788461 - gail/main.py:164 - [TRPO] iter = 464000 dist_mean = 0.0352 dist_std = 0.2011 vf_loss = 0.1068 grad_norm = 2.2972 nat_grad_norm = 0.1104 cg_residual = 0.8307 step_size = 0.4833 reward = 0.0000 fps = 12 mse_loss = 2.3698 
2022-05-01 05:48:00.606821 - gail/main.py:164 - [TRPO] iter = 465000 dist_mean = 0.0734 dist_std = 0.2014 vf_loss = 0.0855 grad_norm = 2.6321 nat_grad_norm = 0.1073 cg_residual = 1.0922 step_size = 0.4678 reward = -0.0000 fps = 11 mse_loss = 2.3658 
2022-05-01 05:48:00.823359 - gail/main.py:191 - [Discriminator] iter = 465000 loss = -0.9552 grad_norm = 2.4296 grad_penalty = 0.0761 regularization = 0.0000 true_logits = 0.6770 fake_logits = -0.3543 true_prob = 0.6349 fake_prob = 0.4423 
2022-05-01 05:48:04.363139 - gail/main.py:132 - [Evaluate] iter = 465000 episode={ returns = 41.3967 lengths = 24 } discounted_episode={ returns = 42.0484 lengths = 24 } 
2022-05-01 05:48:14.326135 - gail/main.py:164 - [TRPO] iter = 466000 dist_mean = 0.1043 dist_std = 0.2013 vf_loss = 0.0520 grad_norm = 3.2655 nat_grad_norm = 0.1062 cg_residual = 0.5397 step_size = 0.4053 reward = -0.0000 fps = 74 mse_loss = 2.3786 
2022-05-01 05:48:24.180060 - gail/main.py:164 - [TRPO] iter = 467000 dist_mean = 0.0416 dist_std = 0.2014 vf_loss = 0.0616 grad_norm = 2.4991 nat_grad_norm = 0.0999 cg_residual = 0.6611 step_size = 0.4667 reward = 0.0000 fps = 42 mse_loss = 2.2967 
2022-05-01 05:48:34.537824 - gail/main.py:164 - [TRPO] iter = 468000 dist_mean = 0.0449 dist_std = 0.2007 vf_loss = 0.0639 grad_norm = 2.3268 nat_grad_norm = 0.1339 cg_residual = 1.0643 step_size = 0.4462 reward = -0.0000 fps = 29 mse_loss = 2.3204 
2022-05-01 05:48:44.758253 - gail/main.py:164 - [TRPO] iter = 469000 dist_mean = 0.0958 dist_std = 0.2015 vf_loss = 0.0448 grad_norm = 2.8890 nat_grad_norm = 0.1510 cg_residual = 1.1872 step_size = 0.4041 reward = 0.0000 fps = 22 mse_loss = 2.2136 
2022-05-01 05:48:54.643383 - gail/main.py:164 - [TRPO] iter = 470000 dist_mean = 0.1386 dist_std = 0.2010 vf_loss = 0.1321 grad_norm = 2.6211 nat_grad_norm = 0.1385 cg_residual = 0.7030 step_size = 0.3936 reward = 0.0000 fps = 18 mse_loss = 2.2375 
2022-05-01 05:48:54.845362 - gail/main.py:191 - [Discriminator] iter = 470000 loss = -1.5191 grad_norm = 2.7154 grad_penalty = 0.1331 regularization = 0.0000 true_logits = 0.6232 fake_logits = -1.0289 true_prob = 0.6285 fake_prob = 0.3316 
2022-05-01 05:48:58.364080 - gail/main.py:132 - [Evaluate] iter = 470000 episode={ returns = 41.6928 lengths = 24 } discounted_episode={ returns = 40.6011 lengths = 24 } 
2022-05-01 05:49:08.317000 - gail/main.py:164 - [TRPO] iter = 471000 dist_mean = 0.1486 dist_std = 0.2004 vf_loss = 0.1363 grad_norm = 2.6971 nat_grad_norm = 0.1354 cg_residual = 0.8143 step_size = 0.3957 reward = -0.0000 fps = 74 mse_loss = 2.2896 
2022-05-01 05:49:18.402369 - gail/main.py:164 - [TRPO] iter = 472000 dist_mean = 0.0959 dist_std = 0.2001 vf_loss = 0.1148 grad_norm = 3.1421 nat_grad_norm = 0.0805 cg_residual = 0.6136 step_size = 0.5066 reward = 0.0000 fps = 42 mse_loss = 2.2936 
2022-05-01 05:49:28.037423 - gail/main.py:164 - [TRPO] iter = 473000 dist_mean = 0.0740 dist_std = 0.2001 vf_loss = 0.1014 grad_norm = 2.3941 nat_grad_norm = 0.1033 cg_residual = 0.5334 step_size = 0.5175 reward = 0.0000 fps = 30 mse_loss = 2.3327 
2022-05-01 05:49:38.289535 - gail/main.py:164 - [TRPO] iter = 474000 dist_mean = 0.0992 dist_std = 0.1996 vf_loss = 0.1461 grad_norm = 1.9175 nat_grad_norm = 0.1291 cg_residual = 1.1622 step_size = 0.4540 reward = -0.0000 fps = 23 mse_loss = 2.2919 
2022-05-01 05:49:48.273534 - gail/main.py:164 - [TRPO] iter = 475000 dist_mean = 0.0102 dist_std = 0.1995 vf_loss = 0.0641 grad_norm = 2.3353 nat_grad_norm = 0.1290 cg_residual = 1.4988 step_size = 0.4780 reward = 0.0000 fps = 18 mse_loss = 2.1398 
2022-05-01 05:49:48.521799 - gail/main.py:191 - [Discriminator] iter = 475000 loss = -0.6287 grad_norm = 2.5311 grad_penalty = 0.0761 regularization = 0.0000 true_logits = 0.6943 fake_logits = -0.0105 true_prob = 0.6409 fake_prob = 0.5038 
2022-05-01 05:50:03.651430 - gail/main.py:132 - [Evaluate] iter = 475000 episode={ returns = 535.4727 lengths = 161 } discounted_episode={ returns = 154.4355 lengths = 64 } 
2022-05-01 05:50:13.532783 - gail/main.py:164 - [TRPO] iter = 476000 dist_mean = 0.0584 dist_std = 0.1990 vf_loss = 0.0799 grad_norm = 2.6479 nat_grad_norm = 0.1511 cg_residual = 1.3724 step_size = 0.4234 reward = 0.0000 fps = 40 mse_loss = 2.2917 
2022-05-01 05:50:23.218170 - gail/main.py:164 - [TRPO] iter = 477000 dist_mean = 0.0359 dist_std = 0.1984 vf_loss = 0.0523 grad_norm = 2.9115 nat_grad_norm = 0.1272 cg_residual = 1.6871 step_size = 0.4065 reward = 0.0000 fps = 28 mse_loss = 2.2855 
2022-05-01 05:50:33.331481 - gail/main.py:164 - [TRPO] iter = 478000 dist_mean = 0.0952 dist_std = 0.1986 vf_loss = 0.0538 grad_norm = 3.0158 nat_grad_norm = 0.1243 cg_residual = 0.5619 step_size = 0.3935 reward = 0.0000 fps = 22 mse_loss = 2.2070 
2022-05-01 05:50:43.337204 - gail/main.py:164 - [TRPO] iter = 479000 dist_mean = 0.0994 dist_std = 0.1987 vf_loss = 0.1373 grad_norm = 2.4489 nat_grad_norm = 0.1303 cg_residual = 0.9051 step_size = 0.4266 reward = -0.0000 fps = 18 mse_loss = 2.1051 
2022-05-01 05:50:53.372342 - gail/main.py:164 - [TRPO] iter = 480000 dist_mean = 0.0357 dist_std = 0.1987 vf_loss = 0.0843 grad_norm = 2.6119 nat_grad_norm = 0.1360 cg_residual = 1.2284 step_size = 0.3825 reward = -0.0000 fps = 15 mse_loss = 2.1912 
2022-05-01 05:50:53.596768 - gail/main.py:191 - [Discriminator] iter = 480000 loss = -0.9783 grad_norm = 2.9831 grad_penalty = 0.0848 regularization = 0.0000 true_logits = 0.6653 fake_logits = -0.3978 true_prob = 0.6370 fake_prob = 0.4322 
2022-05-01 05:51:13.586590 - gail/main.py:132 - [Evaluate] iter = 480000 episode={ returns = 522.5649 lengths = 163 } discounted_episode={ returns = 389.4452 lengths = 141 } 
2022-05-01 05:51:23.650246 - gail/main.py:164 - [TRPO] iter = 481000 dist_mean = 0.0563 dist_std = 0.1980 vf_loss = 0.0263 grad_norm = 2.0306 nat_grad_norm = 0.0724 cg_residual = 0.4813 step_size = 0.6552 reward = -0.0000 fps = 33 mse_loss = 2.1745 
2022-05-01 05:51:33.400810 - gail/main.py:164 - [TRPO] iter = 482000 dist_mean = 0.1235 dist_std = 0.1983 vf_loss = 0.3587 grad_norm = 2.1955 nat_grad_norm = 0.1176 cg_residual = 1.1067 step_size = 0.4376 reward = -0.0000 fps = 25 mse_loss = 2.2146 
2022-05-01 05:51:43.234152 - gail/main.py:164 - [TRPO] iter = 483000 dist_mean = 0.0887 dist_std = 0.1985 vf_loss = 0.0756 grad_norm = 2.7130 nat_grad_norm = 0.1417 cg_residual = 1.4059 step_size = 0.3932 reward = -0.0000 fps = 20 mse_loss = 2.1810 
2022-05-01 05:51:53.119635 - gail/main.py:164 - [TRPO] iter = 484000 dist_mean = 0.0533 dist_std = 0.1972 vf_loss = 0.0798 grad_norm = 3.3260 nat_grad_norm = 0.1054 cg_residual = 0.8581 step_size = 0.3880 reward = -0.0000 fps = 16 mse_loss = 2.2507 
2022-05-01 05:52:03.145718 - gail/main.py:164 - [TRPO] iter = 485000 dist_mean = 0.0449 dist_std = 0.1970 vf_loss = 0.0677 grad_norm = 2.4090 nat_grad_norm = 0.1378 cg_residual = 1.5873 step_size = 0.4270 reward = 0.0000 fps = 14 mse_loss = 2.2783 
2022-05-01 05:52:03.389534 - gail/main.py:191 - [Discriminator] iter = 485000 loss = -0.7468 grad_norm = 2.6593 grad_penalty = 0.0822 regularization = 0.0000 true_logits = 0.6676 fake_logits = -0.1614 true_prob = 0.6371 fake_prob = 0.4751 
2022-05-01 05:52:29.065379 - gail/main.py:132 - [Evaluate] iter = 485000 episode={ returns = 697.3514 lengths = 213 } discounted_episode={ returns = 484.8387 lengths = 172 } 
2022-05-01 05:52:39.225150 - gail/main.py:164 - [TRPO] iter = 486000 dist_mean = 0.0450 dist_std = 0.1962 vf_loss = 0.0989 grad_norm = 2.3416 nat_grad_norm = 0.1245 cg_residual = 1.3805 step_size = 0.4339 reward = 0.0000 fps = 27 mse_loss = 2.2812 
2022-05-01 05:52:49.286787 - gail/main.py:164 - [TRPO] iter = 487000 dist_mean = 0.0799 dist_std = 0.1960 vf_loss = 0.0563 grad_norm = 3.0580 nat_grad_norm = 0.1212 cg_residual = 0.7329 step_size = 0.4493 reward = 0.0000 fps = 21 mse_loss = 2.2941 
2022-05-01 05:52:58.992412 - gail/main.py:164 - [TRPO] iter = 488000 dist_mean = 0.0530 dist_std = 0.1959 vf_loss = 0.1257 grad_norm = 2.6514 nat_grad_norm = 0.0967 cg_residual = 0.6822 step_size = 0.4510 reward = 0.0000 fps = 17 mse_loss = 2.4718 
2022-05-01 05:53:09.114352 - gail/main.py:164 - [TRPO] iter = 489000 dist_mean = 0.0754 dist_std = 0.1963 vf_loss = 0.0702 grad_norm = 2.8165 nat_grad_norm = 0.1388 cg_residual = 1.4189 step_size = 0.3923 reward = 0.0000 fps = 15 mse_loss = 2.3257 
2022-05-01 05:53:18.892528 - gail/main.py:164 - [TRPO] iter = 490000 dist_mean = 0.0315 dist_std = 0.1959 vf_loss = 0.0587 grad_norm = 2.7445 nat_grad_norm = 0.1146 cg_residual = 1.4685 step_size = 0.4719 reward = -0.0000 fps = 13 mse_loss = 2.2989 
2022-05-01 05:53:19.146068 - gail/main.py:191 - [Discriminator] iter = 490000 loss = -0.6304 grad_norm = 2.7036 grad_penalty = 0.0698 regularization = 0.0000 true_logits = 0.6126 fake_logits = -0.0876 true_prob = 0.6295 fake_prob = 0.4894 
2022-05-01 05:53:53.662916 - gail/main.py:132 - [Evaluate] iter = 490000 episode={ returns = 823.4662 lengths = 250 } discounted_episode={ returns = 719.9532 lengths = 264 } 
2022-05-01 05:54:03.774024 - gail/main.py:164 - [TRPO] iter = 491000 dist_mean = 0.0867 dist_std = 0.1957 vf_loss = 0.0439 grad_norm = 3.2041 nat_grad_norm = 0.1002 cg_residual = 0.7929 step_size = 0.4493 reward = -0.0000 fps = 22 mse_loss = 2.2486 
2022-05-01 05:54:13.566806 - gail/main.py:164 - [TRPO] iter = 492000 dist_mean = 0.1426 dist_std = 0.1955 vf_loss = 0.0547 grad_norm = 2.5901 nat_grad_norm = 0.1885 cg_residual = 1.7466 step_size = 0.3321 reward = 0.0000 fps = 18 mse_loss = 2.3170 
2022-05-01 05:54:23.374485 - gail/main.py:164 - [TRPO] iter = 493000 dist_mean = 0.0787 dist_std = 0.1956 vf_loss = 0.1091 grad_norm = 2.9026 nat_grad_norm = 0.1457 cg_residual = 1.2218 step_size = 0.3801 reward = -0.0000 fps = 15 mse_loss = 2.1937 
2022-05-01 05:54:33.211640 - gail/main.py:164 - [TRPO] iter = 494000 dist_mean = 0.1397 dist_std = 0.1949 vf_loss = 0.0783 grad_norm = 3.0315 nat_grad_norm = 0.1533 cg_residual = 1.6574 step_size = 0.3578 reward = -0.0000 fps = 13 mse_loss = 2.1440 
2022-05-01 05:54:42.432693 - gail/main.py:164 - [TRPO] iter = 495000 dist_mean = 0.0408 dist_std = 0.1941 vf_loss = 0.0863 grad_norm = 2.3751 nat_grad_norm = 0.0968 cg_residual = 0.4195 step_size = 0.4438 reward = -0.0000 fps = 12 mse_loss = 2.1813 
2022-05-01 05:54:42.655158 - gail/main.py:191 - [Discriminator] iter = 495000 loss = -0.7358 grad_norm = 2.7194 grad_penalty = 0.0712 regularization = 0.0000 true_logits = 0.6661 fake_logits = -0.1409 true_prob = 0.6386 fake_prob = 0.4740 
2022-05-01 05:54:59.610643 - gail/main.py:132 - [Evaluate] iter = 495000 episode={ returns = 279.2677 lengths = 90 } discounted_episode={ returns = 433.5069 lengths = 162 } 
2022-05-01 05:55:09.482977 - gail/main.py:164 - [TRPO] iter = 496000 dist_mean = 0.0615 dist_std = 0.1944 vf_loss = 0.0631 grad_norm = 2.2760 nat_grad_norm = 0.1047 cg_residual = 0.9405 step_size = 0.4760 reward = -0.0000 fps = 37 mse_loss = 2.2666 
2022-05-01 05:55:19.201098 - gail/main.py:164 - [TRPO] iter = 497000 dist_mean = 0.0871 dist_std = 0.1936 vf_loss = 0.1332 grad_norm = 3.5682 nat_grad_norm = 0.1356 cg_residual = 0.8756 step_size = 0.3813 reward = 0.0000 fps = 27 mse_loss = 2.1733 
2022-05-01 05:55:28.969565 - gail/main.py:164 - [TRPO] iter = 498000 dist_mean = 0.1262 dist_std = 0.1940 vf_loss = 0.3014 grad_norm = 3.3833 nat_grad_norm = 0.1276 cg_residual = 1.2829 step_size = 0.4199 reward = -0.0000 fps = 21 mse_loss = 2.1905 
2022-05-01 05:55:39.185284 - gail/main.py:164 - [TRPO] iter = 499000 dist_mean = 0.1820 dist_std = 0.1945 vf_loss = 0.1161 grad_norm = 2.1934 nat_grad_norm = 0.1155 cg_residual = 0.6712 step_size = 0.4622 reward = 0.0000 fps = 17 mse_loss = 2.2261 
2022-05-01 05:55:49.294920 - gail/main.py:164 - [TRPO] iter = 500000 dist_mean = 0.1104 dist_std = 0.1943 vf_loss = 0.1615 grad_norm = 2.5481 nat_grad_norm = 0.1192 cg_residual = 0.8459 step_size = 0.4967 reward = 0.0000 fps = 15 mse_loss = 2.1870 
2022-05-01 05:55:49.520841 - gail/main.py:191 - [Discriminator] iter = 500000 loss = -1.5095 grad_norm = 2.2464 grad_penalty = 0.1157 regularization = 0.0000 true_logits = 0.6654 fake_logits = -0.9597 true_prob = 0.6389 fake_prob = 0.3339 
2022-05-01 05:55:58.730139 - gail/main.py:132 - [Evaluate] iter = 500000 episode={ returns = 41.4795 lengths = 24 } discounted_episode={ returns = 41.0676 lengths = 24 } 
2022-05-01 05:56:08.518508 - gail/main.py:164 - [TRPO] iter = 501000 dist_mean = 0.1477 dist_std = 0.1946 vf_loss = 0.0699 grad_norm = 2.6889 nat_grad_norm = 0.1336 cg_residual = 0.6276 step_size = 0.4098 reward = 0.0000 fps = 75 mse_loss = 2.2025 
2022-05-01 05:56:18.358532 - gail/main.py:164 - [TRPO] iter = 502000 dist_mean = 0.0643 dist_std = 0.1947 vf_loss = 0.0533 grad_norm = 2.8181 nat_grad_norm = 0.1244 cg_residual = 1.0432 step_size = 0.4242 reward = -0.0000 fps = 43 mse_loss = 2.1423 
2022-05-01 05:56:28.372161 - gail/main.py:164 - [TRPO] iter = 503000 dist_mean = 0.0790 dist_std = 0.1949 vf_loss = 0.0662 grad_norm = 2.2698 nat_grad_norm = 0.1132 cg_residual = 0.5895 step_size = 0.4675 reward = -0.0000 fps = 30 mse_loss = 2.1918 
2022-05-01 05:56:38.335273 - gail/main.py:164 - [TRPO] iter = 504000 dist_mean = 0.0833 dist_std = 0.1945 vf_loss = 0.0354 grad_norm = 3.0246 nat_grad_norm = 0.0995 cg_residual = 0.6206 step_size = 0.4905 reward = 0.0000 fps = 23 mse_loss = 2.3088 
2022-05-01 05:56:48.563792 - gail/main.py:164 - [TRPO] iter = 505000 dist_mean = 0.0942 dist_std = 0.1947 vf_loss = 0.6957 grad_norm = 2.1160 nat_grad_norm = 0.0862 cg_residual = 0.6546 step_size = 0.4772 reward = -0.0000 fps = 18 mse_loss = 2.2048 
2022-05-01 05:56:48.774852 - gail/main.py:191 - [Discriminator] iter = 505000 loss = -0.8371 grad_norm = 2.1377 grad_penalty = 0.0908 regularization = 0.0000 true_logits = 0.5846 fake_logits = -0.3433 true_prob = 0.6224 fake_prob = 0.4458 
2022-05-01 05:57:03.159944 - gail/main.py:132 - [Evaluate] iter = 505000 episode={ returns = 270.0798 lengths = 97 } discounted_episode={ returns = 305.7328 lengths = 118 } 
2022-05-01 05:57:12.819370 - gail/main.py:164 - [TRPO] iter = 506000 dist_mean = 0.1152 dist_std = 0.1944 vf_loss = 0.1161 grad_norm = 2.0236 nat_grad_norm = 0.1016 cg_residual = 0.8103 step_size = 0.5216 reward = 0.0000 fps = 41 mse_loss = 2.2333 
2022-05-01 05:57:22.599485 - gail/main.py:164 - [TRPO] iter = 507000 dist_mean = 0.1073 dist_std = 0.1945 vf_loss = 0.0948 grad_norm = 2.4539 nat_grad_norm = 0.1539 cg_residual = 1.0689 step_size = 0.3894 reward = 0.0000 fps = 29 mse_loss = 2.3136 
2022-05-01 05:57:32.466319 - gail/main.py:164 - [TRPO] iter = 508000 dist_mean = 0.0544 dist_std = 0.1949 vf_loss = 0.0718 grad_norm = 2.6100 nat_grad_norm = 0.1105 cg_residual = 1.5622 step_size = 0.4524 reward = 0.0000 fps = 22 mse_loss = 2.4566 
2022-05-01 05:57:42.628607 - gail/main.py:164 - [TRPO] iter = 509000 dist_mean = 0.1123 dist_std = 0.1951 vf_loss = 0.1745 grad_norm = 2.4927 nat_grad_norm = 0.1035 cg_residual = 0.9404 step_size = 0.5126 reward = -0.0000 fps = 18 mse_loss = 2.3279 
2022-05-01 05:57:52.749683 - gail/main.py:164 - [TRPO] iter = 510000 dist_mean = 0.0571 dist_std = 0.1945 vf_loss = 0.3030 grad_norm = 3.2685 nat_grad_norm = 0.1171 cg_residual = 0.7158 step_size = 0.4363 reward = -0.0000 fps = 15 mse_loss = 2.2743 
2022-05-01 05:57:52.967995 - gail/main.py:191 - [Discriminator] iter = 510000 loss = -0.5994 grad_norm = 2.5223 grad_penalty = 0.0652 regularization = 0.0000 true_logits = 0.5787 fake_logits = -0.0859 true_prob = 0.6256 fake_prob = 0.4878 
2022-05-01 05:58:13.866839 - gail/main.py:132 - [Evaluate] iter = 510000 episode={ returns = 461.5692 lengths = 155 } discounted_episode={ returns = 409.3355 lengths = 151 } 
2022-05-01 05:58:23.563001 - gail/main.py:164 - [TRPO] iter = 511000 dist_mean = 0.0629 dist_std = 0.1944 vf_loss = 0.1160 grad_norm = 2.8679 nat_grad_norm = 0.1214 cg_residual = 0.8673 step_size = 0.4213 reward = -0.0000 fps = 32 mse_loss = 2.3897 
2022-05-01 05:58:33.501662 - gail/main.py:164 - [TRPO] iter = 512000 dist_mean = 0.0648 dist_std = 0.1939 vf_loss = 0.3626 grad_norm = 2.0670 nat_grad_norm = 0.1098 cg_residual = 0.5365 step_size = 0.4858 reward = 0.0000 fps = 24 mse_loss = 2.2440 
2022-05-01 05:58:43.659353 - gail/main.py:164 - [TRPO] iter = 513000 dist_mean = 0.1286 dist_std = 0.1940 vf_loss = 0.1172 grad_norm = 2.3724 nat_grad_norm = 0.1184 cg_residual = 0.8817 step_size = 0.4462 reward = 0.0000 fps = 19 mse_loss = 2.3566 
2022-05-01 05:58:53.631696 - gail/main.py:164 - [TRPO] iter = 514000 dist_mean = 0.0200 dist_std = 0.1942 vf_loss = 0.1045 grad_norm = 2.7819 nat_grad_norm = 0.1021 cg_residual = 1.0142 step_size = 0.4604 reward = 0.0000 fps = 16 mse_loss = 2.3316 
2022-05-01 05:59:03.860187 - gail/main.py:164 - [TRPO] iter = 515000 dist_mean = 0.0673 dist_std = 0.1938 vf_loss = 0.0992 grad_norm = 1.9384 nat_grad_norm = 0.0963 cg_residual = 1.2229 step_size = 0.4862 reward = 0.0000 fps = 14 mse_loss = 2.1598 
2022-05-01 05:59:04.089137 - gail/main.py:191 - [Discriminator] iter = 515000 loss = -0.9962 grad_norm = 2.7483 grad_penalty = 0.0865 regularization = 0.0000 true_logits = 0.6082 fake_logits = -0.4744 true_prob = 0.6295 fake_prob = 0.4162 
2022-05-01 05:59:34.846575 - gail/main.py:132 - [Evaluate] iter = 515000 episode={ returns = 772.8073 lengths = 235 } discounted_episode={ returns = 636.8816 lengths = 228 } 
2022-05-01 05:59:44.778282 - gail/main.py:164 - [TRPO] iter = 516000 dist_mean = 0.0366 dist_std = 0.1945 vf_loss = 0.0807 grad_norm = 2.1712 nat_grad_norm = 0.1315 cg_residual = 4.1561 step_size = 0.4384 reward = -0.0000 fps = 24 mse_loss = 2.1288 
2022-05-01 05:59:54.892037 - gail/main.py:164 - [TRPO] iter = 517000 dist_mean = 0.0800 dist_std = 0.1947 vf_loss = 0.1494 grad_norm = 1.9276 nat_grad_norm = 0.1264 cg_residual = 1.6396 step_size = 0.4448 reward = -0.0000 fps = 19 mse_loss = 2.1962 
2022-05-01 06:00:04.950345 - gail/main.py:164 - [TRPO] iter = 518000 dist_mean = 0.1182 dist_std = 0.1947 vf_loss = 0.1790 grad_norm = 2.9949 nat_grad_norm = 0.1057 cg_residual = 1.1444 step_size = 0.4030 reward = 0.0000 fps = 16 mse_loss = 2.2345 
2022-05-01 06:00:15.045953 - gail/main.py:164 - [TRPO] iter = 519000 dist_mean = 0.2418 dist_std = 0.1945 vf_loss = 0.0880 grad_norm = 3.0003 nat_grad_norm = 0.1437 cg_residual = 0.9949 step_size = 0.3711 reward = 0.0000 fps = 14 mse_loss = 2.2116 
2022-05-01 06:00:24.905385 - gail/main.py:164 - [TRPO] iter = 520000 dist_mean = 0.0989 dist_std = 0.1939 vf_loss = 0.0838 grad_norm = 2.0765 nat_grad_norm = 0.1053 cg_residual = 0.8056 step_size = 0.5164 reward = 0.0000 fps = 12 mse_loss = 2.3478 
2022-05-01 06:00:25.159580 - gail/main.py:191 - [Discriminator] iter = 520000 loss = -1.0868 grad_norm = 2.8410 grad_penalty = 0.1055 regularization = 0.0000 true_logits = 0.5078 fake_logits = -0.6845 true_prob = 0.6129 fake_prob = 0.3854 
2022-05-01 06:00:28.384644 - gail/main.py:132 - [Evaluate] iter = 520000 episode={ returns = 39.6310 lengths = 23 } discounted_episode={ returns = 39.1220 lengths = 23 } 
2022-05-01 06:00:38.313399 - gail/main.py:164 - [TRPO] iter = 521000 dist_mean = 0.1562 dist_std = 0.1941 vf_loss = 0.0888 grad_norm = 2.9292 nat_grad_norm = 0.0903 cg_residual = 0.7349 step_size = 0.4626 reward = 0.0000 fps = 76 mse_loss = 2.2647 
2022-05-01 06:00:48.257420 - gail/main.py:164 - [TRPO] iter = 522000 dist_mean = 0.1347 dist_std = 0.1945 vf_loss = 0.2233 grad_norm = 2.0833 nat_grad_norm = 0.1115 cg_residual = 0.8865 step_size = 0.4782 reward = -0.0000 fps = 43 mse_loss = 2.1780 
2022-05-01 06:00:58.021083 - gail/main.py:164 - [TRPO] iter = 523000 dist_mean = 0.1065 dist_std = 0.1943 vf_loss = 0.2247 grad_norm = 3.2839 nat_grad_norm = 0.1252 cg_residual = 1.1295 step_size = 0.4476 reward = 0.0000 fps = 30 mse_loss = 2.0837 
2022-05-01 06:01:07.935777 - gail/main.py:164 - [TRPO] iter = 524000 dist_mean = 0.0758 dist_std = 0.1940 vf_loss = 0.0598 grad_norm = 3.4472 nat_grad_norm = 0.1237 cg_residual = 1.0905 step_size = 0.3924 reward = 0.0000 fps = 23 mse_loss = 2.3059 
2022-05-01 06:01:18.100591 - gail/main.py:164 - [TRPO] iter = 525000 dist_mean = 0.1116 dist_std = 0.1946 vf_loss = 0.0759 grad_norm = 1.8218 nat_grad_norm = 0.1324 cg_residual = 1.3719 step_size = 0.4489 reward = 0.0000 fps = 18 mse_loss = 2.0495 
2022-05-01 06:01:18.352469 - gail/main.py:191 - [Discriminator] iter = 525000 loss = -1.1392 grad_norm = 2.4809 grad_penalty = 0.0957 regularization = 0.0000 true_logits = 0.4973 fake_logits = -0.7377 true_prob = 0.6102 fake_prob = 0.3733 
2022-05-01 06:01:21.603216 - gail/main.py:132 - [Evaluate] iter = 525000 episode={ returns = 39.4881 lengths = 23 } discounted_episode={ returns = 39.0127 lengths = 23 } 
2022-05-01 06:01:31.148656 - gail/main.py:164 - [TRPO] iter = 526000 dist_mean = 0.0802 dist_std = 0.1943 vf_loss = 0.2020 grad_norm = 1.7824 nat_grad_norm = 0.1150 cg_residual = 0.6615 step_size = 0.5024 reward = 0.0000 fps = 78 mse_loss = 2.2914 
2022-05-01 06:01:41.347953 - gail/main.py:164 - [TRPO] iter = 527000 dist_mean = 0.0446 dist_std = 0.1939 vf_loss = 1.0845 grad_norm = 2.9390 nat_grad_norm = 0.0715 cg_residual = 0.5896 step_size = 0.5959 reward = -0.0000 fps = 43 mse_loss = 2.3111 
2022-05-01 06:01:51.128998 - gail/main.py:164 - [TRPO] iter = 528000 dist_mean = 0.0529 dist_std = 0.1929 vf_loss = 0.0547 grad_norm = 2.6843 nat_grad_norm = 0.1163 cg_residual = 1.3801 step_size = 0.4502 reward = 0.0000 fps = 30 mse_loss = 2.3615 
2022-05-01 06:02:00.692446 - gail/main.py:164 - [TRPO] iter = 529000 dist_mean = 0.0777 dist_std = 0.1925 vf_loss = 0.0448 grad_norm = 2.8473 nat_grad_norm = 0.1037 cg_residual = 1.3518 step_size = 0.4014 reward = 0.0000 fps = 23 mse_loss = 2.1810 
2022-05-01 06:02:10.909401 - gail/main.py:164 - [TRPO] iter = 530000 dist_mean = 0.0723 dist_std = 0.1923 vf_loss = 0.5175 grad_norm = 1.9717 nat_grad_norm = 0.0920 cg_residual = 0.3422 step_size = 0.5839 reward = -0.0000 fps = 19 mse_loss = 2.1206 
2022-05-01 06:02:11.155837 - gail/main.py:191 - [Discriminator] iter = 530000 loss = -0.6488 grad_norm = 2.3038 grad_penalty = 0.0634 regularization = 0.0000 true_logits = 0.4623 fake_logits = -0.2500 true_prob = 0.6048 fake_prob = 0.4560 
2022-05-01 06:02:23.256191 - gail/main.py:132 - [Evaluate] iter = 530000 episode={ returns = 434.1401 lengths = 137 } discounted_episode={ returns = 86.5932 lengths = 38 } 
2022-05-01 06:02:33.217347 - gail/main.py:164 - [TRPO] iter = 531000 dist_mean = 0.0687 dist_std = 0.1926 vf_loss = 0.1326 grad_norm = 2.1452 nat_grad_norm = 0.1096 cg_residual = 1.4901 step_size = 0.4285 reward = -0.0000 fps = 45 mse_loss = 2.2059 
2022-05-01 06:02:43.202420 - gail/main.py:164 - [TRPO] iter = 532000 dist_mean = 0.0698 dist_std = 0.1935 vf_loss = 0.1201 grad_norm = 2.3634 nat_grad_norm = 0.1196 cg_residual = 0.7387 step_size = 0.4487 reward = -0.0000 fps = 31 mse_loss = 2.2427 
2022-05-01 06:02:53.107248 - gail/main.py:164 - [TRPO] iter = 533000 dist_mean = 0.1253 dist_std = 0.1941 vf_loss = 0.3086 grad_norm = 2.0752 nat_grad_norm = 0.1430 cg_residual = 0.8904 step_size = 0.4132 reward = 0.0000 fps = 23 mse_loss = 2.1289 
2022-05-01 06:03:03.522461 - gail/main.py:164 - [TRPO] iter = 534000 dist_mean = 0.1706 dist_std = 0.1930 vf_loss = 0.0637 grad_norm = 2.4357 nat_grad_norm = 0.1015 cg_residual = 0.5168 step_size = 0.4973 reward = 0.0000 fps = 19 mse_loss = 2.1350 
2022-05-01 06:03:13.590934 - gail/main.py:164 - [TRPO] iter = 535000 dist_mean = 0.0764 dist_std = 0.1920 vf_loss = 0.0852 grad_norm = 2.3390 nat_grad_norm = 0.1197 cg_residual = 0.7228 step_size = 0.4745 reward = -0.0000 fps = 16 mse_loss = 2.1278 
2022-05-01 06:03:13.823628 - gail/main.py:191 - [Discriminator] iter = 535000 loss = -0.9388 grad_norm = 2.5985 grad_penalty = 0.0707 regularization = 0.0000 true_logits = 0.5188 fake_logits = -0.4907 true_prob = 0.6136 fake_prob = 0.4145 
2022-05-01 06:03:17.041038 - gail/main.py:132 - [Evaluate] iter = 535000 episode={ returns = 37.8034 lengths = 22 } discounted_episode={ returns = 37.3970 lengths = 22 } 
2022-05-01 06:03:26.830497 - gail/main.py:164 - [TRPO] iter = 536000 dist_mean = 0.1173 dist_std = 0.1917 vf_loss = 0.1265 grad_norm = 3.0543 nat_grad_norm = 0.1409 cg_residual = 0.8684 step_size = 0.3967 reward = 0.0000 fps = 77 mse_loss = 2.0523 
2022-05-01 06:03:37.049142 - gail/main.py:164 - [TRPO] iter = 537000 dist_mean = 0.1870 dist_std = 0.1909 vf_loss = 0.3468 grad_norm = 2.7279 nat_grad_norm = 0.0971 cg_residual = 0.8771 step_size = 0.4643 reward = -0.0000 fps = 43 mse_loss = 2.1579 
2022-05-01 06:03:46.924499 - gail/main.py:164 - [TRPO] iter = 538000 dist_mean = 0.0642 dist_std = 0.1916 vf_loss = 0.1266 grad_norm = 2.4885 nat_grad_norm = 0.1104 cg_residual = 1.0357 step_size = 0.4695 reward = 0.0000 fps = 30 mse_loss = 2.2753 
2022-05-01 06:03:56.719387 - gail/main.py:164 - [TRPO] iter = 539000 dist_mean = 0.0918 dist_std = 0.1908 vf_loss = 0.0853 grad_norm = 2.4027 nat_grad_norm = 0.1074 cg_residual = 0.9995 step_size = 0.4341 reward = 0.0000 fps = 23 mse_loss = 2.1862 
2022-05-01 06:04:06.813118 - gail/main.py:164 - [TRPO] iter = 540000 dist_mean = 0.1140 dist_std = 0.1902 vf_loss = 0.0993 grad_norm = 2.7604 nat_grad_norm = 0.1135 cg_residual = 0.7699 step_size = 0.4530 reward = -0.0000 fps = 18 mse_loss = 2.2387 
2022-05-01 06:04:07.039493 - gail/main.py:191 - [Discriminator] iter = 540000 loss = -1.2796 grad_norm = 2.0625 grad_penalty = 0.0991 regularization = 0.0000 true_logits = 0.5166 fake_logits = -0.8622 true_prob = 0.6143 fake_prob = 0.3575 
2022-05-01 06:04:17.900527 - gail/main.py:132 - [Evaluate] iter = 540000 episode={ returns = 37.8709 lengths = 22 } discounted_episode={ returns = 300.6386 lengths = 138 } 
2022-05-01 06:04:28.061458 - gail/main.py:164 - [TRPO] iter = 541000 dist_mean = 0.0985 dist_std = 0.1897 vf_loss = 0.1921 grad_norm = 1.8905 nat_grad_norm = 0.1346 cg_residual = 0.8119 step_size = 0.4239 reward = 0.0000 fps = 47 mse_loss = 2.0585 
2022-05-01 06:04:38.147596 - gail/main.py:164 - [TRPO] iter = 542000 dist_mean = 0.0694 dist_std = 0.1895 vf_loss = 0.8246 grad_norm = 1.7906 nat_grad_norm = 0.0710 cg_residual = 0.4434 step_size = 0.7075 reward = -0.0000 fps = 32 mse_loss = 2.1194 
2022-05-01 06:04:48.314964 - gail/main.py:164 - [TRPO] iter = 543000 dist_mean = 0.1370 dist_std = 0.1898 vf_loss = 0.0936 grad_norm = 1.8245 nat_grad_norm = 0.1173 cg_residual = 0.8876 step_size = 0.4677 reward = 0.0000 fps = 24 mse_loss = 2.0782 
2022-05-01 06:04:57.848135 - gail/main.py:164 - [TRPO] iter = 544000 dist_mean = 0.0723 dist_std = 0.1901 vf_loss = 0.0696 grad_norm = 3.8182 nat_grad_norm = 0.1797 cg_residual = 2.9923 step_size = 0.2791 reward = 0.0000 fps = 19 mse_loss = 2.2461 
2022-05-01 06:05:07.496871 - gail/main.py:164 - [TRPO] iter = 545000 dist_mean = 0.0929 dist_std = 0.1894 vf_loss = 0.6318 grad_norm = 2.5530 nat_grad_norm = 0.0685 cg_residual = 0.6656 step_size = 0.6277 reward = -0.0000 fps = 16 mse_loss = 2.1579 
2022-05-01 06:05:07.704357 - gail/main.py:191 - [Discriminator] iter = 545000 loss = -1.0168 grad_norm = 2.1757 grad_penalty = 0.0847 regularization = 0.0000 true_logits = 0.5155 fake_logits = -0.5861 true_prob = 0.6159 fake_prob = 0.3995 
2022-05-01 06:05:10.809748 - gail/main.py:132 - [Evaluate] iter = 545000 episode={ returns = 38.5857 lengths = 22 } discounted_episode={ returns = 37.7101 lengths = 22 } 
2022-05-01 06:05:20.420256 - gail/main.py:164 - [TRPO] iter = 546000 dist_mean = 0.0690 dist_std = 0.1895 vf_loss = 0.0737 grad_norm = 2.9601 nat_grad_norm = 0.1163 cg_residual = 0.8137 step_size = 0.4449 reward = -0.0000 fps = 78 mse_loss = 2.1040 
2022-05-01 06:05:30.156676 - gail/main.py:164 - [TRPO] iter = 547000 dist_mean = 0.0710 dist_std = 0.1897 vf_loss = 0.1259 grad_norm = 3.0591 nat_grad_norm = 0.1065 cg_residual = 1.5420 step_size = 0.4082 reward = 0.0000 fps = 44 mse_loss = 2.1395 
2022-05-01 06:05:40.312058 - gail/main.py:164 - [TRPO] iter = 548000 dist_mean = 0.1524 dist_std = 0.1887 vf_loss = 0.3031 grad_norm = 3.3248 nat_grad_norm = 0.0999 cg_residual = 1.4345 step_size = 0.3873 reward = -0.0000 fps = 30 mse_loss = 2.1484 
2022-05-01 06:05:50.426690 - gail/main.py:164 - [TRPO] iter = 549000 dist_mean = 0.1301 dist_std = 0.1883 vf_loss = 0.0993 grad_norm = 2.7208 nat_grad_norm = 0.1383 cg_residual = 0.7632 step_size = 0.4074 reward = 0.0000 fps = 23 mse_loss = 2.0947 
2022-05-01 06:06:00.708174 - gail/main.py:164 - [TRPO] iter = 550000 dist_mean = 0.1079 dist_std = 0.1879 vf_loss = 0.1189 grad_norm = 2.0904 nat_grad_norm = 0.1168 cg_residual = 1.0717 step_size = 0.4647 reward = 0.0000 fps = 18 mse_loss = 2.1344 
2022-05-01 06:06:00.971837 - gail/main.py:191 - [Discriminator] iter = 550000 loss = -1.1167 grad_norm = 2.3397 grad_penalty = 0.0802 regularization = 0.0000 true_logits = 0.4347 fake_logits = -0.7622 true_prob = 0.5993 fake_prob = 0.3724 
2022-05-01 06:06:04.487760 - gail/main.py:132 - [Evaluate] iter = 550000 episode={ returns = 38.5731 lengths = 22 } discounted_episode={ returns = 38.5270 lengths = 22 } 
2022-05-01 06:06:14.408704 - gail/main.py:164 - [TRPO] iter = 551000 dist_mean = 0.0945 dist_std = 0.1876 vf_loss = 0.0473 grad_norm = 2.1106 nat_grad_norm = 0.1289 cg_residual = 0.9877 step_size = 0.4421 reward = -0.0000 fps = 74 mse_loss = 2.0179 
2022-05-01 06:06:23.669212 - gail/main.py:164 - [TRPO] iter = 552000 dist_mean = 0.0845 dist_std = 0.1874 vf_loss = 0.0349 grad_norm = 3.7078 nat_grad_norm = 0.1177 cg_residual = 0.9702 step_size = 0.3968 reward = -0.0000 fps = 44 mse_loss = 2.0717 
2022-05-01 06:06:33.163333 - gail/main.py:164 - [TRPO] iter = 553000 dist_mean = 0.0453 dist_std = 0.1869 vf_loss = 0.0616 grad_norm = 1.7441 nat_grad_norm = 0.0784 cg_residual = 0.8889 step_size = 0.5887 reward = 0.0000 fps = 31 mse_loss = 2.0606 
2022-05-01 06:06:42.858758 - gail/main.py:164 - [TRPO] iter = 554000 dist_mean = 0.0331 dist_std = 0.1864 vf_loss = 0.2350 grad_norm = 3.4155 nat_grad_norm = 0.1719 cg_residual = 2.5854 step_size = 0.2966 reward = -0.0000 fps = 23 mse_loss = 2.0593 
2022-05-01 06:06:52.906879 - gail/main.py:164 - [TRPO] iter = 555000 dist_mean = 0.1124 dist_std = 0.1858 vf_loss = 0.1534 grad_norm = 2.0469 nat_grad_norm = 0.0961 cg_residual = 0.6883 step_size = 0.4869 reward = -0.0000 fps = 19 mse_loss = 2.1141 
2022-05-01 06:06:53.161758 - gail/main.py:191 - [Discriminator] iter = 555000 loss = -1.3615 grad_norm = 2.3018 grad_penalty = 0.1129 regularization = 0.0000 true_logits = 0.4208 fake_logits = -1.0536 true_prob = 0.5950 fake_prob = 0.3358 
2022-05-01 06:06:56.416903 - gail/main.py:132 - [Evaluate] iter = 555000 episode={ returns = 38.3444 lengths = 22 } discounted_episode={ returns = 38.0072 lengths = 22 } 
2022-05-01 06:07:06.675387 - gail/main.py:164 - [TRPO] iter = 556000 dist_mean = 0.1075 dist_std = 0.1860 vf_loss = 0.0929 grad_norm = 2.0006 nat_grad_norm = 0.1021 cg_residual = 0.6457 step_size = 0.4844 reward = -0.0000 fps = 74 mse_loss = 2.1239 
2022-05-01 06:07:16.362690 - gail/main.py:164 - [TRPO] iter = 557000 dist_mean = 0.0953 dist_std = 0.1860 vf_loss = 0.0936 grad_norm = 2.6812 nat_grad_norm = 0.1153 cg_residual = 0.9087 step_size = 0.4536 reward = -0.0000 fps = 43 mse_loss = 2.1655 
2022-05-01 06:07:26.410339 - gail/main.py:164 - [TRPO] iter = 558000 dist_mean = 0.1721 dist_std = 0.1857 vf_loss = 0.0964 grad_norm = 2.5510 nat_grad_norm = 0.1436 cg_residual = 1.1923 step_size = 0.3931 reward = 0.0000 fps = 30 mse_loss = 2.0146 
2022-05-01 06:07:36.498665 - gail/main.py:164 - [TRPO] iter = 559000 dist_mean = 0.1655 dist_std = 0.1861 vf_loss = 0.1210 grad_norm = 3.0415 nat_grad_norm = 0.1195 cg_residual = 0.9746 step_size = 0.4234 reward = -0.0000 fps = 23 mse_loss = 2.1632 
2022-05-01 06:07:46.353804 - gail/main.py:164 - [TRPO] iter = 560000 dist_mean = 0.2463 dist_std = 0.1850 vf_loss = 0.2038 grad_norm = 2.5351 nat_grad_norm = 0.1289 cg_residual = 1.1592 step_size = 0.4065 reward = 0.0000 fps = 18 mse_loss = 2.1126 
2022-05-01 06:07:46.574524 - gail/main.py:191 - [Discriminator] iter = 560000 loss = -1.5465 grad_norm = 2.2763 grad_penalty = 0.1081 regularization = 0.0000 true_logits = 0.4925 fake_logits = -1.1621 true_prob = 0.6089 fake_prob = 0.3032 
2022-05-01 06:08:15.653237 - gail/main.py:132 - [Evaluate] iter = 560000 episode={ returns = 737.2076 lengths = 219 } discounted_episode={ returns = 559.6244 lengths = 222 } 
2022-05-01 06:08:25.145569 - gail/main.py:164 - [TRPO] iter = 561000 dist_mean = 0.0958 dist_std = 0.1849 vf_loss = 0.1265 grad_norm = 2.2640 nat_grad_norm = 0.1472 cg_residual = 1.8345 step_size = 0.3883 reward = 0.0000 fps = 25 mse_loss = 2.0690 
2022-05-01 06:08:35.004077 - gail/main.py:164 - [TRPO] iter = 562000 dist_mean = 0.1276 dist_std = 0.1839 vf_loss = 0.1527 grad_norm = 2.5861 nat_grad_norm = 0.1162 cg_residual = 1.4909 step_size = 0.4340 reward = 0.0000 fps = 20 mse_loss = 2.0343 
2022-05-01 06:08:44.728671 - gail/main.py:164 - [TRPO] iter = 563000 dist_mean = 0.0993 dist_std = 0.1842 vf_loss = 0.1926 grad_norm = 2.2533 nat_grad_norm = 0.1027 cg_residual = 1.9946 step_size = 0.5261 reward = -0.0000 fps = 17 mse_loss = 1.9766 
2022-05-01 06:08:54.969779 - gail/main.py:164 - [TRPO] iter = 564000 dist_mean = 0.1693 dist_std = 0.1855 vf_loss = 0.3804 grad_norm = 2.0417 nat_grad_norm = 0.1263 cg_residual = 1.0971 step_size = 0.4637 reward = -0.0000 fps = 14 mse_loss = 2.1182 
2022-05-01 06:09:04.958321 - gail/main.py:164 - [TRPO] iter = 565000 dist_mean = 0.0534 dist_std = 0.1862 vf_loss = 0.0576 grad_norm = 2.6124 nat_grad_norm = 0.0883 cg_residual = 1.2659 step_size = 0.4778 reward = 0.0000 fps = 12 mse_loss = 2.0318 
2022-05-01 06:09:05.188848 - gail/main.py:191 - [Discriminator] iter = 565000 loss = -0.4430 grad_norm = 2.5073 grad_penalty = 0.0622 regularization = 0.0000 true_logits = 0.4106 fake_logits = -0.0945 true_prob = 0.5920 fake_prob = 0.4856 
2022-05-01 06:09:46.483401 - gail/main.py:132 - [Evaluate] iter = 565000 episode={ returns = 723.2803 lengths = 237 } discounted_episode={ returns = 893.1821 lengths = 370 } 
2022-05-01 06:09:56.459500 - gail/main.py:164 - [TRPO] iter = 566000 dist_mean = 0.1943 dist_std = 0.1865 vf_loss = 0.2165 grad_norm = 2.2753 nat_grad_norm = 0.1739 cg_residual = 2.2347 step_size = 0.3369 reward = -0.0000 fps = 19 mse_loss = 2.0332 
2022-05-01 06:10:06.690969 - gail/main.py:164 - [TRPO] iter = 567000 dist_mean = 0.1225 dist_std = 0.1857 vf_loss = 0.1509 grad_norm = 2.4409 nat_grad_norm = 0.1081 cg_residual = 1.0865 step_size = 0.4314 reward = -0.0000 fps = 16 mse_loss = 1.9935 
2022-05-01 06:10:17.131272 - gail/main.py:164 - [TRPO] iter = 568000 dist_mean = 0.1295 dist_std = 0.1854 vf_loss = 0.0850 grad_norm = 3.2168 nat_grad_norm = 0.1036 cg_residual = 1.2470 step_size = 0.4511 reward = 0.0000 fps = 13 mse_loss = 1.9030 
2022-05-01 06:10:26.634791 - gail/main.py:164 - [TRPO] iter = 569000 dist_mean = 0.0925 dist_std = 0.1854 vf_loss = 0.1086 grad_norm = 2.5981 nat_grad_norm = 0.0746 cg_residual = 0.5625 step_size = 0.5778 reward = 0.0000 fps = 12 mse_loss = 2.0913 
2022-05-01 06:10:36.633142 - gail/main.py:164 - [TRPO] iter = 570000 dist_mean = 0.0850 dist_std = 0.1853 vf_loss = 0.1106 grad_norm = 2.4012 nat_grad_norm = 0.1212 cg_residual = 1.0729 step_size = 0.4267 reward = -0.0000 fps = 10 mse_loss = 2.0272 
2022-05-01 06:10:36.897379 - gail/main.py:191 - [Discriminator] iter = 570000 loss = -0.8662 grad_norm = 2.5296 grad_penalty = 0.0688 regularization = 0.0000 true_logits = 0.4622 fake_logits = -0.4729 true_prob = 0.6017 fake_prob = 0.4158 
2022-05-01 06:12:02.589922 - gail/main.py:132 - [Evaluate] iter = 570000 episode={ returns = 2079.0753 lengths = 595 } discounted_episode={ returns = 1533.9319 lengths = 660 } 
2022-05-01 06:12:12.665671 - gail/main.py:164 - [TRPO] iter = 571000 dist_mean = 0.1272 dist_std = 0.1853 vf_loss = 0.1689 grad_norm = 3.0538 nat_grad_norm = 0.1444 cg_residual = 0.7953 step_size = 0.3836 reward = -0.0000 fps = 10 mse_loss = 1.9690 
2022-05-01 06:12:22.602798 - gail/main.py:164 - [TRPO] iter = 572000 dist_mean = 0.0379 dist_std = 0.1849 vf_loss = 0.0992 grad_norm = 3.0950 nat_grad_norm = 0.0850 cg_residual = 1.2132 step_size = 0.4876 reward = 0.0000 fps = 9 mse_loss = 2.1199 
2022-05-01 06:12:32.690668 - gail/main.py:164 - [TRPO] iter = 573000 dist_mean = 0.0475 dist_std = 0.1844 vf_loss = 0.0990 grad_norm = 1.9377 nat_grad_norm = 0.0971 cg_residual = 1.4615 step_size = 0.5075 reward = 0.0000 fps = 8 mse_loss = 1.9759 
2022-05-01 06:12:42.542156 - gail/main.py:164 - [TRPO] iter = 574000 dist_mean = 0.0581 dist_std = 0.1840 vf_loss = 0.1715 grad_norm = 1.8790 nat_grad_norm = 0.1083 cg_residual = 0.8962 step_size = 0.4728 reward = 0.0000 fps = 7 mse_loss = 2.0270 
2022-05-01 06:12:52.419581 - gail/main.py:164 - [TRPO] iter = 575000 dist_mean = 0.0370 dist_std = 0.1836 vf_loss = 0.0867 grad_norm = 2.3237 nat_grad_norm = 0.1076 cg_residual = 1.1463 step_size = 0.4225 reward = 0.0000 fps = 7 mse_loss = 1.9947 
2022-05-01 06:12:52.635908 - gail/main.py:191 - [Discriminator] iter = 575000 loss = -0.4499 grad_norm = 2.9825 grad_penalty = 0.0702 regularization = 0.0000 true_logits = 0.3465 fake_logits = -0.1736 true_prob = 0.5792 fake_prob = 0.4704 
2022-05-01 06:13:21.365695 - gail/main.py:132 - [Evaluate] iter = 575000 episode={ returns = 421.9417 lengths = 132 } discounted_episode={ returns = 716.4684 lengths = 300 } 
2022-05-01 06:13:31.127825 - gail/main.py:164 - [TRPO] iter = 576000 dist_mean = 0.0982 dist_std = 0.1831 vf_loss = 0.1204 grad_norm = 2.9480 nat_grad_norm = 0.1172 cg_residual = 0.8062 step_size = 0.4231 reward = 0.0000 fps = 25 mse_loss = 1.9953 
2022-05-01 06:13:41.307791 - gail/main.py:164 - [TRPO] iter = 577000 dist_mean = 0.0521 dist_std = 0.1828 vf_loss = 0.0516 grad_norm = 2.5670 nat_grad_norm = 0.1324 cg_residual = 2.2422 step_size = 0.3606 reward = 0.0000 fps = 20 mse_loss = 1.9021 
2022-05-01 06:13:51.178507 - gail/main.py:164 - [TRPO] iter = 578000 dist_mean = 0.0629 dist_std = 0.1830 vf_loss = 0.1254 grad_norm = 1.9597 nat_grad_norm = 0.1340 cg_residual = 0.9757 step_size = 0.4364 reward = -0.0000 fps = 17 mse_loss = 1.8953 
2022-05-01 06:14:01.076801 - gail/main.py:164 - [TRPO] iter = 579000 dist_mean = 0.1697 dist_std = 0.1823 vf_loss = 0.0847 grad_norm = 2.5007 nat_grad_norm = 0.1293 cg_residual = 0.7379 step_size = 0.4159 reward = 0.0000 fps = 14 mse_loss = 1.8159 
2022-05-01 06:14:11.143600 - gail/main.py:164 - [TRPO] iter = 580000 dist_mean = 0.0735 dist_std = 0.1829 vf_loss = 0.1060 grad_norm = 2.8653 nat_grad_norm = 0.1380 cg_residual = 2.8311 step_size = 0.3793 reward = 0.0000 fps = 12 mse_loss = 1.9295 
2022-05-01 06:14:11.377124 - gail/main.py:191 - [Discriminator] iter = 580000 loss = -0.7972 grad_norm = 2.4021 grad_penalty = 0.0712 regularization = 0.0000 true_logits = 0.3284 fake_logits = -0.5400 true_prob = 0.5749 fake_prob = 0.4040 
2022-05-01 06:14:21.179389 - gail/main.py:132 - [Evaluate] iter = 580000 episode={ returns = 384.7260 lengths = 119 } discounted_episode={ returns = 36.9047 lengths = 21 } 
2022-05-01 06:14:30.682478 - gail/main.py:164 - [TRPO] iter = 581000 dist_mean = 0.1125 dist_std = 0.1828 vf_loss = 0.1272 grad_norm = 1.9172 nat_grad_norm = 0.1216 cg_residual = 1.2530 step_size = 0.4447 reward = -0.0000 fps = 51 mse_loss = 1.8800 
2022-05-01 06:14:40.707156 - gail/main.py:164 - [TRPO] iter = 582000 dist_mean = 0.1173 dist_std = 0.1828 vf_loss = 0.0882 grad_norm = 1.7680 nat_grad_norm = 0.1445 cg_residual = 1.1851 step_size = 0.4235 reward = -0.0000 fps = 34 mse_loss = 1.9456 
2022-05-01 06:14:50.425891 - gail/main.py:164 - [TRPO] iter = 583000 dist_mean = 0.0348 dist_std = 0.1827 vf_loss = 0.0707 grad_norm = 2.9182 nat_grad_norm = 0.1243 cg_residual = 1.8249 step_size = 0.3892 reward = 0.0000 fps = 25 mse_loss = 1.9503 
2022-05-01 06:15:00.651876 - gail/main.py:164 - [TRPO] iter = 584000 dist_mean = 0.0832 dist_std = 0.1834 vf_loss = 0.0467 grad_norm = 1.7623 nat_grad_norm = 0.1216 cg_residual = 0.8054 step_size = 0.4667 reward = -0.0000 fps = 20 mse_loss = 2.0696 
2022-05-01 06:15:10.806476 - gail/main.py:164 - [TRPO] iter = 585000 dist_mean = 0.1121 dist_std = 0.1829 vf_loss = 0.0474 grad_norm = 2.1528 nat_grad_norm = 0.0897 cg_residual = 0.9460 step_size = 0.5341 reward = -0.0000 fps = 16 mse_loss = 1.9996 
2022-05-01 06:15:11.049285 - gail/main.py:191 - [Discriminator] iter = 585000 loss = -0.9596 grad_norm = 3.7667 grad_penalty = 0.0929 regularization = 0.0000 true_logits = 0.3169 fake_logits = -0.7357 true_prob = 0.5754 fake_prob = 0.3717 
2022-05-01 06:15:14.038753 - gail/main.py:132 - [Evaluate] iter = 585000 episode={ returns = 36.8019 lengths = 21 } discounted_episode={ returns = 36.1786 lengths = 21 } 
2022-05-01 06:15:23.907531 - gail/main.py:164 - [TRPO] iter = 586000 dist_mean = 0.0808 dist_std = 0.1828 vf_loss = 0.0586 grad_norm = 3.0944 nat_grad_norm = 0.1020 cg_residual = 0.4650 step_size = 0.4387 reward = 0.0000 fps = 77 mse_loss = 1.9346 
2022-05-01 06:15:34.189722 - gail/main.py:164 - [TRPO] iter = 587000 dist_mean = 0.2094 dist_std = 0.1825 vf_loss = 0.2041 grad_norm = 2.1340 nat_grad_norm = 0.1179 cg_residual = 0.7389 step_size = 0.4788 reward = 0.0000 fps = 43 mse_loss = 1.9210 
2022-05-01 06:15:44.319706 - gail/main.py:164 - [TRPO] iter = 588000 dist_mean = 0.2244 dist_std = 0.1825 vf_loss = 0.3867 grad_norm = 2.3263 nat_grad_norm = 0.0957 cg_residual = 0.7315 step_size = 0.5105 reward = 0.0000 fps = 30 mse_loss = 2.0293 
2022-05-01 06:15:54.447478 - gail/main.py:164 - [TRPO] iter = 589000 dist_mean = 0.1535 dist_std = 0.1824 vf_loss = 0.9613 grad_norm = 3.0697 nat_grad_norm = 0.1143 cg_residual = 1.0880 step_size = 0.4139 reward = -0.0000 fps = 23 mse_loss = 1.9519 
2022-05-01 06:16:04.684165 - gail/main.py:164 - [TRPO] iter = 590000 dist_mean = 0.0766 dist_std = 0.1815 vf_loss = 0.5545 grad_norm = 2.9916 nat_grad_norm = 0.1049 cg_residual = 0.8417 step_size = 0.4536 reward = 0.0000 fps = 18 mse_loss = 1.9780 
2022-05-01 06:16:04.915166 - gail/main.py:191 - [Discriminator] iter = 590000 loss = -1.0736 grad_norm = 3.5156 grad_penalty = 0.1003 regularization = 0.0000 true_logits = 0.2400 fake_logits = -0.9339 true_prob = 0.5602 fake_prob = 0.3408 
2022-05-01 06:16:21.863956 - gail/main.py:132 - [Evaluate] iter = 590000 episode={ returns = 205.5595 lengths = 71 } discounted_episode={ returns = 448.9131 lengths = 184 } 
2022-05-01 06:16:31.488986 - gail/main.py:164 - [TRPO] iter = 591000 dist_mean = 0.0487 dist_std = 0.1819 vf_loss = 0.2267 grad_norm = 3.0785 nat_grad_norm = 0.0922 cg_residual = 1.0066 step_size = 0.4570 reward = -0.0000 fps = 37 mse_loss = 1.9902 
2022-05-01 06:16:41.625681 - gail/main.py:164 - [TRPO] iter = 592000 dist_mean = 0.0331 dist_std = 0.1815 vf_loss = 0.1271 grad_norm = 2.9321 nat_grad_norm = 0.1005 cg_residual = 0.7939 step_size = 0.4726 reward = 0.0000 fps = 27 mse_loss = 1.9312 
2022-05-01 06:16:52.099459 - gail/main.py:164 - [TRPO] iter = 593000 dist_mean = 0.0555 dist_std = 0.1810 vf_loss = 0.0598 grad_norm = 2.6042 nat_grad_norm = 0.0860 cg_residual = 0.6998 step_size = 0.5353 reward = -0.0000 fps = 21 mse_loss = 1.8565 
2022-05-01 06:17:02.892012 - gail/main.py:164 - [TRPO] iter = 594000 dist_mean = 0.1086 dist_std = 0.1812 vf_loss = 0.1396 grad_norm = 2.5569 nat_grad_norm = 0.0930 cg_residual = 0.4705 step_size = 0.4748 reward = -0.0000 fps = 17 mse_loss = 1.8835 
2022-05-01 06:17:13.735241 - gail/main.py:164 - [TRPO] iter = 595000 dist_mean = 0.0258 dist_std = 0.1813 vf_loss = 0.0697 grad_norm = 3.2209 nat_grad_norm = 0.0869 cg_residual = 1.5406 step_size = 0.4612 reward = -0.0000 fps = 14 mse_loss = 1.9423 
2022-05-01 06:17:14.055514 - gail/main.py:191 - [Discriminator] iter = 595000 loss = -0.5943 grad_norm = 3.3762 grad_penalty = 0.0757 regularization = 0.0000 true_logits = 0.2743 fake_logits = -0.3958 true_prob = 0.5674 fake_prob = 0.4230 
2022-05-01 06:18:11.483791 - gail/main.py:132 - [Evaluate] iter = 595000 episode={ returns = 1482.3213 lengths = 431 } discounted_episode={ returns = 853.6698 lengths = 303 } 
2022-05-01 06:18:22.849182 - gail/main.py:164 - [TRPO] iter = 596000 dist_mean = 0.0909 dist_std = 0.1807 vf_loss = 0.3151 grad_norm = 2.5482 nat_grad_norm = 0.1198 cg_residual = 0.7853 step_size = 0.4648 reward = -0.0000 fps = 14 mse_loss = 1.8650 
2022-05-01 06:18:33.975705 - gail/main.py:164 - [TRPO] iter = 597000 dist_mean = 0.0695 dist_std = 0.1805 vf_loss = 0.0461 grad_norm = 2.3960 nat_grad_norm = 0.0962 cg_residual = 1.0625 step_size = 0.4960 reward = 0.0000 fps = 12 mse_loss = 1.8277 
2022-05-01 06:18:45.358421 - gail/main.py:164 - [TRPO] iter = 598000 dist_mean = 0.0485 dist_std = 0.1802 vf_loss = 0.1428 grad_norm = 3.4485 nat_grad_norm = 0.0822 cg_residual = 1.4615 step_size = 0.4336 reward = 0.0000 fps = 10 mse_loss = 1.8687 
2022-05-01 06:18:56.571725 - gail/main.py:164 - [TRPO] iter = 599000 dist_mean = 0.0929 dist_std = 0.1795 vf_loss = 0.1555 grad_norm = 1.7738 nat_grad_norm = 0.1181 cg_residual = 1.2176 step_size = 0.4581 reward = -0.0000 fps = 9 mse_loss = 1.8370 
2022-05-01 06:19:07.914316 - gail/main.py:164 - [TRPO] iter = 600000 dist_mean = 0.1346 dist_std = 0.1793 vf_loss = 0.1583 grad_norm = 2.7143 nat_grad_norm = 0.1389 cg_residual = 1.2431 step_size = 0.3980 reward = -0.0000 fps = 8 mse_loss = 1.8536 
2022-05-01 06:19:08.153595 - gail/main.py:191 - [Discriminator] iter = 600000 loss = -1.0366 grad_norm = 3.1710 grad_penalty = 0.0772 regularization = 0.0000 true_logits = 0.2115 fake_logits = -0.9024 true_prob = 0.5535 fake_prob = 0.3347 
2022-05-01 06:20:00.742782 - gail/main.py:132 - [Evaluate] iter = 600000 episode={ returns = 1257.9854 lengths = 365 } discounted_episode={ returns = 926.6605 lengths = 354 } 
2022-05-01 06:20:11.420394 - gail/main.py:164 - [TRPO] iter = 601000 dist_mean = 0.1160 dist_std = 0.1784 vf_loss = 0.2038 grad_norm = 3.6563 nat_grad_norm = 0.1293 cg_residual = 1.7050 step_size = 0.3929 reward = 0.0000 fps = 15 mse_loss = 2.0748 
2022-05-01 06:20:21.619973 - gail/main.py:164 - [TRPO] iter = 602000 dist_mean = 0.0128 dist_std = 0.1786 vf_loss = 0.0892 grad_norm = 2.5418 nat_grad_norm = 0.1127 cg_residual = 1.8694 step_size = 0.3923 reward = 0.0000 fps = 13 mse_loss = 1.9435 
2022-05-01 06:20:32.355800 - gail/main.py:164 - [TRPO] iter = 603000 dist_mean = 0.0569 dist_std = 0.1779 vf_loss = 0.2134 grad_norm = 2.8180 nat_grad_norm = 0.0908 cg_residual = 0.8731 step_size = 0.5094 reward = -0.0000 fps = 11 mse_loss = 1.9808 
2022-05-01 06:20:42.572696 - gail/main.py:164 - [TRPO] iter = 604000 dist_mean = 0.0670 dist_std = 0.1774 vf_loss = 0.1848 grad_norm = 1.8136 nat_grad_norm = 0.0982 cg_residual = 0.7825 step_size = 0.4757 reward = 0.0000 fps = 10 mse_loss = 1.8873 
2022-05-01 06:20:51.909125 - gail/main.py:164 - [TRPO] iter = 605000 dist_mean = 0.1166 dist_std = 0.1776 vf_loss = 0.1393 grad_norm = 2.0548 nat_grad_norm = 0.1173 cg_residual = 1.2202 step_size = 0.4720 reward = -0.0000 fps = 9 mse_loss = 1.9289 
2022-05-01 06:20:52.147262 - gail/main.py:191 - [Discriminator] iter = 605000 loss = -0.9825 grad_norm = 2.8910 grad_penalty = 0.0962 regularization = 0.0000 true_logits = 0.2070 fake_logits = -0.8718 true_prob = 0.5532 fake_prob = 0.3437 
2022-05-01 06:21:01.696976 - gail/main.py:132 - [Evaluate] iter = 605000 episode={ returns = 37.4294 lengths = 22 } discounted_episode={ returns = 248.1964 lengths = 119 } 
2022-05-01 06:21:11.535432 - gail/main.py:164 - [TRPO] iter = 606000 dist_mean = 0.0541 dist_std = 0.1769 vf_loss = 0.0469 grad_norm = 2.2202 nat_grad_norm = 0.1423 cg_residual = 2.1944 step_size = 0.3630 reward = 0.0000 fps = 51 mse_loss = 1.9641 
2022-05-01 06:21:21.639917 - gail/main.py:164 - [TRPO] iter = 607000 dist_mean = 0.2074 dist_std = 0.1765 vf_loss = 0.2884 grad_norm = 3.5971 nat_grad_norm = 0.1089 cg_residual = 1.0226 step_size = 0.3803 reward = -0.0000 fps = 33 mse_loss = 1.9759 
2022-05-01 06:21:31.899162 - gail/main.py:164 - [TRPO] iter = 608000 dist_mean = 0.1552 dist_std = 0.1761 vf_loss = 0.0488 grad_norm = 3.1289 nat_grad_norm = 0.1290 cg_residual = 0.9694 step_size = 0.3791 reward = -0.0000 fps = 25 mse_loss = 1.8443 
2022-05-01 06:21:42.522024 - gail/main.py:164 - [TRPO] iter = 609000 dist_mean = 0.1961 dist_std = 0.1758 vf_loss = 0.1146 grad_norm = 2.5194 nat_grad_norm = 0.1245 cg_residual = 0.6260 step_size = 0.3526 reward = -0.0000 fps = 19 mse_loss = 1.9728 
2022-05-01 06:21:52.730915 - gail/main.py:164 - [TRPO] iter = 610000 dist_mean = 0.0872 dist_std = 0.1760 vf_loss = 0.0874 grad_norm = 2.4228 nat_grad_norm = 0.0880 cg_residual = 0.5104 step_size = 0.5346 reward = -0.0000 fps = 16 mse_loss = 1.7651 
2022-05-01 06:21:52.947773 - gail/main.py:191 - [Discriminator] iter = 610000 loss = -0.9991 grad_norm = 3.0281 grad_penalty = 0.0835 regularization = 0.0000 true_logits = 0.1598 fake_logits = -0.9228 true_prob = 0.5439 fake_prob = 0.3436 
2022-05-01 06:21:56.048390 - gail/main.py:132 - [Evaluate] iter = 610000 episode={ returns = 37.0162 lengths = 21 } discounted_episode={ returns = 36.7191 lengths = 21 } 
2022-05-01 06:22:06.419025 - gail/main.py:164 - [TRPO] iter = 611000 dist_mean = 0.0246 dist_std = 0.1762 vf_loss = 0.7490 grad_norm = 3.4557 nat_grad_norm = 0.0707 cg_residual = 1.1429 step_size = 0.5422 reward = -0.0000 fps = 74 mse_loss = 1.9179 
2022-05-01 06:22:16.798007 - gail/main.py:164 - [TRPO] iter = 612000 dist_mean = 0.1775 dist_std = 0.1758 vf_loss = 0.3098 grad_norm = 3.1217 nat_grad_norm = 0.1146 cg_residual = 1.5029 step_size = 0.3810 reward = -0.0000 fps = 41 mse_loss = 1.8537 
2022-05-01 06:22:26.722056 - gail/main.py:164 - [TRPO] iter = 613000 dist_mean = 0.0570 dist_std = 0.1758 vf_loss = 0.0552 grad_norm = 2.7925 nat_grad_norm = 0.0898 cg_residual = 0.8600 step_size = 0.4849 reward = -0.0000 fps = 29 mse_loss = 1.8907 
2022-05-01 06:22:36.991945 - gail/main.py:164 - [TRPO] iter = 614000 dist_mean = 0.0259 dist_std = 0.1762 vf_loss = 0.0945 grad_norm = 2.5039 nat_grad_norm = 0.0894 cg_residual = 0.9845 step_size = 0.5252 reward = 0.0000 fps = 22 mse_loss = 1.8350 
2022-05-01 06:22:47.126711 - gail/main.py:164 - [TRPO] iter = 615000 dist_mean = 0.1832 dist_std = 0.1763 vf_loss = 0.2747 grad_norm = 2.5807 nat_grad_norm = 0.0842 cg_residual = 0.7898 step_size = 0.5218 reward = 0.0000 fps = 18 mse_loss = 1.9707 
2022-05-01 06:22:47.328149 - gail/main.py:191 - [Discriminator] iter = 615000 loss = -2.0268 grad_norm = 3.4152 grad_penalty = 0.1573 regularization = 0.0000 true_logits = 0.2014 fake_logits = -1.9827 true_prob = 0.5517 fake_prob = 0.2155 
2022-05-01 06:22:50.646617 - gail/main.py:132 - [Evaluate] iter = 615000 episode={ returns = 37.6183 lengths = 22 } discounted_episode={ returns = 36.9829 lengths = 22 } 
2022-05-01 06:23:00.462357 - gail/main.py:164 - [TRPO] iter = 616000 dist_mean = 0.1100 dist_std = 0.1770 vf_loss = 0.0960 grad_norm = 3.5313 nat_grad_norm = 0.1015 cg_residual = 0.9996 step_size = 0.4066 reward = -0.0000 fps = 76 mse_loss = 1.9185 
2022-05-01 06:23:10.581484 - gail/main.py:164 - [TRPO] iter = 617000 dist_mean = 0.0867 dist_std = 0.1770 vf_loss = 0.1092 grad_norm = 4.0440 nat_grad_norm = 0.0954 cg_residual = 1.5099 step_size = 0.3726 reward = -0.0000 fps = 43 mse_loss = 1.9248 
2022-05-01 06:23:20.423113 - gail/main.py:164 - [TRPO] iter = 618000 dist_mean = 0.1533 dist_std = 0.1770 vf_loss = 0.0940 grad_norm = 2.9288 nat_grad_norm = 0.0929 cg_residual = 0.9846 step_size = 0.4875 reward = 0.0000 fps = 30 mse_loss = 1.8217 
2022-05-01 06:23:30.384568 - gail/main.py:164 - [TRPO] iter = 619000 dist_mean = 0.0021 dist_std = 0.1777 vf_loss = 0.0871 grad_norm = 3.2761 nat_grad_norm = 0.0981 cg_residual = 1.1100 step_size = 0.4565 reward = 0.0000 fps = 23 mse_loss = 1.8572 
2022-05-01 06:23:40.330260 - gail/main.py:164 - [TRPO] iter = 620000 dist_mean = 0.0857 dist_std = 0.1773 vf_loss = 0.0705 grad_norm = 2.6618 nat_grad_norm = 0.0980 cg_residual = 0.8999 step_size = 0.5070 reward = 0.0000 fps = 18 mse_loss = 1.8397 
2022-05-01 06:23:40.573946 - gail/main.py:191 - [Discriminator] iter = 620000 loss = -0.8661 grad_norm = 3.1447 grad_penalty = 0.0911 regularization = 0.0000 true_logits = 0.2274 fake_logits = -0.7299 true_prob = 0.5560 fake_prob = 0.3774 
2022-05-01 06:24:34.879256 - gail/main.py:132 - [Evaluate] iter = 620000 episode={ returns = 629.8209 lengths = 191 } discounted_episode={ returns = 1377.1087 lengths = 606 } 
2022-05-01 06:24:44.849309 - gail/main.py:164 - [TRPO] iter = 621000 dist_mean = 0.0519 dist_std = 0.1778 vf_loss = 0.0704 grad_norm = 3.0259 nat_grad_norm = 0.1101 cg_residual = 0.5987 step_size = 0.3983 reward = -0.0000 fps = 15 mse_loss = 1.9028 
2022-05-01 06:24:54.672029 - gail/main.py:164 - [TRPO] iter = 622000 dist_mean = 0.0703 dist_std = 0.1780 vf_loss = 0.0927 grad_norm = 3.0729 nat_grad_norm = 0.1144 cg_residual = 1.1790 step_size = 0.4288 reward = 0.0000 fps = 13 mse_loss = 1.8874 
2022-05-01 06:25:04.840217 - gail/main.py:164 - [TRPO] iter = 623000 dist_mean = 0.0488 dist_std = 0.1778 vf_loss = 0.0552 grad_norm = 2.4396 nat_grad_norm = 0.0937 cg_residual = 0.9564 step_size = 0.5279 reward = -0.0000 fps = 11 mse_loss = 1.8901 
2022-05-01 06:25:14.764308 - gail/main.py:164 - [TRPO] iter = 624000 dist_mean = 0.0255 dist_std = 0.1769 vf_loss = 0.0853 grad_norm = 2.4210 nat_grad_norm = 0.0973 cg_residual = 1.0443 step_size = 0.4877 reward = -0.0000 fps = 10 mse_loss = 1.9283 
2022-05-01 06:25:24.786392 - gail/main.py:164 - [TRPO] iter = 625000 dist_mean = 0.0207 dist_std = 0.1764 vf_loss = 0.4306 grad_norm = 2.6653 nat_grad_norm = 0.0921 cg_residual = 0.7792 step_size = 0.5119 reward = 0.0000 fps = 9 mse_loss = 1.8755 
2022-05-01 06:25:25.036207 - gail/main.py:191 - [Discriminator] iter = 625000 loss = -0.5295 grad_norm = 2.2994 grad_penalty = 0.0637 regularization = 0.0000 true_logits = 0.1833 fake_logits = -0.4099 true_prob = 0.5467 fake_prob = 0.4267 
2022-05-01 06:26:58.287288 - gail/main.py:132 - [Evaluate] iter = 625000 episode={ returns = 2557.4097 lengths = 729 } discounted_episode={ returns = 1506.2634 lengths = 645 } 
2022-05-01 06:27:08.334481 - gail/main.py:164 - [TRPO] iter = 626000 dist_mean = 0.0946 dist_std = 0.1766 vf_loss = 0.0781 grad_norm = 4.4751 nat_grad_norm = 0.1101 cg_residual = 0.9339 step_size = 0.4090 reward = -0.0000 fps = 9 mse_loss = 1.8004 
2022-05-01 06:27:17.965551 - gail/main.py:164 - [TRPO] iter = 627000 dist_mean = 0.0496 dist_std = 0.1765 vf_loss = 0.0529 grad_norm = 1.9943 nat_grad_norm = 0.1090 cg_residual = 0.9305 step_size = 0.4811 reward = 0.0000 fps = 8 mse_loss = 1.8463 
2022-05-01 06:27:27.720080 - gail/main.py:164 - [TRPO] iter = 628000 dist_mean = 0.0236 dist_std = 0.1769 vf_loss = 0.1484 grad_norm = 3.1474 nat_grad_norm = 0.0819 cg_residual = 0.7191 step_size = 0.5142 reward = -0.0000 fps = 8 mse_loss = 1.9019 
2022-05-01 06:27:37.622814 - gail/main.py:164 - [TRPO] iter = 629000 dist_mean = 0.0094 dist_std = 0.1773 vf_loss = 0.3636 grad_norm = 2.1125 nat_grad_norm = 0.0596 cg_residual = 0.4322 step_size = 0.7230 reward = 0.0000 fps = 7 mse_loss = 1.8172 
2022-05-01 06:27:47.331228 - gail/main.py:164 - [TRPO] iter = 630000 dist_mean = 0.0349 dist_std = 0.1777 vf_loss = 0.2334 grad_norm = 2.2215 nat_grad_norm = 0.0591 cg_residual = 0.9932 step_size = 0.6230 reward = -0.0000 fps = 7 mse_loss = 1.7630 
2022-05-01 06:27:47.464450 - gail/main.py:191 - [Discriminator] iter = 630000 loss = -0.5142 grad_norm = 2.3759 grad_penalty = 0.0514 regularization = 0.0000 true_logits = 0.2846 fake_logits = -0.2810 true_prob = 0.5668 fake_prob = 0.4488 
2022-05-01 06:27:50.534011 - gail/main.py:132 - [Evaluate] iter = 630000 episode={ returns = 37.2369 lengths = 21 } discounted_episode={ returns = 37.1736 lengths = 22 } 
2022-05-01 06:28:00.858727 - gail/main.py:164 - [TRPO] iter = 631000 dist_mean = 0.2548 dist_std = 0.1781 vf_loss = 0.1692 grad_norm = 3.3233 nat_grad_norm = 0.1004 cg_residual = 1.4040 step_size = 0.3805 reward = -0.0000 fps = 74 mse_loss = 1.7468 
2022-05-01 06:28:11.025944 - gail/main.py:164 - [TRPO] iter = 632000 dist_mean = 0.0796 dist_std = 0.1778 vf_loss = 0.0610 grad_norm = 1.8841 nat_grad_norm = 0.0880 cg_residual = 0.5037 step_size = 0.6203 reward = -0.0000 fps = 42 mse_loss = 1.7517 
2022-05-01 06:28:21.415066 - gail/main.py:164 - [TRPO] iter = 633000 dist_mean = 0.2447 dist_std = 0.1775 vf_loss = 0.2227 grad_norm = 3.0901 nat_grad_norm = 0.0983 cg_residual = 0.9372 step_size = 0.4214 reward = -0.0000 fps = 29 mse_loss = 1.6709 
2022-05-01 06:28:31.189384 - gail/main.py:164 - [TRPO] iter = 634000 dist_mean = 0.0663 dist_std = 0.1775 vf_loss = 0.1408 grad_norm = 1.9014 nat_grad_norm = 0.0813 cg_residual = 0.6440 step_size = 0.5562 reward = -0.0000 fps = 22 mse_loss = 1.6804 
2022-05-01 06:28:41.362511 - gail/main.py:164 - [TRPO] iter = 635000 dist_mean = 0.2367 dist_std = 0.1776 vf_loss = 0.5509 grad_norm = 3.3131 nat_grad_norm = 0.1044 cg_residual = 0.7334 step_size = 0.4271 reward = -0.0000 fps = 18 mse_loss = 1.8025 
2022-05-01 06:28:41.626242 - gail/main.py:191 - [Discriminator] iter = 635000 loss = -1.9378 grad_norm = 2.7457 grad_penalty = 0.1261 regularization = 0.0000 true_logits = 0.2684 fake_logits = -1.7955 true_prob = 0.5649 fake_prob = 0.2266 
2022-05-01 06:28:44.895602 - gail/main.py:132 - [Evaluate] iter = 635000 episode={ returns = 37.4829 lengths = 22 } discounted_episode={ returns = 36.9565 lengths = 22 } 
2022-05-01 06:28:55.378695 - gail/main.py:164 - [TRPO] iter = 636000 dist_mean = 0.2169 dist_std = 0.1774 vf_loss = 0.6998 grad_norm = 3.0996 nat_grad_norm = 0.0920 cg_residual = 0.5738 step_size = 0.4431 reward = -0.0000 fps = 72 mse_loss = 1.8728 
2022-05-01 06:29:05.411482 - gail/main.py:164 - [TRPO] iter = 637000 dist_mean = 0.1021 dist_std = 0.1781 vf_loss = 0.3416 grad_norm = 3.2912 nat_grad_norm = 0.1211 cg_residual = 0.8879 step_size = 0.3778 reward = 0.0000 fps = 42 mse_loss = 1.7246 
2022-05-01 06:29:15.698145 - gail/main.py:164 - [TRPO] iter = 638000 dist_mean = 0.0523 dist_std = 0.1776 vf_loss = 0.5724 grad_norm = 2.6831 nat_grad_norm = 0.1032 cg_residual = 1.9525 step_size = 0.5323 reward = 0.0000 fps = 29 mse_loss = 1.6817 
2022-05-01 06:29:26.127773 - gail/main.py:164 - [TRPO] iter = 639000 dist_mean = 0.1123 dist_std = 0.1763 vf_loss = 0.1385 grad_norm = 2.3979 nat_grad_norm = 0.1558 cg_residual = 2.6152 step_size = 0.3372 reward = 0.0000 fps = 22 mse_loss = 1.7520 
2022-05-01 06:29:36.434844 - gail/main.py:164 - [TRPO] iter = 640000 dist_mean = 0.0891 dist_std = 0.1765 vf_loss = 0.8281 grad_norm = 2.8883 nat_grad_norm = 0.1061 cg_residual = 1.4897 step_size = 0.4312 reward = 0.0000 fps = 18 mse_loss = 1.6908 
2022-05-01 06:29:36.681155 - gail/main.py:191 - [Discriminator] iter = 640000 loss = -0.8690 grad_norm = 2.6295 grad_penalty = 0.0950 regularization = 0.0000 true_logits = 0.3142 fake_logits = -0.6498 true_prob = 0.5738 fake_prob = 0.3972 
2022-05-01 06:30:32.746952 - gail/main.py:132 - [Evaluate] iter = 640000 episode={ returns = 1414.2958 lengths = 413 } discounted_episode={ returns = 890.6310 lengths = 413 } 
2022-05-01 06:30:42.615663 - gail/main.py:164 - [TRPO] iter = 641000 dist_mean = 0.0506 dist_std = 0.1767 vf_loss = 0.0652 grad_norm = 2.2537 nat_grad_norm = 0.0977 cg_residual = 0.6186 step_size = 0.5356 reward = -0.0000 fps = 15 mse_loss = 1.7065 
2022-05-01 06:30:52.563471 - gail/main.py:164 - [TRPO] iter = 642000 dist_mean = 0.0546 dist_std = 0.1772 vf_loss = 0.0719 grad_norm = 3.1843 nat_grad_norm = 0.0956 cg_residual = 1.2916 step_size = 0.4421 reward = 0.0000 fps = 13 mse_loss = 1.6186 
2022-05-01 06:31:02.756069 - gail/main.py:164 - [TRPO] iter = 643000 dist_mean = 0.1134 dist_std = 0.1771 vf_loss = 0.0897 grad_norm = 3.8155 nat_grad_norm = 0.0979 cg_residual = 0.7983 step_size = 0.4188 reward = -0.0000 fps = 11 mse_loss = 1.6134 
2022-05-01 06:31:13.084126 - gail/main.py:164 - [TRPO] iter = 644000 dist_mean = 0.0976 dist_std = 0.1762 vf_loss = 0.0585 grad_norm = 2.3474 nat_grad_norm = 0.0971 cg_residual = 0.7264 step_size = 0.4570 reward = 0.0000 fps = 10 mse_loss = 1.7017 
2022-05-01 06:31:23.100847 - gail/main.py:164 - [TRPO] iter = 645000 dist_mean = 0.0494 dist_std = 0.1756 vf_loss = 0.4354 grad_norm = 1.9238 nat_grad_norm = 0.0608 cg_residual = 0.5980 step_size = 0.6026 reward = 0.0000 fps = 9 mse_loss = 1.7899 
2022-05-01 06:31:23.323164 - gail/main.py:191 - [Discriminator] iter = 645000 loss = -0.4702 grad_norm = 3.0747 grad_penalty = 0.0578 regularization = 0.0000 true_logits = 0.3694 fake_logits = -0.1586 true_prob = 0.5821 fake_prob = 0.4696 
2022-05-01 06:33:17.427778 - gail/main.py:132 - [Evaluate] iter = 645000 episode={ returns = 3028.9082 lengths = 875 } discounted_episode={ returns = 1743.5585 lengths = 804 } 
2022-05-01 06:33:27.290615 - gail/main.py:164 - [TRPO] iter = 646000 dist_mean = 0.0580 dist_std = 0.1753 vf_loss = 0.0597 grad_norm = 2.4551 nat_grad_norm = 0.1039 cg_residual = 1.1290 step_size = 0.4347 reward = 0.0000 fps = 8 mse_loss = 1.7355 
2022-05-01 06:33:37.150687 - gail/main.py:164 - [TRPO] iter = 647000 dist_mean = 0.0124 dist_std = 0.1753 vf_loss = 0.2771 grad_norm = 1.8999 nat_grad_norm = 0.0870 cg_residual = 1.1478 step_size = 0.5343 reward = 0.0000 fps = 7 mse_loss = 1.6477 
2022-05-01 06:33:47.064881 - gail/main.py:164 - [TRPO] iter = 648000 dist_mean = 0.0708 dist_std = 0.1749 vf_loss = 0.0665 grad_norm = 2.5613 nat_grad_norm = 0.1371 cg_residual = 2.3849 step_size = 0.3795 reward = -0.0000 fps = 6 mse_loss = 1.7177 
2022-05-01 06:33:56.353993 - gail/main.py:164 - [TRPO] iter = 649000 dist_mean = 0.0726 dist_std = 0.1751 vf_loss = 0.0714 grad_norm = 2.3931 nat_grad_norm = 0.1068 cg_residual = 0.7200 step_size = 0.4718 reward = 0.0000 fps = 6 mse_loss = 1.7424 
2022-05-01 06:34:06.267360 - gail/main.py:164 - [TRPO] iter = 650000 dist_mean = 0.0975 dist_std = 0.1751 vf_loss = 0.5042 grad_norm = 2.3242 nat_grad_norm = 0.0671 cg_residual = 0.4551 step_size = 0.6983 reward = -0.0000 fps = 6 mse_loss = 1.6561 
2022-05-01 06:34:06.475232 - gail/main.py:191 - [Discriminator] iter = 650000 loss = -1.0724 grad_norm = 2.7401 grad_penalty = 0.0657 regularization = 0.0000 true_logits = 0.4562 fake_logits = -0.6819 true_prob = 0.5992 fake_prob = 0.3935 
2022-05-01 06:34:10.680559 - gail/main.py:132 - [Evaluate] iter = 650000 episode={ returns = 94.1767 lengths = 38 } discounted_episode={ returns = 36.9828 lengths = 22 } 
2022-05-01 06:34:20.373436 - gail/main.py:164 - [TRPO] iter = 651000 dist_mean = 0.0216 dist_std = 0.1756 vf_loss = 0.2903 grad_norm = 2.9642 nat_grad_norm = 0.0752 cg_residual = 1.0357 step_size = 0.5367 reward = -0.0000 fps = 72 mse_loss = 1.7158 
2022-05-01 06:34:30.067587 - gail/main.py:164 - [TRPO] iter = 652000 dist_mean = 0.0206 dist_std = 0.1758 vf_loss = 0.0778 grad_norm = 2.7248 nat_grad_norm = 0.0898 cg_residual = 1.1333 step_size = 0.4549 reward = -0.0000 fps = 42 mse_loss = 1.6261 
2022-05-01 06:34:40.083736 - gail/main.py:164 - [TRPO] iter = 653000 dist_mean = 0.1466 dist_std = 0.1756 vf_loss = 0.0834 grad_norm = 2.6709 nat_grad_norm = 0.1449 cg_residual = 1.9254 step_size = 0.3548 reward = -0.0000 fps = 29 mse_loss = 1.6709 
2022-05-01 06:34:50.312755 - gail/main.py:164 - [TRPO] iter = 654000 dist_mean = 0.2688 dist_std = 0.1753 vf_loss = 0.4148 grad_norm = 2.8848 nat_grad_norm = 0.0998 cg_residual = 0.8982 step_size = 0.4029 reward = -0.0000 fps = 22 mse_loss = 1.6199 
2022-05-01 06:35:00.092000 - gail/main.py:164 - [TRPO] iter = 655000 dist_mean = 0.1750 dist_std = 0.1755 vf_loss = 1.3312 grad_norm = 4.1011 nat_grad_norm = 0.0831 cg_residual = 1.0493 step_size = 0.4949 reward = -0.0000 fps = 18 mse_loss = 1.6967 
2022-05-01 06:35:00.312001 - gail/main.py:191 - [Discriminator] iter = 655000 loss = -2.2925 grad_norm = 3.0017 grad_penalty = 0.1807 regularization = 0.0000 true_logits = 0.3808 fake_logits = -2.0923 true_prob = 0.5841 fake_prob = 0.2012 
2022-05-01 06:35:03.556528 - gail/main.py:132 - [Evaluate] iter = 655000 episode={ returns = 36.1453 lengths = 21 } discounted_episode={ returns = 35.7529 lengths = 21 } 
2022-05-01 06:35:13.680238 - gail/main.py:164 - [TRPO] iter = 656000 dist_mean = 0.1362 dist_std = 0.1760 vf_loss = 0.1807 grad_norm = 2.4491 nat_grad_norm = 0.1051 cg_residual = 1.8004 step_size = 0.4641 reward = 0.0000 fps = 74 mse_loss = 1.6338 
2022-05-01 06:35:23.486696 - gail/main.py:164 - [TRPO] iter = 657000 dist_mean = 0.2599 dist_std = 0.1764 vf_loss = 1.3075 grad_norm = 2.6819 nat_grad_norm = 0.0795 cg_residual = 1.2450 step_size = 0.5390 reward = 0.0000 fps = 43 mse_loss = 1.6913 
2022-05-01 06:35:33.432776 - gail/main.py:164 - [TRPO] iter = 658000 dist_mean = 0.0294 dist_std = 0.1765 vf_loss = 1.2967 grad_norm = 3.0003 nat_grad_norm = 0.0838 cg_residual = 0.8443 step_size = 0.5255 reward = -0.0000 fps = 30 mse_loss = 1.6470 
2022-05-01 06:35:43.494521 - gail/main.py:164 - [TRPO] iter = 659000 dist_mean = 0.1576 dist_std = 0.1763 vf_loss = 2.2637 grad_norm = 3.3784 nat_grad_norm = 0.0906 cg_residual = 0.9245 step_size = 0.4287 reward = -0.0000 fps = 23 mse_loss = 1.8087 
2022-05-01 06:35:53.024817 - gail/main.py:164 - [TRPO] iter = 660000 dist_mean = 0.0605 dist_std = 0.1766 vf_loss = 1.3201 grad_norm = 2.7999 nat_grad_norm = 0.1077 cg_residual = 1.4252 step_size = 0.4720 reward = 0.0000 fps = 18 mse_loss = 1.7313 
2022-05-01 06:35:53.236432 - gail/main.py:191 - [Discriminator] iter = 660000 loss = -1.0662 grad_norm = 2.3000 grad_penalty = 0.0972 regularization = 0.0000 true_logits = 0.4269 fake_logits = -0.7365 true_prob = 0.5918 fake_prob = 0.3886 
2022-05-01 06:36:04.217279 - gail/main.py:132 - [Evaluate] iter = 660000 episode={ returns = 319.7643 lengths = 107 } discounted_episode={ returns = 149.6278 lengths = 60 } 
2022-05-01 06:36:14.128394 - gail/main.py:164 - [TRPO] iter = 661000 dist_mean = 0.0735 dist_std = 0.1770 vf_loss = 1.8211 grad_norm = 2.9910 nat_grad_norm = 0.1068 cg_residual = 0.8180 step_size = 0.4550 reward = 0.0000 fps = 47 mse_loss = 1.7807 
2022-05-01 06:36:23.828701 - gail/main.py:164 - [TRPO] iter = 662000 dist_mean = 0.0812 dist_std = 0.1771 vf_loss = 1.3147 grad_norm = 2.6160 nat_grad_norm = 0.1128 cg_residual = 1.0025 step_size = 0.4133 reward = -0.0000 fps = 32 mse_loss = 1.6937 
2022-05-01 06:36:33.783228 - gail/main.py:164 - [TRPO] iter = 663000 dist_mean = 0.0690 dist_std = 0.1762 vf_loss = 0.2392 grad_norm = 3.3808 nat_grad_norm = 0.1436 cg_residual = 1.3528 step_size = 0.3696 reward = 0.0000 fps = 24 mse_loss = 1.7456 
2022-05-01 06:36:43.611770 - gail/main.py:164 - [TRPO] iter = 664000 dist_mean = 0.0382 dist_std = 0.1764 vf_loss = 0.2673 grad_norm = 2.6837 nat_grad_norm = 0.0919 cg_residual = 0.8828 step_size = 0.4347 reward = -0.0000 fps = 19 mse_loss = 1.7830 
2022-05-01 06:36:53.704411 - gail/main.py:164 - [TRPO] iter = 665000 dist_mean = 0.0092 dist_std = 0.1764 vf_loss = 0.1274 grad_norm = 2.7982 nat_grad_norm = 0.0969 cg_residual = 1.4869 step_size = 0.4622 reward = 0.0000 fps = 16 mse_loss = 1.7405 
2022-05-01 06:36:53.929071 - gail/main.py:191 - [Discriminator] iter = 665000 loss = -0.5432 grad_norm = 2.8930 grad_penalty = 0.0682 regularization = 0.0000 true_logits = 0.4340 fake_logits = -0.1774 true_prob = 0.5920 fake_prob = 0.4707 
2022-05-01 06:37:20.172676 - gail/main.py:132 - [Evaluate] iter = 665000 episode={ returns = 773.6164 lengths = 230 } discounted_episode={ returns = 465.7533 lengths = 161 } 
2022-05-01 06:37:29.869624 - gail/main.py:164 - [TRPO] iter = 666000 dist_mean = -0.0004 dist_std = 0.1772 vf_loss = 0.3767 grad_norm = 3.8961 nat_grad_norm = 0.0945 cg_residual = 1.8014 step_size = 0.4496 reward = 0.0000 fps = 27 mse_loss = 1.7783 
2022-05-01 06:37:39.991432 - gail/main.py:164 - [TRPO] iter = 667000 dist_mean = 0.0043 dist_std = 0.1767 vf_loss = 0.1673 grad_norm = 1.9915 nat_grad_norm = 0.0984 cg_residual = 0.9486 step_size = 0.4731 reward = -0.0000 fps = 21 mse_loss = 1.6154 
2022-05-01 06:37:49.946534 - gail/main.py:164 - [TRPO] iter = 668000 dist_mean = 0.0516 dist_std = 0.1771 vf_loss = 0.1219 grad_norm = 2.2201 nat_grad_norm = 0.1165 cg_residual = 1.1565 step_size = 0.4600 reward = -0.0000 fps = 17 mse_loss = 1.7404 
2022-05-01 06:37:59.979658 - gail/main.py:164 - [TRPO] iter = 669000 dist_mean = 0.0397 dist_std = 0.1769 vf_loss = 0.1176 grad_norm = 2.7732 nat_grad_norm = 0.1130 cg_residual = 0.9724 step_size = 0.4554 reward = 0.0000 fps = 15 mse_loss = 1.7716 
2022-05-01 06:38:09.810624 - gail/main.py:164 - [TRPO] iter = 670000 dist_mean = 0.0155 dist_std = 0.1760 vf_loss = 0.0824 grad_norm = 3.1935 nat_grad_norm = 0.1518 cg_residual = 1.7721 step_size = 0.3166 reward = 0.0000 fps = 13 mse_loss = 1.7477 
2022-05-01 06:38:10.029055 - gail/main.py:191 - [Discriminator] iter = 670000 loss = -0.4916 grad_norm = 3.0121 grad_penalty = 0.0625 regularization = 0.0000 true_logits = 0.4857 fake_logits = -0.0684 true_prob = 0.6046 fake_prob = 0.4896 
2022-05-01 06:38:14.209033 - gail/main.py:132 - [Evaluate] iter = 670000 episode={ returns = 81.8639 lengths = 35 } discounted_episode={ returns = 35.9595 lengths = 21 } 
2022-05-01 06:38:24.020703 - gail/main.py:164 - [TRPO] iter = 671000 dist_mean = 0.0973 dist_std = 0.1765 vf_loss = 0.2173 grad_norm = 3.5662 nat_grad_norm = 0.1650 cg_residual = 1.5401 step_size = 0.3636 reward = -0.0000 fps = 71 mse_loss = 1.8033 
2022-05-01 06:38:33.774799 - gail/main.py:164 - [TRPO] iter = 672000 dist_mean = 0.1182 dist_std = 0.1763 vf_loss = 0.1103 grad_norm = 2.8728 nat_grad_norm = 0.1385 cg_residual = 2.2366 step_size = 0.3854 reward = 0.0000 fps = 42 mse_loss = 1.7092 
2022-05-01 06:38:43.606264 - gail/main.py:164 - [TRPO] iter = 673000 dist_mean = 0.1374 dist_std = 0.1768 vf_loss = 0.2534 grad_norm = 3.6713 nat_grad_norm = 0.1049 cg_residual = 1.0464 step_size = 0.4402 reward = 0.0000 fps = 29 mse_loss = 1.7699 
2022-05-01 06:38:53.239967 - gail/main.py:164 - [TRPO] iter = 674000 dist_mean = 0.0700 dist_std = 0.1764 vf_loss = 0.2185 grad_norm = 2.6706 nat_grad_norm = 0.0818 cg_residual = 1.0029 step_size = 0.5389 reward = 0.0000 fps = 23 mse_loss = 1.7392 
2022-05-01 06:39:02.908741 - gail/main.py:164 - [TRPO] iter = 675000 dist_mean = 0.0986 dist_std = 0.1762 vf_loss = 0.2180 grad_norm = 2.4144 nat_grad_norm = 0.1000 cg_residual = 0.7356 step_size = 0.5005 reward = -0.0000 fps = 18 mse_loss = 1.7867 
2022-05-01 06:39:03.217905 - gail/main.py:191 - [Discriminator] iter = 675000 loss = -1.2955 grad_norm = 3.1981 grad_penalty = 0.1083 regularization = 0.0000 true_logits = 0.4261 fake_logits = -0.9777 true_prob = 0.5942 fake_prob = 0.3238 
2022-05-01 06:39:23.703364 - gail/main.py:132 - [Evaluate] iter = 675000 episode={ returns = 472.6883 lengths = 156 } discounted_episode={ returns = 440.2726 lengths = 158 } 
2022-05-01 06:39:33.466235 - gail/main.py:164 - [TRPO] iter = 676000 dist_mean = 0.0773 dist_std = 0.1762 vf_loss = 0.1710 grad_norm = 3.2431 nat_grad_norm = 0.1160 cg_residual = 0.8399 step_size = 0.4615 reward = 0.0000 fps = 33 mse_loss = 1.8655 
2022-05-01 06:39:44.019174 - gail/main.py:164 - [TRPO] iter = 677000 dist_mean = 0.0737 dist_std = 0.1766 vf_loss = 0.1888 grad_norm = 2.1040 nat_grad_norm = 0.1339 cg_residual = 0.8793 step_size = 0.4264 reward = 0.0000 fps = 24 mse_loss = 1.7702 
2022-05-01 06:39:54.013273 - gail/main.py:164 - [TRPO] iter = 678000 dist_mean = -0.0062 dist_std = 0.1760 vf_loss = 0.1059 grad_norm = 3.1203 nat_grad_norm = 0.1045 cg_residual = 1.0321 step_size = 0.4467 reward = 0.0000 fps = 19 mse_loss = 1.8478 
2022-05-01 06:40:04.077233 - gail/main.py:164 - [TRPO] iter = 679000 dist_mean = 0.0505 dist_std = 0.1762 vf_loss = 0.1062 grad_norm = 2.8865 nat_grad_norm = 0.1052 cg_residual = 0.8631 step_size = 0.4525 reward = 0.0000 fps = 16 mse_loss = 1.8205 
2022-05-01 06:40:13.779004 - gail/main.py:164 - [TRPO] iter = 680000 dist_mean = -0.0164 dist_std = 0.1761 vf_loss = 0.5654 grad_norm = 2.6482 nat_grad_norm = 0.1001 cg_residual = 0.7732 step_size = 0.4501 reward = 0.0000 fps = 14 mse_loss = 1.7414 
2022-05-01 06:40:14.049343 - gail/main.py:191 - [Discriminator] iter = 680000 loss = -0.6925 grad_norm = 3.2621 grad_penalty = 0.0887 regularization = 0.0000 true_logits = 0.3515 fake_logits = -0.4297 true_prob = 0.5810 fake_prob = 0.4181 
2022-05-01 06:41:17.837445 - gail/main.py:132 - [Evaluate] iter = 680000 episode={ returns = 1502.1668 lengths = 419 } discounted_episode={ returns = 1338.6716 lengths = 512 } 
2022-05-01 06:41:27.532713 - gail/main.py:164 - [TRPO] iter = 681000 dist_mean = 0.0052 dist_std = 0.1757 vf_loss = 0.1042 grad_norm = 4.1500 nat_grad_norm = 0.1057 cg_residual = 2.3213 step_size = 0.3762 reward = -0.0000 fps = 13 mse_loss = 1.8125 
2022-05-01 06:41:37.821246 - gail/main.py:164 - [TRPO] iter = 682000 dist_mean = 0.0363 dist_std = 0.1759 vf_loss = 0.2533 grad_norm = 1.9716 nat_grad_norm = 0.1072 cg_residual = 0.4747 step_size = 0.4960 reward = 0.0000 fps = 11 mse_loss = 1.8708 
2022-05-01 06:41:47.829212 - gail/main.py:164 - [TRPO] iter = 683000 dist_mean = -0.0015 dist_std = 0.1761 vf_loss = 0.1385 grad_norm = 2.4681 nat_grad_norm = 0.1020 cg_residual = 1.0348 step_size = 0.4588 reward = -0.0000 fps = 10 mse_loss = 1.7849 
2022-05-01 06:41:57.941528 - gail/main.py:164 - [TRPO] iter = 684000 dist_mean = 0.0597 dist_std = 0.1761 vf_loss = 0.1140 grad_norm = 2.3464 nat_grad_norm = 0.1275 cg_residual = 1.6105 step_size = 0.4180 reward = -0.0000 fps = 9 mse_loss = 1.7673 
2022-05-01 06:42:07.537770 - gail/main.py:164 - [TRPO] iter = 685000 dist_mean = -0.0116 dist_std = 0.1763 vf_loss = 0.1228 grad_norm = 2.0837 nat_grad_norm = 0.1124 cg_residual = 1.3104 step_size = 0.4492 reward = 0.0000 fps = 8 mse_loss = 1.8053 
2022-05-01 06:42:07.767992 - gail/main.py:191 - [Discriminator] iter = 685000 loss = -0.6715 grad_norm = 2.7231 grad_penalty = 0.0803 regularization = 0.0000 true_logits = 0.3002 fake_logits = -0.4516 true_prob = 0.5732 fake_prob = 0.4111 
2022-05-01 06:43:29.160912 - gail/main.py:132 - [Evaluate] iter = 685000 episode={ returns = 2086.2410 lengths = 600 } discounted_episode={ returns = 1449.5469 lengths = 614 } 
2022-05-01 06:43:39.051935 - gail/main.py:164 - [TRPO] iter = 686000 dist_mean = 0.0055 dist_std = 0.1758 vf_loss = 0.1679 grad_norm = 2.9701 nat_grad_norm = 0.1072 cg_residual = 1.7549 step_size = 0.4164 reward = 0.0000 fps = 10 mse_loss = 1.8199 
2022-05-01 06:43:48.892153 - gail/main.py:164 - [TRPO] iter = 687000 dist_mean = 0.0106 dist_std = 0.1755 vf_loss = 0.0573 grad_norm = 2.9538 nat_grad_norm = 0.1091 cg_residual = 2.6919 step_size = 0.4117 reward = 0.0000 fps = 9 mse_loss = 1.8930 
2022-05-01 06:43:58.254990 - gail/main.py:164 - [TRPO] iter = 688000 dist_mean = -0.0091 dist_std = 0.1755 vf_loss = 0.0557 grad_norm = 3.0510 nat_grad_norm = 0.0897 cg_residual = 0.9050 step_size = 0.5248 reward = 0.0000 fps = 9 mse_loss = 1.8019 
2022-05-01 06:44:08.128795 - gail/main.py:164 - [TRPO] iter = 689000 dist_mean = -0.0059 dist_std = 0.1752 vf_loss = 0.3301 grad_norm = 2.3677 nat_grad_norm = 0.0918 cg_residual = 0.9965 step_size = 0.5405 reward = -0.0000 fps = 8 mse_loss = 1.8759 
2022-05-01 06:44:17.596854 - gail/main.py:164 - [TRPO] iter = 690000 dist_mean = 0.0045 dist_std = 0.1754 vf_loss = 0.0961 grad_norm = 2.4395 nat_grad_norm = 0.0838 cg_residual = 0.5378 step_size = 0.5783 reward = 0.0000 fps = 7 mse_loss = 1.9674 
2022-05-01 06:44:17.889122 - gail/main.py:191 - [Discriminator] iter = 690000 loss = -0.5131 grad_norm = 2.6219 grad_penalty = 0.0613 regularization = 0.0000 true_logits = 0.3613 fake_logits = -0.2131 true_prob = 0.5856 fake_prob = 0.4559 
2022-05-01 06:46:17.400087 - gail/main.py:132 - [Evaluate] iter = 690000 episode={ returns = 3067.8876 lengths = 868 } discounted_episode={ returns = 2076.2796 lengths = 925 } 
2022-05-01 06:46:26.993645 - gail/main.py:164 - [TRPO] iter = 691000 dist_mean = 0.0037 dist_std = 0.1741 vf_loss = 0.1256 grad_norm = 2.1161 nat_grad_norm = 0.0936 cg_residual = 0.8913 step_size = 0.4550 reward = 0.0000 fps = 7 mse_loss = 1.9681 
2022-05-01 06:46:36.809076 - gail/main.py:164 - [TRPO] iter = 692000 dist_mean = -0.0038 dist_std = 0.1738 vf_loss = 0.1177 grad_norm = 2.1527 nat_grad_norm = 0.1118 cg_residual = 1.2606 step_size = 0.4798 reward = 0.0000 fps = 7 mse_loss = 1.9030 
2022-05-01 06:46:46.779562 - gail/main.py:164 - [TRPO] iter = 693000 dist_mean = -0.0042 dist_std = 0.1733 vf_loss = 0.1880 grad_norm = 2.9988 nat_grad_norm = 0.0890 cg_residual = 1.2603 step_size = 0.4698 reward = 0.0000 fps = 6 mse_loss = 2.0268 
2022-05-01 06:46:56.834146 - gail/main.py:164 - [TRPO] iter = 694000 dist_mean = 0.0008 dist_std = 0.1731 vf_loss = 0.0564 grad_norm = 3.1044 nat_grad_norm = 0.1494 cg_residual = 3.5367 step_size = 0.3732 reward = 0.0000 fps = 6 mse_loss = 2.0131 
2022-05-01 06:47:06.356057 - gail/main.py:164 - [TRPO] iter = 695000 dist_mean = -0.0242 dist_std = 0.1726 vf_loss = 0.0928 grad_norm = 2.6976 nat_grad_norm = 0.1096 cg_residual = 1.0625 step_size = 0.4477 reward = 0.0000 fps = 5 mse_loss = 1.9126 
2022-05-01 06:47:06.591207 - gail/main.py:191 - [Discriminator] iter = 695000 loss = -0.8061 grad_norm = 2.5193 grad_penalty = 0.0746 regularization = 0.0000 true_logits = 0.4389 fake_logits = -0.4419 true_prob = 0.6004 fake_prob = 0.4100 
2022-05-01 06:48:08.622332 - gail/main.py:132 - [Evaluate] iter = 695000 episode={ returns = 1662.3590 lengths = 454 } discounted_episode={ returns = 1356.9568 lengths = 480 } 
2022-05-01 06:48:18.370022 - gail/main.py:164 - [TRPO] iter = 696000 dist_mean = -0.0292 dist_std = 0.1722 vf_loss = 0.2918 grad_norm = 3.2824 nat_grad_norm = 0.1043 cg_residual = 1.2758 step_size = 0.4502 reward = 0.0000 fps = 13 mse_loss = 1.9800 
2022-05-01 06:48:28.377995 - gail/main.py:164 - [TRPO] iter = 697000 dist_mean = -0.0013 dist_std = 0.1715 vf_loss = 0.0903 grad_norm = 2.7972 nat_grad_norm = 0.1215 cg_residual = 0.9557 step_size = 0.4116 reward = -0.0000 fps = 12 mse_loss = 1.9278 
2022-05-01 06:48:38.348575 - gail/main.py:164 - [TRPO] iter = 698000 dist_mean = -0.0052 dist_std = 0.1711 vf_loss = 0.0952 grad_norm = 2.9986 nat_grad_norm = 0.1095 cg_residual = 0.9827 step_size = 0.3702 reward = -0.0000 fps = 10 mse_loss = 2.0373 
2022-05-01 06:48:48.634093 - gail/main.py:164 - [TRPO] iter = 699000 dist_mean = -0.0065 dist_std = 0.1707 vf_loss = 0.0962 grad_norm = 3.5863 nat_grad_norm = 0.1502 cg_residual = 1.4940 step_size = 0.3296 reward = 0.0000 fps = 9 mse_loss = 1.8824 
2022-05-01 06:48:58.082100 - gail/main.py:164 - [TRPO] iter = 700000 dist_mean = -0.0056 dist_std = 0.1707 vf_loss = 0.1134 grad_norm = 2.3417 nat_grad_norm = 0.1015 cg_residual = 1.2362 step_size = 0.4803 reward = 0.0000 fps = 8 mse_loss = 1.8351 
2022-05-01 06:48:58.327398 - gail/main.py:191 - [Discriminator] iter = 700000 loss = -0.5504 grad_norm = 2.6586 grad_penalty = 0.0684 regularization = 0.0000 true_logits = 0.4509 fake_logits = -0.1679 true_prob = 0.6037 fake_prob = 0.4649 
2022-05-01 06:50:33.655632 - gail/main.py:132 - [Evaluate] iter = 700000 episode={ returns = 2113.7623 lengths = 598 } discounted_episode={ returns = 1870.1233 lengths = 804 } 
2022-05-01 06:50:43.595378 - gail/main.py:164 - [TRPO] iter = 701000 dist_mean = 0.0118 dist_std = 0.1700 vf_loss = 0.1178 grad_norm = 2.6539 nat_grad_norm = 0.1458 cg_residual = 1.9166 step_size = 0.3664 reward = 0.0000 fps = 9 mse_loss = 1.8656 
2022-05-01 06:50:53.429630 - gail/main.py:164 - [TRPO] iter = 702000 dist_mean = 0.0056 dist_std = 0.1701 vf_loss = 0.1329 grad_norm = 2.8326 nat_grad_norm = 0.1135 cg_residual = 1.9197 step_size = 0.4131 reward = 0.0000 fps = 8 mse_loss = 1.8485 
2022-05-01 06:51:03.121523 - gail/main.py:164 - [TRPO] iter = 703000 dist_mean = 0.0147 dist_std = 0.1699 vf_loss = 0.3067 grad_norm = 2.0274 nat_grad_norm = 0.0701 cg_residual = 0.4057 step_size = 0.6765 reward = -0.0000 fps = 8 mse_loss = 1.9307 
2022-05-01 06:51:13.167305 - gail/main.py:164 - [TRPO] iter = 704000 dist_mean = 0.0031 dist_std = 0.1698 vf_loss = 0.0591 grad_norm = 3.5034 nat_grad_norm = 0.1007 cg_residual = 2.0952 step_size = 0.4207 reward = -0.0000 fps = 7 mse_loss = 2.0132 
2022-05-01 06:51:22.562790 - gail/main.py:164 - [TRPO] iter = 705000 dist_mean = 0.0117 dist_std = 0.1693 vf_loss = 0.3226 grad_norm = 2.7958 nat_grad_norm = 0.0864 cg_residual = 1.5599 step_size = 0.4920 reward = -0.0000 fps = 6 mse_loss = 1.9186 
2022-05-01 06:51:22.791429 - gail/main.py:191 - [Discriminator] iter = 705000 loss = -0.6456 grad_norm = 2.9310 grad_penalty = 0.0668 regularization = 0.0000 true_logits = 0.4666 fake_logits = -0.2457 true_prob = 0.6069 fake_prob = 0.4506 
2022-05-01 06:53:31.410639 - gail/main.py:132 - [Evaluate] iter = 705000 episode={ returns = 3362.0197 lengths = 959 } discounted_episode={ returns = 2168.4893 lengths = 1000 } 
2022-05-01 06:53:41.146392 - gail/main.py:164 - [TRPO] iter = 706000 dist_mean = 0.0219 dist_std = 0.1693 vf_loss = 0.0722 grad_norm = 2.3423 nat_grad_norm = 0.1084 cg_residual = 0.8293 step_size = 0.4367 reward = -0.0000 fps = 7 mse_loss = 1.9250 
2022-05-01 06:53:51.196004 - gail/main.py:164 - [TRPO] iter = 707000 dist_mean = 0.0231 dist_std = 0.1696 vf_loss = 0.0615 grad_norm = 3.1232 nat_grad_norm = 0.0904 cg_residual = 1.6258 step_size = 0.4854 reward = -0.0000 fps = 6 mse_loss = 1.9590 
2022-05-01 06:54:01.228374 - gail/main.py:164 - [TRPO] iter = 708000 dist_mean = 0.0166 dist_std = 0.1699 vf_loss = 0.2611 grad_norm = 3.1956 nat_grad_norm = 0.0926 cg_residual = 0.8681 step_size = 0.5118 reward = 0.0000 fps = 6 mse_loss = 1.9541 
2022-05-01 06:54:11.014799 - gail/main.py:164 - [TRPO] iter = 709000 dist_mean = 0.0045 dist_std = 0.1699 vf_loss = 0.0579 grad_norm = 2.8206 nat_grad_norm = 0.0761 cg_residual = 0.6692 step_size = 0.5535 reward = 0.0000 fps = 5 mse_loss = 1.9464 
2022-05-01 06:54:21.005547 - gail/main.py:164 - [TRPO] iter = 710000 dist_mean = 0.0131 dist_std = 0.1701 vf_loss = 0.0994 grad_norm = 2.7961 nat_grad_norm = 0.1584 cg_residual = 1.2428 step_size = 0.3593 reward = -0.0000 fps = 5 mse_loss = 2.0240 
2022-05-01 06:54:21.237467 - gail/main.py:191 - [Discriminator] iter = 710000 loss = -1.0042 grad_norm = 2.6030 grad_penalty = 0.0779 regularization = 0.0000 true_logits = 0.4770 fake_logits = -0.6051 true_prob = 0.6094 fake_prob = 0.3822 
2022-05-01 06:56:06.594255 - gail/main.py:132 - [Evaluate] iter = 710000 episode={ returns = 2464.4331 lengths = 705 } discounted_episode={ returns = 1911.7794 lengths = 841 } 
2022-05-01 06:56:16.394338 - gail/main.py:164 - [TRPO] iter = 711000 dist_mean = -0.0006 dist_std = 0.1701 vf_loss = 0.4206 grad_norm = 2.6471 nat_grad_norm = 0.0611 cg_residual = 0.8713 step_size = 0.5638 reward = -0.0000 fps = 8 mse_loss = 1.9370 
2022-05-01 06:56:26.243324 - gail/main.py:164 - [TRPO] iter = 712000 dist_mean = 0.0046 dist_std = 0.1699 vf_loss = 0.2587 grad_norm = 2.8871 nat_grad_norm = 0.0757 cg_residual = 0.9647 step_size = 0.5096 reward = 0.0000 fps = 8 mse_loss = 1.9778 
2022-05-01 06:56:36.318154 - gail/main.py:164 - [TRPO] iter = 713000 dist_mean = 0.0145 dist_std = 0.1695 vf_loss = 0.0735 grad_norm = 3.0377 nat_grad_norm = 0.1150 cg_residual = 1.5140 step_size = 0.3569 reward = -0.0000 fps = 7 mse_loss = 2.1118 
2022-05-01 06:56:46.479055 - gail/main.py:164 - [TRPO] iter = 714000 dist_mean = 0.0150 dist_std = 0.1699 vf_loss = 0.1709 grad_norm = 3.9101 nat_grad_norm = 0.0580 cg_residual = 0.3475 step_size = 0.5688 reward = 0.0000 fps = 6 mse_loss = 1.8582 
2022-05-01 06:56:56.125912 - gail/main.py:164 - [TRPO] iter = 715000 dist_mean = -0.0014 dist_std = 0.1702 vf_loss = 0.0297 grad_norm = 1.8335 nat_grad_norm = 0.0663 cg_residual = 0.6876 step_size = 0.5910 reward = -0.0000 fps = 6 mse_loss = 1.8779 
2022-05-01 06:56:56.326570 - gail/main.py:191 - [Discriminator] iter = 715000 loss = -0.5967 grad_norm = 2.7296 grad_penalty = 0.0764 regularization = 0.0000 true_logits = 0.4487 fake_logits = -0.2245 true_prob = 0.6042 fake_prob = 0.4552 
2022-05-01 06:58:42.195859 - gail/main.py:132 - [Evaluate] iter = 715000 episode={ returns = 2779.4707 lengths = 788 } discounted_episode={ returns = 1805.7521 lengths = 780 } 
2022-05-01 06:58:52.194154 - gail/main.py:164 - [TRPO] iter = 716000 dist_mean = 0.0229 dist_std = 0.1702 vf_loss = 0.1088 grad_norm = 1.8481 nat_grad_norm = 0.0835 cg_residual = 0.8478 step_size = 0.5740 reward = -0.0000 fps = 8 mse_loss = 1.9186 
2022-05-01 06:59:01.930934 - gail/main.py:164 - [TRPO] iter = 717000 dist_mean = 0.0092 dist_std = 0.1701 vf_loss = 0.0593 grad_norm = 2.4498 nat_grad_norm = 0.1093 cg_residual = 0.9772 step_size = 0.4484 reward = 0.0000 fps = 7 mse_loss = 1.8316 
2022-05-01 06:59:11.726053 - gail/main.py:164 - [TRPO] iter = 718000 dist_mean = 0.0020 dist_std = 0.1704 vf_loss = 0.0609 grad_norm = 3.1569 nat_grad_norm = 0.0868 cg_residual = 0.9752 step_size = 0.5119 reward = 0.0000 fps = 7 mse_loss = 1.9265 
2022-05-01 06:59:21.579262 - gail/main.py:164 - [TRPO] iter = 719000 dist_mean = 0.0162 dist_std = 0.1706 vf_loss = 0.0712 grad_norm = 3.4825 nat_grad_norm = 0.1024 cg_residual = 0.6530 step_size = 0.4597 reward = -0.0000 fps = 6 mse_loss = 1.8389 
2022-05-01 06:59:31.446779 - gail/main.py:164 - [TRPO] iter = 720000 dist_mean = 0.0643 dist_std = 0.1705 vf_loss = 0.0819 grad_norm = 2.8407 nat_grad_norm = 0.1028 cg_residual = 1.0307 step_size = 0.4949 reward = 0.0000 fps = 6 mse_loss = 1.8943 
2022-05-01 06:59:31.676433 - gail/main.py:191 - [Discriminator] iter = 720000 loss = -0.7390 grad_norm = 2.5756 grad_penalty = 0.0648 regularization = 0.0000 true_logits = 0.4073 fake_logits = -0.3965 true_prob = 0.5933 fake_prob = 0.4187 
2022-05-01 07:01:01.545198 - gail/main.py:132 - [Evaluate] iter = 720000 episode={ returns = 2230.4185 lengths = 630 } discounted_episode={ returns = 1720.7222 lengths = 710 } 
2022-05-01 07:01:11.464628 - gail/main.py:164 - [TRPO] iter = 721000 dist_mean = 0.0040 dist_std = 0.1700 vf_loss = 0.1014 grad_norm = 2.3975 nat_grad_norm = 0.0737 cg_residual = 0.7524 step_size = 0.5471 reward = -0.0000 fps = 10 mse_loss = 1.8482 
2022-05-01 07:01:21.285292 - gail/main.py:164 - [TRPO] iter = 722000 dist_mean = 0.0074 dist_std = 0.1699 vf_loss = 0.0435 grad_norm = 3.1539 nat_grad_norm = 0.0772 cg_residual = 1.6264 step_size = 0.5042 reward = -0.0000 fps = 9 mse_loss = 1.8195 
2022-05-01 07:01:30.809639 - gail/main.py:164 - [TRPO] iter = 723000 dist_mean = 0.0089 dist_std = 0.1698 vf_loss = 0.1278 grad_norm = 3.4500 nat_grad_norm = 0.0845 cg_residual = 0.9666 step_size = 0.4574 reward = 0.0000 fps = 8 mse_loss = 1.8545 
2022-05-01 07:01:40.882015 - gail/main.py:164 - [TRPO] iter = 724000 dist_mean = 0.0302 dist_std = 0.1691 vf_loss = 0.0488 grad_norm = 3.5063 nat_grad_norm = 0.0858 cg_residual = 1.5133 step_size = 0.5082 reward = 0.0000 fps = 7 mse_loss = 1.8273 
2022-05-01 07:01:51.052032 - gail/main.py:164 - [TRPO] iter = 725000 dist_mean = 0.0256 dist_std = 0.1691 vf_loss = 0.0535 grad_norm = 2.6997 nat_grad_norm = 0.1202 cg_residual = 1.1537 step_size = 0.4328 reward = 0.0000 fps = 7 mse_loss = 1.7792 
2022-05-01 07:01:51.273901 - gail/main.py:191 - [Discriminator] iter = 725000 loss = -0.7236 grad_norm = 2.3780 grad_penalty = 0.0638 regularization = 0.0000 true_logits = 0.3990 fake_logits = -0.3884 true_prob = 0.5922 fake_prob = 0.4216 
2022-05-01 07:03:39.031246 - gail/main.py:132 - [Evaluate] iter = 725000 episode={ returns = 3168.5850 lengths = 914 } discounted_episode={ returns = 1716.9922 lengths = 723 } 
2022-05-01 07:03:48.669751 - gail/main.py:164 - [TRPO] iter = 726000 dist_mean = 0.0363 dist_std = 0.1686 vf_loss = 0.1129 grad_norm = 1.6332 nat_grad_norm = 0.0920 cg_residual = 0.6208 step_size = 0.6018 reward = -0.0000 fps = 8 mse_loss = 1.8921 
2022-05-01 07:03:58.414616 - gail/main.py:164 - [TRPO] iter = 727000 dist_mean = -0.0039 dist_std = 0.1690 vf_loss = 0.2275 grad_norm = 3.3598 nat_grad_norm = 0.0854 cg_residual = 1.9112 step_size = 0.4216 reward = -0.0000 fps = 7 mse_loss = 1.7440 
2022-05-01 07:04:08.350196 - gail/main.py:164 - [TRPO] iter = 728000 dist_mean = 0.0142 dist_std = 0.1684 vf_loss = 0.2530 grad_norm = 3.9862 nat_grad_norm = 0.0675 cg_residual = 0.7094 step_size = 0.4886 reward = 0.0000 fps = 7 mse_loss = 1.7663 
2022-05-01 07:04:18.050193 - gail/main.py:164 - [TRPO] iter = 729000 dist_mean = 0.0045 dist_std = 0.1684 vf_loss = 0.0311 grad_norm = 2.6414 nat_grad_norm = 0.0963 cg_residual = 0.6549 step_size = 0.5079 reward = 0.0000 fps = 6 mse_loss = 1.6776 
2022-05-01 07:04:27.851674 - gail/main.py:164 - [TRPO] iter = 730000 dist_mean = 0.0249 dist_std = 0.1682 vf_loss = 0.2471 grad_norm = 2.2520 nat_grad_norm = 0.0946 cg_residual = 1.1317 step_size = 0.4946 reward = -0.0000 fps = 6 mse_loss = 1.7740 
2022-05-01 07:04:28.090342 - gail/main.py:191 - [Discriminator] iter = 730000 loss = -0.7249 grad_norm = 2.4807 grad_penalty = 0.0664 regularization = 0.0000 true_logits = 0.3812 fake_logits = -0.4101 true_prob = 0.5893 fake_prob = 0.4171 
2022-05-01 07:06:04.350721 - gail/main.py:132 - [Evaluate] iter = 730000 episode={ returns = 2093.5453 lengths = 586 } discounted_episode={ returns = 1915.4890 lengths = 849 } 
2022-05-01 07:06:14.236959 - gail/main.py:164 - [TRPO] iter = 731000 dist_mean = 0.0303 dist_std = 0.1684 vf_loss = 0.0544 grad_norm = 2.3780 nat_grad_norm = 0.1088 cg_residual = 1.0860 step_size = 0.4508 reward = 0.0000 fps = 9 mse_loss = 1.7837 
2022-05-01 07:06:24.266964 - gail/main.py:164 - [TRPO] iter = 732000 dist_mean = 0.0412 dist_std = 0.1687 vf_loss = 0.3516 grad_norm = 1.6635 nat_grad_norm = 0.0710 cg_residual = 0.7572 step_size = 0.6208 reward = 0.0000 fps = 8 mse_loss = 1.8539 
2022-05-01 07:06:34.070337 - gail/main.py:164 - [TRPO] iter = 733000 dist_mean = 0.0042 dist_std = 0.1688 vf_loss = 0.0551 grad_norm = 2.2455 nat_grad_norm = 0.0842 cg_residual = 1.2667 step_size = 0.5711 reward = -0.0000 fps = 7 mse_loss = 1.8779 
2022-05-01 07:06:43.811723 - gail/main.py:164 - [TRPO] iter = 734000 dist_mean = 0.0180 dist_std = 0.1690 vf_loss = 0.3243 grad_norm = 3.8822 nat_grad_norm = 0.0955 cg_residual = 1.5331 step_size = 0.4258 reward = -0.0000 fps = 7 mse_loss = 1.8025 
2022-05-01 07:06:53.563392 - gail/main.py:164 - [TRPO] iter = 735000 dist_mean = 0.0454 dist_std = 0.1688 vf_loss = 0.3370 grad_norm = 2.6580 nat_grad_norm = 0.0801 cg_residual = 0.6803 step_size = 0.5901 reward = -0.0000 fps = 6 mse_loss = 1.7906 
2022-05-01 07:06:53.769549 - gail/main.py:191 - [Discriminator] iter = 735000 loss = -0.9069 grad_norm = 2.5996 grad_penalty = 0.0757 regularization = 0.0000 true_logits = 0.3725 fake_logits = -0.6101 true_prob = 0.5872 fake_prob = 0.3789 
2022-05-01 07:08:16.215140 - gail/main.py:132 - [Evaluate] iter = 735000 episode={ returns = 2133.7092 lengths = 609 } discounted_episode={ returns = 1526.4622 lengths = 617 } 
2022-05-01 07:08:26.041423 - gail/main.py:164 - [TRPO] iter = 736000 dist_mean = 0.0202 dist_std = 0.1687 vf_loss = 0.0566 grad_norm = 2.1596 nat_grad_norm = 0.0831 cg_residual = 0.3966 step_size = 0.5486 reward = 0.0000 fps = 10 mse_loss = 1.7949 
2022-05-01 07:08:36.058686 - gail/main.py:164 - [TRPO] iter = 737000 dist_mean = 0.0134 dist_std = 0.1688 vf_loss = 0.1793 grad_norm = 4.5540 nat_grad_norm = 0.0873 cg_residual = 0.6750 step_size = 0.4378 reward = -0.0000 fps = 9 mse_loss = 1.8153 
2022-05-01 07:08:46.132676 - gail/main.py:164 - [TRPO] iter = 738000 dist_mean = 0.0131 dist_std = 0.1688 vf_loss = 0.0496 grad_norm = 3.2750 nat_grad_norm = 0.1077 cg_residual = 0.5580 step_size = 0.4042 reward = -0.0000 fps = 8 mse_loss = 1.8943 
2022-05-01 07:08:55.961034 - gail/main.py:164 - [TRPO] iter = 739000 dist_mean = 0.0186 dist_std = 0.1690 vf_loss = 0.0458 grad_norm = 2.5619 nat_grad_norm = 0.1399 cg_residual = 1.6040 step_size = 0.3783 reward = 0.0000 fps = 8 mse_loss = 1.7963 
2022-05-01 07:09:05.855322 - gail/main.py:164 - [TRPO] iter = 740000 dist_mean = 0.0439 dist_std = 0.1694 vf_loss = 0.2466 grad_norm = 2.4841 nat_grad_norm = 0.0992 cg_residual = 0.7205 step_size = 0.5281 reward = -0.0000 fps = 7 mse_loss = 1.7584 
2022-05-01 07:09:06.069217 - gail/main.py:191 - [Discriminator] iter = 740000 loss = -0.9931 grad_norm = 2.9915 grad_penalty = 0.0943 regularization = 0.0000 true_logits = 0.3001 fake_logits = -0.7873 true_prob = 0.5727 fake_prob = 0.3478 
2022-05-01 07:10:56.781064 - gail/main.py:132 - [Evaluate] iter = 740000 episode={ returns = 3104.6368 lengths = 902 } discounted_episode={ returns = 1710.8052 lengths = 732 } 
2022-05-01 07:11:07.001275 - gail/main.py:164 - [TRPO] iter = 741000 dist_mean = 0.0300 dist_std = 0.1692 vf_loss = 0.0711 grad_norm = 4.4847 nat_grad_norm = 0.1333 cg_residual = 1.5364 step_size = 0.3413 reward = 0.0000 fps = 8 mse_loss = 1.7940 
2022-05-01 07:11:16.969867 - gail/main.py:164 - [TRPO] iter = 742000 dist_mean = -0.0099 dist_std = 0.1693 vf_loss = 0.0856 grad_norm = 3.4249 nat_grad_norm = 0.1075 cg_residual = 2.0822 step_size = 0.4389 reward = -0.0000 fps = 7 mse_loss = 1.7991 
2022-05-01 07:11:27.154102 - gail/main.py:164 - [TRPO] iter = 743000 dist_mean = 0.0430 dist_std = 0.1685 vf_loss = 0.0802 grad_norm = 2.5014 nat_grad_norm = 0.1096 cg_residual = 1.1440 step_size = 0.4484 reward = -0.0000 fps = 7 mse_loss = 1.8158 
2022-05-01 07:11:37.527877 - gail/main.py:164 - [TRPO] iter = 744000 dist_mean = 0.0241 dist_std = 0.1684 vf_loss = 0.4011 grad_norm = 3.1437 nat_grad_norm = 0.0871 cg_residual = 1.4360 step_size = 0.4234 reward = -0.0000 fps = 6 mse_loss = 1.7159 
2022-05-01 07:11:47.589641 - gail/main.py:164 - [TRPO] iter = 745000 dist_mean = 0.0140 dist_std = 0.1684 vf_loss = 0.2438 grad_norm = 2.5509 nat_grad_norm = 0.0954 cg_residual = 0.6764 step_size = 0.4709 reward = 0.0000 fps = 6 mse_loss = 1.7665 
2022-05-01 07:11:47.844485 - gail/main.py:191 - [Discriminator] iter = 745000 loss = -0.7561 grad_norm = 2.9590 grad_penalty = 0.0778 regularization = 0.0000 true_logits = 0.2929 fake_logits = -0.5409 true_prob = 0.5709 fake_prob = 0.3909 
2022-05-01 07:13:45.850833 - gail/main.py:132 - [Evaluate] iter = 745000 episode={ returns = 2829.7076 lengths = 817 } discounted_episode={ returns = 1944.1847 lengths = 894 } 
2022-05-01 07:13:56.126972 - gail/main.py:164 - [TRPO] iter = 746000 dist_mean = 0.0263 dist_std = 0.1683 vf_loss = 0.0555 grad_norm = 2.3618 nat_grad_norm = 0.1319 cg_residual = 2.0067 step_size = 0.3416 reward = 0.0000 fps = 7 mse_loss = 1.7818 
2022-05-01 07:14:05.646555 - gail/main.py:164 - [TRPO] iter = 747000 dist_mean = 0.0467 dist_std = 0.1684 vf_loss = 0.1819 grad_norm = 2.1722 nat_grad_norm = 0.0950 cg_residual = 1.8896 step_size = 0.4925 reward = 0.0000 fps = 7 mse_loss = 1.7696 
2022-05-01 07:14:15.428124 - gail/main.py:164 - [TRPO] iter = 748000 dist_mean = 0.0452 dist_std = 0.1686 vf_loss = 0.0531 grad_norm = 2.1196 nat_grad_norm = 0.0746 cg_residual = 1.1727 step_size = 0.5591 reward = 0.0000 fps = 6 mse_loss = 1.7902 
2022-05-01 07:14:25.269264 - gail/main.py:164 - [TRPO] iter = 749000 dist_mean = 0.0403 dist_std = 0.1688 vf_loss = 0.0933 grad_norm = 2.7419 nat_grad_norm = 0.0958 cg_residual = 2.3186 step_size = 0.4897 reward = -0.0000 fps = 6 mse_loss = 1.8032 
2022-05-01 07:14:35.370552 - gail/main.py:164 - [TRPO] iter = 750000 dist_mean = 0.0563 dist_std = 0.1690 vf_loss = 0.1809 grad_norm = 2.9489 nat_grad_norm = 0.1156 cg_residual = 0.7532 step_size = 0.4405 reward = 0.0000 fps = 5 mse_loss = 1.7135 
2022-05-01 07:14:35.619448 - gail/main.py:191 - [Discriminator] iter = 750000 loss = -1.0111 grad_norm = 2.6885 grad_penalty = 0.0812 regularization = 0.0000 true_logits = 0.1959 fake_logits = -0.8965 true_prob = 0.5486 fake_prob = 0.3241 
2022-05-01 07:16:35.238202 - gail/main.py:132 - [Evaluate] iter = 750000 episode={ returns = 2976.7197 lengths = 861 } discounted_episode={ returns = 1955.8923 lengths = 875 } 
2022-05-01 07:16:45.485851 - gail/main.py:164 - [TRPO] iter = 751000 dist_mean = 0.0019 dist_std = 0.1691 vf_loss = 0.1483 grad_norm = 2.4519 nat_grad_norm = 0.0985 cg_residual = 1.0328 step_size = 0.4969 reward = -0.0000 fps = 7 mse_loss = 1.7962 
2022-05-01 07:16:55.869416 - gail/main.py:164 - [TRPO] iter = 752000 dist_mean = 0.0346 dist_std = 0.1690 vf_loss = 0.0525 grad_norm = 3.1365 nat_grad_norm = 0.1236 cg_residual = 3.8210 step_size = 0.3488 reward = -0.0000 fps = 7 mse_loss = 1.7276 
2022-05-01 07:17:06.063371 - gail/main.py:164 - [TRPO] iter = 753000 dist_mean = 0.0190 dist_std = 0.1691 vf_loss = 0.0601 grad_norm = 3.0224 nat_grad_norm = 0.1462 cg_residual = 2.8762 step_size = 0.3125 reward = -0.0000 fps = 6 mse_loss = 1.7438 
2022-05-01 07:17:16.221494 - gail/main.py:164 - [TRPO] iter = 754000 dist_mean = 0.0128 dist_std = 0.1691 vf_loss = 0.2469 grad_norm = 2.8109 nat_grad_norm = 0.0828 cg_residual = 1.4339 step_size = 0.4427 reward = -0.0000 fps = 6 mse_loss = 1.7936 
2022-05-01 07:17:26.301510 - gail/main.py:164 - [TRPO] iter = 755000 dist_mean = 0.0353 dist_std = 0.1690 vf_loss = 0.2031 grad_norm = 2.9196 nat_grad_norm = 0.0637 cg_residual = 0.3786 step_size = 0.5774 reward = -0.0000 fps = 5 mse_loss = 1.7894 
2022-05-01 07:17:26.499571 - gail/main.py:191 - [Discriminator] iter = 755000 loss = -0.5275 grad_norm = 2.3807 grad_penalty = 0.0600 regularization = 0.0000 true_logits = 0.2117 fake_logits = -0.3759 true_prob = 0.5525 fake_prob = 0.4194 
2022-05-01 07:19:41.855152 - gail/main.py:132 - [Evaluate] iter = 755000 episode={ returns = 3435.5687 lengths = 1000 } discounted_episode={ returns = 2125.2805 lengths = 1000 } 
2022-05-01 07:19:52.250258 - gail/main.py:164 - [TRPO] iter = 756000 dist_mean = 0.0373 dist_std = 0.1690 vf_loss = 0.1977 grad_norm = 2.3617 nat_grad_norm = 0.0633 cg_residual = 0.7806 step_size = 0.6137 reward = 0.0000 fps = 6 mse_loss = 1.7607 
2022-05-01 07:20:02.778889 - gail/main.py:164 - [TRPO] iter = 757000 dist_mean = 0.0030 dist_std = 0.1690 vf_loss = 0.0417 grad_norm = 2.9144 nat_grad_norm = 0.0890 cg_residual = 0.7753 step_size = 0.4114 reward = 0.0000 fps = 6 mse_loss = 1.7458 
2022-05-01 07:20:12.899152 - gail/main.py:164 - [TRPO] iter = 758000 dist_mean = 0.0351 dist_std = 0.1691 vf_loss = 0.2331 grad_norm = 1.5462 nat_grad_norm = 0.0717 cg_residual = 1.0855 step_size = 0.6946 reward = -0.0000 fps = 6 mse_loss = 1.8079 
2022-05-01 07:20:23.049995 - gail/main.py:164 - [TRPO] iter = 759000 dist_mean = 0.0560 dist_std = 0.1683 vf_loss = 0.1511 grad_norm = 2.5798 nat_grad_norm = 0.0842 cg_residual = 0.6812 step_size = 0.4874 reward = -0.0000 fps = 5 mse_loss = 1.7595 
2022-05-01 07:20:33.034820 - gail/main.py:164 - [TRPO] iter = 760000 dist_mean = 0.0133 dist_std = 0.1682 vf_loss = 0.0379 grad_norm = 3.2900 nat_grad_norm = 0.0964 cg_residual = 1.1941 step_size = 0.5054 reward = 0.0000 fps = 5 mse_loss = 1.8244 
2022-05-01 07:20:33.267139 - gail/main.py:191 - [Discriminator] iter = 760000 loss = -0.5431 grad_norm = 2.6256 grad_penalty = 0.0613 regularization = 0.0000 true_logits = 0.2471 fake_logits = -0.3573 true_prob = 0.5603 fake_prob = 0.4220 
2022-05-01 07:22:54.153205 - gail/main.py:132 - [Evaluate] iter = 760000 episode={ returns = 3468.8242 lengths = 1000 } discounted_episode={ returns = 2140.8495 lengths = 1000 } 
2022-05-01 07:23:04.721112 - gail/main.py:164 - [TRPO] iter = 761000 dist_mean = 0.0129 dist_std = 0.1686 vf_loss = 0.1490 grad_norm = 2.5567 nat_grad_norm = 0.0570 cg_residual = 0.3167 step_size = 0.6988 reward = -0.0000 fps = 6 mse_loss = 1.8094 
2022-05-01 07:23:14.915802 - gail/main.py:164 - [TRPO] iter = 762000 dist_mean = 0.0242 dist_std = 0.1689 vf_loss = 0.1486 grad_norm = 4.2916 nat_grad_norm = 0.0770 cg_residual = 0.8830 step_size = 0.4536 reward = -0.0000 fps = 6 mse_loss = 1.8207 
2022-05-01 07:23:25.106663 - gail/main.py:164 - [TRPO] iter = 763000 dist_mean = 0.0156 dist_std = 0.1687 vf_loss = 0.1064 grad_norm = 2.1467 nat_grad_norm = 0.0816 cg_residual = 0.3591 step_size = 0.5898 reward = 0.0000 fps = 5 mse_loss = 1.8914 
2022-05-01 07:23:35.165582 - gail/main.py:164 - [TRPO] iter = 764000 dist_mean = 0.0509 dist_std = 0.1688 vf_loss = 0.1587 grad_norm = 2.5358 nat_grad_norm = 0.0770 cg_residual = 0.8743 step_size = 0.5652 reward = -0.0000 fps = 5 mse_loss = 1.9288 
2022-05-01 07:23:45.089054 - gail/main.py:164 - [TRPO] iter = 765000 dist_mean = 0.0456 dist_std = 0.1689 vf_loss = 0.1349 grad_norm = 2.6366 nat_grad_norm = 0.1020 cg_residual = 0.7528 step_size = 0.4679 reward = 0.0000 fps = 5 mse_loss = 1.9504 
2022-05-01 07:23:45.332660 - gail/main.py:191 - [Discriminator] iter = 765000 loss = -0.5133 grad_norm = 2.3306 grad_penalty = 0.0580 regularization = 0.0000 true_logits = 0.2751 fake_logits = -0.2962 true_prob = 0.5648 fake_prob = 0.4342 
2022-05-01 07:26:04.342642 - gail/main.py:132 - [Evaluate] iter = 765000 episode={ returns = 3494.7206 lengths = 1000 } discounted_episode={ returns = 2163.5034 lengths = 1000 } 
2022-05-01 07:26:14.644014 - gail/main.py:164 - [TRPO] iter = 766000 dist_mean = 0.0216 dist_std = 0.1689 vf_loss = 0.0466 grad_norm = 3.2062 nat_grad_norm = 0.0796 cg_residual = 1.2076 step_size = 0.4867 reward = -0.0000 fps = 6 mse_loss = 1.8822 
2022-05-01 07:26:24.374027 - gail/main.py:164 - [TRPO] iter = 767000 dist_mean = 0.0545 dist_std = 0.1694 vf_loss = 0.0993 grad_norm = 2.8525 nat_grad_norm = 0.0980 cg_residual = 1.4600 step_size = 0.4488 reward = 0.0000 fps = 6 mse_loss = 1.8873 
2022-05-01 07:26:34.832574 - gail/main.py:164 - [TRPO] iter = 768000 dist_mean = 0.0611 dist_std = 0.1696 vf_loss = 0.1285 grad_norm = 2.4221 nat_grad_norm = 0.0780 cg_residual = 0.4748 step_size = 0.6001 reward = 0.0000 fps = 5 mse_loss = 1.9865 
2022-05-01 07:26:45.135716 - gail/main.py:164 - [TRPO] iter = 769000 dist_mean = 0.0413 dist_std = 0.1695 vf_loss = 0.0778 grad_norm = 3.0285 nat_grad_norm = 0.0897 cg_residual = 0.5595 step_size = 0.4848 reward = -0.0000 fps = 5 mse_loss = 2.0284 
2022-05-01 07:26:55.241036 - gail/main.py:164 - [TRPO] iter = 770000 dist_mean = 0.0594 dist_std = 0.1694 vf_loss = 0.0980 grad_norm = 2.2240 nat_grad_norm = 0.0625 cg_residual = 0.8650 step_size = 0.6342 reward = 0.0000 fps = 5 mse_loss = 2.0108 
2022-05-01 07:26:55.477534 - gail/main.py:191 - [Discriminator] iter = 770000 loss = -0.5837 grad_norm = 2.5443 grad_penalty = 0.0558 regularization = 0.0000 true_logits = 0.3736 fake_logits = -0.2659 true_prob = 0.5858 fake_prob = 0.4405 
2022-05-01 07:29:10.471639 - gail/main.py:132 - [Evaluate] iter = 770000 episode={ returns = 3269.4468 lengths = 939 } discounted_episode={ returns = 2016.6750 lengths = 932 } 
2022-05-01 07:29:21.064393 - gail/main.py:164 - [TRPO] iter = 771000 dist_mean = 0.0342 dist_std = 0.1693 vf_loss = 0.0662 grad_norm = 4.4270 nat_grad_norm = 0.0602 cg_residual = 0.3781 step_size = 0.5161 reward = -0.0000 fps = 6 mse_loss = 1.9596 
2022-05-01 07:29:31.178558 - gail/main.py:164 - [TRPO] iter = 772000 dist_mean = 0.0426 dist_std = 0.1692 vf_loss = 0.0696 grad_norm = 3.1763 nat_grad_norm = 0.1067 cg_residual = 1.6278 step_size = 0.4295 reward = 0.0000 fps = 6 mse_loss = 1.9365 
2022-05-01 07:29:41.487827 - gail/main.py:164 - [TRPO] iter = 773000 dist_mean = 0.0563 dist_std = 0.1692 vf_loss = 0.0507 grad_norm = 2.2947 nat_grad_norm = 0.0882 cg_residual = 1.2788 step_size = 0.5173 reward = 0.0000 fps = 6 mse_loss = 2.0089 
2022-05-01 07:29:52.434467 - gail/main.py:164 - [TRPO] iter = 774000 dist_mean = 0.0349 dist_std = 0.1695 vf_loss = 0.0826 grad_norm = 3.0132 nat_grad_norm = 0.0701 cg_residual = 0.5162 step_size = 0.5192 reward = -0.0000 fps = 5 mse_loss = 1.9634 
2022-05-01 07:30:02.678373 - gail/main.py:164 - [TRPO] iter = 775000 dist_mean = 0.0312 dist_std = 0.1699 vf_loss = 0.0256 grad_norm = 2.9008 nat_grad_norm = 0.1102 cg_residual = 1.8142 step_size = 0.4433 reward = 0.0000 fps = 5 mse_loss = 1.8887 
2022-05-01 07:30:02.931791 - gail/main.py:191 - [Discriminator] iter = 775000 loss = -0.5382 grad_norm = 2.1694 grad_penalty = 0.0538 regularization = 0.0000 true_logits = 0.4575 fake_logits = -0.1346 true_prob = 0.6040 fake_prob = 0.4703 
2022-05-01 07:32:24.223336 - gail/main.py:132 - [Evaluate] iter = 775000 episode={ returns = 3542.0250 lengths = 1000 } discounted_episode={ returns = 2198.1612 lengths = 1000 } 
2022-05-01 07:32:34.559032 - gail/main.py:164 - [TRPO] iter = 776000 dist_mean = 0.0256 dist_std = 0.1695 vf_loss = 0.0370 grad_norm = 2.0607 nat_grad_norm = 0.1098 cg_residual = 2.3382 step_size = 0.5038 reward = 0.0000 fps = 6 mse_loss = 1.8877 
2022-05-01 07:32:44.840135 - gail/main.py:164 - [TRPO] iter = 777000 dist_mean = 0.0379 dist_std = 0.1691 vf_loss = 0.0923 grad_norm = 3.5865 nat_grad_norm = 0.0895 cg_residual = 0.8757 step_size = 0.4609 reward = 0.0000 fps = 6 mse_loss = 1.8885 
2022-05-01 07:32:55.296875 - gail/main.py:164 - [TRPO] iter = 778000 dist_mean = 0.0665 dist_std = 0.1692 vf_loss = 0.1429 grad_norm = 2.7776 nat_grad_norm = 0.1182 cg_residual = 1.4708 step_size = 0.3779 reward = 0.0000 fps = 5 mse_loss = 1.8234 
2022-05-01 07:33:05.418102 - gail/main.py:164 - [TRPO] iter = 779000 dist_mean = 0.0146 dist_std = 0.1694 vf_loss = 0.0768 grad_norm = 4.6126 nat_grad_norm = 0.1233 cg_residual = 1.8778 step_size = 0.3100 reward = -0.0000 fps = 5 mse_loss = 1.9585 
2022-05-01 07:33:16.134718 - gail/main.py:164 - [TRPO] iter = 780000 dist_mean = 0.0379 dist_std = 0.1695 vf_loss = 0.1794 grad_norm = 1.6298 nat_grad_norm = 0.0703 cg_residual = 0.4352 step_size = 0.6506 reward = -0.0000 fps = 5 mse_loss = 1.8771 
2022-05-01 07:33:16.323239 - gail/main.py:191 - [Discriminator] iter = 780000 loss = -0.6554 grad_norm = 2.8313 grad_penalty = 0.0534 regularization = 0.0000 true_logits = 0.4941 fake_logits = -0.2147 true_prob = 0.6101 fake_prob = 0.4525 
2022-05-01 07:34:28.229013 - gail/main.py:132 - [Evaluate] iter = 780000 episode={ returns = 2341.3759 lengths = 670 } discounted_episode={ returns = 858.1000 lengths = 348 } 
2022-05-01 07:34:38.817680 - gail/main.py:164 - [TRPO] iter = 781000 dist_mean = 0.0312 dist_std = 0.1700 vf_loss = 0.2810 grad_norm = 3.2819 nat_grad_norm = 0.1266 cg_residual = 1.9379 step_size = 0.3385 reward = -0.0000 fps = 12 mse_loss = 1.9115 
2022-05-01 07:34:48.909050 - gail/main.py:164 - [TRPO] iter = 782000 dist_mean = 0.0739 dist_std = 0.1700 vf_loss = 0.0727 grad_norm = 3.2767 nat_grad_norm = 0.0969 cg_residual = 1.0063 step_size = 0.4140 reward = 0.0000 fps = 10 mse_loss = 1.9191 
2022-05-01 07:34:59.417910 - gail/main.py:164 - [TRPO] iter = 783000 dist_mean = 0.0853 dist_std = 0.1695 vf_loss = 0.1573 grad_norm = 2.7831 nat_grad_norm = 0.1203 cg_residual = 1.4131 step_size = 0.3828 reward = -0.0000 fps = 9 mse_loss = 1.9329 
2022-05-01 07:35:09.879034 - gail/main.py:164 - [TRPO] iter = 784000 dist_mean = 0.0635 dist_std = 0.1690 vf_loss = 0.0363 grad_norm = 3.4434 nat_grad_norm = 0.1181 cg_residual = 1.4892 step_size = 0.3916 reward = -0.0000 fps = 8 mse_loss = 1.8403 
2022-05-01 07:35:19.953482 - gail/main.py:164 - [TRPO] iter = 785000 dist_mean = 0.0152 dist_std = 0.1687 vf_loss = 0.4211 grad_norm = 1.9619 nat_grad_norm = 0.0934 cg_residual = 1.2685 step_size = 0.5228 reward = -0.0000 fps = 8 mse_loss = 1.8883 
2022-05-01 07:35:20.166717 - gail/main.py:191 - [Discriminator] iter = 785000 loss = -0.6675 grad_norm = 2.8021 grad_penalty = 0.0630 regularization = 0.0000 true_logits = 0.4526 fake_logits = -0.2779 true_prob = 0.5999 fake_prob = 0.4417 
2022-05-01 07:37:22.819620 - gail/main.py:132 - [Evaluate] iter = 785000 episode={ returns = 3241.9667 lengths = 918 } discounted_episode={ returns = 1858.7805 lengths = 836 } 
2022-05-01 07:37:33.098428 - gail/main.py:164 - [TRPO] iter = 786000 dist_mean = 0.0158 dist_std = 0.1687 vf_loss = 0.0314 grad_norm = 2.5620 nat_grad_norm = 0.0886 cg_residual = 2.3650 step_size = 0.4515 reward = 0.0000 fps = 7 mse_loss = 1.9002 
2022-05-01 07:37:42.936231 - gail/main.py:164 - [TRPO] iter = 787000 dist_mean = 0.0575 dist_std = 0.1683 vf_loss = 0.1530 grad_norm = 3.3541 nat_grad_norm = 0.1124 cg_residual = 1.0276 step_size = 0.4506 reward = -0.0000 fps = 7 mse_loss = 1.8607 
2022-05-01 07:37:53.070825 - gail/main.py:164 - [TRPO] iter = 788000 dist_mean = 0.0786 dist_std = 0.1686 vf_loss = 0.0650 grad_norm = 3.2331 nat_grad_norm = 0.1088 cg_residual = 1.1929 step_size = 0.4207 reward = 0.0000 fps = 6 mse_loss = 1.8254 
2022-05-01 07:38:02.941675 - gail/main.py:164 - [TRPO] iter = 789000 dist_mean = 0.0343 dist_std = 0.1683 vf_loss = 0.2759 grad_norm = 2.5802 nat_grad_norm = 0.0801 cg_residual = 1.1372 step_size = 0.5531 reward = -0.0000 fps = 6 mse_loss = 1.8578 
2022-05-01 07:38:12.992702 - gail/main.py:164 - [TRPO] iter = 790000 dist_mean = 0.0708 dist_std = 0.1681 vf_loss = 0.0684 grad_norm = 2.4234 nat_grad_norm = 0.1339 cg_residual = 1.3632 step_size = 0.3994 reward = 0.0000 fps = 5 mse_loss = 1.8746 
2022-05-01 07:38:13.215116 - gail/main.py:191 - [Discriminator] iter = 790000 loss = -1.2019 grad_norm = 2.5193 grad_penalty = 0.1031 regularization = 0.0000 true_logits = 0.3712 fake_logits = -0.9337 true_prob = 0.5849 fake_prob = 0.3210 
2022-05-01 07:39:09.882564 - gail/main.py:132 - [Evaluate] iter = 790000 episode={ returns = 1100.0320 lengths = 333 } discounted_episode={ returns = 1156.7510 lengths = 502 } 
2022-05-01 07:39:20.026148 - gail/main.py:164 - [TRPO] iter = 791000 dist_mean = 0.0462 dist_std = 0.1685 vf_loss = 0.0446 grad_norm = 3.1911 nat_grad_norm = 0.1053 cg_residual = 1.8513 step_size = 0.3696 reward = 0.0000 fps = 14 mse_loss = 1.8118 
2022-05-01 07:39:29.906760 - gail/main.py:164 - [TRPO] iter = 792000 dist_mean = 0.0490 dist_std = 0.1680 vf_loss = 0.0570 grad_norm = 2.7526 nat_grad_norm = 0.0851 cg_residual = 0.6703 step_size = 0.4880 reward = -0.0000 fps = 13 mse_loss = 1.8762 
2022-05-01 07:39:40.058143 - gail/main.py:164 - [TRPO] iter = 793000 dist_mean = 0.0427 dist_std = 0.1678 vf_loss = 0.3182 grad_norm = 2.0989 nat_grad_norm = 0.0925 cg_residual = 0.9604 step_size = 0.5125 reward = 0.0000 fps = 11 mse_loss = 1.7954 
2022-05-01 07:39:50.155018 - gail/main.py:164 - [TRPO] iter = 794000 dist_mean = 0.0348 dist_std = 0.1679 vf_loss = 0.1206 grad_norm = 2.4385 nat_grad_norm = 0.0880 cg_residual = 1.1788 step_size = 0.4781 reward = -0.0000 fps = 10 mse_loss = 1.8957 
2022-05-01 07:39:59.869681 - gail/main.py:164 - [TRPO] iter = 795000 dist_mean = 0.0067 dist_std = 0.1681 vf_loss = 0.0472 grad_norm = 2.5222 nat_grad_norm = 0.0769 cg_residual = 0.6832 step_size = 0.5119 reward = 0.0000 fps = 9 mse_loss = 1.8275 
2022-05-01 07:40:00.124973 - gail/main.py:191 - [Discriminator] iter = 795000 loss = -0.5217 grad_norm = 3.0621 grad_penalty = 0.0663 regularization = 0.0000 true_logits = 0.2091 fake_logits = -0.3789 true_prob = 0.5508 fake_prob = 0.4200 
2022-05-01 07:42:11.240336 - gail/main.py:132 - [Evaluate] iter = 795000 episode={ returns = 3256.2639 lengths = 924 } discounted_episode={ returns = 2202.3104 lengths = 1000 } 
2022-05-01 07:42:21.172720 - gail/main.py:164 - [TRPO] iter = 796000 dist_mean = 0.0327 dist_std = 0.1681 vf_loss = 0.0436 grad_norm = 3.5057 nat_grad_norm = 0.0656 cg_residual = 1.1614 step_size = 0.5560 reward = 0.0000 fps = 7 mse_loss = 1.8485 
2022-05-01 07:42:31.131832 - gail/main.py:164 - [TRPO] iter = 797000 dist_mean = 0.0415 dist_std = 0.1681 vf_loss = 0.1248 grad_norm = 4.6482 nat_grad_norm = 0.0833 cg_residual = 1.2178 step_size = 0.4521 reward = 0.0000 fps = 6 mse_loss = 1.7765 
2022-05-01 07:42:41.043490 - gail/main.py:164 - [TRPO] iter = 798000 dist_mean = 0.0456 dist_std = 0.1678 vf_loss = 0.0704 grad_norm = 2.4386 nat_grad_norm = 0.1055 cg_residual = 0.8958 step_size = 0.4357 reward = -0.0000 fps = 6 mse_loss = 1.9223 
2022-05-01 07:42:50.612818 - gail/main.py:164 - [TRPO] iter = 799000 dist_mean = 0.0538 dist_std = 0.1676 vf_loss = 0.0588 grad_norm = 2.9076 nat_grad_norm = 0.0662 cg_residual = 0.6977 step_size = 0.5743 reward = -0.0000 fps = 5 mse_loss = 1.8696 
2022-05-01 07:43:00.692389 - gail/main.py:164 - [TRPO] iter = 800000 dist_mean = 0.0412 dist_std = 0.1674 vf_loss = 0.0779 grad_norm = 2.5562 nat_grad_norm = 0.1265 cg_residual = 1.2955 step_size = 0.4089 reward = 0.0000 fps = 5 mse_loss = 1.9049 
2022-05-01 07:43:00.915547 - gail/main.py:191 - [Discriminator] iter = 800000 loss = -0.8253 grad_norm = 2.9219 grad_penalty = 0.0698 regularization = 0.0000 true_logits = 0.2018 fake_logits = -0.6933 true_prob = 0.5490 fake_prob = 0.3626 
2022-05-01 07:45:12.785882 - gail/main.py:132 - [Evaluate] iter = 800000 episode={ returns = 3534.9597 lengths = 1000 } discounted_episode={ returns = 2106.0194 lengths = 942 } 
2022-05-01 07:45:22.829692 - gail/main.py:164 - [TRPO] iter = 801000 dist_mean = 0.0474 dist_std = 0.1673 vf_loss = 0.0250 grad_norm = 2.4839 nat_grad_norm = 0.1000 cg_residual = 1.6897 step_size = 0.4178 reward = -0.0000 fps = 7 mse_loss = 1.8250 
2022-05-01 07:45:32.609349 - gail/main.py:164 - [TRPO] iter = 802000 dist_mean = 0.0221 dist_std = 0.1670 vf_loss = 0.0957 grad_norm = 2.5388 nat_grad_norm = 0.0835 cg_residual = 0.7075 step_size = 0.5476 reward = -0.0000 fps = 6 mse_loss = 1.8586 
2022-05-01 07:45:42.659692 - gail/main.py:164 - [TRPO] iter = 803000 dist_mean = 0.0438 dist_std = 0.1669 vf_loss = 0.2755 grad_norm = 2.4741 nat_grad_norm = 0.0876 cg_residual = 0.4725 step_size = 0.5334 reward = 0.0000 fps = 6 mse_loss = 1.8996 
2022-05-01 07:45:52.939442 - gail/main.py:164 - [TRPO] iter = 804000 dist_mean = 0.0225 dist_std = 0.1672 vf_loss = 0.0402 grad_norm = 3.0287 nat_grad_norm = 0.1180 cg_residual = 2.0430 step_size = 0.4138 reward = 0.0000 fps = 5 mse_loss = 1.8486 
2022-05-01 07:46:03.085572 - gail/main.py:164 - [TRPO] iter = 805000 dist_mean = 0.0478 dist_std = 0.1672 vf_loss = 0.0503 grad_norm = 2.4818 nat_grad_norm = 0.0953 cg_residual = 1.5134 step_size = 0.4766 reward = -0.0000 fps = 5 mse_loss = 1.9388 
2022-05-01 07:46:03.287597 - gail/main.py:191 - [Discriminator] iter = 805000 loss = -0.5239 grad_norm = 2.5096 grad_penalty = 0.0527 regularization = 0.0000 true_logits = 0.2286 fake_logits = -0.3480 true_prob = 0.5546 fake_prob = 0.4256 
2022-05-01 07:48:18.000472 - gail/main.py:132 - [Evaluate] iter = 805000 episode={ returns = 3424.2078 lengths = 960 } discounted_episode={ returns = 2202.3201 lengths = 1000 } 
2022-05-01 07:48:27.864503 - gail/main.py:164 - [TRPO] iter = 806000 dist_mean = 0.0076 dist_std = 0.1672 vf_loss = 0.0364 grad_norm = 3.0792 nat_grad_norm = 0.0844 cg_residual = 1.1005 step_size = 0.4553 reward = -0.0000 fps = 6 mse_loss = 1.9041 
2022-05-01 07:48:37.900837 - gail/main.py:164 - [TRPO] iter = 807000 dist_mean = 0.0283 dist_std = 0.1672 vf_loss = 0.1100 grad_norm = 2.7960 nat_grad_norm = 0.1175 cg_residual = 1.5488 step_size = 0.4689 reward = 0.0000 fps = 6 mse_loss = 1.8985 
2022-05-01 07:48:48.049841 - gail/main.py:164 - [TRPO] iter = 808000 dist_mean = 0.0288 dist_std = 0.1668 vf_loss = 0.0859 grad_norm = 2.5955 nat_grad_norm = 0.0741 cg_residual = 0.8242 step_size = 0.4977 reward = -0.0000 fps = 6 mse_loss = 1.9121 
2022-05-01 07:48:57.845459 - gail/main.py:164 - [TRPO] iter = 809000 dist_mean = 0.0203 dist_std = 0.1668 vf_loss = 0.1081 grad_norm = 2.7140 nat_grad_norm = 0.0810 cg_residual = 0.8850 step_size = 0.5536 reward = -0.0000 fps = 5 mse_loss = 1.9452 
2022-05-01 07:49:07.855915 - gail/main.py:164 - [TRPO] iter = 810000 dist_mean = 0.0157 dist_std = 0.1668 vf_loss = 0.1252 grad_norm = 3.2078 nat_grad_norm = 0.0924 cg_residual = 1.3147 step_size = 0.4410 reward = -0.0000 fps = 5 mse_loss = 1.9201 
2022-05-01 07:49:08.087867 - gail/main.py:191 - [Discriminator] iter = 810000 loss = -0.4923 grad_norm = 2.6309 grad_penalty = 0.0526 regularization = 0.0000 true_logits = 0.2252 fake_logits = -0.3197 true_prob = 0.5528 fake_prob = 0.4304 
2022-05-01 07:51:02.824122 - gail/main.py:132 - [Evaluate] iter = 810000 episode={ returns = 3203.4027 lengths = 905 } discounted_episode={ returns = 1715.1213 lengths = 772 } 
2022-05-01 07:51:12.884724 - gail/main.py:164 - [TRPO] iter = 811000 dist_mean = 0.0189 dist_std = 0.1664 vf_loss = 0.2170 grad_norm = 3.3240 nat_grad_norm = 0.0888 cg_residual = 1.3324 step_size = 0.4943 reward = -0.0000 fps = 8 mse_loss = 1.8860 
2022-05-01 07:51:22.908337 - gail/main.py:164 - [TRPO] iter = 812000 dist_mean = 0.0093 dist_std = 0.1661 vf_loss = 0.1329 grad_norm = 2.5458 nat_grad_norm = 0.0771 cg_residual = 1.0671 step_size = 0.4805 reward = -0.0000 fps = 7 mse_loss = 2.0227 
2022-05-01 07:51:32.511354 - gail/main.py:164 - [TRPO] iter = 813000 dist_mean = 0.0161 dist_std = 0.1664 vf_loss = 0.0413 grad_norm = 2.5412 nat_grad_norm = 0.1245 cg_residual = 1.7459 step_size = 0.3944 reward = 0.0000 fps = 6 mse_loss = 2.0363 
2022-05-01 07:51:42.054693 - gail/main.py:164 - [TRPO] iter = 814000 dist_mean = 0.0148 dist_std = 0.1663 vf_loss = 0.1350 grad_norm = 2.7545 nat_grad_norm = 0.0723 cg_residual = 0.9551 step_size = 0.5254 reward = 0.0000 fps = 6 mse_loss = 1.9622 
2022-05-01 07:51:51.949360 - gail/main.py:164 - [TRPO] iter = 815000 dist_mean = 0.0180 dist_std = 0.1661 vf_loss = 0.0495 grad_norm = 2.7794 nat_grad_norm = 0.0898 cg_residual = 1.8745 step_size = 0.4619 reward = -0.0000 fps = 6 mse_loss = 1.9252 
2022-05-01 07:51:52.180861 - gail/main.py:191 - [Discriminator] iter = 815000 loss = -0.4870 grad_norm = 2.2132 grad_penalty = 0.0471 regularization = 0.0000 true_logits = 0.3046 fake_logits = -0.2294 true_prob = 0.5697 fake_prob = 0.4499 
2022-05-01 07:54:02.505878 - gail/main.py:132 - [Evaluate] iter = 815000 episode={ returns = 3563.3784 lengths = 1000 } discounted_episode={ returns = 2088.5518 lengths = 925 } 
2022-05-01 07:54:12.576944 - gail/main.py:164 - [TRPO] iter = 816000 dist_mean = 0.0378 dist_std = 0.1660 vf_loss = 0.0362 grad_norm = 2.0264 nat_grad_norm = 0.0847 cg_residual = 1.2014 step_size = 0.5610 reward = -0.0000 fps = 7 mse_loss = 1.9795 
2022-05-01 07:54:22.607134 - gail/main.py:164 - [TRPO] iter = 817000 dist_mean = 0.0247 dist_std = 0.1657 vf_loss = 0.1736 grad_norm = 2.1072 nat_grad_norm = 0.0943 cg_residual = 1.5976 step_size = 0.5331 reward = -0.0000 fps = 6 mse_loss = 1.9217 
2022-05-01 07:54:32.377277 - gail/main.py:164 - [TRPO] iter = 818000 dist_mean = 0.0136 dist_std = 0.1656 vf_loss = 0.1666 grad_norm = 2.5455 nat_grad_norm = 0.0999 cg_residual = 1.2985 step_size = 0.4156 reward = 0.0000 fps = 6 mse_loss = 1.9135 
2022-05-01 07:54:42.479080 - gail/main.py:164 - [TRPO] iter = 819000 dist_mean = 0.0231 dist_std = 0.1653 vf_loss = 0.0242 grad_norm = 3.4162 nat_grad_norm = 0.1127 cg_residual = 1.5620 step_size = 0.4035 reward = 0.0000 fps = 5 mse_loss = 1.9121 
2022-05-01 07:54:52.312407 - gail/main.py:164 - [TRPO] iter = 820000 dist_mean = 0.0377 dist_std = 0.1656 vf_loss = 0.1191 grad_norm = 2.6215 nat_grad_norm = 0.1376 cg_residual = 2.1281 step_size = 0.3634 reward = 0.0000 fps = 5 mse_loss = 1.8959 
2022-05-01 07:54:52.519363 - gail/main.py:191 - [Discriminator] iter = 820000 loss = -0.6306 grad_norm = 2.8572 grad_penalty = 0.0526 regularization = 0.0000 true_logits = 0.3676 fake_logits = -0.3156 true_prob = 0.5836 fake_prob = 0.4321 
2022-05-01 07:56:54.452897 - gail/main.py:132 - [Evaluate] iter = 820000 episode={ returns = 3074.3698 lengths = 868 } discounted_episode={ returns = 2038.6367 lengths = 914 } 
2022-05-01 07:57:04.255890 - gail/main.py:164 - [TRPO] iter = 821000 dist_mean = 0.0080 dist_std = 0.1649 vf_loss = 0.0580 grad_norm = 2.8532 nat_grad_norm = 0.0746 cg_residual = 1.0053 step_size = 0.5338 reward = 0.0000 fps = 7 mse_loss = 1.8450 
2022-05-01 07:57:14.444282 - gail/main.py:164 - [TRPO] iter = 822000 dist_mean = 0.0411 dist_std = 0.1647 vf_loss = 0.0999 grad_norm = 2.7520 nat_grad_norm = 0.0786 cg_residual = 1.4311 step_size = 0.5518 reward = 0.0000 fps = 7 mse_loss = 1.8450 
2022-05-01 07:57:24.468844 - gail/main.py:164 - [TRPO] iter = 823000 dist_mean = 0.0252 dist_std = 0.1647 vf_loss = 0.0320 grad_norm = 3.2560 nat_grad_norm = 0.0872 cg_residual = 1.2196 step_size = 0.4343 reward = -0.0000 fps = 6 mse_loss = 1.8169 
2022-05-01 07:57:34.593337 - gail/main.py:164 - [TRPO] iter = 824000 dist_mean = 0.0346 dist_std = 0.1651 vf_loss = 0.0257 grad_norm = 3.5368 nat_grad_norm = 0.0749 cg_residual = 1.3258 step_size = 0.4845 reward = -0.0000 fps = 6 mse_loss = 1.9336 
2022-05-01 07:57:44.701800 - gail/main.py:164 - [TRPO] iter = 825000 dist_mean = 0.0523 dist_std = 0.1649 vf_loss = 0.0439 grad_norm = 3.6682 nat_grad_norm = 0.0915 cg_residual = 1.5266 step_size = 0.4690 reward = -0.0000 fps = 5 mse_loss = 1.9133 
2022-05-01 07:57:44.902149 - gail/main.py:191 - [Discriminator] iter = 825000 loss = -0.5318 grad_norm = 3.2348 grad_penalty = 0.0555 regularization = 0.0000 true_logits = 0.3666 fake_logits = -0.2207 true_prob = 0.5837 fake_prob = 0.4522 
2022-05-01 08:00:01.832765 - gail/main.py:132 - [Evaluate] iter = 825000 episode={ returns = 3579.1727 lengths = 1000 } discounted_episode={ returns = 2196.6009 lengths = 1000 } 
2022-05-01 08:00:11.869180 - gail/main.py:164 - [TRPO] iter = 826000 dist_mean = 0.0084 dist_std = 0.1644 vf_loss = 0.3679 grad_norm = 4.5251 nat_grad_norm = 0.1322 cg_residual = 3.2495 step_size = 0.2691 reward = 0.0000 fps = 6 mse_loss = 1.9646 
2022-05-01 08:00:21.862044 - gail/main.py:164 - [TRPO] iter = 827000 dist_mean = 0.0563 dist_std = 0.1644 vf_loss = 0.6740 grad_norm = 2.5428 nat_grad_norm = 0.1096 cg_residual = 0.6869 step_size = 0.4173 reward = 0.0000 fps = 6 mse_loss = 1.9317 
2022-05-01 08:00:31.802335 - gail/main.py:164 - [TRPO] iter = 828000 dist_mean = 0.0298 dist_std = 0.1641 vf_loss = 0.0350 grad_norm = 3.1255 nat_grad_norm = 0.1536 cg_residual = 2.4747 step_size = 0.3033 reward = -0.0000 fps = 5 mse_loss = 1.8344 
2022-05-01 08:00:42.405112 - gail/main.py:164 - [TRPO] iter = 829000 dist_mean = 0.4569 dist_std = 0.1645 vf_loss = 0.3163 grad_norm = 3.2588 nat_grad_norm = 0.0929 cg_residual = 0.2909 step_size = 0.3983 reward = 0.0000 fps = 5 mse_loss = 1.9355 
2022-05-01 08:00:52.168907 - gail/main.py:164 - [TRPO] iter = 830000 dist_mean = 0.1903 dist_std = 0.1647 vf_loss = 0.2700 grad_norm = 2.7270 nat_grad_norm = 0.1151 cg_residual = 1.1498 step_size = 0.4401 reward = 0.0000 fps = 5 mse_loss = 1.8818 
2022-05-01 08:00:52.375779 - gail/main.py:191 - [Discriminator] iter = 830000 loss = -1.1771 grad_norm = 3.2332 grad_penalty = 0.1020 regularization = 0.0000 true_logits = 0.2922 fake_logits = -0.9869 true_prob = 0.5682 fake_prob = 0.3133 
2022-05-01 08:00:55.656677 - gail/main.py:132 - [Evaluate] iter = 830000 episode={ returns = 38.5373 lengths = 22 } discounted_episode={ returns = 38.0763 lengths = 22 } 
2022-05-01 08:01:05.799101 - gail/main.py:164 - [TRPO] iter = 831000 dist_mean = 0.2652 dist_std = 0.1641 vf_loss = 0.6202 grad_norm = 2.1105 nat_grad_norm = 0.0885 cg_residual = 1.5492 step_size = 0.5470 reward = 0.0000 fps = 74 mse_loss = 1.7994 
2022-05-01 08:01:15.918715 - gail/main.py:164 - [TRPO] iter = 832000 dist_mean = 0.1383 dist_std = 0.1647 vf_loss = 0.2266 grad_norm = 2.6910 nat_grad_norm = 0.1050 cg_residual = 1.3356 step_size = 0.4355 reward = 0.0000 fps = 42 mse_loss = 1.8985 
2022-05-01 08:01:25.974269 - gail/main.py:164 - [TRPO] iter = 833000 dist_mean = 0.2155 dist_std = 0.1649 vf_loss = 0.1467 grad_norm = 2.7651 nat_grad_norm = 0.0999 cg_residual = 0.7697 step_size = 0.4583 reward = -0.0000 fps = 29 mse_loss = 1.9599 
2022-05-01 08:01:36.176617 - gail/main.py:164 - [TRPO] iter = 834000 dist_mean = 0.3496 dist_std = 0.1645 vf_loss = 0.1660 grad_norm = 3.0566 nat_grad_norm = 0.1199 cg_residual = 4.1872 step_size = 0.3526 reward = -0.0000 fps = 22 mse_loss = 1.8924 
2022-05-01 08:01:46.302129 - gail/main.py:164 - [TRPO] iter = 835000 dist_mean = 0.4812 dist_std = 0.1643 vf_loss = 0.0588 grad_norm = 2.8815 nat_grad_norm = 0.0489 cg_residual = 0.2442 step_size = 0.6969 reward = 0.0000 fps = 18 mse_loss = 1.8648 
2022-05-01 08:01:46.528431 - gail/main.py:191 - [Discriminator] iter = 835000 loss = -3.0516 grad_norm = 3.9724 grad_penalty = 0.2842 regularization = 0.0000 true_logits = 0.0894 fake_logits = -3.2464 true_prob = 0.5257 fake_prob = 0.0439 
2022-05-01 08:01:49.799715 - gail/main.py:132 - [Evaluate] iter = 835000 episode={ returns = 38.5150 lengths = 22 } discounted_episode={ returns = 37.4520 lengths = 22 } 
2022-05-01 08:01:59.989642 - gail/main.py:164 - [TRPO] iter = 836000 dist_mean = 0.2023 dist_std = 0.1640 vf_loss = 0.3774 grad_norm = 2.5534 nat_grad_norm = 0.1026 cg_residual = 1.1099 step_size = 0.4824 reward = -0.0000 fps = 74 mse_loss = 1.8932 
2022-05-01 08:02:10.268291 - gail/main.py:164 - [TRPO] iter = 837000 dist_mean = 0.1971 dist_std = 0.1640 vf_loss = 0.8935 grad_norm = 3.6458 nat_grad_norm = 0.1177 cg_residual = 1.5149 step_size = 0.3776 reward = -0.0000 fps = 42 mse_loss = 1.8223 
2022-05-01 08:02:20.263452 - gail/main.py:164 - [TRPO] iter = 838000 dist_mean = 0.0359 dist_std = 0.1642 vf_loss = 1.3176 grad_norm = 2.6876 nat_grad_norm = 0.0648 cg_residual = 1.1449 step_size = 0.5512 reward = 0.0000 fps = 29 mse_loss = 1.7426 
2022-05-01 08:02:30.082184 - gail/main.py:164 - [TRPO] iter = 839000 dist_mean = 0.1502 dist_std = 0.1643 vf_loss = 0.5567 grad_norm = 3.4895 nat_grad_norm = 0.1157 cg_residual = 3.3162 step_size = 0.3754 reward = 0.0000 fps = 22 mse_loss = 1.8263 
2022-05-01 08:02:40.095042 - gail/main.py:164 - [TRPO] iter = 840000 dist_mean = 0.0699 dist_std = 0.1641 vf_loss = 0.4858 grad_norm = 2.6885 nat_grad_norm = 0.0894 cg_residual = 1.6656 step_size = 0.4361 reward = 0.0000 fps = 18 mse_loss = 1.7642 
2022-05-01 08:02:40.373365 - gail/main.py:191 - [Discriminator] iter = 840000 loss = -0.5803 grad_norm = 3.1153 grad_penalty = 0.1085 regularization = 0.0000 true_logits = -0.0331 fake_logits = -0.7219 true_prob = 0.4989 fake_prob = 0.3686 
2022-05-01 08:02:58.807750 - gail/main.py:132 - [Evaluate] iter = 840000 episode={ returns = 491.4745 lengths = 163 } discounted_episode={ returns = 253.4532 lengths = 102 } 
2022-05-01 08:03:09.231087 - gail/main.py:164 - [TRPO] iter = 841000 dist_mean = 0.0635 dist_std = 0.1644 vf_loss = 0.8892 grad_norm = 3.0097 nat_grad_norm = 0.1060 cg_residual = 1.8404 step_size = 0.4009 reward = -0.0000 fps = 34 mse_loss = 1.8106 
2022-05-01 08:03:19.403076 - gail/main.py:164 - [TRPO] iter = 842000 dist_mean = 0.1793 dist_std = 0.1642 vf_loss = 0.2979 grad_norm = 4.0856 nat_grad_norm = 0.1118 cg_residual = 1.1548 step_size = 0.4098 reward = 0.0000 fps = 25 mse_loss = 1.8164 
2022-05-01 08:03:29.400355 - gail/main.py:164 - [TRPO] iter = 843000 dist_mean = 0.1321 dist_std = 0.1641 vf_loss = 1.0178 grad_norm = 3.1933 nat_grad_norm = 0.1055 cg_residual = 0.8898 step_size = 0.4073 reward = 0.0000 fps = 20 mse_loss = 1.7868 
2022-05-01 08:03:39.470586 - gail/main.py:164 - [TRPO] iter = 844000 dist_mean = 0.0967 dist_std = 0.1641 vf_loss = 0.5559 grad_norm = 2.5898 nat_grad_norm = 0.0869 cg_residual = 0.8637 step_size = 0.5177 reward = -0.0000 fps = 16 mse_loss = 1.7958 
2022-05-01 08:03:49.138089 - gail/main.py:164 - [TRPO] iter = 845000 dist_mean = 0.0538 dist_std = 0.1643 vf_loss = 0.1120 grad_norm = 2.9054 nat_grad_norm = 0.0877 cg_residual = 1.1971 step_size = 0.4647 reward = 0.0000 fps = 14 mse_loss = 1.7679 
2022-05-01 08:03:49.353857 - gail/main.py:191 - [Discriminator] iter = 845000 loss = -0.6063 grad_norm = 3.1618 grad_penalty = 0.0726 regularization = 0.0000 true_logits = 0.0160 fake_logits = -0.6629 true_prob = 0.5042 fake_prob = 0.3716 
2022-05-01 08:05:06.201713 - gail/main.py:132 - [Evaluate] iter = 845000 episode={ returns = 2289.6910 lengths = 658 } discounted_episode={ returns = 1098.3072 lengths = 460 } 
2022-05-01 08:05:16.683717 - gail/main.py:164 - [TRPO] iter = 846000 dist_mean = 0.0272 dist_std = 0.1647 vf_loss = 0.2633 grad_norm = 2.9302 nat_grad_norm = 0.0839 cg_residual = 1.9048 step_size = 0.4382 reward = 0.0000 fps = 11 mse_loss = 1.8825 
2022-05-01 08:05:26.844715 - gail/main.py:164 - [TRPO] iter = 847000 dist_mean = 0.0585 dist_std = 0.1644 vf_loss = 0.5398 grad_norm = 3.0868 nat_grad_norm = 0.0741 cg_residual = 0.5739 step_size = 0.5226 reward = -0.0000 fps = 10 mse_loss = 1.8599 
2022-05-01 08:05:37.134600 - gail/main.py:164 - [TRPO] iter = 848000 dist_mean = 0.0965 dist_std = 0.1643 vf_loss = 0.2180 grad_norm = 3.1459 nat_grad_norm = 0.1244 cg_residual = 2.0072 step_size = 0.3807 reward = 0.0000 fps = 9 mse_loss = 1.8197 
2022-05-01 08:05:47.371450 - gail/main.py:164 - [TRPO] iter = 849000 dist_mean = 0.0461 dist_std = 0.1642 vf_loss = 0.3454 grad_norm = 2.8681 nat_grad_norm = 0.1417 cg_residual = 2.5077 step_size = 0.3366 reward = -0.0000 fps = 8 mse_loss = 1.7506 
2022-05-01 08:05:57.873572 - gail/main.py:164 - [TRPO] iter = 850000 dist_mean = 0.0606 dist_std = 0.1640 vf_loss = 0.1684 grad_norm = 2.9826 nat_grad_norm = 0.1113 cg_residual = 1.0104 step_size = 0.4289 reward = -0.0000 fps = 7 mse_loss = 1.7347 
2022-05-01 08:05:58.123088 - gail/main.py:191 - [Discriminator] iter = 850000 loss = -0.7431 grad_norm = 3.0340 grad_penalty = 0.0682 regularization = 0.0000 true_logits = 0.0146 fake_logits = -0.7966 true_prob = 0.5077 fake_prob = 0.3467 
2022-05-01 08:07:54.070074 - gail/main.py:132 - [Evaluate] iter = 850000 episode={ returns = 3141.6788 lengths = 885 } discounted_episode={ returns = 1886.9120 lengths = 838 } 
2022-05-01 08:08:04.098323 - gail/main.py:164 - [TRPO] iter = 851000 dist_mean = 0.0406 dist_std = 0.1640 vf_loss = 0.1087 grad_norm = 2.7209 nat_grad_norm = 0.0995 cg_residual = 1.4489 step_size = 0.4586 reward = 0.0000 fps = 7 mse_loss = 1.7673 
2022-05-01 08:08:14.003771 - gail/main.py:164 - [TRPO] iter = 852000 dist_mean = 0.1073 dist_std = 0.1645 vf_loss = 0.3463 grad_norm = 3.6602 nat_grad_norm = 0.0922 cg_residual = 0.8417 step_size = 0.3947 reward = -0.0000 fps = 7 mse_loss = 1.8795 
2022-05-01 08:08:23.643167 - gail/main.py:164 - [TRPO] iter = 853000 dist_mean = 0.0530 dist_std = 0.1646 vf_loss = 0.1648 grad_norm = 2.9653 nat_grad_norm = 0.1215 cg_residual = 1.7334 step_size = 0.4249 reward = -0.0000 fps = 6 mse_loss = 1.6976 
2022-05-01 08:08:33.494148 - gail/main.py:164 - [TRPO] iter = 854000 dist_mean = 0.0594 dist_std = 0.1648 vf_loss = 0.4635 grad_norm = 2.5045 nat_grad_norm = 0.0594 cg_residual = 0.5436 step_size = 0.6220 reward = -0.0000 fps = 6 mse_loss = 1.8328 
2022-05-01 08:08:43.236909 - gail/main.py:164 - [TRPO] iter = 855000 dist_mean = 0.0524 dist_std = 0.1647 vf_loss = 0.1103 grad_norm = 2.0910 nat_grad_norm = 0.0868 cg_residual = 1.3583 step_size = 0.5045 reward = -0.0000 fps = 6 mse_loss = 1.7830 
2022-05-01 08:08:43.528122 - gail/main.py:191 - [Discriminator] iter = 855000 loss = -0.4526 grad_norm = 3.0228 grad_penalty = 0.0588 regularization = 0.0000 true_logits = 0.0514 fake_logits = -0.4600 true_prob = 0.5144 fake_prob = 0.4058 
2022-05-01 08:08:46.655928 - gail/main.py:132 - [Evaluate] iter = 855000 episode={ returns = 38.4633 lengths = 22 } discounted_episode={ returns = 37.8304 lengths = 22 } 
2022-05-01 08:08:56.430674 - gail/main.py:164 - [TRPO] iter = 856000 dist_mean = 0.0095 dist_std = 0.1644 vf_loss = 0.0699 grad_norm = 2.5376 nat_grad_norm = 0.0984 cg_residual = 1.7724 step_size = 0.4795 reward = -0.0000 fps = 77 mse_loss = 1.7445 
2022-05-01 08:09:06.351027 - gail/main.py:164 - [TRPO] iter = 857000 dist_mean = 0.0485 dist_std = 0.1642 vf_loss = 0.2166 grad_norm = 3.3139 nat_grad_norm = 0.1054 cg_residual = 0.9981 step_size = 0.3968 reward = 0.0000 fps = 43 mse_loss = 1.8158 
2022-05-01 08:09:16.570138 - gail/main.py:164 - [TRPO] iter = 858000 dist_mean = 0.3967 dist_std = 0.1644 vf_loss = 0.2306 grad_norm = 2.5744 nat_grad_norm = 0.0828 cg_residual = 0.5927 step_size = 0.6040 reward = 0.0000 fps = 30 mse_loss = 1.7458 
2022-05-01 08:09:26.157839 - gail/main.py:164 - [TRPO] iter = 859000 dist_mean = 0.1649 dist_std = 0.1644 vf_loss = 0.1818 grad_norm = 2.8394 nat_grad_norm = 0.1036 cg_residual = 0.8660 step_size = 0.4955 reward = -0.0000 fps = 23 mse_loss = 1.7327 
2022-05-01 08:09:35.729425 - gail/main.py:164 - [TRPO] iter = 860000 dist_mean = 0.0138 dist_std = 0.1644 vf_loss = 0.1219 grad_norm = 3.3467 nat_grad_norm = 0.0979 cg_residual = 1.1794 step_size = 0.4358 reward = 0.0000 fps = 19 mse_loss = 1.7654 
2022-05-01 08:09:35.932643 - gail/main.py:191 - [Discriminator] iter = 860000 loss = -0.4807 grad_norm = 3.0862 grad_penalty = 0.0565 regularization = 0.0000 true_logits = 0.1606 fake_logits = -0.3766 true_prob = 0.5374 fake_prob = 0.4231 
2022-05-01 08:09:45.370507 - gail/main.py:132 - [Evaluate] iter = 860000 episode={ returns = 38.7064 lengths = 22 } discounted_episode={ returns = 256.5266 lengths = 120 } 
2022-05-01 08:09:55.177941 - gail/main.py:164 - [TRPO] iter = 861000 dist_mean = 0.1208 dist_std = 0.1642 vf_loss = 0.1057 grad_norm = 2.9926 nat_grad_norm = 0.1009 cg_residual = 0.8891 step_size = 0.4944 reward = -0.0000 fps = 52 mse_loss = 1.7199 
2022-05-01 08:10:05.164872 - gail/main.py:164 - [TRPO] iter = 862000 dist_mean = 0.0804 dist_std = 0.1639 vf_loss = 0.6778 grad_norm = 1.8544 nat_grad_norm = 0.0789 cg_residual = 0.5767 step_size = 0.6414 reward = -0.0000 fps = 34 mse_loss = 1.7464 
2022-05-01 08:10:15.053373 - gail/main.py:164 - [TRPO] iter = 863000 dist_mean = 0.0711 dist_std = 0.1640 vf_loss = 0.0929 grad_norm = 3.1317 nat_grad_norm = 0.1212 cg_residual = 2.2091 step_size = 0.3662 reward = -0.0000 fps = 25 mse_loss = 1.6134 
2022-05-01 08:10:24.942384 - gail/main.py:164 - [TRPO] iter = 864000 dist_mean = 0.1881 dist_std = 0.1642 vf_loss = 0.0926 grad_norm = 3.0794 nat_grad_norm = 0.0971 cg_residual = 1.1497 step_size = 0.4452 reward = 0.0000 fps = 20 mse_loss = 1.7811 
2022-05-01 08:10:34.874707 - gail/main.py:164 - [TRPO] iter = 865000 dist_mean = 0.0623 dist_std = 0.1646 vf_loss = 0.1037 grad_norm = 3.2453 nat_grad_norm = 0.0900 cg_residual = 1.2424 step_size = 0.4497 reward = 0.0000 fps = 16 mse_loss = 1.6983 
2022-05-01 08:10:35.033058 - gail/main.py:191 - [Discriminator] iter = 865000 loss = -0.6130 grad_norm = 2.7644 grad_penalty = 0.0583 regularization = 0.0000 true_logits = 0.1325 fake_logits = -0.5388 true_prob = 0.5323 fake_prob = 0.3909 
2022-05-01 08:11:47.764113 - gail/main.py:132 - [Evaluate] iter = 865000 episode={ returns = 1670.6169 lengths = 475 } discounted_episode={ returns = 1285.3765 lengths = 571 } 
2022-05-01 08:11:57.811130 - gail/main.py:164 - [TRPO] iter = 866000 dist_mean = 0.0623 dist_std = 0.1649 vf_loss = 0.0480 grad_norm = 3.7619 nat_grad_norm = 0.0875 cg_residual = 1.3684 step_size = 0.4545 reward = 0.0000 fps = 12 mse_loss = 1.7325 
2022-05-01 08:12:08.419832 - gail/main.py:164 - [TRPO] iter = 867000 dist_mean = 0.0393 dist_std = 0.1655 vf_loss = 0.0806 grad_norm = 2.7968 nat_grad_norm = 0.1053 cg_residual = 2.8367 step_size = 0.4246 reward = -0.0000 fps = 10 mse_loss = 1.7091 
2022-05-01 08:12:18.489028 - gail/main.py:164 - [TRPO] iter = 868000 dist_mean = 0.0565 dist_std = 0.1649 vf_loss = 0.0795 grad_norm = 2.3309 nat_grad_norm = 0.0934 cg_residual = 1.4458 step_size = 0.4632 reward = 0.0000 fps = 9 mse_loss = 1.6679 
2022-05-01 08:12:28.519296 - gail/main.py:164 - [TRPO] iter = 869000 dist_mean = 0.0755 dist_std = 0.1644 vf_loss = 0.4870 grad_norm = 2.9183 nat_grad_norm = 0.0938 cg_residual = 1.5705 step_size = 0.4281 reward = -0.0000 fps = 8 mse_loss = 1.6752 
2022-05-01 08:12:38.990147 - gail/main.py:164 - [TRPO] iter = 870000 dist_mean = 0.0503 dist_std = 0.1640 vf_loss = 0.4129 grad_norm = 2.6541 nat_grad_norm = 0.0927 cg_residual = 0.4577 step_size = 0.4920 reward = 0.0000 fps = 8 mse_loss = 1.6316 
2022-05-01 08:12:39.213994 - gail/main.py:191 - [Discriminator] iter = 870000 loss = -0.5603 grad_norm = 2.4327 grad_penalty = 0.0518 regularization = 0.0000 true_logits = 0.1395 fake_logits = -0.4726 true_prob = 0.5336 fake_prob = 0.4044 
2022-05-01 08:14:49.877084 - gail/main.py:132 - [Evaluate] iter = 870000 episode={ returns = 3452.5509 lengths = 970 } discounted_episode={ returns = 2050.2133 lengths = 938 } 
2022-05-01 08:15:00.127587 - gail/main.py:164 - [TRPO] iter = 871000 dist_mean = 0.0488 dist_std = 0.1639 vf_loss = 0.2141 grad_norm = 4.0103 nat_grad_norm = 0.1181 cg_residual = 1.7901 step_size = 0.4193 reward = 0.0000 fps = 7 mse_loss = 1.6924 
2022-05-01 08:15:10.331267 - gail/main.py:164 - [TRPO] iter = 872000 dist_mean = 0.0440 dist_std = 0.1642 vf_loss = 0.2030 grad_norm = 2.5772 nat_grad_norm = 0.0787 cg_residual = 0.8256 step_size = 0.4793 reward = -0.0000 fps = 6 mse_loss = 1.6224 
2022-05-01 08:15:20.366992 - gail/main.py:164 - [TRPO] iter = 873000 dist_mean = 0.0752 dist_std = 0.1639 vf_loss = 0.1308 grad_norm = 2.8830 nat_grad_norm = 0.1022 cg_residual = 1.0981 step_size = 0.4119 reward = 0.0000 fps = 6 mse_loss = 1.6129 
2022-05-01 08:15:30.372244 - gail/main.py:164 - [TRPO] iter = 874000 dist_mean = 0.0664 dist_std = 0.1637 vf_loss = 0.1052 grad_norm = 2.1541 nat_grad_norm = 0.1136 cg_residual = 0.9038 step_size = 0.4159 reward = -0.0000 fps = 5 mse_loss = 1.6617 
2022-05-01 08:15:40.213675 - gail/main.py:164 - [TRPO] iter = 875000 dist_mean = 0.0278 dist_std = 0.1640 vf_loss = 0.0475 grad_norm = 2.6310 nat_grad_norm = 0.1068 cg_residual = 2.5296 step_size = 0.4566 reward = 0.0000 fps = 5 mse_loss = 1.5857 
2022-05-01 08:15:40.438822 - gail/main.py:191 - [Discriminator] iter = 875000 loss = -0.5665 grad_norm = 2.6612 grad_penalty = 0.0499 regularization = 0.0000 true_logits = 0.2240 fake_logits = -0.3923 true_prob = 0.5513 fake_prob = 0.4161 
2022-05-01 08:15:43.670064 - gail/main.py:132 - [Evaluate] iter = 875000 episode={ returns = 38.2589 lengths = 22 } discounted_episode={ returns = 37.5031 lengths = 22 } 
2022-05-01 08:15:53.842579 - gail/main.py:164 - [TRPO] iter = 876000 dist_mean = 0.0713 dist_std = 0.1642 vf_loss = 0.2699 grad_norm = 2.8874 nat_grad_norm = 0.0672 cg_residual = 1.1665 step_size = 0.4915 reward = -0.0000 fps = 74 mse_loss = 1.5847 
2022-05-01 08:16:03.782157 - gail/main.py:164 - [TRPO] iter = 877000 dist_mean = 0.1076 dist_std = 0.1646 vf_loss = 0.0978 grad_norm = 4.0122 nat_grad_norm = 0.1062 cg_residual = 1.4461 step_size = 0.3788 reward = -0.0000 fps = 42 mse_loss = 1.4386 
2022-05-01 08:16:13.338897 - gail/main.py:164 - [TRPO] iter = 878000 dist_mean = 0.1619 dist_std = 0.1644 vf_loss = 0.5676 grad_norm = 2.7644 nat_grad_norm = 0.0898 cg_residual = 1.1030 step_size = 0.4911 reward = 0.0000 fps = 30 mse_loss = 1.6369 
2022-05-01 08:16:23.580049 - gail/main.py:164 - [TRPO] iter = 879000 dist_mean = 0.0570 dist_std = 0.1644 vf_loss = 0.2074 grad_norm = 2.6869 nat_grad_norm = 0.0751 cg_residual = 0.9309 step_size = 0.5055 reward = -0.0000 fps = 23 mse_loss = 1.5418 
2022-05-01 08:16:33.540236 - gail/main.py:164 - [TRPO] iter = 880000 dist_mean = 0.1949 dist_std = 0.1648 vf_loss = 0.0731 grad_norm = 2.1942 nat_grad_norm = 0.0993 cg_residual = 0.8771 step_size = 0.4799 reward = 0.0000 fps = 18 mse_loss = 1.6426 
2022-05-01 08:16:33.759395 - gail/main.py:191 - [Discriminator] iter = 880000 loss = -1.4636 grad_norm = 3.7394 grad_penalty = 0.1022 regularization = 0.0000 true_logits = 0.1455 fake_logits = -1.4203 true_prob = 0.5349 fake_prob = 0.2777 
2022-05-01 08:16:36.921618 - gail/main.py:132 - [Evaluate] iter = 880000 episode={ returns = 38.0780 lengths = 22 } discounted_episode={ returns = 37.6044 lengths = 22 } 
2022-05-01 08:16:46.424781 - gail/main.py:164 - [TRPO] iter = 881000 dist_mean = 0.0389 dist_std = 0.1645 vf_loss = 0.0730 grad_norm = 2.9825 nat_grad_norm = 0.0806 cg_residual = 1.0285 step_size = 0.4934 reward = -0.0000 fps = 79 mse_loss = 1.5223 
2022-05-01 08:16:56.696944 - gail/main.py:164 - [TRPO] iter = 882000 dist_mean = 0.2133 dist_std = 0.1652 vf_loss = 0.4108 grad_norm = 3.0962 nat_grad_norm = 0.0797 cg_residual = 1.0303 step_size = 0.4552 reward = -0.0000 fps = 43 mse_loss = 1.5384 
2022-05-01 08:17:06.852812 - gail/main.py:164 - [TRPO] iter = 883000 dist_mean = 0.1237 dist_std = 0.1653 vf_loss = 0.1035 grad_norm = 4.4377 nat_grad_norm = 0.0935 cg_residual = 0.8065 step_size = 0.4068 reward = -0.0000 fps = 30 mse_loss = 1.5840 
2022-05-01 08:17:16.413178 - gail/main.py:164 - [TRPO] iter = 884000 dist_mean = 0.0732 dist_std = 0.1654 vf_loss = 0.5233 grad_norm = 3.4288 nat_grad_norm = 0.0775 cg_residual = 0.9566 step_size = 0.5493 reward = 0.0000 fps = 23 mse_loss = 1.5630 
2022-05-01 08:17:26.009135 - gail/main.py:164 - [TRPO] iter = 885000 dist_mean = 0.0865 dist_std = 0.1652 vf_loss = 0.7063 grad_norm = 2.1334 nat_grad_norm = 0.0450 cg_residual = 0.3700 step_size = 0.8690 reward = -0.0000 fps = 19 mse_loss = 1.5231 
2022-05-01 08:17:26.220756 - gail/main.py:191 - [Discriminator] iter = 885000 loss = -0.6459 grad_norm = 3.3997 grad_penalty = 0.0802 regularization = 0.0000 true_logits = 0.1427 fake_logits = -0.5834 true_prob = 0.5343 fake_prob = 0.4022 
2022-05-01 08:17:29.031724 - gail/main.py:132 - [Evaluate] iter = 885000 episode={ returns = 37.8878 lengths = 22 } discounted_episode={ returns = 37.3521 lengths = 22 } 
2022-05-01 08:17:39.508371 - gail/main.py:164 - [TRPO] iter = 886000 dist_mean = 0.1983 dist_std = 0.1651 vf_loss = 0.1639 grad_norm = 1.8683 nat_grad_norm = 0.1111 cg_residual = 1.7220 step_size = 0.4430 reward = -0.0000 fps = 75 mse_loss = 1.6100 
2022-05-01 08:17:49.849196 - gail/main.py:164 - [TRPO] iter = 887000 dist_mean = 0.0839 dist_std = 0.1651 vf_loss = 0.9236 grad_norm = 2.1513 nat_grad_norm = 0.0806 cg_residual = 0.6727 step_size = 0.5750 reward = -0.0000 fps = 42 mse_loss = 1.6227 
2022-05-01 08:18:00.108920 - gail/main.py:164 - [TRPO] iter = 888000 dist_mean = 0.0287 dist_std = 0.1649 vf_loss = 0.0575 grad_norm = 1.7829 nat_grad_norm = 0.0880 cg_residual = 1.2195 step_size = 0.5490 reward = 0.0000 fps = 29 mse_loss = 1.5584 
2022-05-01 08:18:10.292594 - gail/main.py:164 - [TRPO] iter = 889000 dist_mean = 0.0266 dist_std = 0.1647 vf_loss = 0.0667 grad_norm = 1.9823 nat_grad_norm = 0.0803 cg_residual = 0.5391 step_size = 0.5973 reward = 0.0000 fps = 22 mse_loss = 1.4965 
2022-05-01 08:18:20.378738 - gail/main.py:164 - [TRPO] iter = 890000 dist_mean = 0.0691 dist_std = 0.1643 vf_loss = 0.1206 grad_norm = 3.0180 nat_grad_norm = 0.0990 cg_residual = 1.6741 step_size = 0.4586 reward = 0.0000 fps = 18 mse_loss = 1.5903 
2022-05-01 08:18:20.617854 - gail/main.py:191 - [Discriminator] iter = 890000 loss = -0.9359 grad_norm = 2.8488 grad_penalty = 0.0717 regularization = 0.0000 true_logits = 0.2186 fake_logits = -0.7891 true_prob = 0.5479 fake_prob = 0.3639 
2022-05-01 08:19:09.496096 - gail/main.py:132 - [Evaluate] iter = 890000 episode={ returns = 1798.9131 lengths = 511 } discounted_episode={ returns = 469.8860 lengths = 218 } 
2022-05-01 08:19:19.540185 - gail/main.py:164 - [TRPO] iter = 891000 dist_mean = 0.0721 dist_std = 0.1638 vf_loss = 0.0484 grad_norm = 3.3052 nat_grad_norm = 0.1020 cg_residual = 1.2549 step_size = 0.4661 reward = -0.0000 fps = 16 mse_loss = 1.6505 
2022-05-01 08:19:29.260374 - gail/main.py:164 - [TRPO] iter = 892000 dist_mean = 0.0392 dist_std = 0.1634 vf_loss = 0.3789 grad_norm = 2.5610 nat_grad_norm = 0.0655 cg_residual = 1.0190 step_size = 0.5925 reward = -0.0000 fps = 14 mse_loss = 1.6616 
2022-05-01 08:19:39.376791 - gail/main.py:164 - [TRPO] iter = 893000 dist_mean = 0.0677 dist_std = 0.1632 vf_loss = 0.0643 grad_norm = 3.3444 nat_grad_norm = 0.1082 cg_residual = 1.0078 step_size = 0.3571 reward = -0.0000 fps = 12 mse_loss = 1.5555 
2022-05-01 08:19:49.107399 - gail/main.py:164 - [TRPO] iter = 894000 dist_mean = 0.0387 dist_std = 0.1629 vf_loss = 0.4246 grad_norm = 2.8456 nat_grad_norm = 0.0343 cg_residual = 0.2419 step_size = 0.7666 reward = -0.0000 fps = 11 mse_loss = 1.5290 
2022-05-01 08:19:59.004979 - gail/main.py:164 - [TRPO] iter = 895000 dist_mean = 0.1149 dist_std = 0.1630 vf_loss = 0.4393 grad_norm = 3.6853 nat_grad_norm = 0.0862 cg_residual = 0.9686 step_size = 0.4370 reward = 0.0000 fps = 10 mse_loss = 1.5535 
2022-05-01 08:19:59.265790 - gail/main.py:191 - [Discriminator] iter = 895000 loss = -1.2884 grad_norm = 2.5463 grad_penalty = 0.1022 regularization = 0.0000 true_logits = 0.2303 fake_logits = -1.1603 true_prob = 0.5520 fake_prob = 0.3223 
2022-05-01 08:20:02.557654 - gail/main.py:132 - [Evaluate] iter = 895000 episode={ returns = 37.9977 lengths = 22 } discounted_episode={ returns = 37.4861 lengths = 22 } 
2022-05-01 08:20:12.493990 - gail/main.py:164 - [TRPO] iter = 896000 dist_mean = 0.1179 dist_std = 0.1631 vf_loss = 0.0804 grad_norm = 2.4149 nat_grad_norm = 0.0968 cg_residual = 0.9894 step_size = 0.4828 reward = -0.0000 fps = 75 mse_loss = 1.5760 
2022-05-01 08:20:22.449205 - gail/main.py:164 - [TRPO] iter = 897000 dist_mean = 0.0400 dist_std = 0.1624 vf_loss = 0.0596 grad_norm = 3.2949 nat_grad_norm = 0.0820 cg_residual = 1.9856 step_size = 0.5231 reward = 0.0000 fps = 43 mse_loss = 1.5222 
2022-05-01 08:20:32.164596 - gail/main.py:164 - [TRPO] iter = 898000 dist_mean = 0.2300 dist_std = 0.1625 vf_loss = 0.1013 grad_norm = 3.3299 nat_grad_norm = 0.0838 cg_residual = 0.7486 step_size = 0.4983 reward = -0.0000 fps = 30 mse_loss = 1.6017 
2022-05-01 08:20:42.038441 - gail/main.py:164 - [TRPO] iter = 899000 dist_mean = 0.0861 dist_std = 0.1631 vf_loss = 0.0501 grad_norm = 4.0239 nat_grad_norm = 0.0971 cg_residual = 1.8042 step_size = 0.4197 reward = 0.0000 fps = 23 mse_loss = 1.6951 
2022-05-01 08:20:52.238824 - gail/main.py:164 - [TRPO] iter = 900000 dist_mean = 0.2681 dist_std = 0.1634 vf_loss = 0.9308 grad_norm = 3.7590 nat_grad_norm = 0.0763 cg_residual = 1.9400 step_size = 0.4256 reward = -0.0000 fps = 18 mse_loss = 1.6115 
2022-05-01 08:20:52.471275 - gail/main.py:191 - [Discriminator] iter = 900000 loss = -2.1885 grad_norm = 2.8446 grad_penalty = 0.1876 regularization = 0.0000 true_logits = 0.2035 fake_logits = -2.1726 true_prob = 0.5443 fake_prob = 0.2157 
2022-05-01 08:20:55.519183 - gail/main.py:132 - [Evaluate] iter = 900000 episode={ returns = 37.3971 lengths = 21 } discounted_episode={ returns = 37.3223 lengths = 21 } 
2022-05-01 08:21:05.735109 - gail/main.py:164 - [TRPO] iter = 901000 dist_mean = 0.0681 dist_std = 0.1636 vf_loss = 0.9170 grad_norm = 2.2713 nat_grad_norm = 0.0590 cg_residual = 0.4341 step_size = 0.6797 reward = -0.0000 fps = 75 mse_loss = 1.5883 
2022-05-01 08:21:15.631758 - gail/main.py:164 - [TRPO] iter = 902000 dist_mean = 0.0589 dist_std = 0.1637 vf_loss = 0.1009 grad_norm = 3.0683 nat_grad_norm = 0.1036 cg_residual = 0.9924 step_size = 0.4233 reward = 0.0000 fps = 43 mse_loss = 1.5867 
2022-05-01 08:21:25.615421 - gail/main.py:164 - [TRPO] iter = 903000 dist_mean = 0.0700 dist_std = 0.1638 vf_loss = 0.0614 grad_norm = 4.3997 nat_grad_norm = 0.1040 cg_residual = 1.9566 step_size = 0.3710 reward = -0.0000 fps = 30 mse_loss = 1.5512 
2022-05-01 08:21:35.723117 - gail/main.py:164 - [TRPO] iter = 904000 dist_mean = 0.0223 dist_std = 0.1638 vf_loss = 0.0664 grad_norm = 2.5547 nat_grad_norm = 0.1078 cg_residual = 1.3201 step_size = 0.4008 reward = -0.0000 fps = 23 mse_loss = 1.5603 
2022-05-01 08:21:46.007695 - gail/main.py:164 - [TRPO] iter = 905000 dist_mean = 0.0265 dist_std = 0.1635 vf_loss = 0.0505 grad_norm = 3.2643 nat_grad_norm = 0.1297 cg_residual = 2.4171 step_size = 0.3729 reward = 0.0000 fps = 18 mse_loss = 1.5917 
2022-05-01 08:21:46.351697 - gail/main.py:191 - [Discriminator] iter = 905000 loss = -0.4327 grad_norm = 3.3092 grad_penalty = 0.0780 regularization = 0.0000 true_logits = 0.2091 fake_logits = -0.3016 true_prob = 0.5425 fake_prob = 0.4520 
2022-05-01 08:23:38.735156 - gail/main.py:132 - [Evaluate] iter = 905000 episode={ returns = 3237.0597 lengths = 903 } discounted_episode={ returns = 1749.2373 lengths = 779 } 
2022-05-01 08:23:48.290768 - gail/main.py:164 - [TRPO] iter = 906000 dist_mean = 0.0527 dist_std = 0.1636 vf_loss = 0.0599 grad_norm = 2.2720 nat_grad_norm = 0.1043 cg_residual = 0.9163 step_size = 0.4772 reward = 0.0000 fps = 8 mse_loss = 1.5054 
2022-05-01 08:23:58.178804 - gail/main.py:164 - [TRPO] iter = 907000 dist_mean = 0.0500 dist_std = 0.1632 vf_loss = 0.0312 grad_norm = 3.0522 nat_grad_norm = 0.1674 cg_residual = 2.5685 step_size = 0.3586 reward = 0.0000 fps = 7 mse_loss = 1.5577 
2022-05-01 08:24:07.868874 - gail/main.py:164 - [TRPO] iter = 908000 dist_mean = 0.0449 dist_std = 0.1627 vf_loss = 0.3419 grad_norm = 3.2081 nat_grad_norm = 0.0875 cg_residual = 0.9857 step_size = 0.4689 reward = -0.0000 fps = 7 mse_loss = 1.6062 
2022-05-01 08:24:17.530045 - gail/main.py:164 - [TRPO] iter = 909000 dist_mean = 0.0495 dist_std = 0.1626 vf_loss = 0.0685 grad_norm = 3.3510 nat_grad_norm = 0.1265 cg_residual = 1.3198 step_size = 0.3749 reward = -0.0000 fps = 6 mse_loss = 1.5174 
2022-05-01 08:24:27.751415 - gail/main.py:164 - [TRPO] iter = 910000 dist_mean = 0.0359 dist_std = 0.1625 vf_loss = 0.0453 grad_norm = 2.3375 nat_grad_norm = 0.0765 cg_residual = 1.4004 step_size = 0.5555 reward = 0.0000 fps = 6 mse_loss = 1.5619 
2022-05-01 08:24:27.971130 - gail/main.py:191 - [Discriminator] iter = 910000 loss = -0.6092 grad_norm = 3.3742 grad_penalty = 0.0671 regularization = 0.0000 true_logits = 0.3994 fake_logits = -0.2769 true_prob = 0.5782 fake_prob = 0.4457 
2022-05-01 08:26:03.039078 - gail/main.py:132 - [Evaluate] iter = 910000 episode={ returns = 2420.8232 lengths = 678 } discounted_episode={ returns = 1618.3610 lengths = 711 } 
2022-05-01 08:26:12.809875 - gail/main.py:164 - [TRPO] iter = 911000 dist_mean = 0.0596 dist_std = 0.1626 vf_loss = 0.0353 grad_norm = 2.5092 nat_grad_norm = 0.0763 cg_residual = 1.1288 step_size = 0.5205 reward = -0.0000 fps = 9 mse_loss = 1.4743 
2022-05-01 08:26:22.659826 - gail/main.py:164 - [TRPO] iter = 912000 dist_mean = 0.0362 dist_std = 0.1630 vf_loss = 0.2176 grad_norm = 2.8088 nat_grad_norm = 0.0798 cg_residual = 1.3151 step_size = 0.5266 reward = -0.0000 fps = 8 mse_loss = 1.5297 
2022-05-01 08:26:32.583896 - gail/main.py:164 - [TRPO] iter = 913000 dist_mean = 0.0529 dist_std = 0.1626 vf_loss = 0.2337 grad_norm = 1.6674 nat_grad_norm = 0.1112 cg_residual = 3.6817 step_size = 0.4564 reward = 0.0000 fps = 8 mse_loss = 1.5430 
2022-05-01 08:26:42.427584 - gail/main.py:164 - [TRPO] iter = 914000 dist_mean = 0.0443 dist_std = 0.1630 vf_loss = 0.1829 grad_norm = 3.1835 nat_grad_norm = 0.0641 cg_residual = 0.8566 step_size = 0.5609 reward = -0.0000 fps = 7 mse_loss = 1.4762 
2022-05-01 08:26:52.326816 - gail/main.py:164 - [TRPO] iter = 915000 dist_mean = 0.0627 dist_std = 0.1635 vf_loss = 0.0966 grad_norm = 2.9332 nat_grad_norm = 0.1208 cg_residual = 1.5612 step_size = 0.4016 reward = 0.0000 fps = 6 mse_loss = 1.5069 
2022-05-01 08:26:52.564038 - gail/main.py:191 - [Discriminator] iter = 915000 loss = -0.7449 grad_norm = 4.4903 grad_penalty = 0.0745 regularization = 0.0000 true_logits = 0.2364 fake_logits = -0.5830 true_prob = 0.5499 fake_prob = 0.3983 
2022-05-01 08:28:44.945847 - gail/main.py:132 - [Evaluate] iter = 915000 episode={ returns = 2883.2640 lengths = 807 } discounted_episode={ returns = 1904.4708 lengths = 856 } 
2022-05-01 08:28:54.663040 - gail/main.py:164 - [TRPO] iter = 916000 dist_mean = 0.0516 dist_std = 0.1633 vf_loss = 0.0439 grad_norm = 2.0798 nat_grad_norm = 0.0924 cg_residual = 1.5007 step_size = 0.4779 reward = 0.0000 fps = 8 mse_loss = 1.5630 
2022-05-01 08:29:04.434109 - gail/main.py:164 - [TRPO] iter = 917000 dist_mean = 0.0439 dist_std = 0.1634 vf_loss = 0.0620 grad_norm = 3.5027 nat_grad_norm = 0.0797 cg_residual = 0.4750 step_size = 0.4634 reward = 0.0000 fps = 7 mse_loss = 1.5092 
2022-05-01 08:29:14.814976 - gail/main.py:164 - [TRPO] iter = 918000 dist_mean = 0.0503 dist_std = 0.1636 vf_loss = 0.1025 grad_norm = 2.1192 nat_grad_norm = 0.1003 cg_residual = 0.9860 step_size = 0.5241 reward = 0.0000 fps = 7 mse_loss = 1.6302 
2022-05-01 08:29:24.754148 - gail/main.py:164 - [TRPO] iter = 919000 dist_mean = 0.0344 dist_std = 0.1633 vf_loss = 0.1019 grad_norm = 4.9988 nat_grad_norm = 0.1428 cg_residual = 4.1079 step_size = 0.2522 reward = 0.0000 fps = 6 mse_loss = 1.5781 
2022-05-01 08:29:34.950958 - gail/main.py:164 - [TRPO] iter = 920000 dist_mean = 0.0497 dist_std = 0.1631 vf_loss = 0.1198 grad_norm = 4.5562 nat_grad_norm = 0.1539 cg_residual = 2.6963 step_size = 0.2589 reward = 0.0000 fps = 6 mse_loss = 1.4832 
2022-05-01 08:29:35.219345 - gail/main.py:191 - [Discriminator] iter = 920000 loss = -0.6600 grad_norm = 4.2656 grad_penalty = 0.0754 regularization = 0.0000 true_logits = 0.1966 fake_logits = -0.5388 true_prob = 0.5430 fake_prob = 0.4119 
2022-05-01 08:29:49.361222 - gail/main.py:132 - [Evaluate] iter = 920000 episode={ returns = 281.2579 lengths = 87 } discounted_episode={ returns = 255.1381 lengths = 119 } 
2022-05-01 08:29:59.262331 - gail/main.py:164 - [TRPO] iter = 921000 dist_mean = 0.0852 dist_std = 0.1634 vf_loss = 0.1642 grad_norm = 2.6221 nat_grad_norm = 0.0840 cg_residual = 0.7543 step_size = 0.4480 reward = 0.0000 fps = 41 mse_loss = 1.4462 
2022-05-01 08:30:09.209243 - gail/main.py:164 - [TRPO] iter = 922000 dist_mean = 0.0166 dist_std = 0.1633 vf_loss = 0.0649 grad_norm = 3.4111 nat_grad_norm = 0.1085 cg_residual = 2.7734 step_size = 0.4033 reward = -0.0000 fps = 29 mse_loss = 1.5194 
2022-05-01 08:30:19.202940 - gail/main.py:164 - [TRPO] iter = 923000 dist_mean = 0.0461 dist_std = 0.1630 vf_loss = 0.0960 grad_norm = 3.3710 nat_grad_norm = 0.0849 cg_residual = 0.8333 step_size = 0.4514 reward = 0.0000 fps = 22 mse_loss = 1.5135 
2022-05-01 08:30:29.058438 - gail/main.py:164 - [TRPO] iter = 924000 dist_mean = 0.0281 dist_std = 0.1630 vf_loss = 0.2713 grad_norm = 2.3076 nat_grad_norm = 0.0886 cg_residual = 1.5161 step_size = 0.5143 reward = 0.0000 fps = 18 mse_loss = 1.5042 
2022-05-01 08:30:39.715166 - gail/main.py:164 - [TRPO] iter = 925000 dist_mean = 0.3363 dist_std = 0.1629 vf_loss = 0.0717 grad_norm = 2.3300 nat_grad_norm = 0.1002 cg_residual = 1.1590 step_size = 0.4744 reward = 0.0000 fps = 15 mse_loss = 1.5029 
2022-05-01 08:30:39.917708 - gail/main.py:191 - [Discriminator] iter = 925000 loss = -2.8314 grad_norm = 3.8944 grad_penalty = 0.2547 regularization = 0.0000 true_logits = 0.1657 fake_logits = -2.9203 true_prob = 0.5365 fake_prob = 0.1317 
2022-05-01 08:30:42.983092 - gail/main.py:132 - [Evaluate] iter = 925000 episode={ returns = 37.4540 lengths = 21 } discounted_episode={ returns = 37.1844 lengths = 21 } 
2022-05-01 08:30:53.170229 - gail/main.py:164 - [TRPO] iter = 926000 dist_mean = 0.2417 dist_std = 0.1627 vf_loss = 0.1022 grad_norm = 3.9451 nat_grad_norm = 0.0847 cg_residual = 1.5713 step_size = 0.4599 reward = 0.0000 fps = 75 mse_loss = 1.5253 
2022-05-01 08:31:03.499124 - gail/main.py:164 - [TRPO] iter = 927000 dist_mean = 0.3097 dist_std = 0.1624 vf_loss = 0.3145 grad_norm = 2.6358 nat_grad_norm = 0.0767 cg_residual = 0.6353 step_size = 0.4796 reward = 0.0000 fps = 42 mse_loss = 1.4731 
2022-05-01 08:31:13.385773 - gail/main.py:164 - [TRPO] iter = 928000 dist_mean = 0.1117 dist_std = 0.1621 vf_loss = 0.3010 grad_norm = 2.6861 nat_grad_norm = 0.0857 cg_residual = 1.2974 step_size = 0.4817 reward = 0.0000 fps = 29 mse_loss = 1.4961 
2022-05-01 08:31:23.367097 - gail/main.py:164 - [TRPO] iter = 929000 dist_mean = 0.3103 dist_std = 0.1625 vf_loss = 0.1005 grad_norm = 2.4668 nat_grad_norm = 0.0654 cg_residual = 1.2734 step_size = 0.5553 reward = -0.0000 fps = 23 mse_loss = 1.5807 
2022-05-01 08:31:33.536973 - gail/main.py:164 - [TRPO] iter = 930000 dist_mean = 0.4129 dist_std = 0.1627 vf_loss = 0.0923 grad_norm = 3.5609 nat_grad_norm = 0.0461 cg_residual = 0.2185 step_size = 0.6509 reward = -0.0000 fps = 18 mse_loss = 1.5319 
2022-05-01 08:31:33.779643 - gail/main.py:191 - [Discriminator] iter = 930000 loss = -4.2423 grad_norm = 3.3643 grad_penalty = 0.3787 regularization = 0.0000 true_logits = 0.2230 fake_logits = -4.3980 true_prob = 0.5407 fake_prob = 0.0158 
2022-05-01 08:31:36.948238 - gail/main.py:132 - [Evaluate] iter = 930000 episode={ returns = 37.4082 lengths = 21 } discounted_episode={ returns = 37.5854 lengths = 22 } 
2022-05-01 08:31:46.932177 - gail/main.py:164 - [TRPO] iter = 931000 dist_mean = 0.2560 dist_std = 0.1629 vf_loss = 1.6144 grad_norm = 3.7550 nat_grad_norm = 0.0733 cg_residual = 0.7770 step_size = 0.4495 reward = -0.0000 fps = 76 mse_loss = 1.4868 
2022-05-01 08:31:56.287197 - gail/main.py:164 - [TRPO] iter = 932000 dist_mean = 0.0803 dist_std = 0.1632 vf_loss = 1.0805 grad_norm = 2.4500 nat_grad_norm = 0.1062 cg_residual = 1.0134 step_size = 0.4250 reward = -0.0000 fps = 44 mse_loss = 1.5787 
2022-05-01 08:32:05.921947 - gail/main.py:164 - [TRPO] iter = 933000 dist_mean = 0.0721 dist_std = 0.1628 vf_loss = 0.5799 grad_norm = 2.3922 nat_grad_norm = 0.0936 cg_residual = 0.9963 step_size = 0.4755 reward = 0.0000 fps = 31 mse_loss = 1.5974 
2022-05-01 08:32:15.665163 - gail/main.py:164 - [TRPO] iter = 934000 dist_mean = 0.1294 dist_std = 0.1624 vf_loss = 0.9840 grad_norm = 3.9693 nat_grad_norm = 0.0733 cg_residual = 0.9630 step_size = 0.4550 reward = 0.0000 fps = 23 mse_loss = 1.6217 
2022-05-01 08:32:25.278927 - gail/main.py:164 - [TRPO] iter = 935000 dist_mean = 0.0579 dist_std = 0.1623 vf_loss = 0.9290 grad_norm = 2.1379 nat_grad_norm = 0.0788 cg_residual = 0.6258 step_size = 0.5273 reward = -0.0000 fps = 19 mse_loss = 1.5137 
2022-05-01 08:32:25.521884 - gail/main.py:191 - [Discriminator] iter = 935000 loss = -0.9319 grad_norm = 4.4080 grad_penalty = 0.1736 regularization = 0.0000 true_logits = 0.4231 fake_logits = -0.6825 true_prob = 0.5581 fake_prob = 0.4232 
2022-05-01 08:33:17.804345 - gail/main.py:132 - [Evaluate] iter = 935000 episode={ returns = 1960.5813 lengths = 560 } discounted_episode={ returns = 525.6345 lengths = 225 } 
2022-05-01 08:33:27.617219 - gail/main.py:164 - [TRPO] iter = 936000 dist_mean = 0.0311 dist_std = 0.1628 vf_loss = 1.3879 grad_norm = 2.4189 nat_grad_norm = 0.0716 cg_residual = 1.2057 step_size = 0.5547 reward = -0.0000 fps = 16 mse_loss = 1.5327 
2022-05-01 08:33:37.335005 - gail/main.py:164 - [TRPO] iter = 937000 dist_mean = 0.0527 dist_std = 0.1629 vf_loss = 0.2164 grad_norm = 4.1897 nat_grad_norm = 0.1158 cg_residual = 2.6435 step_size = 0.3708 reward = -0.0000 fps = 13 mse_loss = 1.4615 
2022-05-01 08:33:46.937124 - gail/main.py:164 - [TRPO] iter = 938000 dist_mean = 0.0316 dist_std = 0.1630 vf_loss = 0.1283 grad_norm = 3.3808 nat_grad_norm = 0.0910 cg_residual = 1.0380 step_size = 0.3718 reward = -0.0000 fps = 12 mse_loss = 1.4933 
2022-05-01 08:33:56.624213 - gail/main.py:164 - [TRPO] iter = 939000 dist_mean = 0.0652 dist_std = 0.1630 vf_loss = 0.1888 grad_norm = 3.4917 nat_grad_norm = 0.0921 cg_residual = 1.2182 step_size = 0.4286 reward = -0.0000 fps = 10 mse_loss = 1.5390 
2022-05-01 08:34:06.297564 - gail/main.py:164 - [TRPO] iter = 940000 dist_mean = 0.0353 dist_std = 0.1628 vf_loss = 0.2362 grad_norm = 3.9615 nat_grad_norm = 0.0854 cg_residual = 1.8520 step_size = 0.4941 reward = -0.0000 fps = 9 mse_loss = 1.5892 
2022-05-01 08:34:06.510884 - gail/main.py:191 - [Discriminator] iter = 940000 loss = -0.3572 grad_norm = 3.8947 grad_penalty = 0.0657 regularization = 0.0000 true_logits = 0.5803 fake_logits = 0.1574 true_prob = 0.5912 fake_prob = 0.5281 
2022-05-01 08:35:06.230690 - gail/main.py:132 - [Evaluate] iter = 940000 episode={ returns = 1236.5293 lengths = 385 } discounted_episode={ returns = 1176.9474 lengths = 511 } 
2022-05-01 08:35:16.197811 - gail/main.py:164 - [TRPO] iter = 941000 dist_mean = 0.0345 dist_std = 0.1625 vf_loss = 0.0898 grad_norm = 2.6190 nat_grad_norm = 0.1197 cg_residual = 0.7270 step_size = 0.3849 reward = 0.0000 fps = 14 mse_loss = 1.5497 
2022-05-01 08:35:26.053061 - gail/main.py:164 - [TRPO] iter = 942000 dist_mean = 0.0360 dist_std = 0.1625 vf_loss = 0.0696 grad_norm = 3.2365 nat_grad_norm = 0.1512 cg_residual = 1.2183 step_size = 0.3154 reward = 0.0000 fps = 12 mse_loss = 1.5761 
2022-05-01 08:35:35.453485 - gail/main.py:164 - [TRPO] iter = 943000 dist_mean = 0.0211 dist_std = 0.1623 vf_loss = 0.0503 grad_norm = 2.7358 nat_grad_norm = 0.1030 cg_residual = 2.6774 step_size = 0.4727 reward = -0.0000 fps = 11 mse_loss = 1.6427 
2022-05-01 08:35:44.854375 - gail/main.py:164 - [TRPO] iter = 944000 dist_mean = 0.0504 dist_std = 0.1619 vf_loss = 0.0895 grad_norm = 2.1075 nat_grad_norm = 0.0950 cg_residual = 1.1879 step_size = 0.4749 reward = -0.0000 fps = 10 mse_loss = 1.6369 
2022-05-01 08:35:54.503497 - gail/main.py:164 - [TRPO] iter = 945000 dist_mean = 0.0584 dist_std = 0.1621 vf_loss = 0.0824 grad_norm = 2.5895 nat_grad_norm = 0.1234 cg_residual = 1.7861 step_size = 0.4175 reward = -0.0000 fps = 9 mse_loss = 1.6407 
2022-05-01 08:35:54.746180 - gail/main.py:191 - [Discriminator] iter = 945000 loss = -0.7686 grad_norm = 3.5238 grad_penalty = 0.0742 regularization = 0.0000 true_logits = 0.5035 fake_logits = -0.3394 true_prob = 0.5774 fake_prob = 0.4470 
2022-05-01 08:37:31.542080 - gail/main.py:132 - [Evaluate] iter = 945000 episode={ returns = 2338.5329 lengths = 673 } discounted_episode={ returns = 1817.5617 lengths = 800 } 
2022-05-01 08:37:41.112564 - gail/main.py:164 - [TRPO] iter = 946000 dist_mean = 0.0281 dist_std = 0.1628 vf_loss = 0.0642 grad_norm = 3.5675 nat_grad_norm = 0.0792 cg_residual = 1.2143 step_size = 0.5548 reward = -0.0000 fps = 9 mse_loss = 1.5683 
2022-05-01 08:37:50.937572 - gail/main.py:164 - [TRPO] iter = 947000 dist_mean = 0.0806 dist_std = 0.1633 vf_loss = 0.0708 grad_norm = 3.2687 nat_grad_norm = 0.1013 cg_residual = 1.1781 step_size = 0.4346 reward = 0.0000 fps = 8 mse_loss = 1.5975 
2022-05-01 08:38:00.569868 - gail/main.py:164 - [TRPO] iter = 948000 dist_mean = 0.0335 dist_std = 0.1635 vf_loss = 0.0831 grad_norm = 2.4818 nat_grad_norm = 0.1005 cg_residual = 1.1572 step_size = 0.4241 reward = 0.0000 fps = 7 mse_loss = 1.6456 
2022-05-01 08:38:10.223006 - gail/main.py:164 - [TRPO] iter = 949000 dist_mean = 0.0652 dist_std = 0.1633 vf_loss = 0.0809 grad_norm = 2.7134 nat_grad_norm = 0.1088 cg_residual = 1.9068 step_size = 0.4194 reward = -0.0000 fps = 7 mse_loss = 1.7186 
2022-05-01 08:38:20.009900 - gail/main.py:164 - [TRPO] iter = 950000 dist_mean = 0.0403 dist_std = 0.1636 vf_loss = 0.0605 grad_norm = 2.7373 nat_grad_norm = 0.1270 cg_residual = 0.6839 step_size = 0.4039 reward = -0.0000 fps = 6 mse_loss = 1.6734 
2022-05-01 08:38:20.251064 - gail/main.py:191 - [Discriminator] iter = 950000 loss = -0.5247 grad_norm = 3.3523 grad_penalty = 0.0746 regularization = 0.0000 true_logits = 0.3751 fake_logits = -0.2242 true_prob = 0.5655 fake_prob = 0.4656 
2022-05-01 08:40:10.805131 - gail/main.py:132 - [Evaluate] iter = 950000 episode={ returns = 2958.3219 lengths = 847 } discounted_episode={ returns = 1895.2321 lengths = 833 } 
2022-05-01 08:40:20.648733 - gail/main.py:164 - [TRPO] iter = 951000 dist_mean = 0.0725 dist_std = 0.1633 vf_loss = 0.0624 grad_norm = 2.7725 nat_grad_norm = 0.0853 cg_residual = 1.6167 step_size = 0.5138 reward = -0.0000 fps = 8 mse_loss = 1.6234 
2022-05-01 08:40:30.243961 - gail/main.py:164 - [TRPO] iter = 952000 dist_mean = 0.0206 dist_std = 0.1632 vf_loss = 0.0470 grad_norm = 3.5191 nat_grad_norm = 0.0711 cg_residual = 1.4808 step_size = 0.5881 reward = -0.0000 fps = 7 mse_loss = 1.6257 
2022-05-01 08:40:40.142205 - gail/main.py:164 - [TRPO] iter = 953000 dist_mean = 0.0388 dist_std = 0.1631 vf_loss = 0.0498 grad_norm = 3.4775 nat_grad_norm = 0.0914 cg_residual = 1.3989 step_size = 0.4705 reward = 0.0000 fps = 7 mse_loss = 1.7846 
2022-05-01 08:40:49.977164 - gail/main.py:164 - [TRPO] iter = 954000 dist_mean = 0.0324 dist_std = 0.1632 vf_loss = 0.0469 grad_norm = 2.5253 nat_grad_norm = 0.1096 cg_residual = 0.5298 step_size = 0.4271 reward = -0.0000 fps = 6 mse_loss = 1.7182 
2022-05-01 08:40:59.672349 - gail/main.py:164 - [TRPO] iter = 955000 dist_mean = 0.0727 dist_std = 0.1628 vf_loss = 0.0608 grad_norm = 3.7942 nat_grad_norm = 0.1296 cg_residual = 1.4951 step_size = 0.3483 reward = -0.0000 fps = 6 mse_loss = 1.7860 
2022-05-01 08:40:59.874203 - gail/main.py:191 - [Discriminator] iter = 955000 loss = -0.8103 grad_norm = 2.9619 grad_penalty = 0.0768 regularization = 0.0000 true_logits = 0.3827 fake_logits = -0.5044 true_prob = 0.5702 fake_prob = 0.4223 
2022-05-01 08:42:38.314474 - gail/main.py:132 - [Evaluate] iter = 955000 episode={ returns = 2285.9565 lengths = 665 } discounted_episode={ returns = 1835.8196 lengths = 812 } 
2022-05-01 08:42:48.053770 - gail/main.py:164 - [TRPO] iter = 956000 dist_mean = 0.0452 dist_std = 0.1628 vf_loss = 0.0492 grad_norm = 2.7419 nat_grad_norm = 0.0891 cg_residual = 0.4991 step_size = 0.5116 reward = -0.0000 fps = 9 mse_loss = 1.8537 
2022-05-01 08:42:58.009893 - gail/main.py:164 - [TRPO] iter = 957000 dist_mean = 0.0418 dist_std = 0.1626 vf_loss = 0.0448 grad_norm = 3.7745 nat_grad_norm = 0.0728 cg_residual = 1.1968 step_size = 0.4565 reward = -0.0000 fps = 8 mse_loss = 1.7935 
2022-05-01 08:43:07.981762 - gail/main.py:164 - [TRPO] iter = 958000 dist_mean = 0.0358 dist_std = 0.1624 vf_loss = 0.0289 grad_norm = 3.3543 nat_grad_norm = 0.1273 cg_residual = 1.8282 step_size = 0.4251 reward = 0.0000 fps = 7 mse_loss = 1.7705 
2022-05-01 08:43:17.954514 - gail/main.py:164 - [TRPO] iter = 959000 dist_mean = 0.0319 dist_std = 0.1629 vf_loss = 0.0399 grad_norm = 3.1809 nat_grad_norm = 0.1467 cg_residual = 2.6503 step_size = 0.3537 reward = 0.0000 fps = 7 mse_loss = 1.7961 
2022-05-01 08:43:27.524702 - gail/main.py:164 - [TRPO] iter = 960000 dist_mean = 0.0718 dist_std = 0.1631 vf_loss = 0.0406 grad_norm = 1.8748 nat_grad_norm = 0.0910 cg_residual = 1.1155 step_size = 0.4744 reward = -0.0000 fps = 6 mse_loss = 1.7998 
2022-05-01 08:43:27.813417 - gail/main.py:191 - [Discriminator] iter = 960000 loss = -0.6939 grad_norm = 2.8355 grad_penalty = 0.0748 regularization = 0.0000 true_logits = 0.2981 fake_logits = -0.4705 true_prob = 0.5572 fake_prob = 0.4270 
2022-05-01 08:44:50.237870 - gail/main.py:132 - [Evaluate] iter = 960000 episode={ returns = 2009.4456 lengths = 567 } discounted_episode={ returns = 1628.8761 lengths = 665 } 
2022-05-01 08:45:00.106283 - gail/main.py:164 - [TRPO] iter = 961000 dist_mean = 0.0283 dist_std = 0.1632 vf_loss = 0.0282 grad_norm = 2.5195 nat_grad_norm = 0.0991 cg_residual = 2.2586 step_size = 0.4128 reward = -0.0000 fps = 10 mse_loss = 1.8354 
2022-05-01 08:45:09.947882 - gail/main.py:164 - [TRPO] iter = 962000 dist_mean = 0.0312 dist_std = 0.1633 vf_loss = 0.0311 grad_norm = 2.7390 nat_grad_norm = 0.0927 cg_residual = 1.8888 step_size = 0.4446 reward = 0.0000 fps = 9 mse_loss = 1.9246 
2022-05-01 08:45:19.700828 - gail/main.py:164 - [TRPO] iter = 963000 dist_mean = 0.0548 dist_std = 0.1630 vf_loss = 0.0408 grad_norm = 2.1937 nat_grad_norm = 0.1000 cg_residual = 0.7718 step_size = 0.4666 reward = 0.0000 fps = 8 mse_loss = 1.9122 
2022-05-01 08:45:29.671206 - gail/main.py:164 - [TRPO] iter = 964000 dist_mean = 0.0551 dist_std = 0.1628 vf_loss = 0.0243 grad_norm = 1.9038 nat_grad_norm = 0.0864 cg_residual = 1.3577 step_size = 0.5524 reward = 0.0000 fps = 8 mse_loss = 1.8808 
2022-05-01 08:45:39.689929 - gail/main.py:164 - [TRPO] iter = 965000 dist_mean = 0.0616 dist_std = 0.1631 vf_loss = 0.0232 grad_norm = 3.3415 nat_grad_norm = 0.1546 cg_residual = 2.5459 step_size = 0.3213 reward = 0.0000 fps = 7 mse_loss = 1.8939 
2022-05-01 08:45:39.898327 - gail/main.py:191 - [Discriminator] iter = 965000 loss = -0.4395 grad_norm = 2.9671 grad_penalty = 0.0688 regularization = 0.0000 true_logits = 0.2307 fake_logits = -0.2776 true_prob = 0.5477 fake_prob = 0.4607 
2022-05-01 08:46:40.311346 - gail/main.py:132 - [Evaluate] iter = 965000 episode={ returns = 1511.2479 lengths = 422 } discounted_episode={ returns = 1285.8896 lengths = 478 } 
2022-05-01 08:46:49.741950 - gail/main.py:164 - [TRPO] iter = 966000 dist_mean = 0.0346 dist_std = 0.1627 vf_loss = 0.0204 grad_norm = 2.8662 nat_grad_norm = 0.0818 cg_residual = 1.6430 step_size = 0.5296 reward = 0.0000 fps = 14 mse_loss = 1.8315 
2022-05-01 08:46:59.226387 - gail/main.py:164 - [TRPO] iter = 967000 dist_mean = 0.0614 dist_std = 0.1625 vf_loss = 0.0162 grad_norm = 3.4762 nat_grad_norm = 0.1065 cg_residual = 0.7655 step_size = 0.4468 reward = -0.0000 fps = 12 mse_loss = 1.8504 
2022-05-01 08:47:09.190798 - gail/main.py:164 - [TRPO] iter = 968000 dist_mean = 0.0628 dist_std = 0.1628 vf_loss = 0.0479 grad_norm = 4.3959 nat_grad_norm = 0.1004 cg_residual = 1.4638 step_size = 0.3297 reward = -0.0000 fps = 11 mse_loss = 1.8092 
2022-05-01 08:47:19.203004 - gail/main.py:164 - [TRPO] iter = 969000 dist_mean = 0.0446 dist_std = 0.1628 vf_loss = 0.0320 grad_norm = 2.0955 nat_grad_norm = 0.1062 cg_residual = 0.7683 step_size = 0.4597 reward = 0.0000 fps = 10 mse_loss = 1.8524 
2022-05-01 08:47:28.673529 - gail/main.py:164 - [TRPO] iter = 970000 dist_mean = 0.0574 dist_std = 0.1626 vf_loss = 0.0256 grad_norm = 2.5209 nat_grad_norm = 0.0830 cg_residual = 1.4895 step_size = 0.4712 reward = -0.0000 fps = 9 mse_loss = 1.8344 
2022-05-01 08:47:28.904752 - gail/main.py:191 - [Discriminator] iter = 970000 loss = -0.6270 grad_norm = 3.3413 grad_penalty = 0.0611 regularization = 0.0000 true_logits = 0.3187 fake_logits = -0.3694 true_prob = 0.5667 fake_prob = 0.4452 
2022-05-01 08:49:08.501082 - gail/main.py:132 - [Evaluate] iter = 970000 episode={ returns = 2688.8619 lengths = 759 } discounted_episode={ returns = 1778.1111 lengths = 751 } 
2022-05-01 08:49:18.253617 - gail/main.py:164 - [TRPO] iter = 971000 dist_mean = 0.0332 dist_std = 0.1627 vf_loss = 0.0189 grad_norm = 2.4182 nat_grad_norm = 0.0999 cg_residual = 2.4250 step_size = 0.4102 reward = 0.0000 fps = 9 mse_loss = 1.8234 
2022-05-01 08:49:28.119901 - gail/main.py:164 - [TRPO] iter = 972000 dist_mean = 0.0345 dist_std = 0.1626 vf_loss = 0.0124 grad_norm = 2.6507 nat_grad_norm = 0.0702 cg_residual = 0.5626 step_size = 0.5640 reward = -0.0000 fps = 8 mse_loss = 1.8879 
2022-05-01 08:49:37.992444 - gail/main.py:164 - [TRPO] iter = 973000 dist_mean = 0.0600 dist_std = 0.1627 vf_loss = 0.0136 grad_norm = 3.2459 nat_grad_norm = 0.1015 cg_residual = 2.6533 step_size = 0.4470 reward = 0.0000 fps = 7 mse_loss = 1.8589 
2022-05-01 08:49:47.583261 - gail/main.py:164 - [TRPO] iter = 974000 dist_mean = 0.0246 dist_std = 0.1626 vf_loss = 0.0555 grad_norm = 4.5875 nat_grad_norm = 0.1607 cg_residual = 2.7603 step_size = 0.2426 reward = 0.0000 fps = 7 mse_loss = 1.8661 
2022-05-01 08:49:57.244754 - gail/main.py:164 - [TRPO] iter = 975000 dist_mean = 0.0509 dist_std = 0.1625 vf_loss = 0.0217 grad_norm = 3.4152 nat_grad_norm = 0.1203 cg_residual = 1.6241 step_size = 0.4265 reward = -0.0000 fps = 6 mse_loss = 1.8003 
2022-05-01 08:49:57.456787 - gail/main.py:191 - [Discriminator] iter = 975000 loss = -0.5874 grad_norm = 3.5898 grad_penalty = 0.0713 regularization = 0.0000 true_logits = 0.1974 fake_logits = -0.4612 true_prob = 0.5420 fake_prob = 0.4231 
2022-05-01 08:51:31.785394 - gail/main.py:132 - [Evaluate] iter = 975000 episode={ returns = 2644.3390 lengths = 743 } discounted_episode={ returns = 1674.9913 lengths = 688 } 
2022-05-01 08:51:41.162318 - gail/main.py:164 - [TRPO] iter = 976000 dist_mean = 0.0480 dist_std = 0.1622 vf_loss = 0.0154 grad_norm = 3.4460 nat_grad_norm = 0.1054 cg_residual = 1.6505 step_size = 0.3686 reward = 0.0000 fps = 9 mse_loss = 1.7918 
2022-05-01 08:51:50.898529 - gail/main.py:164 - [TRPO] iter = 977000 dist_mean = 0.0488 dist_std = 0.1620 vf_loss = 0.0162 grad_norm = 2.8786 nat_grad_norm = 0.0694 cg_residual = 1.6189 step_size = 0.5424 reward = 0.0000 fps = 8 mse_loss = 1.8024 
2022-05-01 08:52:00.317986 - gail/main.py:164 - [TRPO] iter = 978000 dist_mean = 0.0529 dist_std = 0.1620 vf_loss = 0.0171 grad_norm = 3.6884 nat_grad_norm = 0.0879 cg_residual = 1.5424 step_size = 0.4840 reward = 0.0000 fps = 8 mse_loss = 1.6536 
2022-05-01 08:52:10.171414 - gail/main.py:164 - [TRPO] iter = 979000 dist_mean = 0.0585 dist_std = 0.1620 vf_loss = 0.0144 grad_norm = 3.4227 nat_grad_norm = 0.0733 cg_residual = 1.3522 step_size = 0.4727 reward = 0.0000 fps = 7 mse_loss = 1.6791 
2022-05-01 08:52:19.791434 - gail/main.py:164 - [TRPO] iter = 980000 dist_mean = 0.0330 dist_std = 0.1620 vf_loss = 0.0576 grad_norm = 2.4220 nat_grad_norm = 0.0695 cg_residual = 1.3410 step_size = 0.5339 reward = 0.0000 fps = 7 mse_loss = 1.6385 
2022-05-01 08:52:20.002921 - gail/main.py:191 - [Discriminator] iter = 980000 loss = -0.3795 grad_norm = 4.0985 grad_penalty = 0.0696 regularization = 0.0000 true_logits = 0.1460 fake_logits = -0.3030 true_prob = 0.5327 fake_prob = 0.4494 
2022-05-01 08:53:51.031330 - gail/main.py:132 - [Evaluate] iter = 980000 episode={ returns = 2624.7104 lengths = 730 } discounted_episode={ returns = 1622.3296 lengths = 632 } 
2022-05-01 08:54:00.537267 - gail/main.py:164 - [TRPO] iter = 981000 dist_mean = 0.0455 dist_std = 0.1626 vf_loss = 0.0165 grad_norm = 2.4891 nat_grad_norm = 0.0766 cg_residual = 1.4597 step_size = 0.5409 reward = -0.0000 fps = 9 mse_loss = 1.6979 
2022-05-01 08:54:10.346334 - gail/main.py:164 - [TRPO] iter = 982000 dist_mean = 0.0455 dist_std = 0.1629 vf_loss = 0.0609 grad_norm = 3.3496 nat_grad_norm = 0.0910 cg_residual = 1.8726 step_size = 0.4063 reward = 0.0000 fps = 9 mse_loss = 1.6130 
2022-05-01 08:54:20.061665 - gail/main.py:164 - [TRPO] iter = 983000 dist_mean = 0.0443 dist_std = 0.1626 vf_loss = 0.0135 grad_norm = 4.0783 nat_grad_norm = 0.0799 cg_residual = 1.0640 step_size = 0.4798 reward = -0.0000 fps = 8 mse_loss = 1.6487 
2022-05-01 08:54:30.216863 - gail/main.py:164 - [TRPO] iter = 984000 dist_mean = 0.0180 dist_std = 0.1624 vf_loss = 0.0118 grad_norm = 3.7723 nat_grad_norm = 0.0954 cg_residual = 1.4613 step_size = 0.4881 reward = -0.0000 fps = 7 mse_loss = 1.7473 
2022-05-01 08:54:40.001212 - gail/main.py:164 - [TRPO] iter = 985000 dist_mean = 0.0278 dist_std = 0.1621 vf_loss = 0.0144 grad_norm = 2.9638 nat_grad_norm = 0.1048 cg_residual = 1.4719 step_size = 0.4410 reward = -0.0000 fps = 7 mse_loss = 1.6615 
2022-05-01 08:54:40.221861 - gail/main.py:191 - [Discriminator] iter = 985000 loss = -0.4271 grad_norm = 4.6931 grad_penalty = 0.0571 regularization = 0.0000 true_logits = 0.1104 fake_logits = -0.3738 true_prob = 0.5306 fake_prob = 0.4314 
2022-05-01 08:56:04.274100 - gail/main.py:132 - [Evaluate] iter = 985000 episode={ returns = 2556.4521 lengths = 707 } discounted_episode={ returns = 1537.0941 lengths = 570 } 
2022-05-01 08:56:13.883077 - gail/main.py:164 - [TRPO] iter = 986000 dist_mean = 0.0262 dist_std = 0.1616 vf_loss = 0.0234 grad_norm = 2.7721 nat_grad_norm = 0.1383 cg_residual = 3.0069 step_size = 0.4083 reward = 0.0000 fps = 10 mse_loss = 1.7602 
2022-05-01 08:56:23.855211 - gail/main.py:164 - [TRPO] iter = 987000 dist_mean = 0.0227 dist_std = 0.1621 vf_loss = 0.0097 grad_norm = 2.9736 nat_grad_norm = 0.0916 cg_residual = 0.8763 step_size = 0.4376 reward = -0.0000 fps = 9 mse_loss = 1.6558 
2022-05-01 08:56:33.459220 - gail/main.py:164 - [TRPO] iter = 988000 dist_mean = 0.0117 dist_std = 0.1621 vf_loss = 0.0157 grad_norm = 3.6682 nat_grad_norm = 0.0767 cg_residual = 1.6714 step_size = 0.5422 reward = -0.0000 fps = 8 mse_loss = 1.6976 
2022-05-01 08:56:43.261490 - gail/main.py:164 - [TRPO] iter = 989000 dist_mean = 0.0262 dist_std = 0.1612 vf_loss = 0.0152 grad_norm = 3.9875 nat_grad_norm = 0.0732 cg_residual = 0.4310 step_size = 0.4900 reward = -0.0000 fps = 8 mse_loss = 1.7672 
2022-05-01 08:56:53.274658 - gail/main.py:164 - [TRPO] iter = 990000 dist_mean = 0.0115 dist_std = 0.1611 vf_loss = 0.0111 grad_norm = 2.9569 nat_grad_norm = 0.0657 cg_residual = 0.8235 step_size = 0.5268 reward = 0.0000 fps = 7 mse_loss = 1.7579 
2022-05-01 08:56:53.478175 - gail/main.py:191 - [Discriminator] iter = 990000 loss = -0.3521 grad_norm = 3.4474 grad_penalty = 0.0608 regularization = 0.0000 true_logits = 0.0750 fake_logits = -0.3379 true_prob = 0.5203 fake_prob = 0.4364 
2022-05-01 08:59:04.808231 - gail/main.py:132 - [Evaluate] iter = 990000 episode={ returns = 3570.0649 lengths = 1000 } discounted_episode={ returns = 2210.1343 lengths = 1000 } 
2022-05-01 08:59:14.778899 - gail/main.py:164 - [TRPO] iter = 991000 dist_mean = 0.0061 dist_std = 0.1608 vf_loss = 0.1265 grad_norm = 2.4419 nat_grad_norm = 0.1532 cg_residual = 1.5765 step_size = 0.2951 reward = -0.0000 fps = 7 mse_loss = 1.6691 
2022-05-01 08:59:24.525827 - gail/main.py:164 - [TRPO] iter = 992000 dist_mean = 0.0258 dist_std = 0.1606 vf_loss = 0.0145 grad_norm = 3.5905 nat_grad_norm = 0.0729 cg_residual = 0.9568 step_size = 0.4956 reward = 0.0000 fps = 6 mse_loss = 1.7330 
2022-05-01 08:59:34.274913 - gail/main.py:164 - [TRPO] iter = 993000 dist_mean = 0.0194 dist_std = 0.1604 vf_loss = 0.0403 grad_norm = 4.0672 nat_grad_norm = 0.0916 cg_residual = 3.7151 step_size = 0.4080 reward = -0.0000 fps = 6 mse_loss = 1.6569 
2022-05-01 08:59:44.030669 - gail/main.py:164 - [TRPO] iter = 994000 dist_mean = 0.0011 dist_std = 0.1600 vf_loss = 0.1195 grad_norm = 3.1205 nat_grad_norm = 0.0597 cg_residual = 1.3260 step_size = 0.5474 reward = 0.0000 fps = 5 mse_loss = 1.6479 
2022-05-01 08:59:53.954689 - gail/main.py:164 - [TRPO] iter = 995000 dist_mean = 0.0036 dist_std = 0.1598 vf_loss = 0.0116 grad_norm = 3.9390 nat_grad_norm = 0.1827 cg_residual = 2.3638 step_size = 0.2700 reward = -0.0000 fps = 5 mse_loss = 1.6048 
2022-05-01 08:59:54.234170 - gail/main.py:191 - [Discriminator] iter = 995000 loss = -0.3826 grad_norm = 2.9416 grad_penalty = 0.0566 regularization = 0.0000 true_logits = 0.0073 fake_logits = -0.4319 true_prob = 0.5062 fake_prob = 0.4134 
2022-05-01 09:02:07.063759 - gail/main.py:132 - [Evaluate] iter = 995000 episode={ returns = 3567.9876 lengths = 1000 } discounted_episode={ returns = 2211.9072 lengths = 1000 } 
2022-05-01 09:02:16.736872 - gail/main.py:164 - [TRPO] iter = 996000 dist_mean = 0.0189 dist_std = 0.1602 vf_loss = 0.0163 grad_norm = 2.4918 nat_grad_norm = 0.1404 cg_residual = 2.0211 step_size = 0.3676 reward = -0.0000 fps = 7 mse_loss = 1.6220 
2022-05-01 09:02:26.260529 - gail/main.py:164 - [TRPO] iter = 997000 dist_mean = 0.0160 dist_std = 0.1605 vf_loss = 0.0153 grad_norm = 3.2076 nat_grad_norm = 0.1305 cg_residual = 2.0195 step_size = 0.3797 reward = 0.0000 fps = 6 mse_loss = 1.6432 
2022-05-01 09:02:35.984771 - gail/main.py:164 - [TRPO] iter = 998000 dist_mean = 0.0189 dist_std = 0.1602 vf_loss = 0.0161 grad_norm = 3.2698 nat_grad_norm = 0.0977 cg_residual = 1.5477 step_size = 0.4222 reward = 0.0000 fps = 6 mse_loss = 1.6114 
2022-05-01 09:02:45.661730 - gail/main.py:164 - [TRPO] iter = 999000 dist_mean = 0.0098 dist_std = 0.1601 vf_loss = 0.0182 grad_norm = 3.7634 nat_grad_norm = 0.1016 cg_residual = 0.5979 step_size = 0.3449 reward = -0.0000 fps = 5 mse_loss = 1.6163 
2022-05-01 09:02:55.244231 - gail/main.py:164 - [TRPO] iter = 1000000 dist_mean = 0.0106 dist_std = 0.1601 vf_loss = 0.0154 grad_norm = 4.7169 nat_grad_norm = 0.0849 cg_residual = 2.2377 step_size = 0.4707 reward = -0.0000 fps = 5 mse_loss = 1.4813 
2022-05-01 09:02:55.511176 - gail/main.py:191 - [Discriminator] iter = 1000000 loss = -0.4218 grad_norm = 2.8334 grad_penalty = 0.0541 regularization = 0.0000 true_logits = -0.0156 fake_logits = -0.4915 true_prob = 0.4979 fake_prob = 0.3978 
2022-05-01 09:05:07.049391 - gail/main.py:132 - [Evaluate] iter = 1000000 episode={ returns = 3591.3739 lengths = 1000 } discounted_episode={ returns = 2225.1290 lengths = 1000 } 
2022-05-01 09:05:16.382211 - gail/main.py:164 - [TRPO] iter = 1001000 dist_mean = 0.0154 dist_std = 0.1606 vf_loss = 0.0205 grad_norm = 3.5818 nat_grad_norm = 0.0672 cg_residual = 0.3431 step_size = 0.5545 reward = -0.0000 fps = 7 mse_loss = 1.5777 
2022-05-01 09:05:25.984250 - gail/main.py:164 - [TRPO] iter = 1002000 dist_mean = 0.0113 dist_std = 0.1602 vf_loss = 0.0144 grad_norm = 2.7016 nat_grad_norm = 0.0765 cg_residual = 1.1106 step_size = 0.5079 reward = -0.0000 fps = 6 mse_loss = 1.6015 
2022-05-01 09:05:35.795240 - gail/main.py:164 - [TRPO] iter = 1003000 dist_mean = 0.0389 dist_std = 0.1604 vf_loss = 0.0183 grad_norm = 2.7607 nat_grad_norm = 0.0694 cg_residual = 0.9187 step_size = 0.5542 reward = 0.0000 fps = 6 mse_loss = 1.5309 
2022-05-01 09:05:45.398632 - gail/main.py:164 - [TRPO] iter = 1004000 dist_mean = 0.0335 dist_std = 0.1603 vf_loss = 0.0208 grad_norm = 2.7039 nat_grad_norm = 0.1011 cg_residual = 1.7386 step_size = 0.4049 reward = 0.0000 fps = 5 mse_loss = 1.5719 
2022-05-01 09:05:55.593020 - gail/main.py:164 - [TRPO] iter = 1005000 dist_mean = 0.0178 dist_std = 0.1601 vf_loss = 0.0181 grad_norm = 2.7061 nat_grad_norm = 0.0811 cg_residual = 0.7703 step_size = 0.4969 reward = 0.0000 fps = 5 mse_loss = 1.5302 
2022-05-01 09:05:55.823051 - gail/main.py:191 - [Discriminator] iter = 1005000 loss = -0.4235 grad_norm = 3.1446 grad_penalty = 0.0542 regularization = 0.0000 true_logits = -0.0038 fake_logits = -0.4814 true_prob = 0.5001 fake_prob = 0.3985 
2022-05-01 09:08:06.212964 - gail/main.py:132 - [Evaluate] iter = 1005000 episode={ returns = 3588.5662 lengths = 1000 } discounted_episode={ returns = 2225.1293 lengths = 1000 } 
2022-05-01 09:08:15.804124 - gail/main.py:164 - [TRPO] iter = 1006000 dist_mean = 0.0181 dist_std = 0.1600 vf_loss = 0.0127 grad_norm = 3.6706 nat_grad_norm = 0.0925 cg_residual = 2.1056 step_size = 0.4314 reward = -0.0000 fps = 7 mse_loss = 1.5421 
2022-05-01 09:08:25.236729 - gail/main.py:164 - [TRPO] iter = 1007000 dist_mean = 0.0169 dist_std = 0.1602 vf_loss = 0.0099 grad_norm = 2.6609 nat_grad_norm = 0.1292 cg_residual = 0.8162 step_size = 0.3751 reward = 0.0000 fps = 6 mse_loss = 1.6135 
2022-05-01 09:08:34.996470 - gail/main.py:164 - [TRPO] iter = 1008000 dist_mean = 0.0280 dist_std = 0.1600 vf_loss = 0.0196 grad_norm = 4.0185 nat_grad_norm = 0.1081 cg_residual = 1.3196 step_size = 0.4562 reward = -0.0000 fps = 6 mse_loss = 1.5604 
2022-05-01 09:08:44.452091 - gail/main.py:164 - [TRPO] iter = 1009000 dist_mean = 0.0259 dist_std = 0.1600 vf_loss = 0.0126 grad_norm = 3.4526 nat_grad_norm = 0.0978 cg_residual = 1.4524 step_size = 0.4181 reward = -0.0000 fps = 5 mse_loss = 1.5579 
2022-05-01 09:08:54.088776 - gail/main.py:164 - [TRPO] iter = 1010000 dist_mean = 0.0077 dist_std = 0.1598 vf_loss = 0.0706 grad_norm = 4.0649 nat_grad_norm = 0.0750 cg_residual = 0.9571 step_size = 0.5327 reward = 0.0000 fps = 5 mse_loss = 1.5501 
2022-05-01 09:08:54.317678 - gail/main.py:191 - [Discriminator] iter = 1010000 loss = -0.4418 grad_norm = 4.2413 grad_penalty = 0.0553 regularization = 0.0000 true_logits = 0.0198 fake_logits = -0.4773 true_prob = 0.5051 fake_prob = 0.3975 
2022-05-01 09:11:07.511763 - gail/main.py:132 - [Evaluate] iter = 1010000 episode={ returns = 3585.1362 lengths = 1000 } discounted_episode={ returns = 2217.2809 lengths = 1000 } 
2022-05-01 09:11:17.211742 - gail/main.py:164 - [TRPO] iter = 1011000 dist_mean = 0.0185 dist_std = 0.1594 vf_loss = 0.0145 grad_norm = 4.0149 nat_grad_norm = 0.0973 cg_residual = 1.3202 step_size = 0.4374 reward = -0.0000 fps = 6 mse_loss = 1.5180 
2022-05-01 09:11:26.823454 - gail/main.py:164 - [TRPO] iter = 1012000 dist_mean = 0.0211 dist_std = 0.1588 vf_loss = 0.0101 grad_norm = 3.2159 nat_grad_norm = 0.0721 cg_residual = 0.9523 step_size = 0.4563 reward = 0.0000 fps = 6 mse_loss = 1.4333 
2022-05-01 09:11:36.724276 - gail/main.py:164 - [TRPO] iter = 1013000 dist_mean = 0.0406 dist_std = 0.1586 vf_loss = 0.0088 grad_norm = 2.5807 nat_grad_norm = 0.0774 cg_residual = 0.9251 step_size = 0.5449 reward = 0.0000 fps = 6 mse_loss = 1.4412 
2022-05-01 09:11:46.276768 - gail/main.py:164 - [TRPO] iter = 1014000 dist_mean = 0.0530 dist_std = 0.1590 vf_loss = 0.0408 grad_norm = 3.1384 nat_grad_norm = 0.1161 cg_residual = 0.9638 step_size = 0.3921 reward = -0.0000 fps = 5 mse_loss = 1.4816 
2022-05-01 09:11:56.232269 - gail/main.py:164 - [TRPO] iter = 1015000 dist_mean = 0.0194 dist_std = 0.1586 vf_loss = 0.0112 grad_norm = 3.0808 nat_grad_norm = 0.0889 cg_residual = 1.6154 step_size = 0.5057 reward = 0.0000 fps = 5 mse_loss = 1.3989 
2022-05-01 09:11:56.450467 - gail/main.py:191 - [Discriminator] iter = 1015000 loss = -0.4483 grad_norm = 3.1746 grad_penalty = 0.0513 regularization = 0.0000 true_logits = -0.0057 fake_logits = -0.5052 true_prob = 0.4995 fake_prob = 0.3914 
2022-05-01 09:14:10.913875 - gail/main.py:132 - [Evaluate] iter = 1015000 episode={ returns = 3594.2419 lengths = 1000 } discounted_episode={ returns = 2222.1261 lengths = 1000 } 
2022-05-01 09:14:20.542959 - gail/main.py:164 - [TRPO] iter = 1016000 dist_mean = 0.0036 dist_std = 0.1585 vf_loss = 0.0206 grad_norm = 2.4237 nat_grad_norm = 0.1276 cg_residual = 3.0958 step_size = 0.4102 reward = 0.0000 fps = 6 mse_loss = 1.3882 
2022-05-01 09:14:30.358671 - gail/main.py:164 - [TRPO] iter = 1017000 dist_mean = 0.0251 dist_std = 0.1586 vf_loss = 0.0205 grad_norm = 2.4426 nat_grad_norm = 0.1268 cg_residual = 1.2441 step_size = 0.4423 reward = -0.0000 fps = 6 mse_loss = 1.5670 
2022-05-01 09:14:40.726252 - gail/main.py:164 - [TRPO] iter = 1018000 dist_mean = 0.0222 dist_std = 0.1576 vf_loss = 0.0117 grad_norm = 2.6953 nat_grad_norm = 0.0992 cg_residual = 1.2004 step_size = 0.4088 reward = 0.0000 fps = 6 mse_loss = 1.4543 
2022-05-01 09:14:50.752724 - gail/main.py:164 - [TRPO] iter = 1019000 dist_mean = 0.0117 dist_std = 0.1578 vf_loss = 0.0138 grad_norm = 2.7490 nat_grad_norm = 0.0945 cg_residual = 1.8213 step_size = 0.4607 reward = 0.0000 fps = 5 mse_loss = 1.5083 
2022-05-01 09:15:00.758408 - gail/main.py:164 - [TRPO] iter = 1020000 dist_mean = 0.0346 dist_std = 0.1577 vf_loss = 0.0112 grad_norm = 2.4505 nat_grad_norm = 0.0927 cg_residual = 1.0645 step_size = 0.5045 reward = -0.0000 fps = 5 mse_loss = 1.4911 
2022-05-01 09:15:01.030112 - gail/main.py:191 - [Discriminator] iter = 1020000 loss = -0.3858 grad_norm = 3.2450 grad_penalty = 0.0491 regularization = 0.0000 true_logits = -0.0604 fake_logits = -0.4954 true_prob = 0.4860 fake_prob = 0.3951 
2022-05-01 09:17:13.031883 - gail/main.py:132 - [Evaluate] iter = 1020000 episode={ returns = 3594.6972 lengths = 1000 } discounted_episode={ returns = 2221.3988 lengths = 1000 } 
2022-05-01 09:17:22.927831 - gail/main.py:164 - [TRPO] iter = 1021000 dist_mean = 0.0078 dist_std = 0.1576 vf_loss = 0.0248 grad_norm = 3.2588 nat_grad_norm = 0.0665 cg_residual = 0.4868 step_size = 0.5675 reward = -0.0000 fps = 7 mse_loss = 1.4588 
2022-05-01 09:17:32.501099 - gail/main.py:164 - [TRPO] iter = 1022000 dist_mean = 0.0107 dist_std = 0.1578 vf_loss = 0.0133 grad_norm = 3.4218 nat_grad_norm = 0.0948 cg_residual = 1.1501 step_size = 0.4260 reward = 0.0000 fps = 6 mse_loss = 1.4441 
2022-05-01 09:17:42.215154 - gail/main.py:164 - [TRPO] iter = 1023000 dist_mean = 0.0097 dist_std = 0.1578 vf_loss = 0.0234 grad_norm = 4.5719 nat_grad_norm = 0.0507 cg_residual = 0.7861 step_size = 0.5699 reward = -0.0000 fps = 6 mse_loss = 1.3189 
2022-05-01 09:17:52.805715 - gail/main.py:164 - [TRPO] iter = 1024000 dist_mean = 0.0188 dist_std = 0.1577 vf_loss = 0.0093 grad_norm = 3.8490 nat_grad_norm = 0.1283 cg_residual = 1.7068 step_size = 0.3498 reward = 0.0000 fps = 5 mse_loss = 1.4140 
2022-05-01 09:18:02.908630 - gail/main.py:164 - [TRPO] iter = 1025000 dist_mean = -0.0008 dist_std = 0.1576 vf_loss = 0.0124 grad_norm = 3.6320 nat_grad_norm = 0.1220 cg_residual = 1.9399 step_size = 0.3531 reward = -0.0000 fps = 5 mse_loss = 1.4262 
2022-05-01 09:18:03.142928 - gail/main.py:191 - [Discriminator] iter = 1025000 loss = -0.3710 grad_norm = 3.1684 grad_penalty = 0.0549 regularization = 0.0000 true_logits = -0.0353 fake_logits = -0.4612 true_prob = 0.4920 fake_prob = 0.4005 
2022-05-01 09:20:14.354916 - gail/main.py:132 - [Evaluate] iter = 1025000 episode={ returns = 3578.4052 lengths = 1000 } discounted_episode={ returns = 2209.7468 lengths = 1000 } 
2022-05-01 09:20:23.921649 - gail/main.py:164 - [TRPO] iter = 1026000 dist_mean = 0.0254 dist_std = 0.1577 vf_loss = 0.0852 grad_norm = 2.6853 nat_grad_norm = 0.0613 cg_residual = 0.4627 step_size = 0.6030 reward = -0.0000 fps = 7 mse_loss = 1.4691 
2022-05-01 09:20:33.449439 - gail/main.py:164 - [TRPO] iter = 1027000 dist_mean = 0.0172 dist_std = 0.1577 vf_loss = 0.0250 grad_norm = 3.1685 nat_grad_norm = 0.1032 cg_residual = 1.5615 step_size = 0.3671 reward = 0.0000 fps = 6 mse_loss = 1.3294 
2022-05-01 09:20:43.209922 - gail/main.py:164 - [TRPO] iter = 1028000 dist_mean = 0.0093 dist_std = 0.1577 vf_loss = 0.0149 grad_norm = 3.1902 nat_grad_norm = 0.1023 cg_residual = 1.4013 step_size = 0.3937 reward = 0.0000 fps = 6 mse_loss = 1.4496 
2022-05-01 09:20:53.211320 - gail/main.py:164 - [TRPO] iter = 1029000 dist_mean = 0.0091 dist_std = 0.1577 vf_loss = 0.0140 grad_norm = 3.2436 nat_grad_norm = 0.1073 cg_residual = 1.6868 step_size = 0.3643 reward = 0.0000 fps = 5 mse_loss = 1.4550 
2022-05-01 09:21:03.093092 - gail/main.py:164 - [TRPO] iter = 1030000 dist_mean = 0.0426 dist_std = 0.1577 vf_loss = 0.0284 grad_norm = 2.3324 nat_grad_norm = 0.0971 cg_residual = 1.7847 step_size = 0.4533 reward = 0.0000 fps = 5 mse_loss = 1.4302 
2022-05-01 09:21:03.298814 - gail/main.py:191 - [Discriminator] iter = 1030000 loss = -0.5967 grad_norm = 3.4210 grad_penalty = 0.0570 regularization = 0.0000 true_logits = -0.1841 fake_logits = -0.8378 true_prob = 0.4587 fake_prob = 0.3282 
2022-05-01 09:23:15.649616 - gail/main.py:132 - [Evaluate] iter = 1030000 episode={ returns = 3568.5910 lengths = 1000 } discounted_episode={ returns = 2210.6019 lengths = 1000 } 
2022-05-01 09:23:25.230236 - gail/main.py:164 - [TRPO] iter = 1031000 dist_mean = 0.0148 dist_std = 0.1575 vf_loss = 0.0523 grad_norm = 3.6712 nat_grad_norm = 0.0866 cg_residual = 0.8427 step_size = 0.4386 reward = 0.0000 fps = 7 mse_loss = 1.3530 
2022-05-01 09:23:34.939150 - gail/main.py:164 - [TRPO] iter = 1032000 dist_mean = 0.0268 dist_std = 0.1576 vf_loss = 0.0210 grad_norm = 3.9706 nat_grad_norm = 0.1169 cg_residual = 1.2810 step_size = 0.3964 reward = 0.0000 fps = 6 mse_loss = 1.3998 
2022-05-01 09:23:45.014887 - gail/main.py:164 - [TRPO] iter = 1033000 dist_mean = 0.0246 dist_std = 0.1572 vf_loss = 0.0277 grad_norm = 2.6876 nat_grad_norm = 0.1041 cg_residual = 2.7690 step_size = 0.4276 reward = -0.0000 fps = 6 mse_loss = 1.3667 
2022-05-01 09:23:54.901626 - gail/main.py:164 - [TRPO] iter = 1034000 dist_mean = 0.0113 dist_std = 0.1571 vf_loss = 0.0318 grad_norm = 2.1106 nat_grad_norm = 0.1054 cg_residual = 1.3134 step_size = 0.4236 reward = 0.0000 fps = 5 mse_loss = 1.3548 
2022-05-01 09:24:04.737128 - gail/main.py:164 - [TRPO] iter = 1035000 dist_mean = 0.0057 dist_std = 0.1568 vf_loss = 0.0354 grad_norm = 2.8769 nat_grad_norm = 0.1158 cg_residual = 1.2916 step_size = 0.3402 reward = 0.0000 fps = 5 mse_loss = 1.3449 
2022-05-01 09:24:04.978295 - gail/main.py:191 - [Discriminator] iter = 1035000 loss = -0.5522 grad_norm = 2.8977 grad_penalty = 0.0658 regularization = 0.0000 true_logits = -0.3591 fake_logits = -0.9771 true_prob = 0.4234 fake_prob = 0.3020 
2022-05-01 09:26:17.473725 - gail/main.py:132 - [Evaluate] iter = 1035000 episode={ returns = 3578.8753 lengths = 1000 } discounted_episode={ returns = 2206.1875 lengths = 1000 } 
2022-05-01 09:26:27.376735 - gail/main.py:164 - [TRPO] iter = 1036000 dist_mean = 0.0001 dist_std = 0.1571 vf_loss = 0.0568 grad_norm = 2.8707 nat_grad_norm = 0.0895 cg_residual = 2.2351 step_size = 0.4551 reward = -0.0000 fps = 7 mse_loss = 1.4060 
2022-05-01 09:26:37.281980 - gail/main.py:164 - [TRPO] iter = 1037000 dist_mean = 0.0121 dist_std = 0.1570 vf_loss = 0.1899 grad_norm = 3.2192 nat_grad_norm = 0.0954 cg_residual = 1.7952 step_size = 0.4076 reward = -0.0000 fps = 6 mse_loss = 1.3677 
2022-05-01 09:26:47.504169 - gail/main.py:164 - [TRPO] iter = 1038000 dist_mean = 0.0241 dist_std = 0.1564 vf_loss = 0.1084 grad_norm = 4.4496 nat_grad_norm = 0.1096 cg_residual = 1.9613 step_size = 0.4041 reward = 0.0000 fps = 6 mse_loss = 1.2948 
2022-05-01 09:26:57.479749 - gail/main.py:164 - [TRPO] iter = 1039000 dist_mean = 0.0176 dist_std = 0.1564 vf_loss = 0.0382 grad_norm = 3.7389 nat_grad_norm = 0.1082 cg_residual = 3.5202 step_size = 0.4187 reward = 0.0000 fps = 5 mse_loss = 1.4077 
2022-05-01 09:27:07.495019 - gail/main.py:164 - [TRPO] iter = 1040000 dist_mean = 0.0393 dist_std = 0.1567 vf_loss = 0.1855 grad_norm = 2.8995 nat_grad_norm = 0.1201 cg_residual = 2.2846 step_size = 0.3846 reward = -0.0000 fps = 5 mse_loss = 1.2606 
2022-05-01 09:27:07.704534 - gail/main.py:191 - [Discriminator] iter = 1040000 loss = -0.5650 grad_norm = 3.1316 grad_penalty = 0.0661 regularization = 0.0000 true_logits = -0.4384 fake_logits = -1.0695 true_prob = 0.4090 fake_prob = 0.2831 
2022-05-01 09:29:17.485387 - gail/main.py:132 - [Evaluate] iter = 1040000 episode={ returns = 3577.5657 lengths = 1000 } discounted_episode={ returns = 2205.3092 lengths = 1000 } 
2022-05-01 09:29:27.160530 - gail/main.py:164 - [TRPO] iter = 1041000 dist_mean = 0.0353 dist_std = 0.1569 vf_loss = 0.1736 grad_norm = 2.4275 nat_grad_norm = 0.0830 cg_residual = 0.9917 step_size = 0.4808 reward = -0.0000 fps = 7 mse_loss = 1.2521 
2022-05-01 09:29:36.705660 - gail/main.py:164 - [TRPO] iter = 1042000 dist_mean = 0.0079 dist_std = 0.1565 vf_loss = 0.0752 grad_norm = 2.1755 nat_grad_norm = 0.0863 cg_residual = 0.7748 step_size = 0.5454 reward = -0.0000 fps = 6 mse_loss = 1.3194 
2022-05-01 09:29:46.415142 - gail/main.py:164 - [TRPO] iter = 1043000 dist_mean = 0.0265 dist_std = 0.1566 vf_loss = 0.1501 grad_norm = 3.6576 nat_grad_norm = 0.0712 cg_residual = 1.4089 step_size = 0.4529 reward = 0.0000 fps = 6 mse_loss = 1.3179 
2022-05-01 09:29:56.193681 - gail/main.py:164 - [TRPO] iter = 1044000 dist_mean = 0.0171 dist_std = 0.1563 vf_loss = 0.0385 grad_norm = 2.3358 nat_grad_norm = 0.0684 cg_residual = 0.6379 step_size = 0.5475 reward = 0.0000 fps = 5 mse_loss = 1.3804 
2022-05-01 09:30:05.977809 - gail/main.py:164 - [TRPO] iter = 1045000 dist_mean = 0.0224 dist_std = 0.1561 vf_loss = 0.1036 grad_norm = 3.3660 nat_grad_norm = 0.1081 cg_residual = 2.5136 step_size = 0.3701 reward = -0.0000 fps = 5 mse_loss = 1.4329 
2022-05-01 09:30:06.248775 - gail/main.py:191 - [Discriminator] iter = 1045000 loss = -0.4022 grad_norm = 3.0149 grad_penalty = 0.0517 regularization = 0.0000 true_logits = -0.4453 fake_logits = -0.8992 true_prob = 0.4096 fake_prob = 0.3175 
2022-05-01 09:31:43.269219 - gail/main.py:132 - [Evaluate] iter = 1045000 episode={ returns = 2375.6651 lengths = 678 } discounted_episode={ returns = 1836.9753 lengths = 806 } 
2022-05-01 09:31:52.871605 - gail/main.py:164 - [TRPO] iter = 1046000 dist_mean = 0.0161 dist_std = 0.1553 vf_loss = 0.2175 grad_norm = 2.9114 nat_grad_norm = 0.0521 cg_residual = 0.9019 step_size = 0.6286 reward = -0.0000 fps = 9 mse_loss = 1.3881 
2022-05-01 09:32:02.871327 - gail/main.py:164 - [TRPO] iter = 1047000 dist_mean = 0.0478 dist_std = 0.1556 vf_loss = 0.1519 grad_norm = 2.6490 nat_grad_norm = 0.1033 cg_residual = 2.5412 step_size = 0.4131 reward = 0.0000 fps = 8 mse_loss = 1.3655 
2022-05-01 09:32:12.790770 - gail/main.py:164 - [TRPO] iter = 1048000 dist_mean = 0.0317 dist_std = 0.1555 vf_loss = 0.0867 grad_norm = 2.7959 nat_grad_norm = 0.0678 cg_residual = 0.9060 step_size = 0.5847 reward = -0.0000 fps = 7 mse_loss = 1.3559 
2022-05-01 09:32:22.692752 - gail/main.py:164 - [TRPO] iter = 1049000 dist_mean = 0.0141 dist_std = 0.1552 vf_loss = 0.1000 grad_norm = 2.2494 nat_grad_norm = 0.0603 cg_residual = 0.7512 step_size = 0.5732 reward = 0.0000 fps = 7 mse_loss = 1.4001 
2022-05-01 09:32:32.152326 - gail/main.py:164 - [TRPO] iter = 1050000 dist_mean = 0.0238 dist_std = 0.1555 vf_loss = 0.0395 grad_norm = 3.2468 nat_grad_norm = 0.0615 cg_residual = 0.8074 step_size = 0.5661 reward = 0.0000 fps = 6 mse_loss = 1.2900 
2022-05-01 09:32:32.396501 - gail/main.py:191 - [Discriminator] iter = 1050000 loss = -0.4283 grad_norm = 2.8122 grad_penalty = 0.0454 regularization = 0.0000 true_logits = -0.3859 fake_logits = -0.8597 true_prob = 0.4224 fake_prob = 0.3263 
2022-05-01 09:33:08.135200 - gail/main.py:132 - [Evaluate] iter = 1050000 episode={ returns = 809.4064 lengths = 264 } discounted_episode={ returns = 701.2421 lengths = 265 } 
2022-05-01 09:33:17.634104 - gail/main.py:164 - [TRPO] iter = 1051000 dist_mean = 0.0270 dist_std = 0.1557 vf_loss = 0.0810 grad_norm = 3.9794 nat_grad_norm = 0.1110 cg_residual = 3.2555 step_size = 0.3836 reward = 0.0000 fps = 22 mse_loss = 1.3890 
2022-05-01 09:33:26.939642 - gail/main.py:164 - [TRPO] iter = 1052000 dist_mean = 0.0331 dist_std = 0.1558 vf_loss = 0.0991 grad_norm = 2.8985 nat_grad_norm = 0.0658 cg_residual = 0.9045 step_size = 0.5572 reward = -0.0000 fps = 18 mse_loss = 1.3100 
2022-05-01 09:33:36.567890 - gail/main.py:164 - [TRPO] iter = 1053000 dist_mean = 0.0487 dist_std = 0.1559 vf_loss = 0.0929 grad_norm = 3.3490 nat_grad_norm = 0.0845 cg_residual = 1.1233 step_size = 0.4154 reward = 0.0000 fps = 15 mse_loss = 1.3257 
2022-05-01 09:33:46.094814 - gail/main.py:164 - [TRPO] iter = 1054000 dist_mean = 0.0403 dist_std = 0.1561 vf_loss = 0.0786 grad_norm = 4.1354 nat_grad_norm = 0.0892 cg_residual = 1.1681 step_size = 0.4061 reward = -0.0000 fps = 13 mse_loss = 1.3816 
2022-05-01 09:33:55.457099 - gail/main.py:164 - [TRPO] iter = 1055000 dist_mean = 0.0351 dist_std = 0.1563 vf_loss = 0.0651 grad_norm = 3.5577 nat_grad_norm = 0.0855 cg_residual = 1.3867 step_size = 0.5200 reward = -0.0000 fps = 12 mse_loss = 1.4009 
2022-05-01 09:33:55.684571 - gail/main.py:191 - [Discriminator] iter = 1055000 loss = -0.4520 grad_norm = 2.8706 grad_penalty = 0.0434 regularization = 0.0000 true_logits = -0.3425 fake_logits = -0.8379 true_prob = 0.4364 fake_prob = 0.3318 
2022-05-01 09:34:30.631330 - gail/main.py:132 - [Evaluate] iter = 1055000 episode={ returns = 827.7679 lengths = 270 } discounted_episode={ returns = 715.6395 lengths = 270 } 
2022-05-01 09:34:40.276762 - gail/main.py:164 - [TRPO] iter = 1056000 dist_mean = 0.0298 dist_std = 0.1566 vf_loss = 0.0547 grad_norm = 3.5156 nat_grad_norm = 0.1139 cg_residual = 1.7046 step_size = 0.3708 reward = -0.0000 fps = 22 mse_loss = 1.3790 
2022-05-01 09:34:50.233564 - gail/main.py:164 - [TRPO] iter = 1057000 dist_mean = 0.0312 dist_std = 0.1566 vf_loss = 0.0512 grad_norm = 4.0474 nat_grad_norm = 0.0717 cg_residual = 1.0708 step_size = 0.4731 reward = 0.0000 fps = 18 mse_loss = 1.4109 
2022-05-01 09:35:00.043062 - gail/main.py:164 - [TRPO] iter = 1058000 dist_mean = 0.0265 dist_std = 0.1568 vf_loss = 0.1698 grad_norm = 3.9500 nat_grad_norm = 0.0894 cg_residual = 1.1881 step_size = 0.4441 reward = 0.0000 fps = 15 mse_loss = 1.3338 
2022-05-01 09:35:10.206791 - gail/main.py:164 - [TRPO] iter = 1059000 dist_mean = 0.0101 dist_std = 0.1570 vf_loss = 0.2077 grad_norm = 3.3799 nat_grad_norm = 0.0491 cg_residual = 0.6190 step_size = 0.6164 reward = -0.0000 fps = 13 mse_loss = 1.3996 
2022-05-01 09:35:19.813869 - gail/main.py:164 - [TRPO] iter = 1060000 dist_mean = 0.0104 dist_std = 0.1569 vf_loss = 0.1068 grad_norm = 4.0460 nat_grad_norm = 0.0540 cg_residual = 0.9269 step_size = 0.5749 reward = -0.0000 fps = 11 mse_loss = 1.2753 
2022-05-01 09:35:20.044323 - gail/main.py:191 - [Discriminator] iter = 1060000 loss = -0.4446 grad_norm = 2.9385 grad_penalty = 0.0473 regularization = 0.0000 true_logits = -0.2570 fake_logits = -0.7489 true_prob = 0.4504 fake_prob = 0.3459 
2022-05-01 09:36:08.343253 - gail/main.py:132 - [Evaluate] iter = 1060000 episode={ returns = 1154.1009 lengths = 357 } discounted_episode={ returns = 977.0886 lengths = 367 } 
2022-05-01 09:36:18.077236 - gail/main.py:164 - [TRPO] iter = 1061000 dist_mean = 0.0165 dist_std = 0.1571 vf_loss = 0.0404 grad_norm = 2.5650 nat_grad_norm = 0.1079 cg_residual = 1.7030 step_size = 0.4211 reward = 0.0000 fps = 17 mse_loss = 1.3107 
2022-05-01 09:36:27.524684 - gail/main.py:164 - [TRPO] iter = 1062000 dist_mean = 0.0634 dist_std = 0.1572 vf_loss = 0.0725 grad_norm = 2.5583 nat_grad_norm = 0.1099 cg_residual = 3.1834 step_size = 0.4217 reward = -0.0000 fps = 14 mse_loss = 1.3846 
2022-05-01 09:36:37.034057 - gail/main.py:164 - [TRPO] iter = 1063000 dist_mean = 0.0095 dist_std = 0.1566 vf_loss = 0.0964 grad_norm = 3.2808 nat_grad_norm = 0.0808 cg_residual = 0.9950 step_size = 0.5042 reward = -0.0000 fps = 12 mse_loss = 1.3379 
2022-05-01 09:36:46.706908 - gail/main.py:164 - [TRPO] iter = 1064000 dist_mean = 0.0144 dist_std = 0.1563 vf_loss = 0.0263 grad_norm = 3.9423 nat_grad_norm = 0.0952 cg_residual = 1.6653 step_size = 0.4770 reward = -0.0000 fps = 11 mse_loss = 1.2800 
2022-05-01 09:36:56.362505 - gail/main.py:164 - [TRPO] iter = 1065000 dist_mean = 0.0489 dist_std = 0.1556 vf_loss = 0.0549 grad_norm = 2.7319 nat_grad_norm = 0.0815 cg_residual = 0.9087 step_size = 0.5219 reward = -0.0000 fps = 10 mse_loss = 1.3056 
2022-05-01 09:36:56.578206 - gail/main.py:191 - [Discriminator] iter = 1065000 loss = -0.5378 grad_norm = 3.1657 grad_penalty = 0.0469 regularization = 0.0000 true_logits = -0.1751 fake_logits = -0.7597 true_prob = 0.4650 fake_prob = 0.3442 
2022-05-01 09:37:57.738918 - gail/main.py:132 - [Evaluate] iter = 1065000 episode={ returns = 1548.6897 lengths = 464 } discounted_episode={ returns = 1184.8523 lengths = 453 } 
2022-05-01 09:38:07.526378 - gail/main.py:164 - [TRPO] iter = 1066000 dist_mean = 0.0258 dist_std = 0.1558 vf_loss = 0.0264 grad_norm = 2.7582 nat_grad_norm = 0.1034 cg_residual = 2.4825 step_size = 0.4629 reward = -0.0000 fps = 14 mse_loss = 1.3051 
2022-05-01 09:38:17.138039 - gail/main.py:164 - [TRPO] iter = 1067000 dist_mean = 0.0111 dist_std = 0.1555 vf_loss = 0.0256 grad_norm = 3.9758 nat_grad_norm = 0.0911 cg_residual = 1.1062 step_size = 0.4500 reward = -0.0000 fps = 12 mse_loss = 1.3462 
2022-05-01 09:38:26.750790 - gail/main.py:164 - [TRPO] iter = 1068000 dist_mean = 0.0256 dist_std = 0.1553 vf_loss = 0.1259 grad_norm = 2.5835 nat_grad_norm = 0.0628 cg_residual = 0.5735 step_size = 0.6627 reward = -0.0000 fps = 11 mse_loss = 1.3079 
2022-05-01 09:38:36.258389 - gail/main.py:164 - [TRPO] iter = 1069000 dist_mean = 0.0289 dist_std = 0.1559 vf_loss = 0.0272 grad_norm = 2.3953 nat_grad_norm = 0.0730 cg_residual = 0.6291 step_size = 0.5750 reward = 0.0000 fps = 10 mse_loss = 1.3567 
2022-05-01 09:38:46.298751 - gail/main.py:164 - [TRPO] iter = 1070000 dist_mean = 0.0166 dist_std = 0.1553 vf_loss = 0.0229 grad_norm = 3.0311 nat_grad_norm = 0.1162 cg_residual = 2.1350 step_size = 0.3467 reward = -0.0000 fps = 9 mse_loss = 1.3836 
2022-05-01 09:38:46.517970 - gail/main.py:191 - [Discriminator] iter = 1070000 loss = -0.4236 grad_norm = 3.0125 grad_penalty = 0.0480 regularization = 0.0000 true_logits = -0.1645 fake_logits = -0.6361 true_prob = 0.4661 fake_prob = 0.3677 
2022-05-01 09:40:49.484881 - gail/main.py:132 - [Evaluate] iter = 1070000 episode={ returns = 3318.9455 lengths = 940 } discounted_episode={ returns = 2026.2194 lengths = 927 } 
2022-05-01 09:40:59.312532 - gail/main.py:164 - [TRPO] iter = 1071000 dist_mean = 0.0221 dist_std = 0.1552 vf_loss = 0.0219 grad_norm = 2.9941 nat_grad_norm = 0.1057 cg_residual = 1.6518 step_size = 0.3580 reward = 0.0000 fps = 7 mse_loss = 1.3434 
2022-05-01 09:41:09.075286 - gail/main.py:164 - [TRPO] iter = 1072000 dist_mean = 0.0597 dist_std = 0.1555 vf_loss = 0.1579 grad_norm = 2.1091 nat_grad_norm = 0.1171 cg_residual = 1.0652 step_size = 0.4075 reward = -0.0000 fps = 7 mse_loss = 1.3472 
2022-05-01 09:41:18.848284 - gail/main.py:164 - [TRPO] iter = 1073000 dist_mean = 0.0253 dist_std = 0.1556 vf_loss = 0.0438 grad_norm = 2.3961 nat_grad_norm = 0.0640 cg_residual = 0.7139 step_size = 0.5455 reward = -0.0000 fps = 6 mse_loss = 1.3171 
2022-05-01 09:41:28.612832 - gail/main.py:164 - [TRPO] iter = 1074000 dist_mean = 0.0340 dist_std = 0.1556 vf_loss = 0.0951 grad_norm = 1.9552 nat_grad_norm = 0.0587 cg_residual = 0.3617 step_size = 0.7052 reward = -0.0000 fps = 6 mse_loss = 1.3735 
2022-05-01 09:41:38.313637 - gail/main.py:164 - [TRPO] iter = 1075000 dist_mean = 0.0162 dist_std = 0.1554 vf_loss = 0.0252 grad_norm = 2.4533 nat_grad_norm = 0.0700 cg_residual = 1.9096 step_size = 0.5609 reward = 0.0000 fps = 5 mse_loss = 1.3841 
2022-05-01 09:41:38.532613 - gail/main.py:191 - [Discriminator] iter = 1075000 loss = -0.4856 grad_norm = 3.3877 grad_penalty = 0.0431 regularization = 0.0000 true_logits = -0.0875 fake_logits = -0.6162 true_prob = 0.4812 fake_prob = 0.3683 
2022-05-01 09:42:54.690306 - gail/main.py:132 - [Evaluate] iter = 1075000 episode={ returns = 2093.4658 lengths = 615 } discounted_episode={ returns = 1277.4697 lengths = 510 } 
2022-05-01 09:43:04.520128 - gail/main.py:164 - [TRPO] iter = 1076000 dist_mean = 0.0322 dist_std = 0.1555 vf_loss = 0.0854 grad_norm = 5.1477 nat_grad_norm = 0.1078 cg_residual = 2.7704 step_size = 0.3390 reward = 0.0000 fps = 11 mse_loss = 1.3192 
2022-05-01 09:43:14.089747 - gail/main.py:164 - [TRPO] iter = 1077000 dist_mean = 0.0434 dist_std = 0.1555 vf_loss = 0.1417 grad_norm = 2.8347 nat_grad_norm = 0.0932 cg_residual = 0.9330 step_size = 0.4708 reward = 0.0000 fps = 10 mse_loss = 1.3460 
2022-05-01 09:43:23.941168 - gail/main.py:164 - [TRPO] iter = 1078000 dist_mean = 0.0239 dist_std = 0.1556 vf_loss = 0.1283 grad_norm = 4.0479 nat_grad_norm = 0.0662 cg_residual = 0.7998 step_size = 0.5938 reward = 0.0000 fps = 9 mse_loss = 1.3180 
2022-05-01 09:43:33.918795 - gail/main.py:164 - [TRPO] iter = 1079000 dist_mean = 0.0110 dist_std = 0.1559 vf_loss = 0.0949 grad_norm = 4.9932 nat_grad_norm = 0.0702 cg_residual = 0.9109 step_size = 0.5393 reward = -0.0000 fps = 8 mse_loss = 1.3646 
2022-05-01 09:43:43.801797 - gail/main.py:164 - [TRPO] iter = 1080000 dist_mean = 0.0078 dist_std = 0.1559 vf_loss = 0.0690 grad_norm = 2.6405 nat_grad_norm = 0.0890 cg_residual = 1.8394 step_size = 0.5072 reward = -0.0000 fps = 7 mse_loss = 1.3634 
2022-05-01 09:43:44.009575 - gail/main.py:191 - [Discriminator] iter = 1080000 loss = -0.4727 grad_norm = 2.8337 grad_penalty = 0.0449 regularization = 0.0000 true_logits = -0.0281 fake_logits = -0.5457 true_prob = 0.4925 fake_prob = 0.3835 
2022-05-01 09:45:46.137607 - gail/main.py:132 - [Evaluate] iter = 1080000 episode={ returns = 3058.3309 lengths = 858 } discounted_episode={ returns = 2228.0653 lengths = 1000 } 
2022-05-01 09:45:56.113629 - gail/main.py:164 - [TRPO] iter = 1081000 dist_mean = 0.0232 dist_std = 0.1561 vf_loss = 0.0338 grad_norm = 3.2054 nat_grad_norm = 0.0949 cg_residual = 2.6385 step_size = 0.4109 reward = -0.0000 fps = 7 mse_loss = 1.4187 
2022-05-01 09:46:06.032660 - gail/main.py:164 - [TRPO] iter = 1082000 dist_mean = 0.0261 dist_std = 0.1558 vf_loss = 0.0327 grad_norm = 3.5832 nat_grad_norm = 0.0881 cg_residual = 2.0184 step_size = 0.4551 reward = -0.0000 fps = 7 mse_loss = 1.4623 
2022-05-01 09:46:15.741744 - gail/main.py:164 - [TRPO] iter = 1083000 dist_mean = 0.0001 dist_std = 0.1558 vf_loss = 0.0221 grad_norm = 2.7391 nat_grad_norm = 0.1362 cg_residual = 4.8373 step_size = 0.3737 reward = -0.0000 fps = 6 mse_loss = 1.3698 
2022-05-01 09:46:25.538879 - gail/main.py:164 - [TRPO] iter = 1084000 dist_mean = 0.0281 dist_std = 0.1562 vf_loss = 0.0215 grad_norm = 2.6982 nat_grad_norm = 0.1348 cg_residual = 2.3396 step_size = 0.3625 reward = 0.0000 fps = 6 mse_loss = 1.4634 
2022-05-01 09:46:35.307936 - gail/main.py:164 - [TRPO] iter = 1085000 dist_mean = 0.0291 dist_std = 0.1559 vf_loss = 0.0312 grad_norm = 3.4751 nat_grad_norm = 0.0971 cg_residual = 1.2884 step_size = 0.4395 reward = 0.0000 fps = 5 mse_loss = 1.4364 
2022-05-01 09:46:35.522658 - gail/main.py:191 - [Discriminator] iter = 1085000 loss = -0.5125 grad_norm = 2.8691 grad_penalty = 0.0431 regularization = 0.0000 true_logits = 0.0139 fake_logits = -0.5417 true_prob = 0.5013 fake_prob = 0.3848 
2022-05-01 09:47:42.141796 - gail/main.py:132 - [Evaluate] iter = 1085000 episode={ returns = 1973.5393 lengths = 587 } discounted_episode={ returns = 997.9262 lengths = 417 } 
2022-05-01 09:47:52.007728 - gail/main.py:164 - [TRPO] iter = 1086000 dist_mean = 0.0542 dist_std = 0.1556 vf_loss = 0.1191 grad_norm = 2.8889 nat_grad_norm = 0.0917 cg_residual = 0.8447 step_size = 0.4781 reward = -0.0000 fps = 13 mse_loss = 1.4080 
2022-05-01 09:48:01.776425 - gail/main.py:164 - [TRPO] iter = 1087000 dist_mean = 0.0493 dist_std = 0.1558 vf_loss = 0.0584 grad_norm = 3.0214 nat_grad_norm = 0.0998 cg_residual = 1.3290 step_size = 0.4451 reward = -0.0000 fps = 11 mse_loss = 1.4242 
2022-05-01 09:48:11.549288 - gail/main.py:164 - [TRPO] iter = 1088000 dist_mean = 0.0625 dist_std = 0.1562 vf_loss = 0.0644 grad_norm = 2.6295 nat_grad_norm = 0.1259 cg_residual = 2.5459 step_size = 0.4235 reward = -0.0000 fps = 10 mse_loss = 1.4490 
2022-05-01 09:48:21.741477 - gail/main.py:164 - [TRPO] iter = 1089000 dist_mean = 0.0475 dist_std = 0.1564 vf_loss = 0.0313 grad_norm = 3.0300 nat_grad_norm = 0.0851 cg_residual = 0.9046 step_size = 0.4725 reward = 0.0000 fps = 9 mse_loss = 1.4469 
2022-05-01 09:48:31.475904 - gail/main.py:164 - [TRPO] iter = 1090000 dist_mean = 0.0420 dist_std = 0.1566 vf_loss = 0.0490 grad_norm = 2.5632 nat_grad_norm = 0.1048 cg_residual = 0.7695 step_size = 0.4657 reward = 0.0000 fps = 8 mse_loss = 1.4689 
2022-05-01 09:48:31.711551 - gail/main.py:191 - [Discriminator] iter = 1090000 loss = -0.5618 grad_norm = 2.9200 grad_penalty = 0.0525 regularization = 0.0000 true_logits = 0.0183 fake_logits = -0.5961 true_prob = 0.5004 fake_prob = 0.3742 
2022-05-01 09:50:28.829738 - gail/main.py:132 - [Evaluate] iter = 1090000 episode={ returns = 2958.4440 lengths = 832 } discounted_episode={ returns = 2073.6447 lengths = 929 } 
2022-05-01 09:50:38.374264 - gail/main.py:164 - [TRPO] iter = 1091000 dist_mean = 0.0490 dist_std = 0.1567 vf_loss = 0.0256 grad_norm = 3.0263 nat_grad_norm = 0.1341 cg_residual = 2.8369 step_size = 0.3634 reward = 0.0000 fps = 7 mse_loss = 1.3779 
2022-05-01 09:50:47.911572 - gail/main.py:164 - [TRPO] iter = 1092000 dist_mean = -0.0033 dist_std = 0.1569 vf_loss = 0.0417 grad_norm = 3.7760 nat_grad_norm = 0.0787 cg_residual = 1.6193 step_size = 0.4805 reward = -0.0000 fps = 7 mse_loss = 1.5544 
2022-05-01 09:50:57.668799 - gail/main.py:164 - [TRPO] iter = 1093000 dist_mean = 0.0772 dist_std = 0.1572 vf_loss = 0.0601 grad_norm = 4.1027 nat_grad_norm = 0.1296 cg_residual = 1.9223 step_size = 0.3177 reward = -0.0000 fps = 6 mse_loss = 1.3146 
2022-05-01 09:51:07.361441 - gail/main.py:164 - [TRPO] iter = 1094000 dist_mean = 0.0125 dist_std = 0.1570 vf_loss = 0.0278 grad_norm = 3.8944 nat_grad_norm = 0.1021 cg_residual = 1.8777 step_size = 0.4061 reward = -0.0000 fps = 6 mse_loss = 1.3605 
2022-05-01 09:51:16.982199 - gail/main.py:164 - [TRPO] iter = 1095000 dist_mean = 0.0411 dist_std = 0.1569 vf_loss = 0.0472 grad_norm = 2.9877 nat_grad_norm = 0.1031 cg_residual = 1.6803 step_size = 0.4767 reward = 0.0000 fps = 6 mse_loss = 1.4510 
2022-05-01 09:51:17.188609 - gail/main.py:191 - [Discriminator] iter = 1095000 loss = -0.6080 grad_norm = 3.1369 grad_penalty = 0.0623 regularization = 0.0000 true_logits = -0.0325 fake_logits = -0.7028 true_prob = 0.4903 fake_prob = 0.3593 
2022-05-01 09:51:24.252000 - gail/main.py:132 - [Evaluate] iter = 1095000 episode={ returns = 65.0416 lengths = 39 } discounted_episode={ returns = 154.7256 lengths = 73 } 
2022-05-01 09:51:33.739076 - gail/main.py:164 - [TRPO] iter = 1096000 dist_mean = 0.0852 dist_std = 0.1566 vf_loss = 0.0320 grad_norm = 2.4388 nat_grad_norm = 0.0882 cg_residual = 1.2815 step_size = 0.4825 reward = 0.0000 fps = 60 mse_loss = 1.4792 
2022-05-01 09:51:43.527949 - gail/main.py:164 - [TRPO] iter = 1097000 dist_mean = 0.0661 dist_std = 0.1567 vf_loss = 0.1552 grad_norm = 3.6602 nat_grad_norm = 0.1283 cg_residual = 1.8898 step_size = 0.3617 reward = -0.0000 fps = 37 mse_loss = 1.3820 
2022-05-01 09:51:53.149880 - gail/main.py:164 - [TRPO] iter = 1098000 dist_mean = 0.0124 dist_std = 0.1565 vf_loss = 0.0395 grad_norm = 3.2719 nat_grad_norm = 0.0841 cg_residual = 1.7806 step_size = 0.4558 reward = -0.0000 fps = 27 mse_loss = 1.3926 
2022-05-01 09:52:03.491626 - gail/main.py:164 - [TRPO] iter = 1099000 dist_mean = 0.2088 dist_std = 0.1562 vf_loss = 0.1250 grad_norm = 3.2952 nat_grad_norm = 0.1223 cg_residual = 3.8693 step_size = 0.3688 reward = 0.0000 fps = 21 mse_loss = 1.3337 
2022-05-01 09:52:13.822050 - gail/main.py:164 - [TRPO] iter = 1100000 dist_mean = -0.0045 dist_std = 0.1562 vf_loss = 0.1953 grad_norm = 2.3318 nat_grad_norm = 0.0497 cg_residual = 1.3747 step_size = 0.6875 reward = 0.0000 fps = 17 mse_loss = 1.4128 
2022-05-01 09:52:14.090867 - gail/main.py:191 - [Discriminator] iter = 1100000 loss = -0.4467 grad_norm = 3.9484 grad_penalty = 0.0491 regularization = 0.0000 true_logits = 0.0050 fake_logits = -0.4908 true_prob = 0.4991 fake_prob = 0.3918 
2022-05-01 09:52:19.717447 - gail/main.py:132 - [Evaluate] iter = 1100000 episode={ returns = 64.4869 lengths = 39 } discounted_episode={ returns = 63.5241 lengths = 39 } 
2022-05-01 09:52:29.811718 - gail/main.py:164 - [TRPO] iter = 1101000 dist_mean = 0.0486 dist_std = 0.1565 vf_loss = 0.0412 grad_norm = 2.8859 nat_grad_norm = 0.0883 cg_residual = 1.3580 step_size = 0.4602 reward = 0.0000 fps = 63 mse_loss = 1.4418 
2022-05-01 09:52:40.444658 - gail/main.py:164 - [TRPO] iter = 1102000 dist_mean = 0.1352 dist_std = 0.1566 vf_loss = 0.1000 grad_norm = 3.9392 nat_grad_norm = 0.0961 cg_residual = 1.2496 step_size = 0.3512 reward = -0.0000 fps = 37 mse_loss = 1.3602 
2022-05-01 09:52:50.944549 - gail/main.py:164 - [TRPO] iter = 1103000 dist_mean = 0.1064 dist_std = 0.1567 vf_loss = 0.1512 grad_norm = 2.8312 nat_grad_norm = 0.0831 cg_residual = 0.8970 step_size = 0.5222 reward = -0.0000 fps = 27 mse_loss = 1.2953 
2022-05-01 09:53:01.130211 - gail/main.py:164 - [TRPO] iter = 1104000 dist_mean = 0.1244 dist_std = 0.1564 vf_loss = 0.5148 grad_norm = 4.0492 nat_grad_norm = 0.1094 cg_residual = 1.6429 step_size = 0.3553 reward = -0.0000 fps = 21 mse_loss = 1.4310 
2022-05-01 09:53:10.766679 - gail/main.py:164 - [TRPO] iter = 1105000 dist_mean = 0.1206 dist_std = 0.1566 vf_loss = 0.1975 grad_norm = 2.8924 nat_grad_norm = 0.1077 cg_residual = 1.7928 step_size = 0.4752 reward = -0.0000 fps = 17 mse_loss = 1.3832 
2022-05-01 09:53:11.000778 - gail/main.py:191 - [Discriminator] iter = 1105000 loss = -1.1202 grad_norm = 2.9804 grad_penalty = 0.0981 regularization = 0.0000 true_logits = -0.0126 fake_logits = -1.2309 true_prob = 0.4968 fake_prob = 0.2767 
2022-05-01 09:53:16.412802 - gail/main.py:132 - [Evaluate] iter = 1105000 episode={ returns = 64.6339 lengths = 39 } discounted_episode={ returns = 63.9141 lengths = 39 } 
2022-05-01 09:53:25.932383 - gail/main.py:164 - [TRPO] iter = 1106000 dist_mean = 0.0651 dist_std = 0.1565 vf_loss = 0.3142 grad_norm = 2.9066 nat_grad_norm = 0.1142 cg_residual = 1.2754 step_size = 0.4011 reward = 0.0000 fps = 67 mse_loss = 1.4730 
2022-05-01 09:53:35.581196 - gail/main.py:164 - [TRPO] iter = 1107000 dist_mean = 0.0070 dist_std = 0.1567 vf_loss = 0.1698 grad_norm = 2.5610 nat_grad_norm = 0.1130 cg_residual = 1.5368 step_size = 0.4159 reward = -0.0000 fps = 40 mse_loss = 1.3643 
2022-05-01 09:53:45.254395 - gail/main.py:164 - [TRPO] iter = 1108000 dist_mean = 0.0184 dist_std = 0.1569 vf_loss = 0.5910 grad_norm = 3.1819 nat_grad_norm = 0.0915 cg_residual = 0.9081 step_size = 0.4768 reward = -0.0000 fps = 29 mse_loss = 1.4539 
2022-05-01 09:53:55.242394 - gail/main.py:164 - [TRPO] iter = 1109000 dist_mean = 0.0138 dist_std = 0.1569 vf_loss = 0.3974 grad_norm = 3.4537 nat_grad_norm = 0.0856 cg_residual = 1.0021 step_size = 0.4016 reward = -0.0000 fps = 22 mse_loss = 1.4157 
2022-05-01 09:54:05.215367 - gail/main.py:164 - [TRPO] iter = 1110000 dist_mean = 0.0350 dist_std = 0.1567 vf_loss = 0.1487 grad_norm = 3.3914 nat_grad_norm = 0.0993 cg_residual = 1.3562 step_size = 0.4111 reward = 0.0000 fps = 18 mse_loss = 1.4064 
2022-05-01 09:54:05.439591 - gail/main.py:191 - [Discriminator] iter = 1110000 loss = -0.8048 grad_norm = 3.6980 grad_penalty = 0.0993 regularization = 0.0000 true_logits = -0.0523 fake_logits = -0.9564 true_prob = 0.4907 fake_prob = 0.3244 
2022-05-01 09:55:49.360316 - gail/main.py:132 - [Evaluate] iter = 1110000 episode={ returns = 2976.9754 lengths = 824 } discounted_episode={ returns = 1793.8791 lengths = 751 } 
2022-05-01 09:55:59.517779 - gail/main.py:164 - [TRPO] iter = 1111000 dist_mean = 0.0030 dist_std = 0.1568 vf_loss = 0.0469 grad_norm = 3.9316 nat_grad_norm = 0.1448 cg_residual = 2.9514 step_size = 0.3246 reward = 0.0000 fps = 8 mse_loss = 1.3942 
2022-05-01 09:56:09.214217 - gail/main.py:164 - [TRPO] iter = 1112000 dist_mean = 0.0145 dist_std = 0.1569 vf_loss = 0.4097 grad_norm = 4.4748 nat_grad_norm = 0.1270 cg_residual = 2.0324 step_size = 0.3690 reward = -0.0000 fps = 8 mse_loss = 1.5050 
2022-05-01 09:56:19.105531 - gail/main.py:164 - [TRPO] iter = 1113000 dist_mean = -0.0075 dist_std = 0.1567 vf_loss = 0.0327 grad_norm = 3.2076 nat_grad_norm = 0.0677 cg_residual = 0.8555 step_size = 0.5334 reward = -0.0000 fps = 7 mse_loss = 1.4369 
2022-05-01 09:56:28.672920 - gail/main.py:164 - [TRPO] iter = 1114000 dist_mean = -0.0021 dist_std = 0.1571 vf_loss = 0.2951 grad_norm = 3.4879 nat_grad_norm = 0.0755 cg_residual = 1.0291 step_size = 0.5040 reward = 0.0000 fps = 6 mse_loss = 1.3800 
2022-05-01 09:56:39.061562 - gail/main.py:164 - [TRPO] iter = 1115000 dist_mean = 0.0044 dist_std = 0.1570 vf_loss = 0.0411 grad_norm = 3.8521 nat_grad_norm = 0.0918 cg_residual = 2.1908 step_size = 0.4057 reward = 0.0000 fps = 6 mse_loss = 1.3905 
2022-05-01 09:56:39.275314 - gail/main.py:191 - [Discriminator] iter = 1115000 loss = -0.4198 grad_norm = 3.4449 grad_penalty = 0.0578 regularization = 0.0000 true_logits = -0.1292 fake_logits = -0.6069 true_prob = 0.4738 fake_prob = 0.3686 
2022-05-01 09:57:33.650075 - gail/main.py:132 - [Evaluate] iter = 1115000 episode={ returns = 1655.9452 lengths = 470 } discounted_episode={ returns = 711.9657 lengths = 327 } 
2022-05-01 09:57:43.642035 - gail/main.py:164 - [TRPO] iter = 1116000 dist_mean = 0.0233 dist_std = 0.1569 vf_loss = 0.0650 grad_norm = 2.9344 nat_grad_norm = 0.0939 cg_residual = 1.1517 step_size = 0.4359 reward = -0.0000 fps = 15 mse_loss = 1.4112 
2022-05-01 09:57:54.082035 - gail/main.py:164 - [TRPO] iter = 1117000 dist_mean = 0.0179 dist_std = 0.1574 vf_loss = 0.0348 grad_norm = 2.4261 nat_grad_norm = 0.0782 cg_residual = 0.6813 step_size = 0.4991 reward = -0.0000 fps = 13 mse_loss = 1.4249 
2022-05-01 09:58:04.484524 - gail/main.py:164 - [TRPO] iter = 1118000 dist_mean = 0.0797 dist_std = 0.1576 vf_loss = 0.1864 grad_norm = 2.3053 nat_grad_norm = 0.1010 cg_residual = 1.0377 step_size = 0.4840 reward = 0.0000 fps = 11 mse_loss = 1.4290 
2022-05-01 09:58:14.872643 - gail/main.py:164 - [TRPO] iter = 1119000 dist_mean = -0.0032 dist_std = 0.1577 vf_loss = 0.0559 grad_norm = 1.8851 nat_grad_norm = 0.0750 cg_residual = 0.7298 step_size = 0.6462 reward = 0.0000 fps = 10 mse_loss = 1.5345 
2022-05-01 09:58:24.944649 - gail/main.py:164 - [TRPO] iter = 1120000 dist_mean = 0.0269 dist_std = 0.1579 vf_loss = 0.0503 grad_norm = 2.9789 nat_grad_norm = 0.1251 cg_residual = 2.0589 step_size = 0.3506 reward = -0.0000 fps = 9 mse_loss = 1.5118 
2022-05-01 09:58:25.170618 - gail/main.py:191 - [Discriminator] iter = 1120000 loss = -0.8350 grad_norm = 2.9715 grad_penalty = 0.0695 regularization = 0.0000 true_logits = -0.0958 fake_logits = -1.0003 true_prob = 0.4814 fake_prob = 0.3034 
2022-05-01 09:58:30.536726 - gail/main.py:132 - [Evaluate] iter = 1120000 episode={ returns = 62.0364 lengths = 37 } discounted_episode={ returns = 60.9494 lengths = 37 } 
2022-05-01 09:58:41.000270 - gail/main.py:164 - [TRPO] iter = 1121000 dist_mean = 0.0597 dist_std = 0.1583 vf_loss = 0.0405 grad_norm = 3.2469 nat_grad_norm = 0.1080 cg_residual = 0.9440 step_size = 0.4380 reward = -0.0000 fps = 63 mse_loss = 1.4721 
2022-05-01 09:58:51.103148 - gail/main.py:164 - [TRPO] iter = 1122000 dist_mean = 0.1452 dist_std = 0.1575 vf_loss = 0.3744 grad_norm = 3.9647 nat_grad_norm = 0.0945 cg_residual = 1.0919 step_size = 0.3821 reward = 0.0000 fps = 38 mse_loss = 1.4602 
2022-05-01 09:59:01.183551 - gail/main.py:164 - [TRPO] iter = 1123000 dist_mean = 0.0621 dist_std = 0.1571 vf_loss = 0.2140 grad_norm = 2.7663 nat_grad_norm = 0.0906 cg_residual = 1.1889 step_size = 0.4594 reward = -0.0000 fps = 27 mse_loss = 1.5189 
2022-05-01 09:59:11.158381 - gail/main.py:164 - [TRPO] iter = 1124000 dist_mean = 0.0076 dist_std = 0.1571 vf_loss = 0.0540 grad_norm = 3.9183 nat_grad_norm = 0.1056 cg_residual = 1.3073 step_size = 0.4427 reward = 0.0000 fps = 21 mse_loss = 1.5973 
2022-05-01 09:59:20.941084 - gail/main.py:164 - [TRPO] iter = 1125000 dist_mean = 0.0142 dist_std = 0.1567 vf_loss = 0.6519 grad_norm = 3.5541 nat_grad_norm = 0.0624 cg_residual = 0.5767 step_size = 0.5402 reward = -0.0000 fps = 17 mse_loss = 1.5319 
2022-05-01 09:59:21.153779 - gail/main.py:191 - [Discriminator] iter = 1125000 loss = -0.6420 grad_norm = 2.7632 grad_penalty = 0.0593 regularization = 0.0000 true_logits = -0.2098 fake_logits = -0.9111 true_prob = 0.4564 fake_prob = 0.3173 
2022-05-01 09:59:26.450315 - gail/main.py:132 - [Evaluate] iter = 1125000 episode={ returns = 63.3561 lengths = 38 } discounted_episode={ returns = 61.9392 lengths = 38 } 
2022-05-01 09:59:36.000868 - gail/main.py:164 - [TRPO] iter = 1126000 dist_mean = 0.0414 dist_std = 0.1570 vf_loss = 0.3344 grad_norm = 3.0961 nat_grad_norm = 0.0892 cg_residual = 1.3022 step_size = 0.4507 reward = 0.0000 fps = 67 mse_loss = 1.4425 
2022-05-01 09:59:45.865483 - gail/main.py:164 - [TRPO] iter = 1127000 dist_mean = -0.0157 dist_std = 0.1570 vf_loss = 0.4520 grad_norm = 2.5783 nat_grad_norm = 0.0592 cg_residual = 1.3100 step_size = 0.5966 reward = 0.0000 fps = 40 mse_loss = 1.4758 
2022-05-01 09:59:56.469160 - gail/main.py:164 - [TRPO] iter = 1128000 dist_mean = 0.0881 dist_std = 0.1572 vf_loss = 0.0824 grad_norm = 3.8155 nat_grad_norm = 0.0983 cg_residual = 1.2167 step_size = 0.4111 reward = -0.0000 fps = 28 mse_loss = 1.5196 
2022-05-01 10:00:06.396873 - gail/main.py:164 - [TRPO] iter = 1129000 dist_mean = 0.0037 dist_std = 0.1573 vf_loss = 0.2026 grad_norm = 3.5552 nat_grad_norm = 0.0700 cg_residual = 1.2167 step_size = 0.5066 reward = -0.0000 fps = 22 mse_loss = 1.4925 
2022-05-01 10:00:16.948154 - gail/main.py:164 - [TRPO] iter = 1130000 dist_mean = 0.0249 dist_std = 0.1572 vf_loss = 0.2133 grad_norm = 2.7590 nat_grad_norm = 0.0852 cg_residual = 1.7138 step_size = 0.5002 reward = -0.0000 fps = 17 mse_loss = 1.5431 
2022-05-01 10:00:17.164521 - gail/main.py:191 - [Discriminator] iter = 1130000 loss = -0.4896 grad_norm = 3.2641 grad_penalty = 0.0554 regularization = 0.0000 true_logits = -0.2710 fake_logits = -0.8160 true_prob = 0.4442 fake_prob = 0.3286 
2022-05-01 10:00:36.155012 - gail/main.py:132 - [Evaluate] iter = 1130000 episode={ returns = 780.1123 lengths = 230 } discounted_episode={ returns = 62.8206 lengths = 38 } 
2022-05-01 10:00:46.458269 - gail/main.py:164 - [TRPO] iter = 1131000 dist_mean = 0.0305 dist_std = 0.1576 vf_loss = 0.1028 grad_norm = 3.1663 nat_grad_norm = 0.1120 cg_residual = 1.5886 step_size = 0.4050 reward = 0.0000 fps = 34 mse_loss = 1.5040 
2022-05-01 10:00:56.412252 - gail/main.py:164 - [TRPO] iter = 1132000 dist_mean = 0.0519 dist_std = 0.1575 vf_loss = 0.1029 grad_norm = 3.1960 nat_grad_norm = 0.0876 cg_residual = 0.9109 step_size = 0.4696 reward = -0.0000 fps = 25 mse_loss = 1.5581 
2022-05-01 10:01:06.386910 - gail/main.py:164 - [TRPO] iter = 1133000 dist_mean = 0.0027 dist_std = 0.1575 vf_loss = 0.1064 grad_norm = 1.7241 nat_grad_norm = 0.0749 cg_residual = 0.6688 step_size = 0.6024 reward = -0.0000 fps = 20 mse_loss = 1.6114 
2022-05-01 10:01:16.516966 - gail/main.py:164 - [TRPO] iter = 1134000 dist_mean = 0.0589 dist_std = 0.1581 vf_loss = 0.1219 grad_norm = 3.1569 nat_grad_norm = 0.1123 cg_residual = 1.5890 step_size = 0.4438 reward = 0.0000 fps = 16 mse_loss = 1.5741 
2022-05-01 10:01:26.521387 - gail/main.py:164 - [TRPO] iter = 1135000 dist_mean = -0.0042 dist_std = 0.1585 vf_loss = 0.0397 grad_norm = 2.7337 nat_grad_norm = 0.1528 cg_residual = 3.2303 step_size = 0.3865 reward = 0.0000 fps = 14 mse_loss = 1.5110 
2022-05-01 10:01:26.797070 - gail/main.py:191 - [Discriminator] iter = 1135000 loss = -0.5225 grad_norm = 4.3517 grad_penalty = 0.0519 regularization = 0.0000 true_logits = -0.2730 fake_logits = -0.8473 true_prob = 0.4439 fake_prob = 0.3272 
2022-05-01 10:01:39.059967 - gail/main.py:132 - [Evaluate] iter = 1135000 episode={ returns = 422.2942 lengths = 135 } discounted_episode={ returns = 63.3181 lengths = 39 } 
2022-05-01 10:01:49.080261 - gail/main.py:164 - [TRPO] iter = 1136000 dist_mean = 0.0235 dist_std = 0.1589 vf_loss = 0.0635 grad_norm = 3.4869 nat_grad_norm = 0.1067 cg_residual = 2.2261 step_size = 0.4012 reward = 0.0000 fps = 44 mse_loss = 1.5987 
2022-05-01 10:01:59.228838 - gail/main.py:164 - [TRPO] iter = 1137000 dist_mean = 0.0507 dist_std = 0.1592 vf_loss = 0.1999 grad_norm = 2.2635 nat_grad_norm = 0.0849 cg_residual = 0.6505 step_size = 0.5648 reward = -0.0000 fps = 30 mse_loss = 1.5216 
2022-05-01 10:02:09.427917 - gail/main.py:164 - [TRPO] iter = 1138000 dist_mean = 0.0776 dist_std = 0.1590 vf_loss = 0.1303 grad_norm = 2.1491 nat_grad_norm = 0.0705 cg_residual = 0.6957 step_size = 0.5843 reward = -0.0000 fps = 23 mse_loss = 1.5245 
2022-05-01 10:02:19.091205 - gail/main.py:164 - [TRPO] iter = 1139000 dist_mean = 0.0876 dist_std = 0.1586 vf_loss = 0.1538 grad_norm = 2.2384 nat_grad_norm = 0.0746 cg_residual = 0.5061 step_size = 0.5860 reward = 0.0000 fps = 19 mse_loss = 1.5658 
2022-05-01 10:02:29.242366 - gail/main.py:164 - [TRPO] iter = 1140000 dist_mean = 0.0579 dist_std = 0.1584 vf_loss = 0.1961 grad_norm = 2.7174 nat_grad_norm = 0.1002 cg_residual = 1.9190 step_size = 0.4919 reward = 0.0000 fps = 16 mse_loss = 1.6126 
2022-05-01 10:02:29.467726 - gail/main.py:191 - [Discriminator] iter = 1140000 loss = -0.6364 grad_norm = 4.4694 grad_penalty = 0.0586 regularization = 0.0000 true_logits = -0.3794 fake_logits = -1.0745 true_prob = 0.4251 fake_prob = 0.2943 
2022-05-01 10:02:35.000892 - gail/main.py:132 - [Evaluate] iter = 1140000 episode={ returns = 63.2430 lengths = 38 } discounted_episode={ returns = 62.3879 lengths = 38 } 
2022-05-01 10:02:44.897521 - gail/main.py:164 - [TRPO] iter = 1141000 dist_mean = 0.0370 dist_std = 0.1579 vf_loss = 0.1161 grad_norm = 2.9718 nat_grad_norm = 0.0572 cg_residual = 1.0740 step_size = 0.5615 reward = -0.0000 fps = 64 mse_loss = 1.4528 
2022-05-01 10:02:54.817265 - gail/main.py:164 - [TRPO] iter = 1142000 dist_mean = 0.0149 dist_std = 0.1577 vf_loss = 0.5367 grad_norm = 2.2463 nat_grad_norm = 0.0561 cg_residual = 0.9385 step_size = 0.7042 reward = 0.0000 fps = 39 mse_loss = 1.4466 
2022-05-01 10:03:04.740289 - gail/main.py:164 - [TRPO] iter = 1143000 dist_mean = 0.0179 dist_std = 0.1572 vf_loss = 0.1083 grad_norm = 3.2939 nat_grad_norm = 0.1166 cg_residual = 1.3128 step_size = 0.4247 reward = 0.0000 fps = 28 mse_loss = 1.5062 
2022-05-01 10:03:14.830197 - gail/main.py:164 - [TRPO] iter = 1144000 dist_mean = 0.0265 dist_std = 0.1570 vf_loss = 0.0635 grad_norm = 2.5748 nat_grad_norm = 0.1103 cg_residual = 2.4885 step_size = 0.4230 reward = 0.0000 fps = 22 mse_loss = 1.5710 
2022-05-01 10:03:24.902216 - gail/main.py:164 - [TRPO] iter = 1145000 dist_mean = 0.0105 dist_std = 0.1569 vf_loss = 0.0685 grad_norm = 3.3941 nat_grad_norm = 0.1029 cg_residual = 1.7884 step_size = 0.4082 reward = -0.0000 fps = 18 mse_loss = 1.5649 
2022-05-01 10:03:25.155124 - gail/main.py:191 - [Discriminator] iter = 1145000 loss = -0.5344 grad_norm = 3.7049 grad_penalty = 0.0579 regularization = 0.0000 true_logits = -0.4286 fake_logits = -1.0209 true_prob = 0.4135 fake_prob = 0.2993 
2022-05-01 10:03:30.572234 - gail/main.py:132 - [Evaluate] iter = 1145000 episode={ returns = 61.7568 lengths = 37 } discounted_episode={ returns = 60.9411 lengths = 37 } 
2022-05-01 10:03:40.654732 - gail/main.py:164 - [TRPO] iter = 1146000 dist_mean = 0.0918 dist_std = 0.1567 vf_loss = 0.1376 grad_norm = 3.1227 nat_grad_norm = 0.1118 cg_residual = 1.7512 step_size = 0.4152 reward = -0.0000 fps = 64 mse_loss = 1.5066 
2022-05-01 10:03:50.409337 - gail/main.py:164 - [TRPO] iter = 1147000 dist_mean = 0.1116 dist_std = 0.1565 vf_loss = 0.1244 grad_norm = 3.8425 nat_grad_norm = 0.0990 cg_residual = 0.9540 step_size = 0.4114 reward = -0.0000 fps = 39 mse_loss = 1.6193 
2022-05-01 10:04:00.548431 - gail/main.py:164 - [TRPO] iter = 1148000 dist_mean = 0.0447 dist_std = 0.1562 vf_loss = 0.0342 grad_norm = 2.7222 nat_grad_norm = 0.1207 cg_residual = 2.4129 step_size = 0.3938 reward = 0.0000 fps = 28 mse_loss = 1.6595 
2022-05-01 10:04:10.688090 - gail/main.py:164 - [TRPO] iter = 1149000 dist_mean = 0.2567 dist_std = 0.1568 vf_loss = 0.2913 grad_norm = 3.5674 nat_grad_norm = 0.0780 cg_residual = 1.4098 step_size = 0.4694 reward = 0.0000 fps = 21 mse_loss = 1.5734 
2022-05-01 10:04:20.489176 - gail/main.py:164 - [TRPO] iter = 1150000 dist_mean = 0.1201 dist_std = 0.1564 vf_loss = 0.0862 grad_norm = 3.5042 nat_grad_norm = 0.0969 cg_residual = 1.6913 step_size = 0.3939 reward = -0.0000 fps = 18 mse_loss = 1.6218 
2022-05-01 10:04:20.693335 - gail/main.py:191 - [Discriminator] iter = 1150000 loss = -1.1042 grad_norm = 3.1343 grad_penalty = 0.0964 regularization = 0.0000 true_logits = -0.3359 fake_logits = -1.5365 true_prob = 0.4327 fake_prob = 0.2364 
2022-05-01 10:04:25.905296 - gail/main.py:132 - [Evaluate] iter = 1150000 episode={ returns = 61.6593 lengths = 37 } discounted_episode={ returns = 60.9215 lengths = 37 } 
2022-05-01 10:04:35.633891 - gail/main.py:164 - [TRPO] iter = 1151000 dist_mean = 0.0392 dist_std = 0.1567 vf_loss = 0.1290 grad_norm = 3.5818 nat_grad_norm = 0.0842 cg_residual = 1.3073 step_size = 0.4591 reward = 0.0000 fps = 67 mse_loss = 1.6222 
2022-05-01 10:04:45.848944 - gail/main.py:164 - [TRPO] iter = 1152000 dist_mean = 0.0372 dist_std = 0.1568 vf_loss = 0.4563 grad_norm = 2.6910 nat_grad_norm = 0.0773 cg_residual = 0.6981 step_size = 0.5646 reward = -0.0000 fps = 39 mse_loss = 1.5474 
2022-05-01 10:04:55.793947 - gail/main.py:164 - [TRPO] iter = 1153000 dist_mean = 0.0477 dist_std = 0.1569 vf_loss = 0.0465 grad_norm = 2.7276 nat_grad_norm = 0.0977 cg_residual = 0.6019 step_size = 0.4912 reward = -0.0000 fps = 28 mse_loss = 1.6813 
2022-05-01 10:05:06.136996 - gail/main.py:164 - [TRPO] iter = 1154000 dist_mean = 0.0529 dist_std = 0.1562 vf_loss = 0.3307 grad_norm = 4.0182 nat_grad_norm = 0.1010 cg_residual = 1.1440 step_size = 0.4493 reward = -0.0000 fps = 22 mse_loss = 1.7358 
2022-05-01 10:05:16.148037 - gail/main.py:164 - [TRPO] iter = 1155000 dist_mean = 0.0896 dist_std = 0.1565 vf_loss = 0.3587 grad_norm = 2.7146 nat_grad_norm = 0.0785 cg_residual = 0.6409 step_size = 0.5883 reward = 0.0000 fps = 18 mse_loss = 1.6067 
2022-05-01 10:05:16.403518 - gail/main.py:191 - [Discriminator] iter = 1155000 loss = -0.8664 grad_norm = 2.5912 grad_penalty = 0.0809 regularization = 0.0000 true_logits = -0.2054 fake_logits = -1.1527 true_prob = 0.4558 fake_prob = 0.2966 
2022-05-01 10:05:21.671852 - gail/main.py:132 - [Evaluate] iter = 1155000 episode={ returns = 61.8286 lengths = 37 } discounted_episode={ returns = 60.8335 lengths = 37 } 
2022-05-01 10:05:31.626102 - gail/main.py:164 - [TRPO] iter = 1156000 dist_mean = 0.0457 dist_std = 0.1566 vf_loss = 0.0584 grad_norm = 2.4581 nat_grad_norm = 0.0723 cg_residual = 1.2167 step_size = 0.5859 reward = 0.0000 fps = 65 mse_loss = 1.7170 
2022-05-01 10:05:41.769599 - gail/main.py:164 - [TRPO] iter = 1157000 dist_mean = -0.0052 dist_std = 0.1565 vf_loss = 0.3755 grad_norm = 3.0493 nat_grad_norm = 0.0858 cg_residual = 1.6785 step_size = 0.5001 reward = 0.0000 fps = 39 mse_loss = 1.6615 
2022-05-01 10:05:52.070319 - gail/main.py:164 - [TRPO] iter = 1158000 dist_mean = 0.0090 dist_std = 0.1565 vf_loss = 0.2513 grad_norm = 2.6584 nat_grad_norm = 0.0787 cg_residual = 1.5390 step_size = 0.5500 reward = -0.0000 fps = 28 mse_loss = 1.6831 
2022-05-01 10:06:02.130915 - gail/main.py:164 - [TRPO] iter = 1159000 dist_mean = 0.0155 dist_std = 0.1566 vf_loss = 0.0274 grad_norm = 1.5750 nat_grad_norm = 0.1021 cg_residual = 0.6386 step_size = 0.5003 reward = 0.0000 fps = 21 mse_loss = 1.6023 
2022-05-01 10:06:12.144916 - gail/main.py:164 - [TRPO] iter = 1160000 dist_mean = 0.0028 dist_std = 0.1561 vf_loss = 0.2392 grad_norm = 3.7077 nat_grad_norm = 0.0819 cg_residual = 1.9424 step_size = 0.4842 reward = -0.0000 fps = 17 mse_loss = 1.7705 
2022-05-01 10:06:12.375865 - gail/main.py:191 - [Discriminator] iter = 1160000 loss = -0.5354 grad_norm = 2.9809 grad_penalty = 0.0538 regularization = 0.0000 true_logits = -0.0961 fake_logits = -0.6854 true_prob = 0.4794 fake_prob = 0.3599 
2022-05-01 10:06:17.732128 - gail/main.py:132 - [Evaluate] iter = 1160000 episode={ returns = 62.0637 lengths = 37 } discounted_episode={ returns = 61.0938 lengths = 37 } 
2022-05-01 10:06:27.309547 - gail/main.py:164 - [TRPO] iter = 1161000 dist_mean = 0.0531 dist_std = 0.1560 vf_loss = 0.0192 grad_norm = 2.6625 nat_grad_norm = 0.0790 cg_residual = 1.3772 step_size = 0.4677 reward = 0.0000 fps = 67 mse_loss = 1.5705 
2022-05-01 10:06:37.812972 - gail/main.py:164 - [TRPO] iter = 1162000 dist_mean = 0.1094 dist_std = 0.1558 vf_loss = 0.1216 grad_norm = 2.5585 nat_grad_norm = 0.0927 cg_residual = 1.2516 step_size = 0.4836 reward = 0.0000 fps = 39 mse_loss = 1.5992 
2022-05-01 10:06:47.846967 - gail/main.py:164 - [TRPO] iter = 1163000 dist_mean = 0.0010 dist_std = 0.1557 vf_loss = 0.3454 grad_norm = 3.8543 nat_grad_norm = 0.0706 cg_residual = 1.0822 step_size = 0.5621 reward = -0.0000 fps = 28 mse_loss = 1.6429 
2022-05-01 10:06:57.950057 - gail/main.py:164 - [TRPO] iter = 1164000 dist_mean = 0.0025 dist_std = 0.1557 vf_loss = 0.0647 grad_norm = 3.3900 nat_grad_norm = 0.0915 cg_residual = 1.3987 step_size = 0.4785 reward = 0.0000 fps = 21 mse_loss = 1.6742 
2022-05-01 10:07:07.935121 - gail/main.py:164 - [TRPO] iter = 1165000 dist_mean = 0.0163 dist_std = 0.1555 vf_loss = 0.2739 grad_norm = 3.6164 nat_grad_norm = 0.0833 cg_residual = 0.7076 step_size = 0.5055 reward = 0.0000 fps = 18 mse_loss = 1.5217 
2022-05-01 10:07:08.142819 - gail/main.py:191 - [Discriminator] iter = 1165000 loss = -0.4982 grad_norm = 3.5455 grad_penalty = 0.0523 regularization = 0.0000 true_logits = -0.0283 fake_logits = -0.5788 true_prob = 0.4917 fake_prob = 0.3759 
2022-05-01 10:09:18.377158 - gail/main.py:132 - [Evaluate] iter = 1165000 episode={ returns = 3640.4733 lengths = 1000 } discounted_episode={ returns = 2024.3201 lengths = 903 } 
2022-05-01 10:09:28.447109 - gail/main.py:164 - [TRPO] iter = 1166000 dist_mean = 0.0153 dist_std = 0.1554 vf_loss = 0.0678 grad_norm = 2.2246 nat_grad_norm = 0.0541 cg_residual = 0.9132 step_size = 0.6343 reward = -0.0000 fps = 7 mse_loss = 1.5432 
2022-05-01 10:09:38.644367 - gail/main.py:164 - [TRPO] iter = 1167000 dist_mean = -0.0079 dist_std = 0.1557 vf_loss = 0.0535 grad_norm = 3.2072 nat_grad_norm = 0.0727 cg_residual = 1.5764 step_size = 0.5239 reward = -0.0000 fps = 6 mse_loss = 1.6286 
2022-05-01 10:09:48.822672 - gail/main.py:164 - [TRPO] iter = 1168000 dist_mean = 0.0312 dist_std = 0.1560 vf_loss = 0.1200 grad_norm = 2.9128 nat_grad_norm = 0.0669 cg_residual = 0.6407 step_size = 0.5552 reward = -0.0000 fps = 6 mse_loss = 1.6255 
2022-05-01 10:09:58.970956 - gail/main.py:164 - [TRPO] iter = 1169000 dist_mean = 0.0085 dist_std = 0.1562 vf_loss = 0.1026 grad_norm = 3.9014 nat_grad_norm = 0.0692 cg_residual = 1.1889 step_size = 0.5137 reward = -0.0000 fps = 5 mse_loss = 1.6517 
2022-05-01 10:10:09.379029 - gail/main.py:164 - [TRPO] iter = 1170000 dist_mean = 0.0084 dist_std = 0.1564 vf_loss = 0.1630 grad_norm = 2.0637 nat_grad_norm = 0.0960 cg_residual = 1.1816 step_size = 0.4566 reward = 0.0000 fps = 5 mse_loss = 1.7141 
2022-05-01 10:10:09.654088 - gail/main.py:191 - [Discriminator] iter = 1170000 loss = -0.5123 grad_norm = 3.3954 grad_penalty = 0.0522 regularization = 0.0000 true_logits = -0.0869 fake_logits = -0.6514 true_prob = 0.4793 fake_prob = 0.3642 
2022-05-01 10:12:26.778113 - gail/main.py:132 - [Evaluate] iter = 1170000 episode={ returns = 3632.9088 lengths = 1000 } discounted_episode={ returns = 2240.0567 lengths = 1000 } 
2022-05-01 10:12:37.142171 - gail/main.py:164 - [TRPO] iter = 1171000 dist_mean = 0.0601 dist_std = 0.1568 vf_loss = 0.0835 grad_norm = 3.8589 nat_grad_norm = 0.0703 cg_residual = 1.2435 step_size = 0.5047 reward = 0.0000 fps = 6 mse_loss = 1.6043 
2022-05-01 10:12:47.635041 - gail/main.py:164 - [TRPO] iter = 1172000 dist_mean = 0.0398 dist_std = 0.1571 vf_loss = 0.0325 grad_norm = 3.1144 nat_grad_norm = 0.0766 cg_residual = 1.0799 step_size = 0.4873 reward = -0.0000 fps = 6 mse_loss = 1.7170 
2022-05-01 10:12:57.906012 - gail/main.py:164 - [TRPO] iter = 1173000 dist_mean = 0.0361 dist_std = 0.1571 vf_loss = 0.0233 grad_norm = 3.1696 nat_grad_norm = 0.0676 cg_residual = 1.3948 step_size = 0.5422 reward = 0.0000 fps = 5 mse_loss = 1.8084 
2022-05-01 10:13:07.932616 - gail/main.py:164 - [TRPO] iter = 1174000 dist_mean = 0.0161 dist_std = 0.1568 vf_loss = 0.0576 grad_norm = 2.3382 nat_grad_norm = 0.0727 cg_residual = 0.9717 step_size = 0.5903 reward = 0.0000 fps = 5 mse_loss = 1.7169 
2022-05-01 10:13:17.446600 - gail/main.py:164 - [TRPO] iter = 1175000 dist_mean = 0.0348 dist_std = 0.1562 vf_loss = 0.0203 grad_norm = 2.4884 nat_grad_norm = 0.1073 cg_residual = 1.2719 step_size = 0.4363 reward = -0.0000 fps = 5 mse_loss = 1.6192 
2022-05-01 10:13:17.745716 - gail/main.py:191 - [Discriminator] iter = 1175000 loss = -0.4766 grad_norm = 2.7819 grad_penalty = 0.0551 regularization = 0.0000 true_logits = -0.0704 fake_logits = -0.6022 true_prob = 0.4813 fake_prob = 0.3700 
2022-05-01 10:15:38.149486 - gail/main.py:132 - [Evaluate] iter = 1175000 episode={ returns = 3637.2731 lengths = 1000 } discounted_episode={ returns = 2244.1908 lengths = 1000 } 
2022-05-01 10:15:48.326925 - gail/main.py:164 - [TRPO] iter = 1176000 dist_mean = 0.0195 dist_std = 0.1562 vf_loss = 0.0241 grad_norm = 3.1298 nat_grad_norm = 0.0648 cg_residual = 0.7701 step_size = 0.5985 reward = -0.0000 fps = 6 mse_loss = 1.6482 
2022-05-01 10:15:58.291990 - gail/main.py:164 - [TRPO] iter = 1177000 dist_mean = 0.0280 dist_std = 0.1562 vf_loss = 0.0177 grad_norm = 3.0403 nat_grad_norm = 0.0893 cg_residual = 1.7386 step_size = 0.4249 reward = -0.0000 fps = 6 mse_loss = 1.6674 
2022-05-01 10:16:08.678318 - gail/main.py:164 - [TRPO] iter = 1178000 dist_mean = 0.0227 dist_std = 0.1564 vf_loss = 0.0363 grad_norm = 4.5104 nat_grad_norm = 0.1055 cg_residual = 2.2511 step_size = 0.4375 reward = 0.0000 fps = 5 mse_loss = 1.5141 
2022-05-01 10:16:18.507748 - gail/main.py:164 - [TRPO] iter = 1179000 dist_mean = 0.0501 dist_std = 0.1567 vf_loss = 0.1079 grad_norm = 2.8558 nat_grad_norm = 0.0931 cg_residual = 1.8669 step_size = 0.4333 reward = -0.0000 fps = 5 mse_loss = 1.5078 
2022-05-01 10:16:27.868889 - gail/main.py:164 - [TRPO] iter = 1180000 dist_mean = 0.0255 dist_std = 0.1565 vf_loss = 0.0507 grad_norm = 3.0576 nat_grad_norm = 0.0955 cg_residual = 0.8737 step_size = 0.4502 reward = -0.0000 fps = 5 mse_loss = 1.6757 
2022-05-01 10:16:28.143899 - gail/main.py:191 - [Discriminator] iter = 1180000 loss = -0.4654 grad_norm = 3.0635 grad_penalty = 0.0481 regularization = 0.0000 true_logits = -0.1262 fake_logits = -0.6397 true_prob = 0.4696 fake_prob = 0.3613 
2022-05-01 10:18:06.741912 - gail/main.py:132 - [Evaluate] iter = 1180000 episode={ returns = 2896.6319 lengths = 807 } discounted_episode={ returns = 1351.2956 lengths = 615 } 
2022-05-01 10:18:16.793707 - gail/main.py:164 - [TRPO] iter = 1181000 dist_mean = 0.0167 dist_std = 0.1569 vf_loss = 0.0468 grad_norm = 3.5223 nat_grad_norm = 0.0854 cg_residual = 1.6897 step_size = 0.4248 reward = 0.0000 fps = 9 mse_loss = 1.5897 
2022-05-01 10:18:26.836731 - gail/main.py:164 - [TRPO] iter = 1182000 dist_mean = 0.0248 dist_std = 0.1569 vf_loss = 0.0252 grad_norm = 2.5144 nat_grad_norm = 0.1042 cg_residual = 1.5875 step_size = 0.4428 reward = -0.0000 fps = 8 mse_loss = 1.6355 
2022-05-01 10:18:36.819138 - gail/main.py:164 - [TRPO] iter = 1183000 dist_mean = 0.0567 dist_std = 0.1564 vf_loss = 0.0484 grad_norm = 3.5791 nat_grad_norm = 0.0908 cg_residual = 0.9001 step_size = 0.4589 reward = 0.0000 fps = 7 mse_loss = 1.7546 
2022-05-01 10:18:46.732105 - gail/main.py:164 - [TRPO] iter = 1184000 dist_mean = 0.0381 dist_std = 0.1561 vf_loss = 0.0266 grad_norm = 2.8554 nat_grad_norm = 0.1496 cg_residual = 2.1771 step_size = 0.3646 reward = -0.0000 fps = 7 mse_loss = 1.7087 
2022-05-01 10:18:56.539250 - gail/main.py:164 - [TRPO] iter = 1185000 dist_mean = 0.0371 dist_std = 0.1560 vf_loss = 0.0923 grad_norm = 3.6483 nat_grad_norm = 0.0776 cg_residual = 1.3581 step_size = 0.5123 reward = 0.0000 fps = 6 mse_loss = 1.6543 
2022-05-01 10:18:56.783553 - gail/main.py:191 - [Discriminator] iter = 1185000 loss = -0.4834 grad_norm = 3.4889 grad_penalty = 0.0559 regularization = 0.0000 true_logits = -0.1602 fake_logits = -0.6994 true_prob = 0.4618 fake_prob = 0.3502 
2022-05-01 10:19:02.035374 - gail/main.py:132 - [Evaluate] iter = 1185000 episode={ returns = 63.4872 lengths = 37 } discounted_episode={ returns = 62.9318 lengths = 37 } 
2022-05-01 10:19:11.868310 - gail/main.py:164 - [TRPO] iter = 1186000 dist_mean = 0.0490 dist_std = 0.1557 vf_loss = 0.0947 grad_norm = 2.5746 nat_grad_norm = 0.0779 cg_residual = 1.1197 step_size = 0.5157 reward = 0.0000 fps = 66 mse_loss = 1.6090 
2022-05-01 10:19:21.739189 - gail/main.py:164 - [TRPO] iter = 1187000 dist_mean = 0.0211 dist_std = 0.1555 vf_loss = 0.1412 grad_norm = 3.3245 nat_grad_norm = 0.0822 cg_residual = 1.2588 step_size = 0.4716 reward = -0.0000 fps = 40 mse_loss = 1.7091 
2022-05-01 10:19:31.521269 - gail/main.py:164 - [TRPO] iter = 1188000 dist_mean = 0.0203 dist_std = 0.1558 vf_loss = 0.1215 grad_norm = 2.1522 nat_grad_norm = 0.0801 cg_residual = 0.2975 step_size = 0.5916 reward = 0.0000 fps = 28 mse_loss = 1.6591 
2022-05-01 10:19:41.705636 - gail/main.py:164 - [TRPO] iter = 1189000 dist_mean = 0.2794 dist_std = 0.1563 vf_loss = 0.1706 grad_norm = 4.4980 nat_grad_norm = 0.0585 cg_residual = 0.6238 step_size = 0.5025 reward = -0.0000 fps = 22 mse_loss = 1.7068 
2022-05-01 10:19:51.606383 - gail/main.py:164 - [TRPO] iter = 1190000 dist_mean = 0.0650 dist_std = 0.1562 vf_loss = 0.0612 grad_norm = 2.9470 nat_grad_norm = 0.0863 cg_residual = 0.9998 step_size = 0.4601 reward = 0.0000 fps = 18 mse_loss = 1.6766 
2022-05-01 10:19:51.834640 - gail/main.py:191 - [Discriminator] iter = 1190000 loss = -0.7131 grad_norm = 3.3503 grad_penalty = 0.0523 regularization = 0.0000 true_logits = -0.1431 fake_logits = -0.9085 true_prob = 0.4682 fake_prob = 0.3219 
2022-05-01 10:19:57.038848 - gail/main.py:132 - [Evaluate] iter = 1190000 episode={ returns = 65.0363 lengths = 37 } discounted_episode={ returns = 62.9627 lengths = 37 } 
2022-05-01 10:20:07.254282 - gail/main.py:164 - [TRPO] iter = 1191000 dist_mean = 0.0940 dist_std = 0.1564 vf_loss = 0.1629 grad_norm = 3.4693 nat_grad_norm = 0.0970 cg_residual = 1.0068 step_size = 0.4275 reward = -0.0000 fps = 64 mse_loss = 1.6590 
2022-05-01 10:20:17.408367 - gail/main.py:164 - [TRPO] iter = 1192000 dist_mean = 0.0546 dist_std = 0.1565 vf_loss = 0.0551 grad_norm = 3.3654 nat_grad_norm = 0.1012 cg_residual = 1.8875 step_size = 0.4430 reward = 0.0000 fps = 39 mse_loss = 1.6808 
2022-05-01 10:20:27.569142 - gail/main.py:164 - [TRPO] iter = 1193000 dist_mean = 0.0712 dist_std = 0.1564 vf_loss = 0.2933 grad_norm = 3.9972 nat_grad_norm = 0.0669 cg_residual = 0.6659 step_size = 0.5151 reward = -0.0000 fps = 28 mse_loss = 1.7148 
2022-05-01 10:20:37.951341 - gail/main.py:164 - [TRPO] iter = 1194000 dist_mean = 0.0349 dist_std = 0.1565 vf_loss = 0.1340 grad_norm = 2.1131 nat_grad_norm = 0.0771 cg_residual = 0.9610 step_size = 0.6077 reward = -0.0000 fps = 21 mse_loss = 1.6264 
2022-05-01 10:20:48.255501 - gail/main.py:164 - [TRPO] iter = 1195000 dist_mean = 0.0220 dist_std = 0.1571 vf_loss = 0.1330 grad_norm = 3.4247 nat_grad_norm = 0.0727 cg_residual = 1.2972 step_size = 0.4616 reward = 0.0000 fps = 17 mse_loss = 1.6557 
2022-05-01 10:20:48.467410 - gail/main.py:191 - [Discriminator] iter = 1195000 loss = -0.4869 grad_norm = 3.4200 grad_penalty = 0.0544 regularization = 0.0000 true_logits = -0.1420 fake_logits = -0.6832 true_prob = 0.4658 fake_prob = 0.3571 
2022-05-01 10:21:53.112182 - gail/main.py:132 - [Evaluate] iter = 1195000 episode={ returns = 1496.7893 lengths = 423 } discounted_episode={ returns = 1163.1953 lengths = 519 } 
2022-05-01 10:22:03.816794 - gail/main.py:164 - [TRPO] iter = 1196000 dist_mean = 0.0492 dist_std = 0.1569 vf_loss = 0.0897 grad_norm = 2.4627 nat_grad_norm = 0.0980 cg_residual = 1.1730 step_size = 0.4706 reward = 0.0000 fps = 13 mse_loss = 1.6667 
2022-05-01 10:22:13.796112 - gail/main.py:164 - [TRPO] iter = 1197000 dist_mean = 0.0776 dist_std = 0.1567 vf_loss = 0.0709 grad_norm = 2.9081 nat_grad_norm = 0.0776 cg_residual = 1.1989 step_size = 0.4646 reward = -0.0000 fps = 11 mse_loss = 1.6521 
2022-05-01 10:22:23.811340 - gail/main.py:164 - [TRPO] iter = 1198000 dist_mean = 0.0135 dist_std = 0.1566 vf_loss = 0.1315 grad_norm = 2.9398 nat_grad_norm = 0.0767 cg_residual = 1.1648 step_size = 0.4854 reward = 0.0000 fps = 10 mse_loss = 1.6051 
2022-05-01 10:22:33.917390 - gail/main.py:164 - [TRPO] iter = 1199000 dist_mean = 0.1392 dist_std = 0.1567 vf_loss = 0.1094 grad_norm = 1.9757 nat_grad_norm = 0.0938 cg_residual = 0.7592 step_size = 0.5419 reward = -0.0000 fps = 9 mse_loss = 1.7151 
2022-05-01 10:22:44.163352 - gail/main.py:164 - [TRPO] iter = 1200000 dist_mean = 0.0519 dist_std = 0.1567 vf_loss = 0.2405 grad_norm = 2.9267 nat_grad_norm = 0.0595 cg_residual = 0.6811 step_size = 0.5678 reward = -0.0000 fps = 8 mse_loss = 1.7672 
2022-05-01 10:22:44.379503 - gail/main.py:191 - [Discriminator] iter = 1200000 loss = -0.6186 grad_norm = 3.0204 grad_penalty = 0.0542 regularization = 0.0000 true_logits = -0.2033 fake_logits = -0.8762 true_prob = 0.4550 fake_prob = 0.3310 
2022-05-01 10:22:49.921467 - gail/main.py:132 - [Evaluate] iter = 1200000 episode={ returns = 65.2155 lengths = 37 } discounted_episode={ returns = 63.4897 lengths = 37 } 
2022-05-01 10:23:00.110653 - gail/main.py:164 - [TRPO] iter = 1201000 dist_mean = 0.0581 dist_std = 0.1565 vf_loss = 0.0393 grad_norm = 2.8663 nat_grad_norm = 0.0882 cg_residual = 1.5793 step_size = 0.4848 reward = -0.0000 fps = 63 mse_loss = 1.5298 
2022-05-01 10:23:10.316135 - gail/main.py:164 - [TRPO] iter = 1202000 dist_mean = 0.0937 dist_std = 0.1564 vf_loss = 0.0963 grad_norm = 3.0416 nat_grad_norm = 0.0922 cg_residual = 1.1222 step_size = 0.5003 reward = 0.0000 fps = 38 mse_loss = 1.6519 
2022-05-01 10:23:20.765818 - gail/main.py:164 - [TRPO] iter = 1203000 dist_mean = 0.0280 dist_std = 0.1563 vf_loss = 0.1228 grad_norm = 2.2387 nat_grad_norm = 0.0675 cg_residual = 0.6630 step_size = 0.6244 reward = 0.0000 fps = 27 mse_loss = 1.6986 
2022-05-01 10:23:31.177738 - gail/main.py:164 - [TRPO] iter = 1204000 dist_mean = 0.0911 dist_std = 0.1563 vf_loss = 0.2034 grad_norm = 4.8431 nat_grad_norm = 0.1074 cg_residual = 1.3030 step_size = 0.3748 reward = 0.0000 fps = 21 mse_loss = 1.6326 
2022-05-01 10:23:41.471897 - gail/main.py:164 - [TRPO] iter = 1205000 dist_mean = 0.1417 dist_std = 0.1561 vf_loss = 0.1233 grad_norm = 2.6995 nat_grad_norm = 0.1183 cg_residual = 1.8443 step_size = 0.3788 reward = 0.0000 fps = 17 mse_loss = 1.7251 
2022-05-01 10:23:41.696152 - gail/main.py:191 - [Discriminator] iter = 1205000 loss = -1.1746 grad_norm = 3.1708 grad_penalty = 0.1234 regularization = 0.0000 true_logits = -0.1822 fake_logits = -1.4802 true_prob = 0.4587 fake_prob = 0.2537 
2022-05-01 10:23:53.951923 - gail/main.py:132 - [Evaluate] iter = 1205000 episode={ returns = 420.5063 lengths = 134 } discounted_episode={ returns = 64.2202 lengths = 38 } 
2022-05-01 10:24:04.412584 - gail/main.py:164 - [TRPO] iter = 1206000 dist_mean = 0.0863 dist_std = 0.1559 vf_loss = 0.0886 grad_norm = 4.3755 nat_grad_norm = 0.1052 cg_residual = 1.7324 step_size = 0.3771 reward = 0.0000 fps = 44 mse_loss = 1.7616 
2022-05-01 10:24:15.044811 - gail/main.py:164 - [TRPO] iter = 1207000 dist_mean = 0.0194 dist_std = 0.1556 vf_loss = 0.2056 grad_norm = 2.6668 nat_grad_norm = 0.0836 cg_residual = 0.7582 step_size = 0.4942 reward = 0.0000 fps = 30 mse_loss = 1.7954 
2022-05-01 10:24:25.455392 - gail/main.py:164 - [TRPO] iter = 1208000 dist_mean = 0.0768 dist_std = 0.1556 vf_loss = 0.1677 grad_norm = 3.5095 nat_grad_norm = 0.0955 cg_residual = 1.3701 step_size = 0.4408 reward = 0.0000 fps = 22 mse_loss = 1.5550 
2022-05-01 10:24:35.712624 - gail/main.py:164 - [TRPO] iter = 1209000 dist_mean = 0.0696 dist_std = 0.1555 vf_loss = 0.1356 grad_norm = 2.9098 nat_grad_norm = 0.1131 cg_residual = 1.4835 step_size = 0.3970 reward = 0.0000 fps = 18 mse_loss = 1.7909 
2022-05-01 10:24:46.270213 - gail/main.py:164 - [TRPO] iter = 1210000 dist_mean = 0.1263 dist_std = 0.1554 vf_loss = 0.1939 grad_norm = 3.0884 nat_grad_norm = 0.1401 cg_residual = 1.4408 step_size = 0.3856 reward = -0.0000 fps = 15 mse_loss = 1.7409 
2022-05-01 10:24:46.506454 - gail/main.py:191 - [Discriminator] iter = 1210000 loss = -0.9665 grad_norm = 3.3181 grad_penalty = 0.1028 regularization = 0.0000 true_logits = -0.2415 fake_logits = -1.3108 true_prob = 0.4483 fake_prob = 0.2872 
2022-05-01 10:24:55.692861 - gail/main.py:132 - [Evaluate] iter = 1210000 episode={ returns = 134.9421 lengths = 61 } discounted_episode={ returns = 127.7713 lengths = 61 } 
2022-05-01 10:25:06.168898 - gail/main.py:164 - [TRPO] iter = 1211000 dist_mean = 0.1414 dist_std = 0.1554 vf_loss = 0.2422 grad_norm = 3.0858 nat_grad_norm = 0.0868 cg_residual = 2.2875 step_size = 0.4213 reward = -0.0000 fps = 50 mse_loss = 1.6748 
2022-05-01 10:25:16.559722 - gail/main.py:164 - [TRPO] iter = 1212000 dist_mean = 0.0763 dist_std = 0.1554 vf_loss = 0.1653 grad_norm = 2.9150 nat_grad_norm = 0.0832 cg_residual = 0.9872 step_size = 0.4506 reward = -0.0000 fps = 33 mse_loss = 1.6396 
2022-05-01 10:25:26.581478 - gail/main.py:164 - [TRPO] iter = 1213000 dist_mean = 0.0852 dist_std = 0.1551 vf_loss = 0.1354 grad_norm = 3.4994 nat_grad_norm = 0.0841 cg_residual = 1.2988 step_size = 0.4366 reward = -0.0000 fps = 24 mse_loss = 1.8202 
2022-05-01 10:25:36.455378 - gail/main.py:164 - [TRPO] iter = 1214000 dist_mean = 0.0274 dist_std = 0.1550 vf_loss = 0.4055 grad_norm = 3.2579 nat_grad_norm = 0.0652 cg_residual = 0.9116 step_size = 0.5398 reward = 0.0000 fps = 20 mse_loss = 1.7434 
2022-05-01 10:25:46.438444 - gail/main.py:164 - [TRPO] iter = 1215000 dist_mean = 0.0488 dist_std = 0.1552 vf_loss = 0.3701 grad_norm = 2.8403 nat_grad_norm = 0.0902 cg_residual = 1.0610 step_size = 0.5108 reward = -0.0000 fps = 16 mse_loss = 1.6052 
2022-05-01 10:25:46.729348 - gail/main.py:191 - [Discriminator] iter = 1215000 loss = -0.3830 grad_norm = 3.2533 grad_penalty = 0.0664 regularization = 0.0000 true_logits = -0.3012 fake_logits = -0.7506 true_prob = 0.4365 fake_prob = 0.3546 
2022-05-01 10:26:26.978653 - gail/main.py:132 - [Evaluate] iter = 1215000 episode={ returns = 930.7415 lengths = 285 } discounted_episode={ returns = 644.2857 lengths = 285 } 
2022-05-01 10:26:37.544780 - gail/main.py:164 - [TRPO] iter = 1216000 dist_mean = 0.0595 dist_std = 0.1550 vf_loss = 0.2104 grad_norm = 2.1219 nat_grad_norm = 0.0700 cg_residual = 1.0470 step_size = 0.5587 reward = 0.0000 fps = 19 mse_loss = 1.6461 
2022-05-01 10:26:47.762431 - gail/main.py:164 - [TRPO] iter = 1217000 dist_mean = 0.0464 dist_std = 0.1549 vf_loss = 0.0908 grad_norm = 2.6573 nat_grad_norm = 0.0955 cg_residual = 1.0943 step_size = 0.4414 reward = -0.0000 fps = 16 mse_loss = 1.6980 
2022-05-01 10:26:58.202013 - gail/main.py:164 - [TRPO] iter = 1218000 dist_mean = 0.0736 dist_std = 0.1546 vf_loss = 0.0639 grad_norm = 4.0201 nat_grad_norm = 0.0980 cg_residual = 1.9440 step_size = 0.4248 reward = -0.0000 fps = 13 mse_loss = 1.7497 
2022-05-01 10:27:08.587632 - gail/main.py:164 - [TRPO] iter = 1219000 dist_mean = 0.0615 dist_std = 0.1545 vf_loss = 0.3525 grad_norm = 2.7302 nat_grad_norm = 0.0527 cg_residual = 0.6378 step_size = 0.7766 reward = -0.0000 fps = 12 mse_loss = 1.6221 
2022-05-01 10:27:18.636436 - gail/main.py:164 - [TRPO] iter = 1220000 dist_mean = 0.0531 dist_std = 0.1548 vf_loss = 0.1472 grad_norm = 2.8929 nat_grad_norm = 0.0606 cg_residual = 1.2217 step_size = 0.5545 reward = 0.0000 fps = 10 mse_loss = 1.6423 
2022-05-01 10:27:18.901758 - gail/main.py:191 - [Discriminator] iter = 1220000 loss = -0.5861 grad_norm = 3.9961 grad_penalty = 0.0574 regularization = 0.0000 true_logits = -0.3291 fake_logits = -0.9726 true_prob = 0.4293 fake_prob = 0.3074 
2022-05-01 10:28:33.840605 - gail/main.py:132 - [Evaluate] iter = 1220000 episode={ returns = 1521.7628 lengths = 439 } discounted_episode={ returns = 1399.3018 lengths = 631 } 
2022-05-01 10:28:43.919151 - gail/main.py:164 - [TRPO] iter = 1221000 dist_mean = 0.0519 dist_std = 0.1547 vf_loss = 0.0571 grad_norm = 3.0658 nat_grad_norm = 0.1302 cg_residual = 1.2312 step_size = 0.3892 reward = -0.0000 fps = 11 mse_loss = 1.6898 
2022-05-01 10:28:53.986159 - gail/main.py:164 - [TRPO] iter = 1222000 dist_mean = 0.0588 dist_std = 0.1549 vf_loss = 0.1676 grad_norm = 3.5622 nat_grad_norm = 0.0826 cg_residual = 1.0913 step_size = 0.4540 reward = -0.0000 fps = 10 mse_loss = 1.5802 
2022-05-01 10:29:03.923133 - gail/main.py:164 - [TRPO] iter = 1223000 dist_mean = 0.0806 dist_std = 0.1544 vf_loss = 0.1928 grad_norm = 2.7617 nat_grad_norm = 0.0827 cg_residual = 1.0190 step_size = 0.5054 reward = -0.0000 fps = 9 mse_loss = 1.6344 
2022-05-01 10:29:13.867187 - gail/main.py:164 - [TRPO] iter = 1224000 dist_mean = 0.0685 dist_std = 0.1548 vf_loss = 0.0629 grad_norm = 2.4646 nat_grad_norm = 0.1045 cg_residual = 2.7961 step_size = 0.4726 reward = -0.0000 fps = 8 mse_loss = 1.6178 
2022-05-01 10:29:23.607956 - gail/main.py:164 - [TRPO] iter = 1225000 dist_mean = 0.0629 dist_std = 0.1546 vf_loss = 0.1250 grad_norm = 2.1010 nat_grad_norm = 0.0961 cg_residual = 1.2298 step_size = 0.4841 reward = -0.0000 fps = 8 mse_loss = 1.7454 
2022-05-01 10:29:23.822888 - gail/main.py:191 - [Discriminator] iter = 1225000 loss = -0.6087 grad_norm = 3.1256 grad_penalty = 0.0618 regularization = 0.0000 true_logits = -0.4518 fake_logits = -1.1224 true_prob = 0.4043 fake_prob = 0.2895 
2022-05-01 10:30:15.476364 - gail/main.py:132 - [Evaluate] iter = 1225000 episode={ returns = 1477.8997 lengths = 423 } discounted_episode={ returns = 713.0268 lengths = 327 } 
2022-05-01 10:30:25.586106 - gail/main.py:164 - [TRPO] iter = 1226000 dist_mean = 0.0974 dist_std = 0.1546 vf_loss = 0.0847 grad_norm = 4.5957 nat_grad_norm = 0.1205 cg_residual = 2.2633 step_size = 0.3386 reward = 0.0000 fps = 16 mse_loss = 1.4413 
2022-05-01 10:30:35.783890 - gail/main.py:164 - [TRPO] iter = 1227000 dist_mean = 0.0973 dist_std = 0.1543 vf_loss = 0.3087 grad_norm = 3.5866 nat_grad_norm = 0.1064 cg_residual = 1.8516 step_size = 0.4240 reward = -0.0000 fps = 13 mse_loss = 1.6359 
2022-05-01 10:30:45.862037 - gail/main.py:164 - [TRPO] iter = 1228000 dist_mean = 0.0231 dist_std = 0.1540 vf_loss = 0.0229 grad_norm = 2.5109 nat_grad_norm = 0.0896 cg_residual = 2.1678 step_size = 0.4660 reward = -0.0000 fps = 12 mse_loss = 1.6308 
2022-05-01 10:30:56.053357 - gail/main.py:164 - [TRPO] iter = 1229000 dist_mean = 0.0952 dist_std = 0.1545 vf_loss = 0.1527 grad_norm = 3.8908 nat_grad_norm = 0.0977 cg_residual = 1.1846 step_size = 0.4134 reward = 0.0000 fps = 10 mse_loss = 1.5706 
2022-05-01 10:31:06.322497 - gail/main.py:164 - [TRPO] iter = 1230000 dist_mean = 0.0363 dist_std = 0.1543 vf_loss = 0.2042 grad_norm = 4.6236 nat_grad_norm = 0.0519 cg_residual = 0.5868 step_size = 0.5587 reward = -0.0000 fps = 9 mse_loss = 1.5412 
2022-05-01 10:31:06.631829 - gail/main.py:191 - [Discriminator] iter = 1230000 loss = -0.5609 grad_norm = 3.4481 grad_penalty = 0.0536 regularization = 0.0000 true_logits = -0.4166 fake_logits = -1.0310 true_prob = 0.4091 fake_prob = 0.2968 
2022-05-01 10:32:04.426887 - gail/main.py:132 - [Evaluate] iter = 1230000 episode={ returns = 2190.2462 lengths = 615 } discounted_episode={ returns = 500.7785 lengths = 232 } 
2022-05-01 10:32:13.901450 - gail/main.py:164 - [TRPO] iter = 1231000 dist_mean = 0.1159 dist_std = 0.1545 vf_loss = 0.2184 grad_norm = 3.9841 nat_grad_norm = 0.0812 cg_residual = 0.7759 step_size = 0.4888 reward = -0.0000 fps = 14 mse_loss = 1.5889 
2022-05-01 10:32:23.580878 - gail/main.py:164 - [TRPO] iter = 1232000 dist_mean = 0.0766 dist_std = 0.1550 vf_loss = 0.0495 grad_norm = 2.2705 nat_grad_norm = 0.0734 cg_residual = 0.7303 step_size = 0.5280 reward = -0.0000 fps = 12 mse_loss = 1.6122 
2022-05-01 10:32:33.685216 - gail/main.py:164 - [TRPO] iter = 1233000 dist_mean = 0.0687 dist_std = 0.1554 vf_loss = 0.0473 grad_norm = 2.3819 nat_grad_norm = 0.0886 cg_residual = 1.2494 step_size = 0.5114 reward = 0.0000 fps = 11 mse_loss = 1.5723 
2022-05-01 10:32:43.457692 - gail/main.py:164 - [TRPO] iter = 1234000 dist_mean = 0.1139 dist_std = 0.1553 vf_loss = 0.2770 grad_norm = 2.9575 nat_grad_norm = 0.0630 cg_residual = 0.6448 step_size = 0.5428 reward = -0.0000 fps = 10 mse_loss = 1.5773 
2022-05-01 10:32:53.334008 - gail/main.py:164 - [TRPO] iter = 1235000 dist_mean = 0.0450 dist_std = 0.1551 vf_loss = 0.1872 grad_norm = 3.0754 nat_grad_norm = 0.0678 cg_residual = 0.7628 step_size = 0.5289 reward = -0.0000 fps = 9 mse_loss = 1.6047 
2022-05-01 10:32:53.558906 - gail/main.py:191 - [Discriminator] iter = 1235000 loss = -0.5388 grad_norm = 3.0528 grad_penalty = 0.0495 regularization = 0.0000 true_logits = -0.4057 fake_logits = -0.9941 true_prob = 0.4129 fake_prob = 0.3026 
2022-05-01 10:33:57.838813 - gail/main.py:132 - [Evaluate] iter = 1235000 episode={ returns = 1840.7861 lengths = 520 } discounted_episode={ returns = 953.3312 lengths = 432 } 
2022-05-01 10:34:07.938810 - gail/main.py:164 - [TRPO] iter = 1236000 dist_mean = 0.0284 dist_std = 0.1551 vf_loss = 0.1158 grad_norm = 2.4925 nat_grad_norm = 0.0844 cg_residual = 1.1387 step_size = 0.5343 reward = 0.0000 fps = 13 mse_loss = 1.6503 
2022-05-01 10:34:17.973322 - gail/main.py:164 - [TRPO] iter = 1237000 dist_mean = 0.1014 dist_std = 0.1552 vf_loss = 0.2218 grad_norm = 3.1971 nat_grad_norm = 0.1035 cg_residual = 1.0783 step_size = 0.3976 reward = -0.0000 fps = 11 mse_loss = 1.6599 
2022-05-01 10:34:27.788358 - gail/main.py:164 - [TRPO] iter = 1238000 dist_mean = 0.0771 dist_std = 0.1551 vf_loss = 0.0285 grad_norm = 3.0325 nat_grad_norm = 0.0689 cg_residual = 1.3761 step_size = 0.5122 reward = 0.0000 fps = 10 mse_loss = 1.5763 
2022-05-01 10:34:37.621903 - gail/main.py:164 - [TRPO] iter = 1239000 dist_mean = 0.0574 dist_std = 0.1550 vf_loss = 0.0899 grad_norm = 3.3406 nat_grad_norm = 0.0991 cg_residual = 1.3792 step_size = 0.3961 reward = 0.0000 fps = 9 mse_loss = 1.8095 
2022-05-01 10:34:47.827817 - gail/main.py:164 - [TRPO] iter = 1240000 dist_mean = 0.0121 dist_std = 0.1551 vf_loss = 0.1340 grad_norm = 3.7889 nat_grad_norm = 0.0974 cg_residual = 2.1023 step_size = 0.4976 reward = 0.0000 fps = 8 mse_loss = 1.6476 
2022-05-01 10:34:48.049900 - gail/main.py:191 - [Discriminator] iter = 1240000 loss = -0.4162 grad_norm = 3.0361 grad_penalty = 0.0493 regularization = 0.0000 true_logits = -0.4778 fake_logits = -0.9434 true_prob = 0.3959 fake_prob = 0.3023 
2022-05-01 10:36:13.591079 - gail/main.py:132 - [Evaluate] iter = 1240000 episode={ returns = 1942.8811 lengths = 559 } discounted_episode={ returns = 1631.6267 lengths = 735 } 
2022-05-01 10:36:23.313740 - gail/main.py:164 - [TRPO] iter = 1241000 dist_mean = 0.0456 dist_std = 0.1547 vf_loss = 0.1701 grad_norm = 2.5549 nat_grad_norm = 0.0976 cg_residual = 1.8362 step_size = 0.4533 reward = -0.0000 fps = 10 mse_loss = 1.6593 
2022-05-01 10:36:33.084911 - gail/main.py:164 - [TRPO] iter = 1242000 dist_mean = 0.0303 dist_std = 0.1540 vf_loss = 0.2359 grad_norm = 4.8641 nat_grad_norm = 0.0803 cg_residual = 0.9044 step_size = 0.4443 reward = -0.0000 fps = 9 mse_loss = 1.6510 
2022-05-01 10:36:42.934197 - gail/main.py:164 - [TRPO] iter = 1243000 dist_mean = 0.0512 dist_std = 0.1539 vf_loss = 0.1717 grad_norm = 3.8630 nat_grad_norm = 0.0948 cg_residual = 2.2912 step_size = 0.4195 reward = 0.0000 fps = 8 mse_loss = 1.5236 
2022-05-01 10:36:52.924091 - gail/main.py:164 - [TRPO] iter = 1244000 dist_mean = 0.0630 dist_std = 0.1537 vf_loss = 0.1428 grad_norm = 1.9476 nat_grad_norm = 0.0703 cg_residual = 1.0190 step_size = 0.5659 reward = -0.0000 fps = 8 mse_loss = 1.6685 
2022-05-01 10:37:02.551078 - gail/main.py:164 - [TRPO] iter = 1245000 dist_mean = 0.0654 dist_std = 0.1535 vf_loss = 0.1003 grad_norm = 4.0386 nat_grad_norm = 0.0999 cg_residual = 1.2191 step_size = 0.4076 reward = -0.0000 fps = 7 mse_loss = 1.6747 
2022-05-01 10:37:02.815598 - gail/main.py:191 - [Discriminator] iter = 1245000 loss = -0.9659 grad_norm = 3.3177 grad_penalty = 0.0779 regularization = 0.0000 true_logits = -0.5488 fake_logits = -1.5927 true_prob = 0.3841 fake_prob = 0.2180 
2022-05-01 10:38:59.367224 - gail/main.py:132 - [Evaluate] iter = 1245000 episode={ returns = 2965.0318 lengths = 838 } discounted_episode={ returns = 2031.4802 lengths = 919 } 
2022-05-01 10:39:09.293779 - gail/main.py:164 - [TRPO] iter = 1246000 dist_mean = 0.0363 dist_std = 0.1534 vf_loss = 0.1133 grad_norm = 4.4900 nat_grad_norm = 0.0836 cg_residual = 1.9940 step_size = 0.4479 reward = 0.0000 fps = 7 mse_loss = 1.6896 
2022-05-01 10:39:18.901007 - gail/main.py:164 - [TRPO] iter = 1247000 dist_mean = 0.0789 dist_std = 0.1536 vf_loss = 0.1260 grad_norm = 2.7112 nat_grad_norm = 0.0986 cg_residual = 1.9640 step_size = 0.4493 reward = 0.0000 fps = 7 mse_loss = 1.6828 
2022-05-01 10:39:28.504463 - gail/main.py:164 - [TRPO] iter = 1248000 dist_mean = 0.0279 dist_std = 0.1535 vf_loss = 0.1527 grad_norm = 4.5239 nat_grad_norm = 0.0862 cg_residual = 1.2041 step_size = 0.4265 reward = -0.0000 fps = 6 mse_loss = 1.5746 
2022-05-01 10:39:38.104563 - gail/main.py:164 - [TRPO] iter = 1249000 dist_mean = 0.0396 dist_std = 0.1534 vf_loss = 0.1423 grad_norm = 3.0266 nat_grad_norm = 0.0723 cg_residual = 0.7232 step_size = 0.5641 reward = -0.0000 fps = 6 mse_loss = 1.7917 
2022-05-01 10:39:47.871589 - gail/main.py:164 - [TRPO] iter = 1250000 dist_mean = 0.0679 dist_std = 0.1534 vf_loss = 0.1199 grad_norm = 2.0436 nat_grad_norm = 0.0730 cg_residual = 1.3236 step_size = 0.6112 reward = 0.0000 fps = 6 mse_loss = 1.7342 
2022-05-01 10:39:48.124808 - gail/main.py:191 - [Discriminator] iter = 1250000 loss = -0.7120 grad_norm = 5.0243 grad_penalty = 0.0869 regularization = 0.0000 true_logits = -0.6831 fake_logits = -1.4820 true_prob = 0.3580 fake_prob = 0.2324 
2022-05-01 10:42:01.738165 - gail/main.py:132 - [Evaluate] iter = 1250000 episode={ returns = 3539.3738 lengths = 1000 } discounted_episode={ returns = 2185.7157 lengths = 1000 } 
2022-05-01 10:42:11.698889 - gail/main.py:164 - [TRPO] iter = 1251000 dist_mean = 0.0545 dist_std = 0.1529 vf_loss = 0.1252 grad_norm = 2.6698 nat_grad_norm = 0.0862 cg_residual = 1.3742 step_size = 0.4763 reward = 0.0000 fps = 6 mse_loss = 1.8000 
2022-05-01 10:42:21.436796 - gail/main.py:164 - [TRPO] iter = 1252000 dist_mean = 0.0619 dist_std = 0.1524 vf_loss = 0.0278 grad_norm = 3.7559 nat_grad_norm = 0.0927 cg_residual = 2.2381 step_size = 0.4264 reward = 0.0000 fps = 6 mse_loss = 1.8430 
2022-05-01 10:42:31.499776 - gail/main.py:164 - [TRPO] iter = 1253000 dist_mean = 0.0400 dist_std = 0.1526 vf_loss = 0.0926 grad_norm = 4.1288 nat_grad_norm = 0.0864 cg_residual = 1.4799 step_size = 0.4367 reward = -0.0000 fps = 6 mse_loss = 1.7303 
2022-05-01 10:42:41.156497 - gail/main.py:164 - [TRPO] iter = 1254000 dist_mean = 0.0389 dist_std = 0.1522 vf_loss = 0.1021 grad_norm = 2.2561 nat_grad_norm = 0.1424 cg_residual = 1.9929 step_size = 0.3503 reward = -0.0000 fps = 5 mse_loss = 1.8106 
2022-05-01 10:42:50.880872 - gail/main.py:164 - [TRPO] iter = 1255000 dist_mean = 0.0544 dist_std = 0.1523 vf_loss = 0.0612 grad_norm = 3.0133 nat_grad_norm = 0.0766 cg_residual = 1.1487 step_size = 0.4322 reward = -0.0000 fps = 5 mse_loss = 1.7216 
2022-05-01 10:42:51.100664 - gail/main.py:191 - [Discriminator] iter = 1255000 loss = -0.3797 grad_norm = 4.5297 grad_penalty = 0.0562 regularization = 0.0000 true_logits = -0.7440 fake_logits = -1.1799 true_prob = 0.3477 fake_prob = 0.2662 
2022-05-01 10:45:05.789566 - gail/main.py:132 - [Evaluate] iter = 1255000 episode={ returns = 3560.7648 lengths = 1000 } discounted_episode={ returns = 2194.6585 lengths = 1000 } 
2022-05-01 10:45:16.074620 - gail/main.py:164 - [TRPO] iter = 1256000 dist_mean = 0.0357 dist_std = 0.1522 vf_loss = 0.0571 grad_norm = 2.7459 nat_grad_norm = 0.0843 cg_residual = 1.7022 step_size = 0.4289 reward = -0.0000 fps = 6 mse_loss = 1.6942 
2022-05-01 10:45:26.019626 - gail/main.py:164 - [TRPO] iter = 1257000 dist_mean = 0.0238 dist_std = 0.1523 vf_loss = 0.1043 grad_norm = 1.9100 nat_grad_norm = 0.0757 cg_residual = 2.3624 step_size = 0.5934 reward = 0.0000 fps = 6 mse_loss = 1.5652 
2022-05-01 10:45:36.171252 - gail/main.py:164 - [TRPO] iter = 1258000 dist_mean = 0.0407 dist_std = 0.1528 vf_loss = 0.0370 grad_norm = 3.1992 nat_grad_norm = 0.0759 cg_residual = 1.7315 step_size = 0.4431 reward = 0.0000 fps = 6 mse_loss = 1.6539 
2022-05-01 10:45:45.995523 - gail/main.py:164 - [TRPO] iter = 1259000 dist_mean = 0.0465 dist_std = 0.1526 vf_loss = 0.0351 grad_norm = 3.1729 nat_grad_norm = 0.0727 cg_residual = 1.1304 step_size = 0.4884 reward = 0.0000 fps = 5 mse_loss = 1.7303 
2022-05-01 10:45:55.891195 - gail/main.py:164 - [TRPO] iter = 1260000 dist_mean = 0.0710 dist_std = 0.1527 vf_loss = 0.0308 grad_norm = 3.8566 nat_grad_norm = 0.0966 cg_residual = 1.4776 step_size = 0.3885 reward = -0.0000 fps = 5 mse_loss = 1.7385 
2022-05-01 10:45:56.160485 - gail/main.py:191 - [Discriminator] iter = 1260000 loss = -0.4354 grad_norm = 3.3478 grad_penalty = 0.0540 regularization = 0.0000 true_logits = -0.6223 fake_logits = -1.1117 true_prob = 0.3670 fake_prob = 0.2760 
2022-05-01 10:48:08.583504 - gail/main.py:132 - [Evaluate] iter = 1260000 episode={ returns = 3548.9169 lengths = 1000 } discounted_episode={ returns = 2186.4180 lengths = 1000 } 
2022-05-01 10:48:18.503222 - gail/main.py:164 - [TRPO] iter = 1261000 dist_mean = 0.0545 dist_std = 0.1527 vf_loss = 0.1130 grad_norm = 2.3652 nat_grad_norm = 0.0717 cg_residual = 0.3710 step_size = 0.5871 reward = 0.0000 fps = 7 mse_loss = 1.7237 
2022-05-01 10:48:28.286144 - gail/main.py:164 - [TRPO] iter = 1262000 dist_mean = 0.0422 dist_std = 0.1528 vf_loss = 0.0323 grad_norm = 3.4565 nat_grad_norm = 0.0596 cg_residual = 0.6847 step_size = 0.5979 reward = -0.0000 fps = 6 mse_loss = 1.6609 
2022-05-01 10:48:38.203043 - gail/main.py:164 - [TRPO] iter = 1263000 dist_mean = 0.0219 dist_std = 0.1529 vf_loss = 0.0439 grad_norm = 2.8029 nat_grad_norm = 0.0751 cg_residual = 0.9905 step_size = 0.5099 reward = 0.0000 fps = 6 mse_loss = 1.6598 
2022-05-01 10:48:47.724638 - gail/main.py:164 - [TRPO] iter = 1264000 dist_mean = 0.0320 dist_std = 0.1528 vf_loss = 0.0705 grad_norm = 4.9301 nat_grad_norm = 0.0572 cg_residual = 0.9380 step_size = 0.5441 reward = 0.0000 fps = 5 mse_loss = 1.5106 
2022-05-01 10:48:57.566215 - gail/main.py:164 - [TRPO] iter = 1265000 dist_mean = 0.0795 dist_std = 0.1532 vf_loss = 0.0566 grad_norm = 2.6190 nat_grad_norm = 0.0823 cg_residual = 1.5375 step_size = 0.4906 reward = -0.0000 fps = 5 mse_loss = 1.7836 
2022-05-01 10:48:57.784573 - gail/main.py:191 - [Discriminator] iter = 1265000 loss = -0.5399 grad_norm = 2.5433 grad_penalty = 0.0524 regularization = 0.0000 true_logits = -0.6136 fake_logits = -1.2059 true_prob = 0.3693 fake_prob = 0.2621 
2022-05-01 10:50:26.982712 - gail/main.py:132 - [Evaluate] iter = 1265000 episode={ returns = 2057.9470 lengths = 596 } discounted_episode={ returns = 1686.7310 lengths = 758 } 
2022-05-01 10:50:36.342521 - gail/main.py:164 - [TRPO] iter = 1266000 dist_mean = 0.0103 dist_std = 0.1531 vf_loss = 0.0443 grad_norm = 2.6076 nat_grad_norm = 0.0724 cg_residual = 1.3116 step_size = 0.5283 reward = -0.0000 fps = 10 mse_loss = 1.6490 
2022-05-01 10:50:46.106208 - gail/main.py:164 - [TRPO] iter = 1267000 dist_mean = 0.0364 dist_std = 0.1531 vf_loss = 0.0855 grad_norm = 3.3344 nat_grad_norm = 0.0697 cg_residual = 0.5487 step_size = 0.5185 reward = 0.0000 fps = 9 mse_loss = 1.6270 
2022-05-01 10:50:55.995327 - gail/main.py:164 - [TRPO] iter = 1268000 dist_mean = 0.0200 dist_std = 0.1526 vf_loss = 0.0187 grad_norm = 3.5783 nat_grad_norm = 0.0984 cg_residual = 1.5128 step_size = 0.4967 reward = 0.0000 fps = 8 mse_loss = 1.5554 
2022-05-01 10:51:05.730117 - gail/main.py:164 - [TRPO] iter = 1269000 dist_mean = 0.0223 dist_std = 0.1526 vf_loss = 0.0170 grad_norm = 3.1377 nat_grad_norm = 0.0792 cg_residual = 1.0391 step_size = 0.4733 reward = 0.0000 fps = 7 mse_loss = 1.6403 
2022-05-01 10:51:15.549324 - gail/main.py:164 - [TRPO] iter = 1270000 dist_mean = 0.0264 dist_std = 0.1529 vf_loss = 0.0260 grad_norm = 2.8767 nat_grad_norm = 0.1178 cg_residual = 1.0990 step_size = 0.4636 reward = -0.0000 fps = 7 mse_loss = 1.6730 
2022-05-01 10:51:15.757835 - gail/main.py:191 - [Discriminator] iter = 1270000 loss = -0.3890 grad_norm = 3.6962 grad_penalty = 0.0520 regularization = 0.0000 true_logits = -0.6461 fake_logits = -1.0870 true_prob = 0.3617 fake_prob = 0.2754 
2022-05-01 10:53:20.310332 - gail/main.py:132 - [Evaluate] iter = 1270000 episode={ returns = 3358.1090 lengths = 952 } discounted_episode={ returns = 2075.7359 lengths = 927 } 
2022-05-01 10:53:29.742400 - gail/main.py:164 - [TRPO] iter = 1271000 dist_mean = 0.0334 dist_std = 0.1528 vf_loss = 0.0377 grad_norm = 2.0084 nat_grad_norm = 0.0743 cg_residual = 0.9112 step_size = 0.5250 reward = 0.0000 fps = 7 mse_loss = 1.6007 
2022-05-01 10:53:39.365161 - gail/main.py:164 - [TRPO] iter = 1272000 dist_mean = 0.0210 dist_std = 0.1522 vf_loss = 0.0335 grad_norm = 2.3034 nat_grad_norm = 0.1006 cg_residual = 0.7990 step_size = 0.4498 reward = 0.0000 fps = 6 mse_loss = 1.5800 
2022-05-01 10:53:48.940398 - gail/main.py:164 - [TRPO] iter = 1273000 dist_mean = 0.0318 dist_std = 0.1518 vf_loss = 0.0378 grad_norm = 3.7904 nat_grad_norm = 0.0736 cg_residual = 1.3541 step_size = 0.4878 reward = 0.0000 fps = 6 mse_loss = 1.6197 
2022-05-01 10:53:58.588629 - gail/main.py:164 - [TRPO] iter = 1274000 dist_mean = 0.0491 dist_std = 0.1519 vf_loss = 0.0247 grad_norm = 2.8535 nat_grad_norm = 0.1160 cg_residual = 4.2234 step_size = 0.3940 reward = -0.0000 fps = 6 mse_loss = 1.5917 
2022-05-01 10:54:08.442768 - gail/main.py:164 - [TRPO] iter = 1275000 dist_mean = 0.0089 dist_std = 0.1520 vf_loss = 0.0219 grad_norm = 3.7731 nat_grad_norm = 0.0769 cg_residual = 1.7739 step_size = 0.4062 reward = 0.0000 fps = 5 mse_loss = 1.7200 
2022-05-01 10:54:08.679389 - gail/main.py:191 - [Discriminator] iter = 1275000 loss = -0.5192 grad_norm = 3.1221 grad_penalty = 0.0534 regularization = 0.0000 true_logits = -0.7146 fake_logits = -1.2872 true_prob = 0.3477 fake_prob = 0.2411 
2022-05-01 10:56:23.304375 - gail/main.py:132 - [Evaluate] iter = 1275000 episode={ returns = 3494.6679 lengths = 1000 } discounted_episode={ returns = 2149.6771 lengths = 1000 } 
2022-05-01 10:56:32.739813 - gail/main.py:164 - [TRPO] iter = 1276000 dist_mean = 0.0126 dist_std = 0.1520 vf_loss = 0.0222 grad_norm = 2.6730 nat_grad_norm = 0.0848 cg_residual = 0.5723 step_size = 0.4870 reward = 0.0000 fps = 6 mse_loss = 1.5358 
2022-05-01 10:56:42.700384 - gail/main.py:164 - [TRPO] iter = 1277000 dist_mean = 0.0331 dist_std = 0.1516 vf_loss = 0.0455 grad_norm = 3.2454 nat_grad_norm = 0.1074 cg_residual = 1.0238 step_size = 0.4514 reward = -0.0000 fps = 6 mse_loss = 1.5483 
2022-05-01 10:56:52.887842 - gail/main.py:164 - [TRPO] iter = 1278000 dist_mean = -0.0032 dist_std = 0.1517 vf_loss = 0.1055 grad_norm = 4.3565 nat_grad_norm = 0.0678 cg_residual = 0.4735 step_size = 0.5141 reward = 0.0000 fps = 6 mse_loss = 1.6214 
2022-05-01 10:57:02.632073 - gail/main.py:164 - [TRPO] iter = 1279000 dist_mean = 0.0263 dist_std = 0.1517 vf_loss = 0.0322 grad_norm = 2.5873 nat_grad_norm = 0.0946 cg_residual = 1.1908 step_size = 0.4436 reward = 0.0000 fps = 5 mse_loss = 1.5784 
2022-05-01 10:57:12.473776 - gail/main.py:164 - [TRPO] iter = 1280000 dist_mean = 0.0087 dist_std = 0.1521 vf_loss = 0.0208 grad_norm = 3.8147 nat_grad_norm = 0.0679 cg_residual = 1.5893 step_size = 0.4193 reward = -0.0000 fps = 5 mse_loss = 1.5366 
2022-05-01 10:57:12.689266 - gail/main.py:191 - [Discriminator] iter = 1280000 loss = -0.4766 grad_norm = 3.1412 grad_penalty = 0.0509 regularization = 0.0000 true_logits = -0.8149 fake_logits = -1.3424 true_prob = 0.3285 fake_prob = 0.2294 
2022-05-01 10:59:24.396882 - gail/main.py:132 - [Evaluate] iter = 1280000 episode={ returns = 3499.2878 lengths = 1000 } discounted_episode={ returns = 2153.3242 lengths = 1000 } 
2022-05-01 10:59:34.132751 - gail/main.py:164 - [TRPO] iter = 1281000 dist_mean = 0.0195 dist_std = 0.1519 vf_loss = 0.0821 grad_norm = 4.0743 nat_grad_norm = 0.0788 cg_residual = 0.8054 step_size = 0.4824 reward = 0.0000 fps = 7 mse_loss = 1.5943 
2022-05-01 10:59:43.959659 - gail/main.py:164 - [TRPO] iter = 1282000 dist_mean = 0.0304 dist_std = 0.1519 vf_loss = 0.0721 grad_norm = 3.4282 nat_grad_norm = 0.0664 cg_residual = 0.8357 step_size = 0.5337 reward = -0.0000 fps = 6 mse_loss = 1.6100 
2022-05-01 10:59:53.322857 - gail/main.py:164 - [TRPO] iter = 1283000 dist_mean = 0.0148 dist_std = 0.1518 vf_loss = 0.0376 grad_norm = 3.9956 nat_grad_norm = 0.0820 cg_residual = 3.0258 step_size = 0.4314 reward = 0.0000 fps = 6 mse_loss = 1.5246 
2022-05-01 11:00:03.182761 - gail/main.py:164 - [TRPO] iter = 1284000 dist_mean = 0.0124 dist_std = 0.1517 vf_loss = 0.0821 grad_norm = 3.0574 nat_grad_norm = 0.0681 cg_residual = 0.7062 step_size = 0.5066 reward = -0.0000 fps = 5 mse_loss = 1.5844 
2022-05-01 11:00:12.926226 - gail/main.py:164 - [TRPO] iter = 1285000 dist_mean = 0.0052 dist_std = 0.1514 vf_loss = 0.1576 grad_norm = 2.7968 nat_grad_norm = 0.0901 cg_residual = 2.2126 step_size = 0.4618 reward = 0.0000 fps = 5 mse_loss = 1.5636 
2022-05-01 11:00:13.172786 - gail/main.py:191 - [Discriminator] iter = 1285000 loss = -0.5292 grad_norm = 3.4200 grad_penalty = 0.0629 regularization = 0.0000 true_logits = -0.7800 fake_logits = -1.3720 true_prob = 0.3387 fake_prob = 0.2300 
2022-05-01 11:02:24.599948 - gail/main.py:132 - [Evaluate] iter = 1285000 episode={ returns = 3498.5777 lengths = 1000 } discounted_episode={ returns = 2155.9245 lengths = 1000 } 
2022-05-01 11:02:34.400565 - gail/main.py:164 - [TRPO] iter = 1286000 dist_mean = 0.0114 dist_std = 0.1512 vf_loss = 0.5021 grad_norm = 4.1788 nat_grad_norm = 0.1179 cg_residual = 1.7487 step_size = 0.2823 reward = 0.0000 fps = 7 mse_loss = 1.5732 
2022-05-01 11:02:44.450076 - gail/main.py:164 - [TRPO] iter = 1287000 dist_mean = 0.0247 dist_std = 0.1512 vf_loss = 0.1459 grad_norm = 4.7474 nat_grad_norm = 0.1164 cg_residual = 2.3877 step_size = 0.3697 reward = -0.0000 fps = 6 mse_loss = 1.4886 
2022-05-01 11:02:54.260716 - gail/main.py:164 - [TRPO] iter = 1288000 dist_mean = 0.0146 dist_std = 0.1509 vf_loss = 0.0405 grad_norm = 3.4006 nat_grad_norm = 0.0854 cg_residual = 1.9010 step_size = 0.4978 reward = -0.0000 fps = 6 mse_loss = 1.4819 
2022-05-01 11:03:03.922014 - gail/main.py:164 - [TRPO] iter = 1289000 dist_mean = 0.0098 dist_std = 0.1509 vf_loss = 0.1461 grad_norm = 2.5702 nat_grad_norm = 0.0524 cg_residual = 0.6644 step_size = 0.6150 reward = -0.0000 fps = 5 mse_loss = 1.5104 
2022-05-01 11:03:13.962718 - gail/main.py:164 - [TRPO] iter = 1290000 dist_mean = 0.0200 dist_std = 0.1511 vf_loss = 0.0337 grad_norm = 3.9546 nat_grad_norm = 0.0730 cg_residual = 0.4295 step_size = 0.5312 reward = 0.0000 fps = 5 mse_loss = 1.5401 
2022-05-01 11:03:14.165119 - gail/main.py:191 - [Discriminator] iter = 1290000 loss = -0.5316 grad_norm = 3.6891 grad_penalty = 0.0604 regularization = 0.0000 true_logits = -0.7559 fake_logits = -1.3480 true_prob = 0.3465 fake_prob = 0.2343 
2022-05-01 11:05:25.481674 - gail/main.py:132 - [Evaluate] iter = 1290000 episode={ returns = 3505.2798 lengths = 1000 } discounted_episode={ returns = 2160.6443 lengths = 1000 } 
2022-05-01 11:05:35.041774 - gail/main.py:164 - [TRPO] iter = 1291000 dist_mean = 0.0087 dist_std = 0.1515 vf_loss = 0.0294 grad_norm = 3.0553 nat_grad_norm = 0.0675 cg_residual = 0.6047 step_size = 0.6049 reward = -0.0000 fps = 7 mse_loss = 1.6160 
2022-05-01 11:05:44.477751 - gail/main.py:164 - [TRPO] iter = 1292000 dist_mean = 0.0314 dist_std = 0.1509 vf_loss = 0.0138 grad_norm = 3.9245 nat_grad_norm = 0.0715 cg_residual = 0.9454 step_size = 0.4932 reward = -0.0000 fps = 6 mse_loss = 1.5486 
2022-05-01 11:05:54.471467 - gail/main.py:164 - [TRPO] iter = 1293000 dist_mean = 0.0561 dist_std = 0.1508 vf_loss = 0.0255 grad_norm = 2.5970 nat_grad_norm = 0.0775 cg_residual = 0.8253 step_size = 0.5083 reward = -0.0000 fps = 6 mse_loss = 1.3925 
2022-05-01 11:06:04.432444 - gail/main.py:164 - [TRPO] iter = 1294000 dist_mean = -0.0096 dist_std = 0.1510 vf_loss = 0.0380 grad_norm = 3.7536 nat_grad_norm = 0.0722 cg_residual = 1.2642 step_size = 0.4440 reward = -0.0000 fps = 5 mse_loss = 1.5446 
2022-05-01 11:06:14.152863 - gail/main.py:164 - [TRPO] iter = 1295000 dist_mean = 0.0205 dist_std = 0.1510 vf_loss = 0.0512 grad_norm = 3.1525 nat_grad_norm = 0.1016 cg_residual = 0.7001 step_size = 0.4477 reward = 0.0000 fps = 5 mse_loss = 1.5017 
2022-05-01 11:06:14.352628 - gail/main.py:191 - [Discriminator] iter = 1295000 loss = -0.5015 grad_norm = 2.9257 grad_penalty = 0.0560 regularization = 0.0000 true_logits = -0.8351 fake_logits = -1.3927 true_prob = 0.3335 fake_prob = 0.2318 
2022-05-01 11:08:25.916256 - gail/main.py:132 - [Evaluate] iter = 1295000 episode={ returns = 3517.4430 lengths = 1000 } discounted_episode={ returns = 2157.2264 lengths = 1000 } 
2022-05-01 11:08:35.547747 - gail/main.py:164 - [TRPO] iter = 1296000 dist_mean = 0.0294 dist_std = 0.1510 vf_loss = 0.0273 grad_norm = 4.9393 nat_grad_norm = 0.0858 cg_residual = 1.8717 step_size = 0.4240 reward = 0.0000 fps = 7 mse_loss = 1.4212 
2022-05-01 11:08:45.252463 - gail/main.py:164 - [TRPO] iter = 1297000 dist_mean = 0.0483 dist_std = 0.1509 vf_loss = 0.0195 grad_norm = 2.3839 nat_grad_norm = 0.0860 cg_residual = 1.2254 step_size = 0.4957 reward = 0.0000 fps = 6 mse_loss = 1.5541 
2022-05-01 11:08:54.978398 - gail/main.py:164 - [TRPO] iter = 1298000 dist_mean = 0.0248 dist_std = 0.1512 vf_loss = 0.0220 grad_norm = 3.0569 nat_grad_norm = 0.0823 cg_residual = 1.4227 step_size = 0.4571 reward = 0.0000 fps = 6 mse_loss = 1.4782 
2022-05-01 11:09:05.063617 - gail/main.py:164 - [TRPO] iter = 1299000 dist_mean = 0.0489 dist_std = 0.1511 vf_loss = 0.0154 grad_norm = 2.9141 nat_grad_norm = 0.0734 cg_residual = 1.5317 step_size = 0.5235 reward = -0.0000 fps = 5 mse_loss = 1.4682 
2022-05-01 11:09:14.909851 - gail/main.py:164 - [TRPO] iter = 1300000 dist_mean = 0.0395 dist_std = 0.1508 vf_loss = 0.0242 grad_norm = 2.9549 nat_grad_norm = 0.0977 cg_residual = 1.9385 step_size = 0.4232 reward = -0.0000 fps = 5 mse_loss = 1.4569 
2022-05-01 11:09:15.169932 - gail/main.py:191 - [Discriminator] iter = 1300000 loss = -0.6044 grad_norm = 2.9779 grad_penalty = 0.0585 regularization = 0.0000 true_logits = -0.8848 fake_logits = -1.5477 true_prob = 0.3289 fake_prob = 0.2155 
2022-05-01 11:11:28.319697 - gail/main.py:132 - [Evaluate] iter = 1300000 episode={ returns = 3500.2679 lengths = 1000 } discounted_episode={ returns = 2152.6438 lengths = 1000 } 
2022-05-01 11:11:38.227383 - gail/main.py:164 - [TRPO] iter = 1301000 dist_mean = 0.0471 dist_std = 0.1508 vf_loss = 0.0607 grad_norm = 2.9139 nat_grad_norm = 0.1879 cg_residual = 6.3297 step_size = 0.3173 reward = -0.0000 fps = 6 mse_loss = 1.3932 
2022-05-01 11:11:48.357028 - gail/main.py:164 - [TRPO] iter = 1302000 dist_mean = 0.0301 dist_std = 0.1510 vf_loss = 0.0151 grad_norm = 3.3435 nat_grad_norm = 0.0971 cg_residual = 1.5291 step_size = 0.3535 reward = 0.0000 fps = 6 mse_loss = 1.5809 
2022-05-01 11:11:57.807378 - gail/main.py:164 - [TRPO] iter = 1303000 dist_mean = 0.0429 dist_std = 0.1509 vf_loss = 0.0299 grad_norm = 2.9632 nat_grad_norm = 0.1124 cg_residual = 1.8795 step_size = 0.3537 reward = -0.0000 fps = 6 mse_loss = 1.4297 
2022-05-01 11:12:07.589875 - gail/main.py:164 - [TRPO] iter = 1304000 dist_mean = 0.0357 dist_std = 0.1509 vf_loss = 0.0165 grad_norm = 3.4327 nat_grad_norm = 0.0756 cg_residual = 1.3566 step_size = 0.4739 reward = 0.0000 fps = 5 mse_loss = 1.3649 
2022-05-01 11:12:17.200967 - gail/main.py:164 - [TRPO] iter = 1305000 dist_mean = 0.0316 dist_std = 0.1507 vf_loss = 0.0504 grad_norm = 3.0294 nat_grad_norm = 0.0796 cg_residual = 1.1099 step_size = 0.4751 reward = -0.0000 fps = 5 mse_loss = 1.3664 
2022-05-01 11:12:17.428909 - gail/main.py:191 - [Discriminator] iter = 1305000 loss = -0.4191 grad_norm = 3.4978 grad_penalty = 0.0602 regularization = 0.0000 true_logits = -0.9422 fake_logits = -1.4215 true_prob = 0.3133 fake_prob = 0.2290 
2022-05-01 11:14:29.468845 - gail/main.py:132 - [Evaluate] iter = 1305000 episode={ returns = 3522.5917 lengths = 1000 } discounted_episode={ returns = 2166.8843 lengths = 1000 } 
2022-05-01 11:14:39.577762 - gail/main.py:164 - [TRPO] iter = 1306000 dist_mean = 0.0199 dist_std = 0.1505 vf_loss = 0.0184 grad_norm = 2.5523 nat_grad_norm = 0.0729 cg_residual = 2.1251 step_size = 0.4965 reward = -0.0000 fps = 7 mse_loss = 1.3584 
2022-05-01 11:14:49.610902 - gail/main.py:164 - [TRPO] iter = 1307000 dist_mean = 0.0462 dist_std = 0.1506 vf_loss = 0.0850 grad_norm = 4.4725 nat_grad_norm = 0.0831 cg_residual = 1.1847 step_size = 0.4567 reward = 0.0000 fps = 6 mse_loss = 1.3797 
2022-05-01 11:14:59.023702 - gail/main.py:164 - [TRPO] iter = 1308000 dist_mean = 0.0321 dist_std = 0.1504 vf_loss = 0.0129 grad_norm = 3.2329 nat_grad_norm = 0.0682 cg_residual = 0.8182 step_size = 0.5242 reward = -0.0000 fps = 6 mse_loss = 1.3664 
2022-05-01 11:15:08.759042 - gail/main.py:164 - [TRPO] iter = 1309000 dist_mean = 0.0120 dist_std = 0.1501 vf_loss = 0.0176 grad_norm = 2.3622 nat_grad_norm = 0.1302 cg_residual = 2.9819 step_size = 0.3853 reward = -0.0000 fps = 5 mse_loss = 1.3818 
2022-05-01 11:15:18.717747 - gail/main.py:164 - [TRPO] iter = 1310000 dist_mean = 0.0236 dist_std = 0.1499 vf_loss = 0.1102 grad_norm = 5.5792 nat_grad_norm = 0.0596 cg_residual = 0.7020 step_size = 0.4694 reward = -0.0000 fps = 5 mse_loss = 1.4126 
2022-05-01 11:15:18.948313 - gail/main.py:191 - [Discriminator] iter = 1310000 loss = -0.5174 grad_norm = 3.1702 grad_penalty = 0.0477 regularization = 0.0000 true_logits = -0.8913 fake_logits = -1.4565 true_prob = 0.3239 fake_prob = 0.2255 
2022-05-01 11:17:30.935005 - gail/main.py:132 - [Evaluate] iter = 1310000 episode={ returns = 3563.9281 lengths = 1000 } discounted_episode={ returns = 2187.6013 lengths = 1000 } 
2022-05-01 11:17:40.731222 - gail/main.py:164 - [TRPO] iter = 1311000 dist_mean = 0.0423 dist_std = 0.1498 vf_loss = 0.0215 grad_norm = 3.5212 nat_grad_norm = 0.0722 cg_residual = 1.2926 step_size = 0.4494 reward = 0.0000 fps = 7 mse_loss = 1.3286 
2022-05-01 11:17:50.532349 - gail/main.py:164 - [TRPO] iter = 1312000 dist_mean = 0.0180 dist_std = 0.1499 vf_loss = 0.0162 grad_norm = 4.5078 nat_grad_norm = 0.0699 cg_residual = 1.3322 step_size = 0.4194 reward = 0.0000 fps = 6 mse_loss = 1.3225 
2022-05-01 11:18:00.464576 - gail/main.py:164 - [TRPO] iter = 1313000 dist_mean = 0.0538 dist_std = 0.1499 vf_loss = 0.0212 grad_norm = 3.1010 nat_grad_norm = 0.0879 cg_residual = 1.4488 step_size = 0.4674 reward = 0.0000 fps = 6 mse_loss = 1.3429 
2022-05-01 11:18:09.990382 - gail/main.py:164 - [TRPO] iter = 1314000 dist_mean = 0.0362 dist_std = 0.1501 vf_loss = 0.0198 grad_norm = 3.6868 nat_grad_norm = 0.0987 cg_residual = 2.3831 step_size = 0.4425 reward = 0.0000 fps = 5 mse_loss = 1.4004 
2022-05-01 11:18:19.706722 - gail/main.py:164 - [TRPO] iter = 1315000 dist_mean = 0.0427 dist_std = 0.1502 vf_loss = 0.0109 grad_norm = 3.0904 nat_grad_norm = 0.0879 cg_residual = 1.8841 step_size = 0.4504 reward = 0.0000 fps = 5 mse_loss = 1.3877 
2022-05-01 11:18:19.918072 - gail/main.py:191 - [Discriminator] iter = 1315000 loss = -0.3980 grad_norm = 3.2382 grad_penalty = 0.0472 regularization = 0.0000 true_logits = -0.9716 fake_logits = -1.4168 true_prob = 0.3126 fake_prob = 0.2317 
2022-05-01 11:20:30.802217 - gail/main.py:132 - [Evaluate] iter = 1315000 episode={ returns = 3578.0250 lengths = 1000 } discounted_episode={ returns = 2196.2347 lengths = 1000 } 
2022-05-01 11:20:40.504179 - gail/main.py:164 - [TRPO] iter = 1316000 dist_mean = 0.0337 dist_std = 0.1501 vf_loss = 0.0161 grad_norm = 3.3582 nat_grad_norm = 0.0850 cg_residual = 1.5091 step_size = 0.5651 reward = -0.0000 fps = 7 mse_loss = 1.4322 
2022-05-01 11:20:50.258328 - gail/main.py:164 - [TRPO] iter = 1317000 dist_mean = 0.0298 dist_std = 0.1504 vf_loss = 0.0117 grad_norm = 2.8815 nat_grad_norm = 0.0967 cg_residual = 1.1614 step_size = 0.4764 reward = -0.0000 fps = 6 mse_loss = 1.4806 
2022-05-01 11:20:59.799722 - gail/main.py:164 - [TRPO] iter = 1318000 dist_mean = -0.0010 dist_std = 0.1507 vf_loss = 0.0249 grad_norm = 4.4564 nat_grad_norm = 0.1710 cg_residual = 3.2299 step_size = 0.2694 reward = 0.0000 fps = 6 mse_loss = 1.3835 
2022-05-01 11:21:09.393737 - gail/main.py:164 - [TRPO] iter = 1319000 dist_mean = 0.0019 dist_std = 0.1507 vf_loss = 0.0151 grad_norm = 3.3392 nat_grad_norm = 0.0959 cg_residual = 1.3060 step_size = 0.4270 reward = 0.0000 fps = 5 mse_loss = 1.3521 
2022-05-01 11:21:19.425930 - gail/main.py:164 - [TRPO] iter = 1320000 dist_mean = 0.0202 dist_std = 0.1508 vf_loss = 0.0112 grad_norm = 2.4098 nat_grad_norm = 0.0739 cg_residual = 1.2469 step_size = 0.5511 reward = 0.0000 fps = 5 mse_loss = 1.4472 
2022-05-01 11:21:19.656808 - gail/main.py:191 - [Discriminator] iter = 1320000 loss = -0.4656 grad_norm = 2.5742 grad_penalty = 0.0456 regularization = 0.0000 true_logits = -0.8448 fake_logits = -1.3560 true_prob = 0.3300 fake_prob = 0.2401 
2022-05-01 11:23:33.149490 - gail/main.py:132 - [Evaluate] iter = 1320000 episode={ returns = 3569.6734 lengths = 1000 } discounted_episode={ returns = 2196.7664 lengths = 1000 } 
2022-05-01 11:23:42.713745 - gail/main.py:164 - [TRPO] iter = 1321000 dist_mean = 0.0071 dist_std = 0.1507 vf_loss = 0.0218 grad_norm = 3.1570 nat_grad_norm = 0.0781 cg_residual = 0.5278 step_size = 0.5178 reward = 0.0000 fps = 6 mse_loss = 1.3905 
2022-05-01 11:23:52.434581 - gail/main.py:164 - [TRPO] iter = 1322000 dist_mean = -0.0123 dist_std = 0.1507 vf_loss = 0.0887 grad_norm = 4.2135 nat_grad_norm = 0.0790 cg_residual = 0.8193 step_size = 0.4803 reward = 0.0000 fps = 6 mse_loss = 1.3950 
2022-05-01 11:24:02.288130 - gail/main.py:164 - [TRPO] iter = 1323000 dist_mean = -0.0079 dist_std = 0.1509 vf_loss = 0.0133 grad_norm = 3.5728 nat_grad_norm = 0.0832 cg_residual = 1.3297 step_size = 0.4365 reward = -0.0000 fps = 6 mse_loss = 1.4149 
2022-05-01 11:24:12.285181 - gail/main.py:164 - [TRPO] iter = 1324000 dist_mean = 0.0306 dist_std = 0.1511 vf_loss = 0.0134 grad_norm = 3.0984 nat_grad_norm = 0.0882 cg_residual = 1.7030 step_size = 0.4654 reward = 0.0000 fps = 5 mse_loss = 1.3796 
2022-05-01 11:24:22.165697 - gail/main.py:164 - [TRPO] iter = 1325000 dist_mean = 0.0229 dist_std = 0.1513 vf_loss = 0.0103 grad_norm = 3.6102 nat_grad_norm = 0.0772 cg_residual = 0.7005 step_size = 0.4665 reward = -0.0000 fps = 5 mse_loss = 1.3139 
2022-05-01 11:24:22.411728 - gail/main.py:191 - [Discriminator] iter = 1325000 loss = -0.4146 grad_norm = 3.1102 grad_penalty = 0.0493 regularization = 0.0000 true_logits = -0.8964 fake_logits = -1.3603 true_prob = 0.3194 fake_prob = 0.2389 
2022-05-01 11:26:35.628498 - gail/main.py:132 - [Evaluate] iter = 1325000 episode={ returns = 3563.8487 lengths = 1000 } discounted_episode={ returns = 2196.2803 lengths = 1000 } 
2022-05-01 11:26:45.454603 - gail/main.py:164 - [TRPO] iter = 1326000 dist_mean = 0.0361 dist_std = 0.1517 vf_loss = 0.0110 grad_norm = 3.7332 nat_grad_norm = 0.0723 cg_residual = 1.0313 step_size = 0.4811 reward = 0.0000 fps = 6 mse_loss = 1.3684 
2022-05-01 11:26:54.971096 - gail/main.py:164 - [TRPO] iter = 1327000 dist_mean = -0.0072 dist_std = 0.1516 vf_loss = 0.0081 grad_norm = 3.9721 nat_grad_norm = 0.1042 cg_residual = 1.2301 step_size = 0.4128 reward = 0.0000 fps = 6 mse_loss = 1.3511 
2022-05-01 11:27:04.656821 - gail/main.py:164 - [TRPO] iter = 1328000 dist_mean = 0.0102 dist_std = 0.1516 vf_loss = 0.0876 grad_norm = 2.5250 nat_grad_norm = 0.0644 cg_residual = 0.4195 step_size = 0.6269 reward = 0.0000 fps = 6 mse_loss = 1.3744 
2022-05-01 11:27:14.380881 - gail/main.py:164 - [TRPO] iter = 1329000 dist_mean = 0.0115 dist_std = 0.1521 vf_loss = 0.0189 grad_norm = 2.9924 nat_grad_norm = 0.1063 cg_residual = 1.8388 step_size = 0.4075 reward = -0.0000 fps = 5 mse_loss = 1.3092 
2022-05-01 11:27:23.811931 - gail/main.py:164 - [TRPO] iter = 1330000 dist_mean = 0.0148 dist_std = 0.1520 vf_loss = 0.0460 grad_norm = 3.9447 nat_grad_norm = 0.0949 cg_residual = 2.5943 step_size = 0.4190 reward = 0.0000 fps = 5 mse_loss = 1.4012 
2022-05-01 11:27:24.078521 - gail/main.py:191 - [Discriminator] iter = 1330000 loss = -0.6002 grad_norm = 3.5418 grad_penalty = 0.0497 regularization = 0.0000 true_logits = -0.9038 fake_logits = -1.5536 true_prob = 0.3173 fake_prob = 0.2117 
2022-05-01 11:29:34.256059 - gail/main.py:132 - [Evaluate] iter = 1330000 episode={ returns = 3556.2742 lengths = 1000 } discounted_episode={ returns = 2180.0660 lengths = 1000 } 
2022-05-01 11:29:43.765372 - gail/main.py:164 - [TRPO] iter = 1331000 dist_mean = -0.0211 dist_std = 0.1523 vf_loss = 0.0136 grad_norm = 3.6253 nat_grad_norm = 0.0707 cg_residual = 0.6825 step_size = 0.4534 reward = -0.0000 fps = 7 mse_loss = 1.3803 
2022-05-01 11:29:53.290271 - gail/main.py:164 - [TRPO] iter = 1332000 dist_mean = -0.0234 dist_std = 0.1526 vf_loss = 0.0615 grad_norm = 3.6566 nat_grad_norm = 0.0718 cg_residual = 0.5199 step_size = 0.5868 reward = -0.0000 fps = 6 mse_loss = 1.3001 
2022-05-01 11:30:02.701887 - gail/main.py:164 - [TRPO] iter = 1333000 dist_mean = -0.0340 dist_std = 0.1523 vf_loss = 0.0562 grad_norm = 2.8424 nat_grad_norm = 0.0946 cg_residual = 1.2561 step_size = 0.5516 reward = 0.0000 fps = 6 mse_loss = 1.3446 
2022-05-01 11:30:12.300840 - gail/main.py:164 - [TRPO] iter = 1334000 dist_mean = -0.0268 dist_std = 0.1532 vf_loss = 0.0271 grad_norm = 3.6388 nat_grad_norm = 0.0782 cg_residual = 1.2335 step_size = 0.4849 reward = -0.0000 fps = 5 mse_loss = 1.3063 
2022-05-01 11:30:22.092646 - gail/main.py:164 - [TRPO] iter = 1335000 dist_mean = -0.0151 dist_std = 0.1529 vf_loss = 0.0252 grad_norm = 3.9869 nat_grad_norm = 0.0813 cg_residual = 0.9079 step_size = 0.4817 reward = -0.0000 fps = 5 mse_loss = 1.3624 
2022-05-01 11:30:22.278691 - gail/main.py:191 - [Discriminator] iter = 1335000 loss = -0.4966 grad_norm = 3.0755 grad_penalty = 0.0539 regularization = 0.0000 true_logits = -0.9747 fake_logits = -1.5251 true_prob = 0.3057 fake_prob = 0.2168 
2022-05-01 11:32:31.585304 - gail/main.py:132 - [Evaluate] iter = 1335000 episode={ returns = 3520.3651 lengths = 1000 } discounted_episode={ returns = 2145.5811 lengths = 1000 } 
2022-05-01 11:32:41.121483 - gail/main.py:164 - [TRPO] iter = 1336000 dist_mean = -0.0016 dist_std = 0.1533 vf_loss = 0.1579 grad_norm = 2.7889 nat_grad_norm = 0.0720 cg_residual = 1.0029 step_size = 0.5149 reward = 0.0000 fps = 7 mse_loss = 1.3536 
2022-05-01 11:32:50.873969 - gail/main.py:164 - [TRPO] iter = 1337000 dist_mean = 0.0159 dist_std = 0.1536 vf_loss = 0.0110 grad_norm = 2.6699 nat_grad_norm = 0.0972 cg_residual = 1.1219 step_size = 0.4381 reward = 0.0000 fps = 6 mse_loss = 1.3723 
2022-05-01 11:33:00.530979 - gail/main.py:164 - [TRPO] iter = 1338000 dist_mean = -0.0131 dist_std = 0.1537 vf_loss = 0.0190 grad_norm = 4.1798 nat_grad_norm = 0.0868 cg_residual = 1.3594 step_size = 0.4246 reward = -0.0000 fps = 6 mse_loss = 1.3370 
2022-05-01 11:33:10.178795 - gail/main.py:164 - [TRPO] iter = 1339000 dist_mean = -0.0314 dist_std = 0.1539 vf_loss = 0.1099 grad_norm = 3.3958 nat_grad_norm = 0.0793 cg_residual = 1.4493 step_size = 0.5272 reward = -0.0000 fps = 5 mse_loss = 1.5295 
2022-05-01 11:33:19.747555 - gail/main.py:164 - [TRPO] iter = 1340000 dist_mean = -0.0018 dist_std = 0.1540 vf_loss = 0.1402 grad_norm = 3.5538 nat_grad_norm = 0.0818 cg_residual = 1.5729 step_size = 0.5575 reward = -0.0000 fps = 5 mse_loss = 1.2689 
2022-05-01 11:33:19.950442 - gail/main.py:191 - [Discriminator] iter = 1340000 loss = -0.5082 grad_norm = 3.2098 grad_penalty = 0.0543 regularization = 0.0000 true_logits = -1.0476 fake_logits = -1.6101 true_prob = 0.2994 fake_prob = 0.2074 
2022-05-01 11:35:30.499064 - gail/main.py:132 - [Evaluate] iter = 1340000 episode={ returns = 3532.0423 lengths = 1000 } discounted_episode={ returns = 2168.3230 lengths = 1000 } 
2022-05-01 11:35:40.313632 - gail/main.py:164 - [TRPO] iter = 1341000 dist_mean = -0.0255 dist_std = 0.1542 vf_loss = 0.0161 grad_norm = 2.7823 nat_grad_norm = 0.0827 cg_residual = 1.2132 step_size = 0.4407 reward = -0.0000 fps = 7 mse_loss = 1.3382 
2022-05-01 11:35:50.099210 - gail/main.py:164 - [TRPO] iter = 1342000 dist_mean = -0.0021 dist_std = 0.1543 vf_loss = 0.0275 grad_norm = 4.2711 nat_grad_norm = 0.1098 cg_residual = 1.2226 step_size = 0.3556 reward = -0.0000 fps = 6 mse_loss = 1.3694 
2022-05-01 11:36:00.233406 - gail/main.py:164 - [TRPO] iter = 1343000 dist_mean = -0.0209 dist_std = 0.1542 vf_loss = 0.0097 grad_norm = 2.5595 nat_grad_norm = 0.0940 cg_residual = 1.3971 step_size = 0.4383 reward = -0.0000 fps = 6 mse_loss = 1.3374 
2022-05-01 11:36:10.402186 - gail/main.py:164 - [TRPO] iter = 1344000 dist_mean = -0.0291 dist_std = 0.1545 vf_loss = 0.0136 grad_norm = 3.8119 nat_grad_norm = 0.1036 cg_residual = 1.3999 step_size = 0.3907 reward = -0.0000 fps = 5 mse_loss = 1.3292 
2022-05-01 11:36:20.393022 - gail/main.py:164 - [TRPO] iter = 1345000 dist_mean = -0.0275 dist_std = 0.1545 vf_loss = 0.0253 grad_norm = 2.2397 nat_grad_norm = 0.0812 cg_residual = 1.3731 step_size = 0.5382 reward = -0.0000 fps = 5 mse_loss = 1.2371 
2022-05-01 11:36:20.612008 - gail/main.py:191 - [Discriminator] iter = 1345000 loss = -0.3663 grad_norm = 2.9075 grad_penalty = 0.0555 regularization = 0.0000 true_logits = -1.1372 fake_logits = -1.5591 true_prob = 0.2883 fake_prob = 0.2146 
2022-05-01 11:38:35.022630 - gail/main.py:132 - [Evaluate] iter = 1345000 episode={ returns = 3569.5317 lengths = 1000 } discounted_episode={ returns = 2194.4464 lengths = 1000 } 
2022-05-01 11:38:44.425966 - gail/main.py:164 - [TRPO] iter = 1346000 dist_mean = 0.0003 dist_std = 0.1546 vf_loss = 0.0223 grad_norm = 3.5781 nat_grad_norm = 0.0805 cg_residual = 1.0111 step_size = 0.5176 reward = 0.0000 fps = 6 mse_loss = 1.2852 
2022-05-01 11:38:54.325869 - gail/main.py:164 - [TRPO] iter = 1347000 dist_mean = -0.0122 dist_std = 0.1551 vf_loss = 0.0953 grad_norm = 3.3053 nat_grad_norm = 0.1236 cg_residual = 3.1361 step_size = 0.3585 reward = -0.0000 fps = 6 mse_loss = 1.2973 
2022-05-01 11:39:03.888709 - gail/main.py:164 - [TRPO] iter = 1348000 dist_mean = -0.0230 dist_std = 0.1550 vf_loss = 0.1345 grad_norm = 2.4316 nat_grad_norm = 0.0654 cg_residual = 1.1928 step_size = 0.6304 reward = 0.0000 fps = 6 mse_loss = 1.3568 
2022-05-01 11:39:13.504474 - gail/main.py:164 - [TRPO] iter = 1349000 dist_mean = -0.0371 dist_std = 0.1552 vf_loss = 0.0218 grad_norm = 4.4661 nat_grad_norm = 0.1019 cg_residual = 1.6559 step_size = 0.3935 reward = 0.0000 fps = 5 mse_loss = 1.3593 
2022-05-01 11:39:23.298455 - gail/main.py:164 - [TRPO] iter = 1350000 dist_mean = 0.0076 dist_std = 0.1551 vf_loss = 0.0153 grad_norm = 1.8270 nat_grad_norm = 0.1071 cg_residual = 1.6873 step_size = 0.4705 reward = 0.0000 fps = 5 mse_loss = 1.2944 
2022-05-01 11:39:23.516951 - gail/main.py:191 - [Discriminator] iter = 1350000 loss = -0.4813 grad_norm = 3.4063 grad_penalty = 0.0528 regularization = 0.0000 true_logits = -0.9683 fake_logits = -1.5024 true_prob = 0.3079 fake_prob = 0.2151 
2022-05-01 11:41:36.001533 - gail/main.py:132 - [Evaluate] iter = 1350000 episode={ returns = 3576.8328 lengths = 1000 } discounted_episode={ returns = 2200.3235 lengths = 1000 } 
2022-05-01 11:41:45.755464 - gail/main.py:164 - [TRPO] iter = 1351000 dist_mean = -0.0034 dist_std = 0.1549 vf_loss = 0.0154 grad_norm = 3.7544 nat_grad_norm = 0.1200 cg_residual = 4.0075 step_size = 0.3572 reward = -0.0000 fps = 7 mse_loss = 1.3502 
2022-05-01 11:41:55.481367 - gail/main.py:164 - [TRPO] iter = 1352000 dist_mean = -0.0025 dist_std = 0.1547 vf_loss = 0.0197 grad_norm = 3.6825 nat_grad_norm = 0.0763 cg_residual = 1.0922 step_size = 0.4548 reward = 0.0000 fps = 6 mse_loss = 1.4044 
2022-05-01 11:42:05.255186 - gail/main.py:164 - [TRPO] iter = 1353000 dist_mean = -0.0204 dist_std = 0.1547 vf_loss = 0.0173 grad_norm = 3.5710 nat_grad_norm = 0.1019 cg_residual = 2.0630 step_size = 0.3810 reward = -0.0000 fps = 6 mse_loss = 1.3745 
2022-05-01 11:42:15.210647 - gail/main.py:164 - [TRPO] iter = 1354000 dist_mean = -0.0490 dist_std = 0.1544 vf_loss = 0.1067 grad_norm = 2.7891 nat_grad_norm = 0.0827 cg_residual = 0.6867 step_size = 0.5552 reward = -0.0000 fps = 5 mse_loss = 1.3520 
2022-05-01 11:42:24.488937 - gail/main.py:164 - [TRPO] iter = 1355000 dist_mean = -0.0395 dist_std = 0.1542 vf_loss = 0.0780 grad_norm = 4.4130 nat_grad_norm = 0.0657 cg_residual = 0.9504 step_size = 0.5619 reward = -0.0000 fps = 5 mse_loss = 1.3634 
2022-05-01 11:42:24.712132 - gail/main.py:191 - [Discriminator] iter = 1355000 loss = -0.5465 grad_norm = 4.5844 grad_penalty = 0.0528 regularization = 0.0000 true_logits = -0.8850 fake_logits = -1.4843 true_prob = 0.3238 fake_prob = 0.2158 
2022-05-01 11:44:34.425365 - gail/main.py:132 - [Evaluate] iter = 1355000 episode={ returns = 3539.5790 lengths = 1000 } discounted_episode={ returns = 2177.2268 lengths = 1000 } 
2022-05-01 11:44:43.674645 - gail/main.py:164 - [TRPO] iter = 1356000 dist_mean = -0.0396 dist_std = 0.1543 vf_loss = 0.0708 grad_norm = 2.1857 nat_grad_norm = 0.0742 cg_residual = 0.9116 step_size = 0.5338 reward = -0.0000 fps = 7 mse_loss = 1.3829 
2022-05-01 11:44:53.004775 - gail/main.py:164 - [TRPO] iter = 1357000 dist_mean = -0.0556 dist_std = 0.1544 vf_loss = 0.0986 grad_norm = 2.2533 nat_grad_norm = 0.0838 cg_residual = 2.1500 step_size = 0.5243 reward = -0.0000 fps = 6 mse_loss = 1.3473 
2022-05-01 11:45:02.546114 - gail/main.py:164 - [TRPO] iter = 1358000 dist_mean = -0.0105 dist_std = 0.1537 vf_loss = 0.0860 grad_norm = 1.8034 nat_grad_norm = 0.0813 cg_residual = 0.6716 step_size = 0.5101 reward = -0.0000 fps = 6 mse_loss = 1.3214 
2022-05-01 11:45:12.052026 - gail/main.py:164 - [TRPO] iter = 1359000 dist_mean = -0.0560 dist_std = 0.1539 vf_loss = 0.0683 grad_norm = 3.9041 nat_grad_norm = 0.0825 cg_residual = 1.1264 step_size = 0.4994 reward = 0.0000 fps = 5 mse_loss = 1.3432 
2022-05-01 11:45:21.467992 - gail/main.py:164 - [TRPO] iter = 1360000 dist_mean = -0.0285 dist_std = 0.1537 vf_loss = 0.0587 grad_norm = 3.9706 nat_grad_norm = 0.0535 cg_residual = 0.4148 step_size = 0.6333 reward = -0.0000 fps = 5 mse_loss = 1.3424 
2022-05-01 11:45:21.694733 - gail/main.py:191 - [Discriminator] iter = 1360000 loss = -0.5346 grad_norm = 2.9345 grad_penalty = 0.0533 regularization = 0.0000 true_logits = -0.8513 fake_logits = -1.4392 true_prob = 0.3341 fake_prob = 0.2269 
2022-05-01 11:47:31.966149 - gail/main.py:132 - [Evaluate] iter = 1360000 episode={ returns = 3540.6085 lengths = 1000 } discounted_episode={ returns = 2170.7311 lengths = 1000 } 
2022-05-01 11:47:41.570218 - gail/main.py:164 - [TRPO] iter = 1361000 dist_mean = -0.0483 dist_std = 0.1533 vf_loss = 0.0622 grad_norm = 3.7963 nat_grad_norm = 0.0846 cg_residual = 1.0552 step_size = 0.4171 reward = -0.0000 fps = 7 mse_loss = 1.2911 
2022-05-01 11:47:51.292980 - gail/main.py:164 - [TRPO] iter = 1362000 dist_mean = -0.0309 dist_std = 0.1535 vf_loss = 0.0137 grad_norm = 2.9793 nat_grad_norm = 0.1255 cg_residual = 2.5797 step_size = 0.3580 reward = 0.0000 fps = 6 mse_loss = 1.3502 
2022-05-01 11:48:00.858741 - gail/main.py:164 - [TRPO] iter = 1363000 dist_mean = -0.0200 dist_std = 0.1534 vf_loss = 0.1181 grad_norm = 2.5351 nat_grad_norm = 0.0686 cg_residual = 0.4455 step_size = 0.5938 reward = 0.0000 fps = 6 mse_loss = 1.4646 
2022-05-01 11:48:10.634669 - gail/main.py:164 - [TRPO] iter = 1364000 dist_mean = -0.0345 dist_std = 0.1532 vf_loss = 0.0151 grad_norm = 3.3885 nat_grad_norm = 0.0924 cg_residual = 0.8372 step_size = 0.4718 reward = 0.0000 fps = 5 mse_loss = 1.3572 
2022-05-01 11:48:20.209413 - gail/main.py:164 - [TRPO] iter = 1365000 dist_mean = -0.0040 dist_std = 0.1530 vf_loss = 0.0235 grad_norm = 3.5160 nat_grad_norm = 0.1093 cg_residual = 1.8584 step_size = 0.4053 reward = -0.0000 fps = 5 mse_loss = 1.4287 
2022-05-01 11:48:20.449119 - gail/main.py:191 - [Discriminator] iter = 1365000 loss = -0.6938 grad_norm = 3.9179 grad_penalty = 0.0705 regularization = 0.0000 true_logits = -0.8091 fake_logits = -1.5734 true_prob = 0.3505 fake_prob = 0.2161 
2022-05-01 11:50:30.161745 - gail/main.py:132 - [Evaluate] iter = 1365000 episode={ returns = 3541.6942 lengths = 1000 } discounted_episode={ returns = 2178.1671 lengths = 1000 } 
2022-05-01 11:50:39.600366 - gail/main.py:164 - [TRPO] iter = 1366000 dist_mean = -0.0426 dist_std = 0.1528 vf_loss = 0.0774 grad_norm = 3.4549 nat_grad_norm = 0.0833 cg_residual = 0.6057 step_size = 0.4660 reward = -0.0000 fps = 7 mse_loss = 1.3774 
2022-05-01 11:50:49.291881 - gail/main.py:164 - [TRPO] iter = 1367000 dist_mean = -0.0423 dist_std = 0.1528 vf_loss = 0.0170 grad_norm = 2.6592 nat_grad_norm = 0.0615 cg_residual = 0.9259 step_size = 0.6615 reward = 0.0000 fps = 6 mse_loss = 1.2685 
2022-05-01 11:50:59.078475 - gail/main.py:164 - [TRPO] iter = 1368000 dist_mean = -0.0359 dist_std = 0.1520 vf_loss = 0.1114 grad_norm = 2.7907 nat_grad_norm = 0.0663 cg_residual = 0.6800 step_size = 0.6143 reward = -0.0000 fps = 6 mse_loss = 1.3030 
2022-05-01 11:51:08.730134 - gail/main.py:164 - [TRPO] iter = 1369000 dist_mean = -0.0471 dist_std = 0.1521 vf_loss = 0.0944 grad_norm = 1.8346 nat_grad_norm = 0.0882 cg_residual = 0.9275 step_size = 0.5909 reward = 0.0000 fps = 5 mse_loss = 1.3734 
2022-05-01 11:51:18.754465 - gail/main.py:164 - [TRPO] iter = 1370000 dist_mean = -0.0315 dist_std = 0.1513 vf_loss = 0.0141 grad_norm = 4.2496 nat_grad_norm = 0.0991 cg_residual = 2.8851 step_size = 0.4178 reward = -0.0000 fps = 5 mse_loss = 1.4178 
2022-05-01 11:51:18.984094 - gail/main.py:191 - [Discriminator] iter = 1370000 loss = -0.5673 grad_norm = 3.8312 grad_penalty = 0.0647 regularization = 0.0000 true_logits = -0.8413 fake_logits = -1.4733 true_prob = 0.3439 fake_prob = 0.2275 
2022-05-01 11:53:28.823113 - gail/main.py:132 - [Evaluate] iter = 1370000 episode={ returns = 3517.8954 lengths = 1000 } discounted_episode={ returns = 2166.0115 lengths = 1000 } 
2022-05-01 11:53:38.457083 - gail/main.py:164 - [TRPO] iter = 1371000 dist_mean = -0.0207 dist_std = 0.1509 vf_loss = 0.0145 grad_norm = 2.6380 nat_grad_norm = 0.0792 cg_residual = 0.9549 step_size = 0.5214 reward = -0.0000 fps = 7 mse_loss = 1.4246 
2022-05-01 11:53:48.510429 - gail/main.py:164 - [TRPO] iter = 1372000 dist_mean = -0.0361 dist_std = 0.1507 vf_loss = 0.0210 grad_norm = 2.4919 nat_grad_norm = 0.1156 cg_residual = 2.9120 step_size = 0.4410 reward = 0.0000 fps = 6 mse_loss = 1.4726 
2022-05-01 11:53:58.075857 - gail/main.py:164 - [TRPO] iter = 1373000 dist_mean = -0.0009 dist_std = 0.1504 vf_loss = 0.0197 grad_norm = 4.6545 nat_grad_norm = 0.0998 cg_residual = 1.0052 step_size = 0.4487 reward = 0.0000 fps = 6 mse_loss = 1.4168 
2022-05-01 11:54:08.379573 - gail/main.py:164 - [TRPO] iter = 1374000 dist_mean = -0.0410 dist_std = 0.1500 vf_loss = 0.0210 grad_norm = 2.3641 nat_grad_norm = 0.0838 cg_residual = 2.4729 step_size = 0.5305 reward = 0.0000 fps = 5 mse_loss = 1.3452 
2022-05-01 11:54:18.191492 - gail/main.py:164 - [TRPO] iter = 1375000 dist_mean = -0.0362 dist_std = 0.1501 vf_loss = 0.0880 grad_norm = 1.8403 nat_grad_norm = 0.0586 cg_residual = 0.8478 step_size = 0.6839 reward = -0.0000 fps = 5 mse_loss = 1.5910 
2022-05-01 11:54:18.431061 - gail/main.py:191 - [Discriminator] iter = 1375000 loss = -0.5406 grad_norm = 3.0057 grad_penalty = 0.0573 regularization = 0.0000 true_logits = -0.8809 fake_logits = -1.4788 true_prob = 0.3389 fake_prob = 0.2287 
2022-05-01 11:56:29.150234 - gail/main.py:132 - [Evaluate] iter = 1375000 episode={ returns = 3538.1209 lengths = 1000 } discounted_episode={ returns = 2176.7348 lengths = 1000 } 
2022-05-01 11:56:38.523568 - gail/main.py:164 - [TRPO] iter = 1376000 dist_mean = -0.0318 dist_std = 0.1502 vf_loss = 0.0858 grad_norm = 4.1449 nat_grad_norm = 0.0536 cg_residual = 0.7173 step_size = 0.6011 reward = 0.0000 fps = 7 mse_loss = 1.5251 
2022-05-01 11:56:48.028364 - gail/main.py:164 - [TRPO] iter = 1377000 dist_mean = -0.0399 dist_std = 0.1500 vf_loss = 0.1007 grad_norm = 2.9594 nat_grad_norm = 0.0440 cg_residual = 0.3665 step_size = 0.6857 reward = 0.0000 fps = 6 mse_loss = 1.4658 
2022-05-01 11:56:57.373716 - gail/main.py:164 - [TRPO] iter = 1378000 dist_mean = -0.0318 dist_std = 0.1501 vf_loss = 0.0281 grad_norm = 4.3938 nat_grad_norm = 0.0591 cg_residual = 0.8520 step_size = 0.5095 reward = -0.0000 fps = 6 mse_loss = 1.5486 
2022-05-01 11:57:07.238399 - gail/main.py:164 - [TRPO] iter = 1379000 dist_mean = -0.0387 dist_std = 0.1501 vf_loss = 0.1035 grad_norm = 3.0611 nat_grad_norm = 0.0601 cg_residual = 0.5704 step_size = 0.5874 reward = 0.0000 fps = 5 mse_loss = 1.5482 
2022-05-01 11:57:17.101900 - gail/main.py:164 - [TRPO] iter = 1380000 dist_mean = -0.0334 dist_std = 0.1506 vf_loss = 0.0792 grad_norm = 3.5642 nat_grad_norm = 0.0657 cg_residual = 1.1901 step_size = 0.5370 reward = 0.0000 fps = 5 mse_loss = 1.5059 
2022-05-01 11:57:17.321250 - gail/main.py:191 - [Discriminator] iter = 1380000 loss = -0.5729 grad_norm = 3.4424 grad_penalty = 0.0598 regularization = 0.0000 true_logits = -0.7724 fake_logits = -1.4050 true_prob = 0.3548 fake_prob = 0.2373 
2022-05-01 11:59:28.867703 - gail/main.py:132 - [Evaluate] iter = 1380000 episode={ returns = 3542.1895 lengths = 1000 } discounted_episode={ returns = 2173.6342 lengths = 1000 } 
2022-05-01 11:59:38.477751 - gail/main.py:164 - [TRPO] iter = 1381000 dist_mean = -0.0365 dist_std = 0.1506 vf_loss = 0.0196 grad_norm = 2.7802 nat_grad_norm = 0.0988 cg_residual = 2.8257 step_size = 0.4083 reward = -0.0000 fps = 7 mse_loss = 1.4887 
2022-05-01 11:59:47.863546 - gail/main.py:164 - [TRPO] iter = 1382000 dist_mean = -0.0375 dist_std = 0.1506 vf_loss = 0.0332 grad_norm = 2.8553 nat_grad_norm = 0.0759 cg_residual = 1.2928 step_size = 0.4786 reward = 0.0000 fps = 6 mse_loss = 1.4337 
2022-05-01 11:59:56.966015 - gail/main.py:164 - [TRPO] iter = 1383000 dist_mean = -0.0110 dist_std = 0.1503 vf_loss = 0.0445 grad_norm = 3.6211 nat_grad_norm = 0.1119 cg_residual = 2.0231 step_size = 0.3967 reward = -0.0000 fps = 6 mse_loss = 1.4637 
2022-05-01 12:00:06.655282 - gail/main.py:164 - [TRPO] iter = 1384000 dist_mean = -0.0230 dist_std = 0.1499 vf_loss = 0.1361 grad_norm = 2.7692 nat_grad_norm = 0.0560 cg_residual = 0.5476 step_size = 0.6196 reward = -0.0000 fps = 5 mse_loss = 1.4883 
2022-05-01 12:00:16.390165 - gail/main.py:164 - [TRPO] iter = 1385000 dist_mean = 0.0146 dist_std = 0.1502 vf_loss = 0.0220 grad_norm = 2.3153 nat_grad_norm = 0.0835 cg_residual = 1.8926 step_size = 0.5125 reward = -0.0000 fps = 5 mse_loss = 1.3655 
2022-05-01 12:00:16.630706 - gail/main.py:191 - [Discriminator] iter = 1385000 loss = -0.4853 grad_norm = 3.6504 grad_penalty = 0.0600 regularization = 0.0000 true_logits = -0.6651 fake_logits = -1.2104 true_prob = 0.3723 fake_prob = 0.2722 
2022-05-01 12:02:26.488348 - gail/main.py:132 - [Evaluate] iter = 1385000 episode={ returns = 3555.6093 lengths = 1000 } discounted_episode={ returns = 2183.7046 lengths = 1000 } 
2022-05-01 12:02:36.227093 - gail/main.py:164 - [TRPO] iter = 1386000 dist_mean = -0.0246 dist_std = 0.1499 vf_loss = 0.0206 grad_norm = 4.2581 nat_grad_norm = 0.1004 cg_residual = 1.5515 step_size = 0.4013 reward = 0.0000 fps = 7 mse_loss = 1.3095 
2022-05-01 12:02:45.754431 - gail/main.py:164 - [TRPO] iter = 1387000 dist_mean = -0.0159 dist_std = 0.1498 vf_loss = 0.0284 grad_norm = 3.9075 nat_grad_norm = 0.0733 cg_residual = 1.2883 step_size = 0.5062 reward = 0.0000 fps = 6 mse_loss = 1.4394 
2022-05-01 12:02:55.215792 - gail/main.py:164 - [TRPO] iter = 1388000 dist_mean = 0.0196 dist_std = 0.1499 vf_loss = 0.0980 grad_norm = 3.0729 nat_grad_norm = 0.0732 cg_residual = 0.5169 step_size = 0.5594 reward = 0.0000 fps = 6 mse_loss = 1.4481 
2022-05-01 12:03:04.862445 - gail/main.py:164 - [TRPO] iter = 1389000 dist_mean = 0.0035 dist_std = 0.1501 vf_loss = 0.0202 grad_norm = 4.4106 nat_grad_norm = 0.0717 cg_residual = 0.7730 step_size = 0.4869 reward = -0.0000 fps = 5 mse_loss = 1.4336 
2022-05-01 12:03:14.625548 - gail/main.py:164 - [TRPO] iter = 1390000 dist_mean = 0.0487 dist_std = 0.1498 vf_loss = 0.0299 grad_norm = 2.6493 nat_grad_norm = 0.0815 cg_residual = 1.3864 step_size = 0.5124 reward = 0.0000 fps = 5 mse_loss = 1.4050 
2022-05-01 12:03:14.844940 - gail/main.py:191 - [Discriminator] iter = 1390000 loss = -0.4267 grad_norm = 3.6031 grad_penalty = 0.0538 regularization = 0.0000 true_logits = -0.6209 fake_logits = -1.1015 true_prob = 0.3780 fake_prob = 0.2930 
2022-05-01 12:04:24.983183 - gail/main.py:132 - [Evaluate] iter = 1390000 episode={ returns = 1827.6033 lengths = 546 } discounted_episode={ returns = 1313.9296 lengths = 519 } 
2022-05-01 12:04:34.366155 - gail/main.py:164 - [TRPO] iter = 1391000 dist_mean = 0.0250 dist_std = 0.1498 vf_loss = 0.0259 grad_norm = 3.4759 nat_grad_norm = 0.0729 cg_residual = 1.0817 step_size = 0.5429 reward = 0.0000 fps = 12 mse_loss = 1.3741 
2022-05-01 12:04:44.211058 - gail/main.py:164 - [TRPO] iter = 1392000 dist_mean = 0.0116 dist_std = 0.1498 vf_loss = 0.0167 grad_norm = 3.7907 nat_grad_norm = 0.0783 cg_residual = 1.2541 step_size = 0.4458 reward = 0.0000 fps = 11 mse_loss = 1.3207 
2022-05-01 12:04:54.174900 - gail/main.py:164 - [TRPO] iter = 1393000 dist_mean = 0.0061 dist_std = 0.1499 vf_loss = 0.0148 grad_norm = 5.1772 nat_grad_norm = 0.0842 cg_residual = 1.4390 step_size = 0.4277 reward = -0.0000 fps = 10 mse_loss = 1.3918 
2022-05-01 12:05:03.746397 - gail/main.py:164 - [TRPO] iter = 1394000 dist_mean = 0.0147 dist_std = 0.1498 vf_loss = 0.0317 grad_norm = 2.8014 nat_grad_norm = 0.0866 cg_residual = 1.6390 step_size = 0.4564 reward = -0.0000 fps = 9 mse_loss = 1.5234 
2022-05-01 12:05:13.480483 - gail/main.py:164 - [TRPO] iter = 1395000 dist_mean = -0.0006 dist_std = 0.1497 vf_loss = 0.0293 grad_norm = 3.4811 nat_grad_norm = 0.0638 cg_residual = 0.8400 step_size = 0.5607 reward = -0.0000 fps = 8 mse_loss = 1.4768 
2022-05-01 12:05:13.704334 - gail/main.py:191 - [Discriminator] iter = 1395000 loss = -0.5272 grad_norm = 3.2016 grad_penalty = 0.0473 regularization = 0.0000 true_logits = -0.5997 fake_logits = -1.1742 true_prob = 0.3779 fake_prob = 0.2724 
2022-05-01 12:06:15.703975 - gail/main.py:132 - [Evaluate] iter = 1395000 episode={ returns = 1516.4219 lengths = 460 } discounted_episode={ returns = 1185.9677 lengths = 460 } 
2022-05-01 12:06:25.321452 - gail/main.py:164 - [TRPO] iter = 1396000 dist_mean = 0.0222 dist_std = 0.1495 vf_loss = 0.0199 grad_norm = 3.4842 nat_grad_norm = 0.0931 cg_residual = 1.2159 step_size = 0.3719 reward = 0.0000 fps = 13 mse_loss = 1.5504 
2022-05-01 12:06:34.776247 - gail/main.py:164 - [TRPO] iter = 1397000 dist_mean = 0.0549 dist_std = 0.1495 vf_loss = 0.1331 grad_norm = 4.1455 nat_grad_norm = 0.1485 cg_residual = 7.0315 step_size = 0.3248 reward = 0.0000 fps = 12 mse_loss = 1.5995 
2022-05-01 12:06:44.681145 - gail/main.py:164 - [TRPO] iter = 1398000 dist_mean = 0.0442 dist_std = 0.1490 vf_loss = 0.0920 grad_norm = 2.9788 nat_grad_norm = 0.0710 cg_residual = 1.2244 step_size = 0.5621 reward = -0.0000 fps = 10 mse_loss = 1.4579 
2022-05-01 12:06:54.606061 - gail/main.py:164 - [TRPO] iter = 1399000 dist_mean = 0.0537 dist_std = 0.1485 vf_loss = 0.0856 grad_norm = 3.8605 nat_grad_norm = 0.0768 cg_residual = 1.2288 step_size = 0.3862 reward = 0.0000 fps = 9 mse_loss = 1.5668 
2022-05-01 12:07:04.190958 - gail/main.py:164 - [TRPO] iter = 1400000 dist_mean = 0.0687 dist_std = 0.1487 vf_loss = 0.2543 grad_norm = 3.2591 nat_grad_norm = 0.0648 cg_residual = 0.9306 step_size = 0.5325 reward = 0.0000 fps = 9 mse_loss = 1.5337 
2022-05-01 12:07:04.423768 - gail/main.py:191 - [Discriminator] iter = 1400000 loss = -0.5344 grad_norm = 3.4470 grad_penalty = 0.0539 regularization = 0.0000 true_logits = -0.5684 fake_logits = -1.1567 true_prob = 0.3854 fake_prob = 0.2838 
2022-05-01 12:08:11.253774 - gail/main.py:132 - [Evaluate] iter = 1400000 episode={ returns = 1707.6632 lengths = 511 } discounted_episode={ returns = 1285.6038 lengths = 502 } 
2022-05-01 12:08:20.949752 - gail/main.py:164 - [TRPO] iter = 1401000 dist_mean = 0.0313 dist_std = 0.1489 vf_loss = 0.0187 grad_norm = 3.3090 nat_grad_norm = 0.0920 cg_residual = 1.4791 step_size = 0.4456 reward = -0.0000 fps = 13 mse_loss = 1.5719 
2022-05-01 12:08:30.694709 - gail/main.py:164 - [TRPO] iter = 1402000 dist_mean = 0.0635 dist_std = 0.1486 vf_loss = 0.0645 grad_norm = 3.3820 nat_grad_norm = 0.0884 cg_residual = 1.0066 step_size = 0.5131 reward = 0.0000 fps = 11 mse_loss = 1.5708 
2022-05-01 12:08:40.689320 - gail/main.py:164 - [TRPO] iter = 1403000 dist_mean = 0.0637 dist_std = 0.1488 vf_loss = 0.1675 grad_norm = 3.2907 nat_grad_norm = 0.0712 cg_residual = 1.3987 step_size = 0.5391 reward = 0.0000 fps = 10 mse_loss = 1.5039 
2022-05-01 12:08:50.587966 - gail/main.py:164 - [TRPO] iter = 1404000 dist_mean = 0.0450 dist_std = 0.1483 vf_loss = 0.0523 grad_norm = 2.4360 nat_grad_norm = 0.0698 cg_residual = 1.1551 step_size = 0.5723 reward = -0.0000 fps = 9 mse_loss = 1.5397 
2022-05-01 12:09:00.427577 - gail/main.py:164 - [TRPO] iter = 1405000 dist_mean = 0.0419 dist_std = 0.1484 vf_loss = 0.1470 grad_norm = 4.0418 nat_grad_norm = 0.1174 cg_residual = 2.2145 step_size = 0.3299 reward = -0.0000 fps = 8 mse_loss = 1.4776 
2022-05-01 12:09:00.642252 - gail/main.py:191 - [Discriminator] iter = 1405000 loss = -0.5473 grad_norm = 2.7255 grad_penalty = 0.0575 regularization = 0.0000 true_logits = -0.5599 fake_logits = -1.1647 true_prob = 0.3859 fake_prob = 0.2813 
2022-05-01 12:11:15.766946 - gail/main.py:132 - [Evaluate] iter = 1405000 episode={ returns = 3525.0415 lengths = 1000 } discounted_episode={ returns = 2170.3911 lengths = 1000 } 
2022-05-01 12:11:25.144651 - gail/main.py:164 - [TRPO] iter = 1406000 dist_mean = -0.0123 dist_std = 0.1482 vf_loss = 0.0353 grad_norm = 3.8238 nat_grad_norm = 0.0714 cg_residual = 0.8569 step_size = 0.5228 reward = -0.0000 fps = 6 mse_loss = 1.5537 
2022-05-01 12:11:34.923693 - gail/main.py:164 - [TRPO] iter = 1407000 dist_mean = 0.0005 dist_std = 0.1480 vf_loss = 0.0211 grad_norm = 4.2129 nat_grad_norm = 0.1074 cg_residual = 3.5718 step_size = 0.3641 reward = -0.0000 fps = 6 mse_loss = 1.6379 
2022-05-01 12:11:44.841402 - gail/main.py:164 - [TRPO] iter = 1408000 dist_mean = 0.0152 dist_std = 0.1480 vf_loss = 0.0217 grad_norm = 3.6751 nat_grad_norm = 0.1408 cg_residual = 4.9781 step_size = 0.3334 reward = -0.0000 fps = 6 mse_loss = 1.4861 
2022-05-01 12:11:54.517213 - gail/main.py:164 - [TRPO] iter = 1409000 dist_mean = 0.0771 dist_std = 0.1479 vf_loss = 0.0238 grad_norm = 4.2420 nat_grad_norm = 0.0652 cg_residual = 0.5559 step_size = 0.5819 reward = -0.0000 fps = 5 mse_loss = 1.5788 
2022-05-01 12:12:04.582817 - gail/main.py:164 - [TRPO] iter = 1410000 dist_mean = 0.0886 dist_std = 0.1475 vf_loss = 0.1469 grad_norm = 2.4548 nat_grad_norm = 0.0686 cg_residual = 0.9883 step_size = 0.6086 reward = 0.0000 fps = 5 mse_loss = 1.5087 
2022-05-01 12:12:04.805443 - gail/main.py:191 - [Discriminator] iter = 1410000 loss = -0.4666 grad_norm = 3.2292 grad_penalty = 0.0502 regularization = 0.0000 true_logits = -0.5702 fake_logits = -1.0870 true_prob = 0.3814 fake_prob = 0.2899 
2022-05-01 12:14:19.135974 - gail/main.py:132 - [Evaluate] iter = 1410000 episode={ returns = 3519.4676 lengths = 1000 } discounted_episode={ returns = 2177.3684 lengths = 1000 } 
2022-05-01 12:14:28.954062 - gail/main.py:164 - [TRPO] iter = 1411000 dist_mean = 0.0516 dist_std = 0.1475 vf_loss = 0.1769 grad_norm = 5.2451 nat_grad_norm = 0.0742 cg_residual = 0.8565 step_size = 0.5146 reward = -0.0000 fps = 6 mse_loss = 1.5953 
2022-05-01 12:14:38.894942 - gail/main.py:164 - [TRPO] iter = 1412000 dist_mean = 0.0012 dist_std = 0.1470 vf_loss = 0.0319 grad_norm = 2.2446 nat_grad_norm = 0.0879 cg_residual = 1.8311 step_size = 0.4945 reward = 0.0000 fps = 6 mse_loss = 1.6234 
2022-05-01 12:14:48.829490 - gail/main.py:164 - [TRPO] iter = 1413000 dist_mean = -0.0001 dist_std = 0.1471 vf_loss = 0.0147 grad_norm = 3.0450 nat_grad_norm = 0.1192 cg_residual = 2.0268 step_size = 0.3904 reward = 0.0000 fps = 6 mse_loss = 1.6205 
2022-05-01 12:14:58.777833 - gail/main.py:164 - [TRPO] iter = 1414000 dist_mean = 0.0082 dist_std = 0.1469 vf_loss = 0.0151 grad_norm = 2.7584 nat_grad_norm = 0.0647 cg_residual = 1.0015 step_size = 0.5109 reward = 0.0000 fps = 5 mse_loss = 1.6618 
2022-05-01 12:15:08.749685 - gail/main.py:164 - [TRPO] iter = 1415000 dist_mean = 0.0862 dist_std = 0.1469 vf_loss = 0.2272 grad_norm = 3.7951 nat_grad_norm = 0.0604 cg_residual = 0.8790 step_size = 0.5849 reward = 0.0000 fps = 5 mse_loss = 1.6375 
2022-05-01 12:15:08.973769 - gail/main.py:191 - [Discriminator] iter = 1415000 loss = -0.4190 grad_norm = 3.4771 grad_penalty = 0.0501 regularization = 0.0000 true_logits = -0.6366 fake_logits = -1.1057 true_prob = 0.3663 fake_prob = 0.2812 
2022-05-01 12:17:23.039522 - gail/main.py:132 - [Evaluate] iter = 1415000 episode={ returns = 3557.4965 lengths = 1000 } discounted_episode={ returns = 2197.9088 lengths = 1000 } 
2022-05-01 12:17:32.709736 - gail/main.py:164 - [TRPO] iter = 1416000 dist_mean = 0.0229 dist_std = 0.1467 vf_loss = 0.0343 grad_norm = 4.0649 nat_grad_norm = 0.0723 cg_residual = 0.7766 step_size = 0.4618 reward = -0.0000 fps = 6 mse_loss = 1.6707 
2022-05-01 12:17:42.341282 - gail/main.py:164 - [TRPO] iter = 1417000 dist_mean = -0.0029 dist_std = 0.1471 vf_loss = 0.0289 grad_norm = 3.3075 nat_grad_norm = 0.0771 cg_residual = 1.9517 step_size = 0.5000 reward = 0.0000 fps = 6 mse_loss = 1.5677 
2022-05-01 12:17:51.943059 - gail/main.py:164 - [TRPO] iter = 1418000 dist_mean = 0.0049 dist_std = 0.1478 vf_loss = 0.0211 grad_norm = 2.6969 nat_grad_norm = 0.0900 cg_residual = 2.0719 step_size = 0.4207 reward = -0.0000 fps = 6 mse_loss = 1.5847 
2022-05-01 12:18:01.900641 - gail/main.py:164 - [TRPO] iter = 1419000 dist_mean = 0.0012 dist_std = 0.1474 vf_loss = 0.0148 grad_norm = 3.0302 nat_grad_norm = 0.0828 cg_residual = 1.5227 step_size = 0.4576 reward = -0.0000 fps = 5 mse_loss = 1.6166 
2022-05-01 12:18:12.450292 - gail/main.py:164 - [TRPO] iter = 1420000 dist_mean = 0.0136 dist_std = 0.1473 vf_loss = 0.0142 grad_norm = 4.9781 nat_grad_norm = 0.1033 cg_residual = 3.3315 step_size = 0.3709 reward = -0.0000 fps = 5 mse_loss = 1.5315 
2022-05-01 12:18:12.660333 - gail/main.py:191 - [Discriminator] iter = 1420000 loss = -0.3350 grad_norm = 4.3531 grad_penalty = 0.0539 regularization = 0.0000 true_logits = -0.6943 fake_logits = -1.0832 true_prob = 0.3522 fake_prob = 0.2801 
2022-05-01 12:20:27.242820 - gail/main.py:132 - [Evaluate] iter = 1420000 episode={ returns = 3573.9112 lengths = 1000 } discounted_episode={ returns = 2202.4116 lengths = 1000 } 
2022-05-01 12:20:37.201990 - gail/main.py:164 - [TRPO] iter = 1421000 dist_mean = 0.0386 dist_std = 0.1470 vf_loss = 0.0231 grad_norm = 3.1924 nat_grad_norm = 0.0903 cg_residual = 2.0420 step_size = 0.4512 reward = 0.0000 fps = 6 mse_loss = 1.6352 
2022-05-01 12:20:47.135749 - gail/main.py:164 - [TRPO] iter = 1422000 dist_mean = 0.0470 dist_std = 0.1469 vf_loss = 0.0577 grad_norm = 4.2496 nat_grad_norm = 0.0771 cg_residual = 1.3912 step_size = 0.4325 reward = -0.0000 fps = 6 mse_loss = 1.6258 
2022-05-01 12:20:57.380412 - gail/main.py:164 - [TRPO] iter = 1423000 dist_mean = 0.0486 dist_std = 0.1469 vf_loss = 0.0144 grad_norm = 3.1664 nat_grad_norm = 0.1083 cg_residual = 2.3744 step_size = 0.4089 reward = -0.0000 fps = 6 mse_loss = 1.5329 
2022-05-01 12:21:07.254691 - gail/main.py:164 - [TRPO] iter = 1424000 dist_mean = 0.0239 dist_std = 0.1465 vf_loss = 0.0171 grad_norm = 3.5226 nat_grad_norm = 0.0927 cg_residual = 1.6128 step_size = 0.4237 reward = 0.0000 fps = 5 mse_loss = 1.6213 
2022-05-01 12:21:17.220557 - gail/main.py:164 - [TRPO] iter = 1425000 dist_mean = -0.0060 dist_std = 0.1465 vf_loss = 0.0207 grad_norm = 4.6516 nat_grad_norm = 0.1283 cg_residual = 4.0934 step_size = 0.3693 reward = -0.0000 fps = 5 mse_loss = 1.6059 
2022-05-01 12:21:17.459117 - gail/main.py:191 - [Discriminator] iter = 1425000 loss = -0.4518 grad_norm = 4.4822 grad_penalty = 0.0477 regularization = 0.0000 true_logits = -0.6248 fake_logits = -1.1242 true_prob = 0.3656 fake_prob = 0.2672 
2022-05-01 12:23:31.099259 - gail/main.py:132 - [Evaluate] iter = 1425000 episode={ returns = 3569.1797 lengths = 1000 } discounted_episode={ returns = 2144.9643 lengths = 962 } 
2022-05-01 12:23:41.550655 - gail/main.py:164 - [TRPO] iter = 1426000 dist_mean = 0.0278 dist_std = 0.1463 vf_loss = 0.0197 grad_norm = 2.9049 nat_grad_norm = 0.1304 cg_residual = 2.5083 step_size = 0.3743 reward = 0.0000 fps = 6 mse_loss = 1.6278 
2022-05-01 12:23:51.851425 - gail/main.py:164 - [TRPO] iter = 1427000 dist_mean = -0.0068 dist_std = 0.1463 vf_loss = 0.0234 grad_norm = 3.7408 nat_grad_norm = 0.0787 cg_residual = 2.0734 step_size = 0.4271 reward = -0.0000 fps = 6 mse_loss = 1.6593 
2022-05-01 12:24:01.676354 - gail/main.py:164 - [TRPO] iter = 1428000 dist_mean = 0.0292 dist_std = 0.1462 vf_loss = 0.0208 grad_norm = 2.9318 nat_grad_norm = 0.0894 cg_residual = 1.5657 step_size = 0.4064 reward = 0.0000 fps = 6 mse_loss = 1.6022 
2022-05-01 12:24:11.488939 - gail/main.py:164 - [TRPO] iter = 1429000 dist_mean = -0.0339 dist_std = 0.1466 vf_loss = 0.0147 grad_norm = 3.1578 nat_grad_norm = 0.1292 cg_residual = 2.8964 step_size = 0.3217 reward = -0.0000 fps = 5 mse_loss = 1.6785 
2022-05-01 12:24:21.865290 - gail/main.py:164 - [TRPO] iter = 1430000 dist_mean = 0.0081 dist_std = 0.1464 vf_loss = 0.0130 grad_norm = 2.8000 nat_grad_norm = 0.1021 cg_residual = 0.9404 step_size = 0.4327 reward = -0.0000 fps = 5 mse_loss = 1.6853 
2022-05-01 12:24:22.138989 - gail/main.py:191 - [Discriminator] iter = 1430000 loss = -0.5292 grad_norm = 3.8404 grad_penalty = 0.0531 regularization = 0.0000 true_logits = -0.7261 fake_logits = -1.3084 true_prob = 0.3493 fake_prob = 0.2456 
2022-05-01 12:26:41.733069 - gail/main.py:132 - [Evaluate] iter = 1430000 episode={ returns = 3583.4882 lengths = 1000 } discounted_episode={ returns = 2210.6701 lengths = 996 } 
2022-05-01 12:26:51.855692 - gail/main.py:164 - [TRPO] iter = 1431000 dist_mean = -0.0370 dist_std = 0.1468 vf_loss = 0.0767 grad_norm = 2.3984 nat_grad_norm = 0.0733 cg_residual = 1.6082 step_size = 0.5904 reward = -0.0000 fps = 6 mse_loss = 1.6468 
2022-05-01 12:27:02.060153 - gail/main.py:164 - [TRPO] iter = 1432000 dist_mean = -0.0029 dist_std = 0.1468 vf_loss = 0.0347 grad_norm = 3.6632 nat_grad_norm = 0.0930 cg_residual = 1.6290 step_size = 0.4647 reward = 0.0000 fps = 6 mse_loss = 1.6356 
2022-05-01 12:27:12.071356 - gail/main.py:164 - [TRPO] iter = 1433000 dist_mean = 0.0150 dist_std = 0.1470 vf_loss = 0.0162 grad_norm = 4.4409 nat_grad_norm = 0.1384 cg_residual = 4.1077 step_size = 0.2649 reward = -0.0000 fps = 5 mse_loss = 1.6258 
2022-05-01 12:27:21.919236 - gail/main.py:164 - [TRPO] iter = 1434000 dist_mean = -0.0012 dist_std = 0.1468 vf_loss = 0.0130 grad_norm = 4.0734 nat_grad_norm = 0.0915 cg_residual = 2.5805 step_size = 0.3789 reward = 0.0000 fps = 5 mse_loss = 1.6079 
2022-05-01 12:27:32.081198 - gail/main.py:164 - [TRPO] iter = 1435000 dist_mean = -0.0084 dist_std = 0.1471 vf_loss = 0.0231 grad_norm = 4.5067 nat_grad_norm = 0.1017 cg_residual = 2.2935 step_size = 0.3232 reward = -0.0000 fps = 5 mse_loss = 1.6628 
2022-05-01 12:27:32.292289 - gail/main.py:191 - [Discriminator] iter = 1435000 loss = -0.6342 grad_norm = 3.4663 grad_penalty = 0.0698 regularization = 0.0000 true_logits = -0.8924 fake_logits = -1.5964 true_prob = 0.3233 fake_prob = 0.2047 
2022-05-01 12:29:47.093413 - gail/main.py:132 - [Evaluate] iter = 1435000 episode={ returns = 3514.3912 lengths = 976 } discounted_episode={ returns = 2214.9839 lengths = 1000 } 
2022-05-01 12:29:57.120223 - gail/main.py:164 - [TRPO] iter = 1436000 dist_mean = -0.0177 dist_std = 0.1470 vf_loss = 0.0194 grad_norm = 3.9208 nat_grad_norm = 0.1424 cg_residual = 3.3788 step_size = 0.2849 reward = 0.0000 fps = 6 mse_loss = 1.6845 
2022-05-01 12:30:07.177524 - gail/main.py:164 - [TRPO] iter = 1437000 dist_mean = -0.0249 dist_std = 0.1471 vf_loss = 0.0224 grad_norm = 3.0855 nat_grad_norm = 0.0802 cg_residual = 1.8847 step_size = 0.4644 reward = -0.0000 fps = 6 mse_loss = 1.6976 
2022-05-01 12:30:17.145642 - gail/main.py:164 - [TRPO] iter = 1438000 dist_mean = -0.0115 dist_std = 0.1466 vf_loss = 0.0522 grad_norm = 4.9302 nat_grad_norm = 0.1382 cg_residual = 2.3538 step_size = 0.2871 reward = 0.0000 fps = 6 mse_loss = 1.6154 
2022-05-01 12:30:26.841139 - gail/main.py:164 - [TRPO] iter = 1439000 dist_mean = 0.0038 dist_std = 0.1468 vf_loss = 0.0328 grad_norm = 3.0381 nat_grad_norm = 0.1126 cg_residual = 1.9885 step_size = 0.3496 reward = -0.0000 fps = 5 mse_loss = 1.7114 
2022-05-01 12:30:36.821172 - gail/main.py:164 - [TRPO] iter = 1440000 dist_mean = -0.0156 dist_std = 0.1469 vf_loss = 0.0327 grad_norm = 3.2881 nat_grad_norm = 0.0590 cg_residual = 1.2716 step_size = 0.5187 reward = 0.0000 fps = 5 mse_loss = 1.6363 
2022-05-01 12:30:37.099507 - gail/main.py:191 - [Discriminator] iter = 1440000 loss = -0.4861 grad_norm = 3.2619 grad_penalty = 0.0605 regularization = 0.0000 true_logits = -0.9859 fake_logits = -1.5325 true_prob = 0.3118 fake_prob = 0.2142 
2022-05-01 12:32:51.653012 - gail/main.py:132 - [Evaluate] iter = 1440000 episode={ returns = 3569.8678 lengths = 1000 } discounted_episode={ returns = 2195.1868 lengths = 989 } 
2022-05-01 12:33:01.497465 - gail/main.py:164 - [TRPO] iter = 1441000 dist_mean = -0.0155 dist_std = 0.1468 vf_loss = 0.0350 grad_norm = 4.7907 nat_grad_norm = 0.1029 cg_residual = 2.5558 step_size = 0.4215 reward = 0.0000 fps = 6 mse_loss = 1.7705 
2022-05-01 12:33:11.534702 - gail/main.py:164 - [TRPO] iter = 1442000 dist_mean = -0.0143 dist_std = 0.1470 vf_loss = 0.0570 grad_norm = 3.4898 nat_grad_norm = 0.0963 cg_residual = 1.6962 step_size = 0.4071 reward = 0.0000 fps = 6 mse_loss = 1.7386 
2022-05-01 12:33:21.585885 - gail/main.py:164 - [TRPO] iter = 1443000 dist_mean = 0.0088 dist_std = 0.1471 vf_loss = 0.0433 grad_norm = 4.1804 nat_grad_norm = 0.0688 cg_residual = 0.9330 step_size = 0.4332 reward = -0.0000 fps = 6 mse_loss = 1.5558 
2022-05-01 12:33:31.544114 - gail/main.py:164 - [TRPO] iter = 1444000 dist_mean = -0.0067 dist_std = 0.1471 vf_loss = 0.0331 grad_norm = 3.9994 nat_grad_norm = 0.0598 cg_residual = 1.1276 step_size = 0.5559 reward = -0.0000 fps = 5 mse_loss = 1.7024 
2022-05-01 12:33:41.566288 - gail/main.py:164 - [TRPO] iter = 1445000 dist_mean = 0.0041 dist_std = 0.1474 vf_loss = 0.0401 grad_norm = 4.0424 nat_grad_norm = 0.0740 cg_residual = 1.8173 step_size = 0.4900 reward = -0.0000 fps = 5 mse_loss = 1.5768 
2022-05-01 12:33:41.799880 - gail/main.py:191 - [Discriminator] iter = 1445000 loss = -0.4391 grad_norm = 3.7785 grad_penalty = 0.0610 regularization = 0.0000 true_logits = -1.0473 fake_logits = -1.5475 true_prob = 0.2982 fake_prob = 0.2085 
2022-05-01 12:35:55.490507 - gail/main.py:132 - [Evaluate] iter = 1445000 episode={ returns = 3556.3005 lengths = 1000 } discounted_episode={ returns = 2195.0017 lengths = 1000 } 
2022-05-01 12:36:05.258371 - gail/main.py:164 - [TRPO] iter = 1446000 dist_mean = -0.0161 dist_std = 0.1473 vf_loss = 0.0277 grad_norm = 5.0430 nat_grad_norm = 0.0821 cg_residual = 1.4858 step_size = 0.4175 reward = -0.0000 fps = 6 mse_loss = 1.7196 
2022-05-01 12:36:15.167177 - gail/main.py:164 - [TRPO] iter = 1447000 dist_mean = 0.0005 dist_std = 0.1471 vf_loss = 0.0324 grad_norm = 2.8062 nat_grad_norm = 0.0837 cg_residual = 1.9346 step_size = 0.4782 reward = -0.0000 fps = 6 mse_loss = 1.6703 
2022-05-01 12:36:25.275078 - gail/main.py:164 - [TRPO] iter = 1448000 dist_mean = 0.0181 dist_std = 0.1472 vf_loss = 0.0320 grad_norm = 2.4645 nat_grad_norm = 0.0751 cg_residual = 1.9434 step_size = 0.5320 reward = 0.0000 fps = 6 mse_loss = 1.5537 
2022-05-01 12:36:35.108444 - gail/main.py:164 - [TRPO] iter = 1449000 dist_mean = 0.0278 dist_std = 0.1465 vf_loss = 0.1090 grad_norm = 2.2682 nat_grad_norm = 0.0706 cg_residual = 0.9752 step_size = 0.6310 reward = 0.0000 fps = 5 mse_loss = 1.6890 
2022-05-01 12:36:44.462038 - gail/main.py:164 - [TRPO] iter = 1450000 dist_mean = 0.0386 dist_std = 0.1458 vf_loss = 0.0280 grad_norm = 5.0857 nat_grad_norm = 0.0771 cg_residual = 1.8648 step_size = 0.4471 reward = 0.0000 fps = 5 mse_loss = 1.6763 
2022-05-01 12:36:44.687049 - gail/main.py:191 - [Discriminator] iter = 1450000 loss = -0.3729 grad_norm = 3.5578 grad_penalty = 0.0508 regularization = 0.0000 true_logits = -0.9943 fake_logits = -1.4180 true_prob = 0.3033 fake_prob = 0.2269 
2022-05-01 12:38:57.801745 - gail/main.py:132 - [Evaluate] iter = 1450000 episode={ returns = 3529.5449 lengths = 1000 } discounted_episode={ returns = 2177.5763 lengths = 1000 } 
2022-05-01 12:39:07.787405 - gail/main.py:164 - [TRPO] iter = 1451000 dist_mean = 0.0092 dist_std = 0.1457 vf_loss = 0.0370 grad_norm = 4.7218 nat_grad_norm = 0.0821 cg_residual = 1.0815 step_size = 0.4264 reward = -0.0000 fps = 6 mse_loss = 1.7061 
2022-05-01 12:39:17.590141 - gail/main.py:164 - [TRPO] iter = 1452000 dist_mean = 0.0407 dist_std = 0.1454 vf_loss = 0.0202 grad_norm = 3.4785 nat_grad_norm = 0.0559 cg_residual = 1.5383 step_size = 0.5586 reward = 0.0000 fps = 6 mse_loss = 1.6584 
2022-05-01 12:39:26.948220 - gail/main.py:164 - [TRPO] iter = 1453000 dist_mean = 0.0691 dist_std = 0.1453 vf_loss = 0.0304 grad_norm = 5.5925 nat_grad_norm = 0.0699 cg_residual = 0.9824 step_size = 0.4767 reward = -0.0000 fps = 6 mse_loss = 1.6204 
2022-05-01 12:39:36.892997 - gail/main.py:164 - [TRPO] iter = 1454000 dist_mean = 0.0600 dist_std = 0.1450 vf_loss = 0.0238 grad_norm = 4.5176 nat_grad_norm = 0.0843 cg_residual = 1.8143 step_size = 0.4084 reward = 0.0000 fps = 5 mse_loss = 1.4451 
2022-05-01 12:39:46.671034 - gail/main.py:164 - [TRPO] iter = 1455000 dist_mean = 0.0881 dist_std = 0.1450 vf_loss = 0.0991 grad_norm = 3.8485 nat_grad_norm = 0.0558 cg_residual = 0.6903 step_size = 0.5914 reward = 0.0000 fps = 5 mse_loss = 1.4809 
2022-05-01 12:39:46.931456 - gail/main.py:191 - [Discriminator] iter = 1455000 loss = -0.4148 grad_norm = 2.7638 grad_penalty = 0.0444 regularization = 0.0000 true_logits = -0.9307 fake_logits = -1.3899 true_prob = 0.3094 fake_prob = 0.2305 
2022-05-01 12:42:03.497979 - gail/main.py:132 - [Evaluate] iter = 1455000 episode={ returns = 3427.1709 lengths = 1000 } discounted_episode={ returns = 2117.5544 lengths = 1000 } 
2022-05-01 12:42:13.536829 - gail/main.py:164 - [TRPO] iter = 1456000 dist_mean = 0.1002 dist_std = 0.1451 vf_loss = 0.1223 grad_norm = 3.5370 nat_grad_norm = 0.0715 cg_residual = 1.3735 step_size = 0.5417 reward = -0.0000 fps = 6 mse_loss = 1.6661 
2022-05-01 12:42:23.365641 - gail/main.py:164 - [TRPO] iter = 1457000 dist_mean = 0.0840 dist_std = 0.1453 vf_loss = 0.0202 grad_norm = 4.2396 nat_grad_norm = 0.0730 cg_residual = 1.5227 step_size = 0.4228 reward = -0.0000 fps = 6 mse_loss = 1.4930 
2022-05-01 12:42:33.112035 - gail/main.py:164 - [TRPO] iter = 1458000 dist_mean = 0.0998 dist_std = 0.1453 vf_loss = 0.0265 grad_norm = 3.2390 nat_grad_norm = 0.0739 cg_residual = 1.3134 step_size = 0.4548 reward = 0.0000 fps = 6 mse_loss = 1.5185 
2022-05-01 12:42:43.051835 - gail/main.py:164 - [TRPO] iter = 1459000 dist_mean = 0.0934 dist_std = 0.1453 vf_loss = 0.0730 grad_norm = 2.6501 nat_grad_norm = 0.0869 cg_residual = 2.1246 step_size = 0.4684 reward = 0.0000 fps = 5 mse_loss = 1.5334 
2022-05-01 12:42:53.009236 - gail/main.py:164 - [TRPO] iter = 1460000 dist_mean = 0.0739 dist_std = 0.1455 vf_loss = 0.0368 grad_norm = 2.4994 nat_grad_norm = 0.0487 cg_residual = 0.7300 step_size = 0.6104 reward = -0.0000 fps = 5 mse_loss = 1.5222 
2022-05-01 12:42:53.232217 - gail/main.py:191 - [Discriminator] iter = 1460000 loss = -0.4457 grad_norm = 2.8736 grad_penalty = 0.0467 regularization = 0.0000 true_logits = -0.9618 fake_logits = -1.4542 true_prob = 0.3065 fake_prob = 0.2195 
2022-05-01 12:45:09.458435 - gail/main.py:132 - [Evaluate] iter = 1460000 episode={ returns = 3449.3091 lengths = 1000 } discounted_episode={ returns = 2128.9709 lengths = 1000 } 
2022-05-01 12:45:19.482415 - gail/main.py:164 - [TRPO] iter = 1461000 dist_mean = 0.0892 dist_std = 0.1456 vf_loss = 0.0160 grad_norm = 2.4726 nat_grad_norm = 0.0698 cg_residual = 0.7955 step_size = 0.5961 reward = -0.0000 fps = 6 mse_loss = 1.5586 
2022-05-01 12:45:29.231801 - gail/main.py:164 - [TRPO] iter = 1462000 dist_mean = 0.0981 dist_std = 0.1457 vf_loss = 0.0594 grad_norm = 2.0336 nat_grad_norm = 0.0618 cg_residual = 1.4394 step_size = 0.5691 reward = 0.0000 fps = 6 mse_loss = 1.5345 
2022-05-01 12:45:38.423096 - gail/main.py:164 - [TRPO] iter = 1463000 dist_mean = 0.0847 dist_std = 0.1457 vf_loss = 0.0383 grad_norm = 4.4151 nat_grad_norm = 0.0921 cg_residual = 2.6907 step_size = 0.3626 reward = -0.0000 fps = 6 mse_loss = 1.4763 
2022-05-01 12:45:48.228530 - gail/main.py:164 - [TRPO] iter = 1464000 dist_mean = 0.0866 dist_std = 0.1455 vf_loss = 0.0240 grad_norm = 2.9988 nat_grad_norm = 0.0722 cg_residual = 1.2322 step_size = 0.4846 reward = 0.0000 fps = 5 mse_loss = 1.4441 
2022-05-01 12:45:58.157628 - gail/main.py:164 - [TRPO] iter = 1465000 dist_mean = 0.1057 dist_std = 0.1458 vf_loss = 0.1112 grad_norm = 3.1034 nat_grad_norm = 0.0701 cg_residual = 0.8225 step_size = 0.5407 reward = -0.0000 fps = 5 mse_loss = 1.5169 
2022-05-01 12:45:58.388781 - gail/main.py:191 - [Discriminator] iter = 1465000 loss = -0.3937 grad_norm = 3.1742 grad_penalty = 0.0492 regularization = 0.0000 true_logits = -0.9815 fake_logits = -1.4245 true_prob = 0.3011 fake_prob = 0.2276 
2022-05-01 12:48:12.273558 - gail/main.py:132 - [Evaluate] iter = 1465000 episode={ returns = 3460.0245 lengths = 1000 } discounted_episode={ returns = 2134.7062 lengths = 1000 } 
2022-05-01 12:48:22.185765 - gail/main.py:164 - [TRPO] iter = 1466000 dist_mean = 0.0664 dist_std = 0.1461 vf_loss = 0.0233 grad_norm = 2.6064 nat_grad_norm = 0.0610 cg_residual = 0.7705 step_size = 0.6035 reward = 0.0000 fps = 6 mse_loss = 1.3923 
2022-05-01 12:48:31.972721 - gail/main.py:164 - [TRPO] iter = 1467000 dist_mean = 0.0789 dist_std = 0.1464 vf_loss = 0.0318 grad_norm = 3.6016 nat_grad_norm = 0.0568 cg_residual = 0.6397 step_size = 0.4808 reward = 0.0000 fps = 6 mse_loss = 1.5867 
2022-05-01 12:48:41.794788 - gail/main.py:164 - [TRPO] iter = 1468000 dist_mean = 0.0558 dist_std = 0.1464 vf_loss = 0.0117 grad_norm = 4.7849 nat_grad_norm = 0.0708 cg_residual = 1.3596 step_size = 0.4253 reward = 0.0000 fps = 6 mse_loss = 1.5097 
2022-05-01 12:48:51.733431 - gail/main.py:164 - [TRPO] iter = 1469000 dist_mean = 0.0963 dist_std = 0.1464 vf_loss = 0.0435 grad_norm = 3.5497 nat_grad_norm = 0.1480 cg_residual = 2.1194 step_size = 0.3278 reward = -0.0000 fps = 5 mse_loss = 1.6226 
2022-05-01 12:49:01.798284 - gail/main.py:164 - [TRPO] iter = 1470000 dist_mean = 0.0441 dist_std = 0.1463 vf_loss = 0.0177 grad_norm = 2.8865 nat_grad_norm = 0.1237 cg_residual = 2.1663 step_size = 0.3334 reward = 0.0000 fps = 5 mse_loss = 1.3706 
2022-05-01 12:49:02.007479 - gail/main.py:191 - [Discriminator] iter = 1470000 loss = -0.4824 grad_norm = 3.1916 grad_penalty = 0.0527 regularization = 0.0000 true_logits = -0.8619 fake_logits = -1.3970 true_prob = 0.3196 fake_prob = 0.2237 
2022-05-01 12:51:17.754510 - gail/main.py:132 - [Evaluate] iter = 1470000 episode={ returns = 3471.7134 lengths = 1000 } discounted_episode={ returns = 2136.6352 lengths = 1000 } 
2022-05-01 12:51:27.759419 - gail/main.py:164 - [TRPO] iter = 1471000 dist_mean = 0.1031 dist_std = 0.1462 vf_loss = 0.0894 grad_norm = 3.4352 nat_grad_norm = 0.0786 cg_residual = 2.7064 step_size = 0.3961 reward = 0.0000 fps = 6 mse_loss = 1.4772 
2022-05-01 12:51:37.771019 - gail/main.py:164 - [TRPO] iter = 1472000 dist_mean = 0.0199 dist_std = 0.1462 vf_loss = 0.0140 grad_norm = 3.8397 nat_grad_norm = 0.1170 cg_residual = 2.9192 step_size = 0.3265 reward = 0.0000 fps = 6 mse_loss = 1.5697 
2022-05-01 12:51:47.955852 - gail/main.py:164 - [TRPO] iter = 1473000 dist_mean = 0.0631 dist_std = 0.1462 vf_loss = 0.0119 grad_norm = 3.2357 nat_grad_norm = 0.1031 cg_residual = 2.3424 step_size = 0.3947 reward = 0.0000 fps = 6 mse_loss = 1.4306 
2022-05-01 12:51:58.034629 - gail/main.py:164 - [TRPO] iter = 1474000 dist_mean = 0.0452 dist_std = 0.1460 vf_loss = 0.0181 grad_norm = 3.3425 nat_grad_norm = 0.1109 cg_residual = 2.0204 step_size = 0.3591 reward = -0.0000 fps = 5 mse_loss = 1.4031 
2022-05-01 12:52:08.286578 - gail/main.py:164 - [TRPO] iter = 1475000 dist_mean = 0.0648 dist_std = 0.1459 vf_loss = 0.0097 grad_norm = 3.3268 nat_grad_norm = 0.1116 cg_residual = 3.6501 step_size = 0.3344 reward = -0.0000 fps = 5 mse_loss = 1.4404 
2022-05-01 12:52:08.534965 - gail/main.py:191 - [Discriminator] iter = 1475000 loss = -0.5111 grad_norm = 3.2086 grad_penalty = 0.0459 regularization = 0.0000 true_logits = -0.8544 fake_logits = -1.4114 true_prob = 0.3248 fake_prob = 0.2248 
2022-05-01 12:52:31.489943 - gail/main.py:132 - [Evaluate] iter = 1475000 episode={ returns = 135.4806 lengths = 70 } discounted_episode={ returns = 538.5098 lengths = 256 } 
2022-05-01 12:52:41.538590 - gail/main.py:164 - [TRPO] iter = 1476000 dist_mean = 0.0431 dist_std = 0.1461 vf_loss = 0.0350 grad_norm = 4.4588 nat_grad_norm = 0.0721 cg_residual = 1.7104 step_size = 0.4293 reward = 0.0000 fps = 30 mse_loss = 1.4074 
2022-05-01 12:52:51.472423 - gail/main.py:164 - [TRPO] iter = 1477000 dist_mean = 0.0284 dist_std = 0.1462 vf_loss = 0.0254 grad_norm = 3.6230 nat_grad_norm = 0.0812 cg_residual = 1.2345 step_size = 0.4894 reward = 0.0000 fps = 23 mse_loss = 1.3045 
2022-05-01 12:53:01.581569 - gail/main.py:164 - [TRPO] iter = 1478000 dist_mean = 0.0389 dist_std = 0.1466 vf_loss = 0.0126 grad_norm = 4.8581 nat_grad_norm = 0.1155 cg_residual = 3.1356 step_size = 0.3230 reward = -0.0000 fps = 18 mse_loss = 1.2920 
2022-05-01 12:53:11.678145 - gail/main.py:164 - [TRPO] iter = 1479000 dist_mean = 0.0325 dist_std = 0.1468 vf_loss = 0.0216 grad_norm = 5.1076 nat_grad_norm = 0.1322 cg_residual = 6.6941 step_size = 0.3022 reward = -0.0000 fps = 15 mse_loss = 1.3463 
2022-05-01 12:53:21.392083 - gail/main.py:164 - [TRPO] iter = 1480000 dist_mean = 0.0332 dist_std = 0.1466 vf_loss = 0.0108 grad_norm = 3.7131 nat_grad_norm = 0.0740 cg_residual = 0.9273 step_size = 0.4485 reward = -0.0000 fps = 13 mse_loss = 1.2993 
2022-05-01 12:53:21.628189 - gail/main.py:191 - [Discriminator] iter = 1480000 loss = -0.4616 grad_norm = 3.4269 grad_penalty = 0.0553 regularization = 0.0000 true_logits = -0.8223 fake_logits = -1.3391 true_prob = 0.3330 fake_prob = 0.2343 
2022-05-01 12:55:38.263007 - gail/main.py:132 - [Evaluate] iter = 1480000 episode={ returns = 3552.4753 lengths = 1000 } discounted_episode={ returns = 2191.5030 lengths = 1000 } 
2022-05-01 12:55:48.188681 - gail/main.py:164 - [TRPO] iter = 1481000 dist_mean = 0.0057 dist_std = 0.1463 vf_loss = 0.0140 grad_norm = 3.4665 nat_grad_norm = 0.1177 cg_residual = 3.5898 step_size = 0.3527 reward = -0.0000 fps = 6 mse_loss = 1.3479 
2022-05-01 12:55:58.139443 - gail/main.py:164 - [TRPO] iter = 1482000 dist_mean = 0.0246 dist_std = 0.1462 vf_loss = 0.0175 grad_norm = 2.0507 nat_grad_norm = 0.0930 cg_residual = 1.4026 step_size = 0.4985 reward = -0.0000 fps = 6 mse_loss = 1.3094 
2022-05-01 12:56:08.330272 - gail/main.py:164 - [TRPO] iter = 1483000 dist_mean = 0.0249 dist_std = 0.1464 vf_loss = 0.0093 grad_norm = 3.3869 nat_grad_norm = 0.1053 cg_residual = 2.5124 step_size = 0.3739 reward = 0.0000 fps = 5 mse_loss = 1.4075 
2022-05-01 12:56:18.327648 - gail/main.py:164 - [TRPO] iter = 1484000 dist_mean = 0.0037 dist_std = 0.1463 vf_loss = 0.0131 grad_norm = 3.1514 nat_grad_norm = 0.0855 cg_residual = 2.3029 step_size = 0.4568 reward = 0.0000 fps = 5 mse_loss = 1.2961 
2022-05-01 12:56:28.443046 - gail/main.py:164 - [TRPO] iter = 1485000 dist_mean = 0.0208 dist_std = 0.1461 vf_loss = 0.0098 grad_norm = 3.0738 nat_grad_norm = 0.0840 cg_residual = 1.4898 step_size = 0.4203 reward = -0.0000 fps = 5 mse_loss = 1.3595 
2022-05-01 12:56:28.666858 - gail/main.py:191 - [Discriminator] iter = 1485000 loss = -0.4709 grad_norm = 3.3143 grad_penalty = 0.0525 regularization = 0.0000 true_logits = -0.8469 fake_logits = -1.3703 true_prob = 0.3296 fake_prob = 0.2322 
2022-05-01 12:58:40.740344 - gail/main.py:132 - [Evaluate] iter = 1485000 episode={ returns = 3566.5463 lengths = 1000 } discounted_episode={ returns = 2203.0838 lengths = 1000 } 
2022-05-01 12:58:50.683024 - gail/main.py:164 - [TRPO] iter = 1486000 dist_mean = 0.0424 dist_std = 0.1461 vf_loss = 0.0125 grad_norm = 2.9529 nat_grad_norm = 0.1252 cg_residual = 1.9968 step_size = 0.3280 reward = 0.0000 fps = 7 mse_loss = 1.4148 
2022-05-01 12:59:00.465934 - gail/main.py:164 - [TRPO] iter = 1487000 dist_mean = 0.0237 dist_std = 0.1464 vf_loss = 0.0109 grad_norm = 2.8219 nat_grad_norm = 0.1037 cg_residual = 3.9848 step_size = 0.3907 reward = -0.0000 fps = 6 mse_loss = 1.3594 
2022-05-01 12:59:10.268978 - gail/main.py:164 - [TRPO] iter = 1488000 dist_mean = 0.0138 dist_std = 0.1460 vf_loss = 0.0175 grad_norm = 4.1022 nat_grad_norm = 0.0845 cg_residual = 2.0371 step_size = 0.4561 reward = -0.0000 fps = 6 mse_loss = 1.4861 
2022-05-01 12:59:20.208891 - gail/main.py:164 - [TRPO] iter = 1489000 dist_mean = 0.0038 dist_std = 0.1461 vf_loss = 0.0235 grad_norm = 2.8060 nat_grad_norm = 0.0719 cg_residual = 1.2752 step_size = 0.4780 reward = -0.0000 fps = 5 mse_loss = 1.3266 
2022-05-01 12:59:30.003297 - gail/main.py:164 - [TRPO] iter = 1490000 dist_mean = 0.0139 dist_std = 0.1460 vf_loss = 0.0098 grad_norm = 5.0481 nat_grad_norm = 0.1081 cg_residual = 2.0640 step_size = 0.3493 reward = -0.0000 fps = 5 mse_loss = 1.2035 
2022-05-01 12:59:30.222792 - gail/main.py:191 - [Discriminator] iter = 1490000 loss = -0.4617 grad_norm = 3.4360 grad_penalty = 0.0541 regularization = 0.0000 true_logits = -0.7904 fake_logits = -1.3062 true_prob = 0.3390 fake_prob = 0.2412 
2022-05-01 13:01:45.402027 - gail/main.py:132 - [Evaluate] iter = 1490000 episode={ returns = 3577.1910 lengths = 1000 } discounted_episode={ returns = 2209.4788 lengths = 1000 } 
2022-05-01 13:01:55.056456 - gail/main.py:164 - [TRPO] iter = 1491000 dist_mean = 0.0015 dist_std = 0.1461 vf_loss = 0.0082 grad_norm = 2.9640 nat_grad_norm = 0.0812 cg_residual = 1.0933 step_size = 0.4635 reward = 0.0000 fps = 6 mse_loss = 1.3255 
2022-05-01 13:02:04.604495 - gail/main.py:164 - [TRPO] iter = 1492000 dist_mean = -0.0070 dist_std = 0.1464 vf_loss = 0.0080 grad_norm = 3.3013 nat_grad_norm = 0.0713 cg_residual = 2.1787 step_size = 0.4958 reward = 0.0000 fps = 6 mse_loss = 1.2562 
2022-05-01 13:02:14.731843 - gail/main.py:164 - [TRPO] iter = 1493000 dist_mean = -0.0156 dist_std = 0.1464 vf_loss = 0.0181 grad_norm = 2.6561 nat_grad_norm = 0.0880 cg_residual = 3.2441 step_size = 0.4566 reward = -0.0000 fps = 6 mse_loss = 1.3241 
2022-05-01 13:02:24.867990 - gail/main.py:164 - [TRPO] iter = 1494000 dist_mean = 0.0151 dist_std = 0.1463 vf_loss = 0.0205 grad_norm = 5.2260 nat_grad_norm = 0.1201 cg_residual = 3.9403 step_size = 0.3456 reward = 0.0000 fps = 5 mse_loss = 1.2733 
2022-05-01 13:02:34.397697 - gail/main.py:164 - [TRPO] iter = 1495000 dist_mean = 0.0056 dist_std = 0.1462 vf_loss = 0.0104 grad_norm = 3.6808 nat_grad_norm = 0.0878 cg_residual = 3.7016 step_size = 0.4034 reward = -0.0000 fps = 5 mse_loss = 1.2248 
2022-05-01 13:02:34.607873 - gail/main.py:191 - [Discriminator] iter = 1495000 loss = -0.5105 grad_norm = 2.9699 grad_penalty = 0.0579 regularization = 0.0000 true_logits = -0.6613 fake_logits = -1.2296 true_prob = 0.3607 fake_prob = 0.2527 
2022-05-01 13:04:38.989883 - gail/main.py:132 - [Evaluate] iter = 1495000 episode={ returns = 3578.7528 lengths = 1000 } discounted_episode={ returns = 2002.8532 lengths = 907 } 
2022-05-01 13:04:48.974209 - gail/main.py:164 - [TRPO] iter = 1496000 dist_mean = -0.0041 dist_std = 0.1463 vf_loss = 0.0083 grad_norm = 3.1784 nat_grad_norm = 0.0758 cg_residual = 1.0188 step_size = 0.4848 reward = -0.0000 fps = 7 mse_loss = 1.3332 
2022-05-01 13:04:58.964389 - gail/main.py:164 - [TRPO] iter = 1497000 dist_mean = 0.0194 dist_std = 0.1463 vf_loss = 0.0095 grad_norm = 4.8092 nat_grad_norm = 0.1056 cg_residual = 3.4543 step_size = 0.3617 reward = -0.0000 fps = 6 mse_loss = 1.2776 
2022-05-01 13:05:08.840316 - gail/main.py:164 - [TRPO] iter = 1498000 dist_mean = 0.0001 dist_std = 0.1460 vf_loss = 0.0093 grad_norm = 3.4366 nat_grad_norm = 0.0907 cg_residual = 3.7633 step_size = 0.3872 reward = -0.0000 fps = 6 mse_loss = 1.2704 
2022-05-01 13:05:18.532286 - gail/main.py:164 - [TRPO] iter = 1499000 dist_mean = 0.0244 dist_std = 0.1460 vf_loss = 0.0250 grad_norm = 3.0091 nat_grad_norm = 0.0884 cg_residual = 1.9380 step_size = 0.4342 reward = 0.0000 fps = 6 mse_loss = 1.3471 
2022-05-01 13:05:28.088593 - gail/main.py:164 - [TRPO] iter = 1500000 dist_mean = 0.0166 dist_std = 0.1457 vf_loss = 0.0142 grad_norm = 3.8479 nat_grad_norm = 0.0916 cg_residual = 2.3687 step_size = 0.4260 reward = 0.0000 fps = 5 mse_loss = 1.3264 
2022-05-01 13:05:28.358025 - gail/main.py:191 - [Discriminator] iter = 1500000 loss = -0.5930 grad_norm = 3.4463 grad_penalty = 0.0580 regularization = 0.0000 true_logits = -0.5666 fake_logits = -1.2177 true_prob = 0.3796 fake_prob = 0.2577 
2022-05-01 13:07:40.260063 - gail/main.py:132 - [Evaluate] iter = 1500000 episode={ returns = 3574.6779 lengths = 1000 } discounted_episode={ returns = 2202.5199 lengths = 1000 } 
2022-05-01 13:07:50.263305 - gail/main.py:164 - [TRPO] iter = 1501000 dist_mean = 0.0027 dist_std = 0.1458 vf_loss = 0.0372 grad_norm = 2.5942 nat_grad_norm = 0.0711 cg_residual = 1.0246 step_size = 0.5413 reward = -0.0000 fps = 7 mse_loss = 1.3194 
2022-05-01 13:07:59.829113 - gail/main.py:164 - [TRPO] iter = 1502000 dist_mean = 0.0021 dist_std = 0.1458 vf_loss = 0.0150 grad_norm = 3.7576 nat_grad_norm = 0.1336 cg_residual = 5.8568 step_size = 0.2885 reward = 0.0000 fps = 6 mse_loss = 1.3642 
2022-05-01 13:08:09.508614 - gail/main.py:164 - [TRPO] iter = 1503000 dist_mean = 0.0237 dist_std = 0.1459 vf_loss = 0.0228 grad_norm = 2.2459 nat_grad_norm = 0.1063 cg_residual = 1.7400 step_size = 0.4024 reward = -0.0000 fps = 6 mse_loss = 1.2025 
2022-05-01 13:08:19.343680 - gail/main.py:164 - [TRPO] iter = 1504000 dist_mean = 0.0098 dist_std = 0.1458 vf_loss = 0.0299 grad_norm = 4.7751 nat_grad_norm = 0.0933 cg_residual = 1.7211 step_size = 0.3577 reward = 0.0000 fps = 5 mse_loss = 1.3231 
2022-05-01 13:08:28.992760 - gail/main.py:164 - [TRPO] iter = 1505000 dist_mean = 0.0292 dist_std = 0.1457 vf_loss = 0.0136 grad_norm = 3.5486 nat_grad_norm = 0.0727 cg_residual = 1.6908 step_size = 0.4460 reward = -0.0000 fps = 5 mse_loss = 1.3310 
2022-05-01 13:08:29.259394 - gail/main.py:191 - [Discriminator] iter = 1505000 loss = -0.4785 grad_norm = 3.1062 grad_penalty = 0.0581 regularization = 0.0000 true_logits = -0.5912 fake_logits = -1.1278 true_prob = 0.3807 fake_prob = 0.2817 
2022-05-01 13:10:41.556698 - gail/main.py:132 - [Evaluate] iter = 1505000 episode={ returns = 3600.7866 lengths = 1000 } discounted_episode={ returns = 2226.6975 lengths = 1000 } 
2022-05-01 13:10:51.546266 - gail/main.py:164 - [TRPO] iter = 1506000 dist_mean = 0.0105 dist_std = 0.1456 vf_loss = 0.0556 grad_norm = 3.2093 nat_grad_norm = 0.0889 cg_residual = 2.4069 step_size = 0.4525 reward = -0.0000 fps = 7 mse_loss = 1.2569 
2022-05-01 13:11:01.494458 - gail/main.py:164 - [TRPO] iter = 1507000 dist_mean = 0.0171 dist_std = 0.1455 vf_loss = 0.0129 grad_norm = 3.7881 nat_grad_norm = 0.0732 cg_residual = 1.9220 step_size = 0.4669 reward = -0.0000 fps = 6 mse_loss = 1.3443 
2022-05-01 13:11:11.352940 - gail/main.py:164 - [TRPO] iter = 1508000 dist_mean = 0.0375 dist_std = 0.1458 vf_loss = 0.0298 grad_norm = 3.6356 nat_grad_norm = 0.0771 cg_residual = 1.4321 step_size = 0.4244 reward = 0.0000 fps = 6 mse_loss = 1.2756 
2022-05-01 13:11:21.686473 - gail/main.py:164 - [TRPO] iter = 1509000 dist_mean = 0.0308 dist_std = 0.1459 vf_loss = 0.0518 grad_norm = 2.9813 nat_grad_norm = 0.0731 cg_residual = 1.8455 step_size = 0.5481 reward = -0.0000 fps = 5 mse_loss = 1.3246 
2022-05-01 13:11:31.242368 - gail/main.py:164 - [TRPO] iter = 1510000 dist_mean = 0.0056 dist_std = 0.1458 vf_loss = 0.0710 grad_norm = 4.3044 nat_grad_norm = 0.0618 cg_residual = 1.1283 step_size = 0.4791 reward = 0.0000 fps = 5 mse_loss = 1.2372 
2022-05-01 13:11:31.455179 - gail/main.py:191 - [Discriminator] iter = 1510000 loss = -0.4631 grad_norm = 3.9833 grad_penalty = 0.0541 regularization = 0.0000 true_logits = -0.6608 fake_logits = -1.1780 true_prob = 0.3696 fake_prob = 0.2738 
2022-05-01 13:13:44.351053 - gail/main.py:132 - [Evaluate] iter = 1510000 episode={ returns = 3588.7681 lengths = 1000 } discounted_episode={ returns = 2212.3366 lengths = 1000 } 
2022-05-01 13:13:53.763674 - gail/main.py:164 - [TRPO] iter = 1511000 dist_mean = 0.0516 dist_std = 0.1457 vf_loss = 0.0283 grad_norm = 3.9462 nat_grad_norm = 0.0557 cg_residual = 0.9259 step_size = 0.5713 reward = -0.0000 fps = 7 mse_loss = 1.1908 
2022-05-01 13:14:03.305352 - gail/main.py:164 - [TRPO] iter = 1512000 dist_mean = 0.0023 dist_std = 0.1455 vf_loss = 0.0168 grad_norm = 5.1564 nat_grad_norm = 0.1220 cg_residual = 4.5325 step_size = 0.3168 reward = 0.0000 fps = 6 mse_loss = 1.2045 
2022-05-01 13:14:13.135581 - gail/main.py:164 - [TRPO] iter = 1513000 dist_mean = -0.0018 dist_std = 0.1457 vf_loss = 0.0333 grad_norm = 3.9674 nat_grad_norm = 0.0673 cg_residual = 1.4504 step_size = 0.5806 reward = -0.0000 fps = 6 mse_loss = 1.1815 
2022-05-01 13:14:22.818504 - gail/main.py:164 - [TRPO] iter = 1514000 dist_mean = 0.0138 dist_std = 0.1459 vf_loss = 0.0150 grad_norm = 3.2264 nat_grad_norm = 0.0915 cg_residual = 1.5850 step_size = 0.4456 reward = 0.0000 fps = 5 mse_loss = 1.2225 
2022-05-01 13:14:32.644801 - gail/main.py:164 - [TRPO] iter = 1515000 dist_mean = 0.0283 dist_std = 0.1455 vf_loss = 0.0145 grad_norm = 3.9854 nat_grad_norm = 0.1621 cg_residual = 7.5161 step_size = 0.2483 reward = 0.0000 fps = 5 mse_loss = 1.2271 
2022-05-01 13:14:32.910455 - gail/main.py:191 - [Discriminator] iter = 1515000 loss = -0.4530 grad_norm = 3.4278 grad_penalty = 0.0633 regularization = 0.0000 true_logits = -0.6438 fake_logits = -1.1601 true_prob = 0.3702 fake_prob = 0.2705 
2022-05-01 13:16:49.008615 - gail/main.py:132 - [Evaluate] iter = 1515000 episode={ returns = 3579.9046 lengths = 1000 } discounted_episode={ returns = 2202.4358 lengths = 1000 } 
2022-05-01 13:16:58.831864 - gail/main.py:164 - [TRPO] iter = 1516000 dist_mean = 0.0364 dist_std = 0.1456 vf_loss = 0.0289 grad_norm = 2.9145 nat_grad_norm = 0.0800 cg_residual = 1.5981 step_size = 0.4344 reward = -0.0000 fps = 6 mse_loss = 1.3628 
2022-05-01 13:17:09.071613 - gail/main.py:164 - [TRPO] iter = 1517000 dist_mean = 0.0446 dist_std = 0.1457 vf_loss = 0.0605 grad_norm = 5.1559 nat_grad_norm = 0.0820 cg_residual = 0.8854 step_size = 0.4422 reward = -0.0000 fps = 6 mse_loss = 1.2716 
2022-05-01 13:17:19.176544 - gail/main.py:164 - [TRPO] iter = 1518000 dist_mean = 0.1162 dist_std = 0.1457 vf_loss = 0.0379 grad_norm = 3.0875 nat_grad_norm = 0.0802 cg_residual = 1.3346 step_size = 0.5001 reward = 0.0000 fps = 6 mse_loss = 1.2166 
2022-05-01 13:17:28.941645 - gail/main.py:164 - [TRPO] iter = 1519000 dist_mean = 0.0728 dist_std = 0.1454 vf_loss = 0.0695 grad_norm = 2.6510 nat_grad_norm = 0.0744 cg_residual = 1.4383 step_size = 0.5636 reward = -0.0000 fps = 5 mse_loss = 1.3269 
2022-05-01 13:17:39.119823 - gail/main.py:164 - [TRPO] iter = 1520000 dist_mean = 0.0499 dist_std = 0.1458 vf_loss = 0.0466 grad_norm = 2.7667 nat_grad_norm = 0.0742 cg_residual = 1.0699 step_size = 0.5524 reward = 0.0000 fps = 5 mse_loss = 1.2938 
2022-05-01 13:17:39.364366 - gail/main.py:191 - [Discriminator] iter = 1520000 loss = -0.4463 grad_norm = 4.3684 grad_penalty = 0.0574 regularization = 0.0000 true_logits = -0.5751 fake_logits = -1.0788 true_prob = 0.3787 fake_prob = 0.2844 
2022-05-01 13:19:51.988070 - gail/main.py:132 - [Evaluate] iter = 1520000 episode={ returns = 3571.8624 lengths = 1000 } discounted_episode={ returns = 2196.3294 lengths = 1000 } 
2022-05-01 13:20:01.826589 - gail/main.py:164 - [TRPO] iter = 1521000 dist_mean = 0.0505 dist_std = 0.1456 vf_loss = 0.1310 grad_norm = 4.3067 nat_grad_norm = 0.0857 cg_residual = 2.1365 step_size = 0.4205 reward = 0.0000 fps = 7 mse_loss = 1.2034 
2022-05-01 13:20:11.712609 - gail/main.py:164 - [TRPO] iter = 1522000 dist_mean = 0.0777 dist_std = 0.1458 vf_loss = 0.0464 grad_norm = 3.3027 nat_grad_norm = 0.0639 cg_residual = 1.0379 step_size = 0.5774 reward = 0.0000 fps = 6 mse_loss = 1.2050 
2022-05-01 13:20:21.600052 - gail/main.py:164 - [TRPO] iter = 1523000 dist_mean = 0.0597 dist_std = 0.1457 vf_loss = 0.0472 grad_norm = 4.5655 nat_grad_norm = 0.0859 cg_residual = 2.3162 step_size = 0.4210 reward = 0.0000 fps = 6 mse_loss = 1.2951 
2022-05-01 13:20:31.419516 - gail/main.py:164 - [TRPO] iter = 1524000 dist_mean = 0.0794 dist_std = 0.1457 vf_loss = 0.0400 grad_norm = 5.9701 nat_grad_norm = 0.1000 cg_residual = 1.6098 step_size = 0.2987 reward = 0.0000 fps = 5 mse_loss = 1.2041 
2022-05-01 13:20:41.123729 - gail/main.py:164 - [TRPO] iter = 1525000 dist_mean = 0.1037 dist_std = 0.1456 vf_loss = 0.1006 grad_norm = 2.6479 nat_grad_norm = 0.0751 cg_residual = 0.7039 step_size = 0.5010 reward = -0.0000 fps = 5 mse_loss = 1.3841 
2022-05-01 13:20:41.340257 - gail/main.py:191 - [Discriminator] iter = 1525000 loss = -0.2621 grad_norm = 4.3979 grad_penalty = 0.0629 regularization = 0.0000 true_logits = -0.7205 fake_logits = -1.0454 true_prob = 0.3543 fake_prob = 0.2969 
2022-05-01 13:22:54.555914 - gail/main.py:132 - [Evaluate] iter = 1525000 episode={ returns = 3549.7373 lengths = 1000 } discounted_episode={ returns = 2184.8153 lengths = 1000 } 
2022-05-01 13:23:04.452907 - gail/main.py:164 - [TRPO] iter = 1526000 dist_mean = 0.0929 dist_std = 0.1456 vf_loss = 0.1303 grad_norm = 4.3410 nat_grad_norm = 0.0626 cg_residual = 0.7369 step_size = 0.5296 reward = 0.0000 fps = 6 mse_loss = 1.2107 
2022-05-01 13:23:14.195969 - gail/main.py:164 - [TRPO] iter = 1527000 dist_mean = 0.0896 dist_std = 0.1454 vf_loss = 0.0102 grad_norm = 3.0449 nat_grad_norm = 0.0667 cg_residual = 0.5867 step_size = 0.5050 reward = 0.0000 fps = 6 mse_loss = 1.2526 
2022-05-01 13:23:24.068143 - gail/main.py:164 - [TRPO] iter = 1528000 dist_mean = 0.1159 dist_std = 0.1452 vf_loss = 0.1691 grad_norm = 2.8489 nat_grad_norm = 0.0674 cg_residual = 1.0878 step_size = 0.5467 reward = 0.0000 fps = 6 mse_loss = 1.2074 
2022-05-01 13:23:33.915144 - gail/main.py:164 - [TRPO] iter = 1529000 dist_mean = 0.1037 dist_std = 0.1452 vf_loss = 0.0948 grad_norm = 2.8292 nat_grad_norm = 0.0653 cg_residual = 1.1893 step_size = 0.5239 reward = -0.0000 fps = 5 mse_loss = 1.1405 
2022-05-01 13:23:43.728083 - gail/main.py:164 - [TRPO] iter = 1530000 dist_mean = 0.0773 dist_std = 0.1452 vf_loss = 0.0895 grad_norm = 3.4268 nat_grad_norm = 0.1065 cg_residual = 2.5311 step_size = 0.4012 reward = 0.0000 fps = 5 mse_loss = 1.1615 
2022-05-01 13:23:43.983438 - gail/main.py:191 - [Discriminator] iter = 1530000 loss = -0.5251 grad_norm = 3.4406 grad_penalty = 0.0602 regularization = 0.0000 true_logits = -0.7707 fake_logits = -1.3560 true_prob = 0.3408 fake_prob = 0.2423 
2022-05-01 13:25:56.504459 - gail/main.py:132 - [Evaluate] iter = 1530000 episode={ returns = 3545.2425 lengths = 1000 } discounted_episode={ returns = 2180.4761 lengths = 1000 } 
2022-05-01 13:26:06.365789 - gail/main.py:164 - [TRPO] iter = 1531000 dist_mean = 0.1048 dist_std = 0.1451 vf_loss = 0.0247 grad_norm = 2.4163 nat_grad_norm = 0.0762 cg_residual = 0.4862 step_size = 0.4875 reward = -0.0000 fps = 7 mse_loss = 1.1539 
2022-05-01 13:26:16.030275 - gail/main.py:164 - [TRPO] iter = 1532000 dist_mean = 0.0969 dist_std = 0.1455 vf_loss = 0.0824 grad_norm = 3.9733 nat_grad_norm = 0.0811 cg_residual = 2.2549 step_size = 0.4793 reward = -0.0000 fps = 6 mse_loss = 1.0996 
2022-05-01 13:26:26.250646 - gail/main.py:164 - [TRPO] iter = 1533000 dist_mean = 0.1208 dist_std = 0.1454 vf_loss = 0.1601 grad_norm = 2.5886 nat_grad_norm = 0.0712 cg_residual = 0.9021 step_size = 0.5561 reward = -0.0000 fps = 6 mse_loss = 1.1060 
2022-05-01 13:26:35.910825 - gail/main.py:164 - [TRPO] iter = 1534000 dist_mean = 0.0838 dist_std = 0.1459 vf_loss = 0.0681 grad_norm = 3.0409 nat_grad_norm = 0.0895 cg_residual = 1.1503 step_size = 0.5004 reward = -0.0000 fps = 5 mse_loss = 1.1818 
2022-05-01 13:26:45.620543 - gail/main.py:164 - [TRPO] iter = 1535000 dist_mean = 0.0772 dist_std = 0.1458 vf_loss = 0.0777 grad_norm = 2.9811 nat_grad_norm = 0.0765 cg_residual = 0.5628 step_size = 0.5397 reward = -0.0000 fps = 5 mse_loss = 1.1341 
2022-05-01 13:26:45.840470 - gail/main.py:191 - [Discriminator] iter = 1535000 loss = -0.4147 grad_norm = 3.3282 grad_penalty = 0.0518 regularization = 0.0000 true_logits = -0.8449 fake_logits = -1.3114 true_prob = 0.3276 fake_prob = 0.2485 
2022-05-01 13:28:57.464833 - gail/main.py:132 - [Evaluate] iter = 1535000 episode={ returns = 3568.6415 lengths = 1000 } discounted_episode={ returns = 2196.9917 lengths = 1000 } 
2022-05-01 13:29:06.977569 - gail/main.py:164 - [TRPO] iter = 1536000 dist_mean = 0.1130 dist_std = 0.1455 vf_loss = 0.0665 grad_norm = 3.1248 nat_grad_norm = 0.0590 cg_residual = 1.1781 step_size = 0.5099 reward = 0.0000 fps = 7 mse_loss = 1.1191 
2022-05-01 13:29:16.668763 - gail/main.py:164 - [TRPO] iter = 1537000 dist_mean = 0.0988 dist_std = 0.1453 vf_loss = 0.1141 grad_norm = 2.5061 nat_grad_norm = 0.0620 cg_residual = 1.4886 step_size = 0.5753 reward = -0.0000 fps = 6 mse_loss = 1.0736 
2022-05-01 13:29:26.023477 - gail/main.py:164 - [TRPO] iter = 1538000 dist_mean = 0.0977 dist_std = 0.1458 vf_loss = 0.1266 grad_norm = 3.7625 nat_grad_norm = 0.0481 cg_residual = 0.5178 step_size = 0.6148 reward = 0.0000 fps = 6 mse_loss = 1.1386 
2022-05-01 13:29:35.805429 - gail/main.py:164 - [TRPO] iter = 1539000 dist_mean = 0.1023 dist_std = 0.1458 vf_loss = 0.0972 grad_norm = 4.0023 nat_grad_norm = 0.0709 cg_residual = 0.8267 step_size = 0.5124 reward = -0.0000 fps = 5 mse_loss = 1.1086 
2022-05-01 13:29:45.537639 - gail/main.py:164 - [TRPO] iter = 1540000 dist_mean = 0.1103 dist_std = 0.1456 vf_loss = 0.1475 grad_norm = 3.2844 nat_grad_norm = 0.0592 cg_residual = 1.1107 step_size = 0.5449 reward = 0.0000 fps = 5 mse_loss = 1.1327 
2022-05-01 13:29:45.751907 - gail/main.py:191 - [Discriminator] iter = 1540000 loss = -0.3622 grad_norm = 3.0168 grad_penalty = 0.0520 regularization = 0.0000 true_logits = -0.9780 fake_logits = -1.3921 true_prob = 0.3070 fake_prob = 0.2415 
2022-05-01 13:31:57.546229 - gail/main.py:132 - [Evaluate] iter = 1540000 episode={ returns = 3568.9733 lengths = 1000 } discounted_episode={ returns = 2199.2725 lengths = 1000 } 
2022-05-01 13:32:07.213427 - gail/main.py:164 - [TRPO] iter = 1541000 dist_mean = 0.1005 dist_std = 0.1456 vf_loss = 0.1457 grad_norm = 2.4388 nat_grad_norm = 0.0570 cg_residual = 0.8783 step_size = 0.6146 reward = -0.0000 fps = 7 mse_loss = 1.1026 
2022-05-01 13:32:17.047139 - gail/main.py:164 - [TRPO] iter = 1542000 dist_mean = 0.0985 dist_std = 0.1453 vf_loss = 0.0732 grad_norm = 2.5787 nat_grad_norm = 0.0531 cg_residual = 1.3639 step_size = 0.6405 reward = 0.0000 fps = 6 mse_loss = 1.1243 
2022-05-01 13:32:26.665809 - gail/main.py:164 - [TRPO] iter = 1543000 dist_mean = 0.1061 dist_std = 0.1454 vf_loss = 0.1123 grad_norm = 3.8526 nat_grad_norm = 0.0520 cg_residual = 1.1136 step_size = 0.5224 reward = -0.0000 fps = 6 mse_loss = 1.1072 
2022-05-01 13:32:36.233901 - gail/main.py:164 - [TRPO] iter = 1544000 dist_mean = 0.0942 dist_std = 0.1454 vf_loss = 0.1113 grad_norm = 2.7147 nat_grad_norm = 0.0476 cg_residual = 0.8607 step_size = 0.7007 reward = 0.0000 fps = 5 mse_loss = 1.1167 
2022-05-01 13:32:45.795733 - gail/main.py:164 - [TRPO] iter = 1545000 dist_mean = 0.1150 dist_std = 0.1453 vf_loss = 0.1076 grad_norm = 3.0296 nat_grad_norm = 0.0587 cg_residual = 1.2133 step_size = 0.6335 reward = 0.0000 fps = 5 mse_loss = 1.0836 
2022-05-01 13:32:46.036215 - gail/main.py:191 - [Discriminator] iter = 1545000 loss = -0.3532 grad_norm = 3.1060 grad_penalty = 0.0427 regularization = 0.0000 true_logits = -1.0437 fake_logits = -1.4396 true_prob = 0.2922 fake_prob = 0.2334 
2022-05-01 13:34:57.949155 - gail/main.py:132 - [Evaluate] iter = 1545000 episode={ returns = 3557.1093 lengths = 1000 } discounted_episode={ returns = 2191.9278 lengths = 1000 } 
2022-05-01 13:35:07.789339 - gail/main.py:164 - [TRPO] iter = 1546000 dist_mean = 0.0974 dist_std = 0.1452 vf_loss = 0.0902 grad_norm = 2.1547 nat_grad_norm = 0.0611 cg_residual = 0.8420 step_size = 0.6214 reward = -0.0000 fps = 7 mse_loss = 1.0811 
2022-05-01 13:35:17.338347 - gail/main.py:164 - [TRPO] iter = 1547000 dist_mean = 0.0929 dist_std = 0.1457 vf_loss = 0.1466 grad_norm = 4.5683 nat_grad_norm = 0.0622 cg_residual = 2.2548 step_size = 0.4739 reward = 0.0000 fps = 6 mse_loss = 1.0244 
2022-05-01 13:35:27.000127 - gail/main.py:164 - [TRPO] iter = 1548000 dist_mean = 0.0998 dist_std = 0.1457 vf_loss = 0.0629 grad_norm = 3.8298 nat_grad_norm = 0.0822 cg_residual = 1.1467 step_size = 0.5038 reward = 0.0000 fps = 6 mse_loss = 1.1086 
2022-05-01 13:35:36.885562 - gail/main.py:164 - [TRPO] iter = 1549000 dist_mean = 0.1164 dist_std = 0.1459 vf_loss = 0.0282 grad_norm = 4.3234 nat_grad_norm = 0.0871 cg_residual = 1.4768 step_size = 0.3992 reward = 0.0000 fps = 5 mse_loss = 1.0524 
2022-05-01 13:35:46.481065 - gail/main.py:164 - [TRPO] iter = 1550000 dist_mean = 0.0975 dist_std = 0.1463 vf_loss = 0.1369 grad_norm = 4.3135 nat_grad_norm = 0.0603 cg_residual = 1.2691 step_size = 0.5993 reward = 0.0000 fps = 5 mse_loss = 0.9831 
2022-05-01 13:35:46.729973 - gail/main.py:191 - [Discriminator] iter = 1550000 loss = -0.3553 grad_norm = 3.9018 grad_penalty = 0.0574 regularization = 0.0000 true_logits = -1.0346 fake_logits = -1.4473 true_prob = 0.2924 fake_prob = 0.2282 
2022-05-01 13:38:00.438753 - gail/main.py:132 - [Evaluate] iter = 1550000 episode={ returns = 3560.0420 lengths = 1000 } discounted_episode={ returns = 2197.5484 lengths = 1000 } 
2022-05-01 13:38:10.492370 - gail/main.py:164 - [TRPO] iter = 1551000 dist_mean = 0.0931 dist_std = 0.1458 vf_loss = 0.0611 grad_norm = 2.9176 nat_grad_norm = 0.0718 cg_residual = 1.7863 step_size = 0.4780 reward = -0.0000 fps = 6 mse_loss = 1.1344 
2022-05-01 13:38:20.199130 - gail/main.py:164 - [TRPO] iter = 1552000 dist_mean = 0.0793 dist_std = 0.1457 vf_loss = 0.0559 grad_norm = 3.9931 nat_grad_norm = 0.0798 cg_residual = 1.5336 step_size = 0.4335 reward = 0.0000 fps = 6 mse_loss = 1.0245 
2022-05-01 13:38:30.097617 - gail/main.py:164 - [TRPO] iter = 1553000 dist_mean = 0.0948 dist_std = 0.1457 vf_loss = 0.0443 grad_norm = 5.3223 nat_grad_norm = 0.0612 cg_residual = 1.8779 step_size = 0.4718 reward = 0.0000 fps = 6 mse_loss = 1.0433 
2022-05-01 13:38:39.775909 - gail/main.py:164 - [TRPO] iter = 1554000 dist_mean = 0.0839 dist_std = 0.1455 vf_loss = 0.0921 grad_norm = 3.4131 nat_grad_norm = 0.0636 cg_residual = 1.3108 step_size = 0.5329 reward = 0.0000 fps = 5 mse_loss = 1.0470 
2022-05-01 13:38:49.452434 - gail/main.py:164 - [TRPO] iter = 1555000 dist_mean = 0.1005 dist_std = 0.1455 vf_loss = 0.0374 grad_norm = 2.9084 nat_grad_norm = 0.0683 cg_residual = 1.3905 step_size = 0.5399 reward = -0.0000 fps = 5 mse_loss = 1.0912 
2022-05-01 13:38:49.745521 - gail/main.py:191 - [Discriminator] iter = 1555000 loss = -0.4076 grad_norm = 3.4810 grad_penalty = 0.0504 regularization = 0.0000 true_logits = -1.0437 fake_logits = -1.5018 true_prob = 0.2853 fake_prob = 0.2156 
2022-05-01 13:41:01.214116 - gail/main.py:132 - [Evaluate] iter = 1555000 episode={ returns = 3546.5476 lengths = 1000 } discounted_episode={ returns = 2184.2117 lengths = 1000 } 
2022-05-01 13:41:10.909272 - gail/main.py:164 - [TRPO] iter = 1556000 dist_mean = 0.0158 dist_std = 0.1456 vf_loss = 0.0207 grad_norm = 2.9010 nat_grad_norm = 0.0705 cg_residual = 1.4812 step_size = 0.5063 reward = -0.0000 fps = 7 mse_loss = 1.0720 
2022-05-01 13:41:20.596320 - gail/main.py:164 - [TRPO] iter = 1557000 dist_mean = 0.0813 dist_std = 0.1451 vf_loss = 0.0579 grad_norm = 3.3922 nat_grad_norm = 0.0556 cg_residual = 1.5976 step_size = 0.5359 reward = -0.0000 fps = 6 mse_loss = 1.0550 
2022-05-01 13:41:30.558899 - gail/main.py:164 - [TRPO] iter = 1558000 dist_mean = 0.0974 dist_std = 0.1454 vf_loss = 0.0629 grad_norm = 3.2500 nat_grad_norm = 0.0790 cg_residual = 1.0445 step_size = 0.4460 reward = -0.0000 fps = 6 mse_loss = 1.0559 
2022-05-01 13:41:40.718818 - gail/main.py:164 - [TRPO] iter = 1559000 dist_mean = 0.0787 dist_std = 0.1455 vf_loss = 0.0773 grad_norm = 3.5253 nat_grad_norm = 0.0683 cg_residual = 0.9270 step_size = 0.4705 reward = -0.0000 fps = 5 mse_loss = 0.9630 
2022-05-01 13:41:50.794271 - gail/main.py:164 - [TRPO] iter = 1560000 dist_mean = 0.0735 dist_std = 0.1454 vf_loss = 0.0769 grad_norm = 4.3433 nat_grad_norm = 0.0678 cg_residual = 1.8858 step_size = 0.4761 reward = 0.0000 fps = 5 mse_loss = 1.1037 
2022-05-01 13:41:51.030522 - gail/main.py:191 - [Discriminator] iter = 1560000 loss = -0.3964 grad_norm = 4.2702 grad_penalty = 0.0512 regularization = 0.0000 true_logits = -1.0474 fake_logits = -1.4950 true_prob = 0.2823 fake_prob = 0.2131 
2022-05-01 13:43:38.076481 - gail/main.py:132 - [Evaluate] iter = 1560000 episode={ returns = 2849.9525 lengths = 813 } discounted_episode={ returns = 1766.9342 lengths = 813 } 
2022-05-01 13:43:47.681715 - gail/main.py:164 - [TRPO] iter = 1561000 dist_mean = 0.0578 dist_std = 0.1451 vf_loss = 0.0644 grad_norm = 3.3585 nat_grad_norm = 0.0805 cg_residual = 0.8616 step_size = 0.4787 reward = 0.0000 fps = 8 mse_loss = 0.9936 
2022-05-01 13:43:57.304070 - gail/main.py:164 - [TRPO] iter = 1562000 dist_mean = 0.1004 dist_std = 0.1453 vf_loss = 0.0679 grad_norm = 2.6561 nat_grad_norm = 0.0803 cg_residual = 2.7966 step_size = 0.4785 reward = -0.0000 fps = 7 mse_loss = 1.0379 
2022-05-01 13:44:07.133764 - gail/main.py:164 - [TRPO] iter = 1563000 dist_mean = 0.0708 dist_std = 0.1454 vf_loss = 0.0299 grad_norm = 4.2281 nat_grad_norm = 0.0855 cg_residual = 1.8300 step_size = 0.4436 reward = 0.0000 fps = 7 mse_loss = 1.0417 
2022-05-01 13:44:16.875590 - gail/main.py:164 - [TRPO] iter = 1564000 dist_mean = 0.0431 dist_std = 0.1455 vf_loss = 0.0848 grad_norm = 2.4165 nat_grad_norm = 0.0713 cg_residual = 0.9507 step_size = 0.5543 reward = 0.0000 fps = 6 mse_loss = 1.1518 
2022-05-01 13:44:26.902133 - gail/main.py:164 - [TRPO] iter = 1565000 dist_mean = 0.0241 dist_std = 0.1454 vf_loss = 0.0234 grad_norm = 4.9578 nat_grad_norm = 0.0865 cg_residual = 2.3767 step_size = 0.4173 reward = -0.0000 fps = 6 mse_loss = 1.0585 
2022-05-01 13:44:27.137807 - gail/main.py:191 - [Discriminator] iter = 1565000 loss = -0.3527 grad_norm = 3.5225 grad_penalty = 0.0478 regularization = 0.0000 true_logits = -1.1431 fake_logits = -1.5436 true_prob = 0.2631 fake_prob = 0.1988 
2022-05-01 13:46:38.456481 - gail/main.py:132 - [Evaluate] iter = 1565000 episode={ returns = 3562.8025 lengths = 1000 } discounted_episode={ returns = 2187.6940 lengths = 1000 } 
2022-05-01 13:46:47.804030 - gail/main.py:164 - [TRPO] iter = 1566000 dist_mean = 0.0429 dist_std = 0.1451 vf_loss = 0.0463 grad_norm = 3.1944 nat_grad_norm = 0.1618 cg_residual = 4.3106 step_size = 0.2736 reward = -0.0000 fps = 7 mse_loss = 1.0797 
2022-05-01 13:46:57.652016 - gail/main.py:164 - [TRPO] iter = 1567000 dist_mean = 0.0451 dist_std = 0.1452 vf_loss = 0.0183 grad_norm = 2.3553 nat_grad_norm = 0.0887 cg_residual = 1.0047 step_size = 0.4594 reward = 0.0000 fps = 6 mse_loss = 1.0501 
2022-05-01 13:47:06.990937 - gail/main.py:164 - [TRPO] iter = 1568000 dist_mean = 0.0225 dist_std = 0.1452 vf_loss = 0.0261 grad_norm = 3.8967 nat_grad_norm = 0.1927 cg_residual = 4.0516 step_size = 0.2489 reward = -0.0000 fps = 6 mse_loss = 1.1112 
2022-05-01 13:47:16.665192 - gail/main.py:164 - [TRPO] iter = 1569000 dist_mean = 0.0276 dist_std = 0.1452 vf_loss = 0.0275 grad_norm = 4.3088 nat_grad_norm = 0.0846 cg_residual = 2.1441 step_size = 0.4318 reward = 0.0000 fps = 5 mse_loss = 1.1557 
2022-05-01 13:47:26.108877 - gail/main.py:164 - [TRPO] iter = 1570000 dist_mean = 0.0480 dist_std = 0.1454 vf_loss = 0.0364 grad_norm = 3.4593 nat_grad_norm = 0.1183 cg_residual = 2.4892 step_size = 0.3659 reward = -0.0000 fps = 5 mse_loss = 1.0738 
2022-05-01 13:47:26.322555 - gail/main.py:191 - [Discriminator] iter = 1570000 loss = -0.6076 grad_norm = 3.7844 grad_penalty = 0.0596 regularization = 0.0000 true_logits = -1.2006 fake_logits = -1.8678 true_prob = 0.2521 fake_prob = 0.1623 
2022-05-01 13:49:37.475743 - gail/main.py:132 - [Evaluate] iter = 1570000 episode={ returns = 3580.6309 lengths = 1000 } discounted_episode={ returns = 2200.0954 lengths = 1000 } 
2022-05-01 13:49:47.135381 - gail/main.py:164 - [TRPO] iter = 1571000 dist_mean = 0.0280 dist_std = 0.1454 vf_loss = 0.0576 grad_norm = 3.8497 nat_grad_norm = 0.0983 cg_residual = 1.9224 step_size = 0.3853 reward = 0.0000 fps = 7 mse_loss = 1.0298 
2022-05-01 13:49:57.011332 - gail/main.py:164 - [TRPO] iter = 1572000 dist_mean = 0.0256 dist_std = 0.1453 vf_loss = 0.0554 grad_norm = 2.8410 nat_grad_norm = 0.0861 cg_residual = 1.1832 step_size = 0.4757 reward = 0.0000 fps = 6 mse_loss = 1.0243 
2022-05-01 13:50:06.538717 - gail/main.py:164 - [TRPO] iter = 1573000 dist_mean = 0.0187 dist_std = 0.1451 vf_loss = 0.0368 grad_norm = 3.7873 nat_grad_norm = 0.1838 cg_residual = 4.2885 step_size = 0.2432 reward = -0.0000 fps = 6 mse_loss = 1.0166 
2022-05-01 13:50:16.245515 - gail/main.py:164 - [TRPO] iter = 1574000 dist_mean = 0.0447 dist_std = 0.1450 vf_loss = 0.0304 grad_norm = 3.0693 nat_grad_norm = 0.0854 cg_residual = 1.7599 step_size = 0.3967 reward = -0.0000 fps = 5 mse_loss = 1.0114 
2022-05-01 13:50:25.728767 - gail/main.py:164 - [TRPO] iter = 1575000 dist_mean = 0.0409 dist_std = 0.1448 vf_loss = 0.0604 grad_norm = 3.9416 nat_grad_norm = 0.0822 cg_residual = 3.3838 step_size = 0.4424 reward = 0.0000 fps = 5 mse_loss = 1.0080 
2022-05-01 13:50:25.952156 - gail/main.py:191 - [Discriminator] iter = 1575000 loss = -0.4749 grad_norm = 3.3610 grad_penalty = 0.0614 regularization = 0.0000 true_logits = -1.2847 fake_logits = -1.8210 true_prob = 0.2391 fake_prob = 0.1598 
2022-05-01 13:52:36.337831 - gail/main.py:132 - [Evaluate] iter = 1575000 episode={ returns = 3582.4270 lengths = 1000 } discounted_episode={ returns = 2200.1478 lengths = 1000 } 
2022-05-01 13:52:46.225990 - gail/main.py:164 - [TRPO] iter = 1576000 dist_mean = 0.0334 dist_std = 0.1451 vf_loss = 0.0511 grad_norm = 3.3383 nat_grad_norm = 0.0821 cg_residual = 2.3567 step_size = 0.4350 reward = 0.0000 fps = 7 mse_loss = 1.0707 
2022-05-01 13:52:55.783763 - gail/main.py:164 - [TRPO] iter = 1577000 dist_mean = 0.0487 dist_std = 0.1451 vf_loss = 0.0608 grad_norm = 3.8957 nat_grad_norm = 0.0758 cg_residual = 2.3515 step_size = 0.5030 reward = 0.0000 fps = 6 mse_loss = 1.0558 
2022-05-01 13:53:05.469668 - gail/main.py:164 - [TRPO] iter = 1578000 dist_mean = 0.0562 dist_std = 0.1448 vf_loss = 0.0727 grad_norm = 3.1443 nat_grad_norm = 0.0677 cg_residual = 1.3729 step_size = 0.5417 reward = -0.0000 fps = 6 mse_loss = 1.0771 
2022-05-01 13:53:15.242235 - gail/main.py:164 - [TRPO] iter = 1579000 dist_mean = 0.0535 dist_std = 0.1447 vf_loss = 0.0428 grad_norm = 3.7894 nat_grad_norm = 0.0665 cg_residual = 1.6214 step_size = 0.4796 reward = 0.0000 fps = 5 mse_loss = 1.0386 
2022-05-01 13:53:24.764722 - gail/main.py:164 - [TRPO] iter = 1580000 dist_mean = 0.0328 dist_std = 0.1446 vf_loss = 0.0574 grad_norm = 5.2885 nat_grad_norm = 0.0820 cg_residual = 1.8743 step_size = 0.4360 reward = -0.0000 fps = 5 mse_loss = 1.0760 
2022-05-01 13:53:24.979592 - gail/main.py:191 - [Discriminator] iter = 1580000 loss = -0.4279 grad_norm = 3.6542 grad_penalty = 0.0539 regularization = 0.0000 true_logits = -1.3240 fake_logits = -1.8059 true_prob = 0.2322 fake_prob = 0.1633 
2022-05-01 13:55:39.188141 - gail/main.py:132 - [Evaluate] iter = 1580000 episode={ returns = 3534.9122 lengths = 1000 } discounted_episode={ returns = 2173.6816 lengths = 1000 } 
2022-05-01 13:55:48.624345 - gail/main.py:164 - [TRPO] iter = 1581000 dist_mean = 0.0259 dist_std = 0.1447 vf_loss = 0.0382 grad_norm = 3.9922 nat_grad_norm = 0.0943 cg_residual = 2.0052 step_size = 0.3806 reward = 0.0000 fps = 6 mse_loss = 1.1070 
2022-05-01 13:55:58.384657 - gail/main.py:164 - [TRPO] iter = 1582000 dist_mean = 0.0582 dist_std = 0.1446 vf_loss = 0.1041 grad_norm = 2.7682 nat_grad_norm = 0.0807 cg_residual = 2.4099 step_size = 0.5012 reward = 0.0000 fps = 6 mse_loss = 1.0197 
2022-05-01 13:56:08.097269 - gail/main.py:164 - [TRPO] iter = 1583000 dist_mean = 0.0485 dist_std = 0.1445 vf_loss = 0.0600 grad_norm = 3.0508 nat_grad_norm = 0.0670 cg_residual = 1.5145 step_size = 0.4970 reward = -0.0000 fps = 6 mse_loss = 1.0483 
2022-05-01 13:56:18.155731 - gail/main.py:164 - [TRPO] iter = 1584000 dist_mean = 0.0598 dist_std = 0.1445 vf_loss = 0.0962 grad_norm = 2.7611 nat_grad_norm = 0.0642 cg_residual = 0.6132 step_size = 0.5796 reward = -0.0000 fps = 5 mse_loss = 1.0404 
2022-05-01 13:56:27.876975 - gail/main.py:164 - [TRPO] iter = 1585000 dist_mean = 0.0510 dist_std = 0.1451 vf_loss = 0.0520 grad_norm = 3.1817 nat_grad_norm = 0.1051 cg_residual = 3.3078 step_size = 0.3817 reward = 0.0000 fps = 5 mse_loss = 1.0476 
2022-05-01 13:56:28.081426 - gail/main.py:191 - [Discriminator] iter = 1585000 loss = -0.5745 grad_norm = 3.9215 grad_penalty = 0.0660 regularization = 0.0000 true_logits = -1.3415 fake_logits = -1.9820 true_prob = 0.2315 fake_prob = 0.1505 
2022-05-01 13:58:39.380989 - gail/main.py:132 - [Evaluate] iter = 1585000 episode={ returns = 3546.7114 lengths = 1000 } discounted_episode={ returns = 2181.7919 lengths = 1000 } 
2022-05-01 13:58:49.246520 - gail/main.py:164 - [TRPO] iter = 1586000 dist_mean = 0.0410 dist_std = 0.1451 vf_loss = 0.0261 grad_norm = 4.9438 nat_grad_norm = 0.0724 cg_residual = 1.6509 step_size = 0.4445 reward = -0.0000 fps = 7 mse_loss = 1.1390 
2022-05-01 13:58:58.946876 - gail/main.py:164 - [TRPO] iter = 1587000 dist_mean = 0.0345 dist_std = 0.1451 vf_loss = 0.0495 grad_norm = 3.1600 nat_grad_norm = 0.0727 cg_residual = 1.7822 step_size = 0.5509 reward = 0.0000 fps = 6 mse_loss = 1.0772 
2022-05-01 13:59:08.686230 - gail/main.py:164 - [TRPO] iter = 1588000 dist_mean = 0.0470 dist_std = 0.1450 vf_loss = 0.0532 grad_norm = 4.4592 nat_grad_norm = 0.1455 cg_residual = 4.5585 step_size = 0.2950 reward = 0.0000 fps = 6 mse_loss = 1.0933 
2022-05-01 13:59:18.469827 - gail/main.py:164 - [TRPO] iter = 1589000 dist_mean = 0.0649 dist_std = 0.1450 vf_loss = 0.0772 grad_norm = 3.6535 nat_grad_norm = 0.0666 cg_residual = 1.7657 step_size = 0.5651 reward = -0.0000 fps = 5 mse_loss = 1.0055 
2022-05-01 13:59:28.107363 - gail/main.py:164 - [TRPO] iter = 1590000 dist_mean = 0.0784 dist_std = 0.1450 vf_loss = 0.1191 grad_norm = 4.7304 nat_grad_norm = 0.0869 cg_residual = 3.4583 step_size = 0.4120 reward = 0.0000 fps = 5 mse_loss = 1.0316 
2022-05-01 13:59:28.330785 - gail/main.py:191 - [Discriminator] iter = 1590000 loss = -0.3897 grad_norm = 4.1970 grad_penalty = 0.0598 regularization = 0.0000 true_logits = -1.3328 fake_logits = -1.7823 true_prob = 0.2329 fake_prob = 0.1714 
2022-05-01 13:59:33.411003 - gail/main.py:132 - [Evaluate] iter = 1590000 episode={ returns = 61.5099 lengths = 37 } discounted_episode={ returns = 59.7992 lengths = 37 } 
2022-05-01 13:59:43.042177 - gail/main.py:164 - [TRPO] iter = 1591000 dist_mean = 0.0918 dist_std = 0.1450 vf_loss = 0.2474 grad_norm = 3.0291 nat_grad_norm = 0.0830 cg_residual = 2.2616 step_size = 0.4150 reward = -0.0000 fps = 68 mse_loss = 1.0297 
2022-05-01 13:59:52.846075 - gail/main.py:164 - [TRPO] iter = 1592000 dist_mean = 0.1294 dist_std = 0.1450 vf_loss = 0.1869 grad_norm = 4.0961 nat_grad_norm = 0.0631 cg_residual = 0.6304 step_size = 0.5203 reward = -0.0000 fps = 40 mse_loss = 1.0487 
2022-05-01 14:00:02.427120 - gail/main.py:164 - [TRPO] iter = 1593000 dist_mean = 0.0591 dist_std = 0.1450 vf_loss = 0.1472 grad_norm = 3.1849 nat_grad_norm = 0.0655 cg_residual = 1.9124 step_size = 0.5196 reward = 0.0000 fps = 29 mse_loss = 1.0998 
2022-05-01 14:00:12.335454 - gail/main.py:164 - [TRPO] iter = 1594000 dist_mean = 0.0613 dist_std = 0.1450 vf_loss = 0.1931 grad_norm = 2.6697 nat_grad_norm = 0.0721 cg_residual = 1.8296 step_size = 0.5257 reward = 0.0000 fps = 22 mse_loss = 1.0540 
2022-05-01 14:00:21.994934 - gail/main.py:164 - [TRPO] iter = 1595000 dist_mean = 0.0903 dist_std = 0.1454 vf_loss = 0.2203 grad_norm = 2.1304 nat_grad_norm = 0.0664 cg_residual = 0.9260 step_size = 0.6526 reward = -0.0000 fps = 18 mse_loss = 1.0559 
2022-05-01 14:00:22.247963 - gail/main.py:191 - [Discriminator] iter = 1595000 loss = -0.5260 grad_norm = 2.9336 grad_penalty = 0.0590 regularization = 0.0000 true_logits = -1.1823 fake_logits = -1.7672 true_prob = 0.2618 fake_prob = 0.1797 
2022-05-01 14:00:27.298351 - gail/main.py:132 - [Evaluate] iter = 1595000 episode={ returns = 61.1995 lengths = 37 } discounted_episode={ returns = 59.1014 lengths = 36 } 
2022-05-01 14:00:36.812421 - gail/main.py:164 - [TRPO] iter = 1596000 dist_mean = 0.0949 dist_std = 0.1458 vf_loss = 0.2494 grad_norm = 2.5278 nat_grad_norm = 0.0628 cg_residual = 0.5436 step_size = 0.6795 reward = 0.0000 fps = 68 mse_loss = 1.0152 
2022-05-01 14:00:46.262413 - gail/main.py:164 - [TRPO] iter = 1597000 dist_mean = 0.0892 dist_std = 0.1460 vf_loss = 0.2726 grad_norm = 2.5634 nat_grad_norm = 0.0551 cg_residual = 0.7298 step_size = 0.6764 reward = -0.0000 fps = 41 mse_loss = 1.0287 
2022-05-01 14:00:55.804991 - gail/main.py:164 - [TRPO] iter = 1598000 dist_mean = 0.0870 dist_std = 0.1457 vf_loss = 0.1980 grad_norm = 2.9573 nat_grad_norm = 0.0599 cg_residual = 1.0649 step_size = 0.6044 reward = 0.0000 fps = 29 mse_loss = 1.0333 
2022-05-01 14:01:05.210760 - gail/main.py:164 - [TRPO] iter = 1599000 dist_mean = 0.0799 dist_std = 0.1455 vf_loss = 0.0244 grad_norm = 3.1922 nat_grad_norm = 0.0806 cg_residual = 1.3916 step_size = 0.5027 reward = -0.0000 fps = 23 mse_loss = 0.9223 
2022-05-01 14:01:14.658031 - gail/main.py:164 - [TRPO] iter = 1600000 dist_mean = 0.1689 dist_std = 0.1454 vf_loss = 0.3011 grad_norm = 4.8046 nat_grad_norm = 0.0793 cg_residual = 1.1511 step_size = 0.4390 reward = 0.0000 fps = 19 mse_loss = 1.1453 
2022-05-01 14:01:14.891002 - gail/main.py:191 - [Discriminator] iter = 1600000 loss = -1.2580 grad_norm = 3.7653 grad_penalty = 0.1307 regularization = 0.0000 true_logits = -1.0926 fake_logits = -2.4814 true_prob = 0.2825 fake_prob = 0.1359 
2022-05-01 14:01:20.125959 - gail/main.py:132 - [Evaluate] iter = 1600000 episode={ returns = 61.1815 lengths = 37 } discounted_episode={ returns = 60.0637 lengths = 37 } 
2022-05-01 14:01:29.685504 - gail/main.py:164 - [TRPO] iter = 1601000 dist_mean = 0.0794 dist_std = 0.1455 vf_loss = 0.2741 grad_norm = 2.1405 nat_grad_norm = 0.0760 cg_residual = 1.3865 step_size = 0.5719 reward = 0.0000 fps = 67 mse_loss = 1.0222 
2022-05-01 14:01:39.303734 - gail/main.py:164 - [TRPO] iter = 1602000 dist_mean = 0.0923 dist_std = 0.1449 vf_loss = 0.4084 grad_norm = 2.8515 nat_grad_norm = 0.0650 cg_residual = 1.2901 step_size = 0.5431 reward = -0.0000 fps = 40 mse_loss = 1.0452 
2022-05-01 14:01:48.739366 - gail/main.py:164 - [TRPO] iter = 1603000 dist_mean = 0.0931 dist_std = 0.1450 vf_loss = 0.3784 grad_norm = 3.2748 nat_grad_norm = 0.0480 cg_residual = 0.8891 step_size = 0.7003 reward = 0.0000 fps = 29 mse_loss = 1.0027 
2022-05-01 14:01:58.486601 - gail/main.py:164 - [TRPO] iter = 1604000 dist_mean = 0.0895 dist_std = 0.1449 vf_loss = 0.1665 grad_norm = 3.9614 nat_grad_norm = 0.0808 cg_residual = 1.6904 step_size = 0.4674 reward = 0.0000 fps = 22 mse_loss = 0.9475 
2022-05-01 14:02:07.727751 - gail/main.py:164 - [TRPO] iter = 1605000 dist_mean = 0.0779 dist_std = 0.1451 vf_loss = 0.2165 grad_norm = 2.1925 nat_grad_norm = 0.0520 cg_residual = 1.3264 step_size = 0.6817 reward = -0.0000 fps = 18 mse_loss = 0.9934 
2022-05-01 14:02:07.975355 - gail/main.py:191 - [Discriminator] iter = 1605000 loss = -0.3911 grad_norm = 3.5719 grad_penalty = 0.0752 regularization = 0.0000 true_logits = -0.8197 fake_logits = -1.2860 true_prob = 0.3439 fake_prob = 0.2683 
2022-05-01 14:03:52.678603 - gail/main.py:132 - [Evaluate] iter = 1605000 episode={ returns = 2815.6298 lengths = 807 } discounted_episode={ returns = 1747.5595 lengths = 807 } 
2022-05-01 14:04:02.406616 - gail/main.py:164 - [TRPO] iter = 1606000 dist_mean = 0.0511 dist_std = 0.1451 vf_loss = 0.1855 grad_norm = 3.0531 nat_grad_norm = 0.0780 cg_residual = 1.3686 step_size = 0.4969 reward = 0.0000 fps = 8 mse_loss = 0.9254 
2022-05-01 14:04:11.981351 - gail/main.py:164 - [TRPO] iter = 1607000 dist_mean = 0.0916 dist_std = 0.1449 vf_loss = 0.1997 grad_norm = 2.9140 nat_grad_norm = 0.0545 cg_residual = 0.8993 step_size = 0.6573 reward = -0.0000 fps = 8 mse_loss = 0.9671 
2022-05-01 14:04:21.866744 - gail/main.py:164 - [TRPO] iter = 1608000 dist_mean = 0.0923 dist_std = 0.1449 vf_loss = 0.3127 grad_norm = 3.8991 nat_grad_norm = 0.0496 cg_residual = 1.3175 step_size = 0.5793 reward = 0.0000 fps = 7 mse_loss = 1.0466 
2022-05-01 14:04:31.470968 - gail/main.py:164 - [TRPO] iter = 1609000 dist_mean = 0.0629 dist_std = 0.1450 vf_loss = 0.2204 grad_norm = 2.5153 nat_grad_norm = 0.0803 cg_residual = 1.5803 step_size = 0.5709 reward = 0.0000 fps = 6 mse_loss = 0.9663 
2022-05-01 14:04:41.038922 - gail/main.py:164 - [TRPO] iter = 1610000 dist_mean = 0.0651 dist_std = 0.1445 vf_loss = 0.0327 grad_norm = 2.2726 nat_grad_norm = 0.1074 cg_residual = 1.8492 step_size = 0.4082 reward = 0.0000 fps = 6 mse_loss = 0.9827 
2022-05-01 14:04:41.316539 - gail/main.py:191 - [Discriminator] iter = 1610000 loss = -0.4418 grad_norm = 4.9596 grad_penalty = 0.0661 regularization = 0.0000 true_logits = -0.7880 fake_logits = -1.2959 true_prob = 0.3523 fake_prob = 0.2732 
2022-05-01 14:06:52.256335 - gail/main.py:132 - [Evaluate] iter = 1610000 episode={ returns = 3500.3861 lengths = 1000 } discounted_episode={ returns = 2165.3514 lengths = 1000 } 
2022-05-01 14:07:02.102665 - gail/main.py:164 - [TRPO] iter = 1611000 dist_mean = 0.0653 dist_std = 0.1446 vf_loss = 0.1050 grad_norm = 3.2797 nat_grad_norm = 0.0785 cg_residual = 1.1149 step_size = 0.5025 reward = 0.0000 fps = 7 mse_loss = 0.9963 
2022-05-01 14:07:11.950007 - gail/main.py:164 - [TRPO] iter = 1612000 dist_mean = 0.0559 dist_std = 0.1449 vf_loss = 0.1494 grad_norm = 3.0757 nat_grad_norm = 0.0764 cg_residual = 0.8378 step_size = 0.5516 reward = 0.0000 fps = 6 mse_loss = 0.9550 
2022-05-01 14:07:21.973353 - gail/main.py:164 - [TRPO] iter = 1613000 dist_mean = 0.0620 dist_std = 0.1447 vf_loss = 0.0989 grad_norm = 2.3137 nat_grad_norm = 0.0758 cg_residual = 1.1539 step_size = 0.5546 reward = -0.0000 fps = 6 mse_loss = 0.9806 
2022-05-01 14:07:31.461125 - gail/main.py:164 - [TRPO] iter = 1614000 dist_mean = 0.0731 dist_std = 0.1448 vf_loss = 0.1264 grad_norm = 3.4051 nat_grad_norm = 0.0636 cg_residual = 1.7949 step_size = 0.5602 reward = 0.0000 fps = 5 mse_loss = 0.9737 
2022-05-01 14:07:41.284443 - gail/main.py:164 - [TRPO] iter = 1615000 dist_mean = 0.0537 dist_std = 0.1445 vf_loss = 0.1292 grad_norm = 2.1897 nat_grad_norm = 0.0734 cg_residual = 1.0666 step_size = 0.5669 reward = 0.0000 fps = 5 mse_loss = 0.9370 
2022-05-01 14:07:41.588106 - gail/main.py:191 - [Discriminator] iter = 1615000 loss = -0.3930 grad_norm = 4.0876 grad_penalty = 0.0479 regularization = 0.0000 true_logits = -0.7783 fake_logits = -1.2192 true_prob = 0.3531 fake_prob = 0.2735 
2022-05-01 14:09:53.651323 - gail/main.py:132 - [Evaluate] iter = 1615000 episode={ returns = 3474.3490 lengths = 1000 } discounted_episode={ returns = 2158.1704 lengths = 1000 } 
2022-05-01 14:10:03.362352 - gail/main.py:164 - [TRPO] iter = 1616000 dist_mean = 0.0736 dist_std = 0.1445 vf_loss = 0.1381 grad_norm = 3.8614 nat_grad_norm = 0.0516 cg_residual = 0.6011 step_size = 0.5610 reward = 0.0000 fps = 7 mse_loss = 1.0242 
2022-05-01 14:10:12.783828 - gail/main.py:164 - [TRPO] iter = 1617000 dist_mean = 0.0635 dist_std = 0.1444 vf_loss = 0.0960 grad_norm = 4.1329 nat_grad_norm = 0.0522 cg_residual = 0.6604 step_size = 0.6144 reward = -0.0000 fps = 6 mse_loss = 0.9721 
2022-05-01 14:10:22.392306 - gail/main.py:164 - [TRPO] iter = 1618000 dist_mean = 0.0438 dist_std = 0.1445 vf_loss = 0.0813 grad_norm = 4.3649 nat_grad_norm = 0.0735 cg_residual = 1.5142 step_size = 0.4816 reward = -0.0000 fps = 6 mse_loss = 0.9867 
2022-05-01 14:10:31.974176 - gail/main.py:164 - [TRPO] iter = 1619000 dist_mean = 0.0404 dist_std = 0.1443 vf_loss = 0.0782 grad_norm = 3.5212 nat_grad_norm = 0.0624 cg_residual = 1.0581 step_size = 0.5370 reward = 0.0000 fps = 5 mse_loss = 0.9789 
2022-05-01 14:10:41.719346 - gail/main.py:164 - [TRPO] iter = 1620000 dist_mean = 0.0288 dist_std = 0.1440 vf_loss = 0.0942 grad_norm = 3.4483 nat_grad_norm = 0.0554 cg_residual = 0.6485 step_size = 0.6309 reward = -0.0000 fps = 5 mse_loss = 1.0055 
2022-05-01 14:10:42.002372 - gail/main.py:191 - [Discriminator] iter = 1620000 loss = -0.3881 grad_norm = 3.5827 grad_penalty = 0.0512 regularization = 0.0000 true_logits = -0.7157 fake_logits = -1.1551 true_prob = 0.3623 fake_prob = 0.2784 
2022-05-01 14:12:54.179944 - gail/main.py:132 - [Evaluate] iter = 1620000 episode={ returns = 3603.6831 lengths = 1000 } discounted_episode={ returns = 2226.0134 lengths = 1000 } 
2022-05-01 14:13:03.584994 - gail/main.py:164 - [TRPO] iter = 1621000 dist_mean = 0.0050 dist_std = 0.1444 vf_loss = 0.0372 grad_norm = 2.2835 nat_grad_norm = 0.0860 cg_residual = 2.4025 step_size = 0.5025 reward = 0.0000 fps = 7 mse_loss = 0.9658 
2022-05-01 14:13:13.182030 - gail/main.py:164 - [TRPO] iter = 1622000 dist_mean = -0.0049 dist_std = 0.1440 vf_loss = 0.0241 grad_norm = 5.0799 nat_grad_norm = 0.0820 cg_residual = 1.7022 step_size = 0.4220 reward = -0.0000 fps = 6 mse_loss = 0.9585 
2022-05-01 14:13:22.647192 - gail/main.py:164 - [TRPO] iter = 1623000 dist_mean = -0.0059 dist_std = 0.1440 vf_loss = 0.0286 grad_norm = 5.3950 nat_grad_norm = 0.0645 cg_residual = 0.9663 step_size = 0.4554 reward = -0.0000 fps = 6 mse_loss = 1.0047 
2022-05-01 14:13:31.932694 - gail/main.py:164 - [TRPO] iter = 1624000 dist_mean = -0.0219 dist_std = 0.1439 vf_loss = 0.0280 grad_norm = 3.0289 nat_grad_norm = 0.1203 cg_residual = 2.9616 step_size = 0.3923 reward = 0.0000 fps = 5 mse_loss = 0.9178 
2022-05-01 14:13:41.239752 - gail/main.py:164 - [TRPO] iter = 1625000 dist_mean = -0.0243 dist_std = 0.1435 vf_loss = 0.0334 grad_norm = 4.9023 nat_grad_norm = 0.0810 cg_residual = 2.3095 step_size = 0.4290 reward = -0.0000 fps = 5 mse_loss = 0.9931 
2022-05-01 14:13:41.443742 - gail/main.py:191 - [Discriminator] iter = 1625000 loss = -0.3129 grad_norm = 4.3458 grad_penalty = 0.0535 regularization = 0.0000 true_logits = -0.7076 fake_logits = -1.0740 true_prob = 0.3577 fake_prob = 0.2883 
2022-05-01 14:15:13.630709 - gail/main.py:132 - [Evaluate] iter = 1625000 episode={ returns = 2568.1480 lengths = 711 } discounted_episode={ returns = 1699.0997 lengths = 686 } 
2022-05-01 14:15:23.259607 - gail/main.py:164 - [TRPO] iter = 1626000 dist_mean = -0.0012 dist_std = 0.1431 vf_loss = 0.0303 grad_norm = 3.2788 nat_grad_norm = 0.0911 cg_residual = 1.9558 step_size = 0.4243 reward = -0.0000 fps = 9 mse_loss = 0.8951 
2022-05-01 14:15:32.914892 - gail/main.py:164 - [TRPO] iter = 1627000 dist_mean = -0.0262 dist_std = 0.1432 vf_loss = 0.0458 grad_norm = 2.9165 nat_grad_norm = 0.0718 cg_residual = 1.8934 step_size = 0.5266 reward = -0.0000 fps = 8 mse_loss = 0.9427 
2022-05-01 14:15:42.175539 - gail/main.py:164 - [TRPO] iter = 1628000 dist_mean = -0.0106 dist_std = 0.1432 vf_loss = 0.0245 grad_norm = 3.7437 nat_grad_norm = 0.0712 cg_residual = 1.4292 step_size = 0.4932 reward = -0.0000 fps = 8 mse_loss = 0.9108 
2022-05-01 14:15:51.898942 - gail/main.py:164 - [TRPO] iter = 1629000 dist_mean = -0.0256 dist_std = 0.1426 vf_loss = 0.0979 grad_norm = 2.4819 nat_grad_norm = 0.0719 cg_residual = 0.8626 step_size = 0.5702 reward = 0.0000 fps = 7 mse_loss = 0.9775 
2022-05-01 14:16:01.737116 - gail/main.py:164 - [TRPO] iter = 1630000 dist_mean = -0.0079 dist_std = 0.1430 vf_loss = 0.0549 grad_norm = 3.2355 nat_grad_norm = 0.0983 cg_residual = 2.3476 step_size = 0.3613 reward = 0.0000 fps = 7 mse_loss = 0.9048 
2022-05-01 14:16:01.949157 - gail/main.py:191 - [Discriminator] iter = 1630000 loss = -0.5733 grad_norm = 3.9920 grad_penalty = 0.0629 regularization = 0.0000 true_logits = -0.6378 fake_logits = -1.2740 true_prob = 0.3654 fake_prob = 0.2533 
2022-05-01 14:17:49.976545 - gail/main.py:132 - [Evaluate] iter = 1630000 episode={ returns = 3216.2505 lengths = 888 } discounted_episode={ returns = 1840.8772 lengths = 759 } 
2022-05-01 14:17:59.334547 - gail/main.py:164 - [TRPO] iter = 1631000 dist_mean = -0.0138 dist_std = 0.1429 vf_loss = 0.1464 grad_norm = 3.9331 nat_grad_norm = 0.0800 cg_residual = 2.2327 step_size = 0.5190 reward = 0.0000 fps = 8 mse_loss = 0.9881 
2022-05-01 14:18:09.108784 - gail/main.py:164 - [TRPO] iter = 1632000 dist_mean = -0.0023 dist_std = 0.1421 vf_loss = 0.0265 grad_norm = 2.7396 nat_grad_norm = 0.0849 cg_residual = 1.4671 step_size = 0.4510 reward = -0.0000 fps = 7 mse_loss = 0.9246 
2022-05-01 14:18:18.788125 - gail/main.py:164 - [TRPO] iter = 1633000 dist_mean = -0.0212 dist_std = 0.1418 vf_loss = 0.0856 grad_norm = 3.4473 nat_grad_norm = 0.0607 cg_residual = 0.8241 step_size = 0.5169 reward = 0.0000 fps = 7 mse_loss = 0.9466 
2022-05-01 14:18:28.592001 - gail/main.py:164 - [TRPO] iter = 1634000 dist_mean = 0.0061 dist_std = 0.1415 vf_loss = 0.0271 grad_norm = 3.9914 nat_grad_norm = 0.0906 cg_residual = 3.0682 step_size = 0.3965 reward = 0.0000 fps = 6 mse_loss = 0.9779 
2022-05-01 14:18:38.364116 - gail/main.py:164 - [TRPO] iter = 1635000 dist_mean = -0.0177 dist_std = 0.1414 vf_loss = 0.0647 grad_norm = 3.6950 nat_grad_norm = 0.0592 cg_residual = 1.6661 step_size = 0.5621 reward = 0.0000 fps = 6 mse_loss = 0.9413 
2022-05-01 14:18:38.606084 - gail/main.py:191 - [Discriminator] iter = 1635000 loss = -0.5693 grad_norm = 3.7936 grad_penalty = 0.0639 regularization = 0.0000 true_logits = -0.6104 fake_logits = -1.2436 true_prob = 0.3712 fake_prob = 0.2507 
2022-05-01 14:20:03.015559 - gail/main.py:132 - [Evaluate] iter = 1635000 episode={ returns = 2238.9482 lengths = 622 } discounted_episode={ returns = 1653.1530 lengths = 653 } 
2022-05-01 14:20:12.729827 - gail/main.py:164 - [TRPO] iter = 1636000 dist_mean = -0.0113 dist_std = 0.1417 vf_loss = 0.0340 grad_norm = 3.0430 nat_grad_norm = 0.0648 cg_residual = 3.0472 step_size = 0.5479 reward = -0.0000 fps = 10 mse_loss = 0.9239 
2022-05-01 14:20:22.472166 - gail/main.py:164 - [TRPO] iter = 1637000 dist_mean = -0.0067 dist_std = 0.1419 vf_loss = 0.0174 grad_norm = 3.1538 nat_grad_norm = 0.0623 cg_residual = 2.7068 step_size = 0.5305 reward = -0.0000 fps = 9 mse_loss = 0.8881 
2022-05-01 14:20:32.198726 - gail/main.py:164 - [TRPO] iter = 1638000 dist_mean = 0.0244 dist_std = 0.1423 vf_loss = 0.0298 grad_norm = 4.0729 nat_grad_norm = 0.1017 cg_residual = 1.6565 step_size = 0.3636 reward = 0.0000 fps = 8 mse_loss = 0.9221 
2022-05-01 14:20:41.836890 - gail/main.py:164 - [TRPO] iter = 1639000 dist_mean = -0.0088 dist_std = 0.1423 vf_loss = 0.0557 grad_norm = 2.8406 nat_grad_norm = 0.0690 cg_residual = 1.4520 step_size = 0.5242 reward = -0.0000 fps = 8 mse_loss = 0.9328 
2022-05-01 14:20:51.302534 - gail/main.py:164 - [TRPO] iter = 1640000 dist_mean = 0.0462 dist_std = 0.1421 vf_loss = 0.0992 grad_norm = 2.7927 nat_grad_norm = 0.0860 cg_residual = 2.2588 step_size = 0.4489 reward = 0.0000 fps = 7 mse_loss = 0.9077 
2022-05-01 14:20:51.514629 - gail/main.py:191 - [Discriminator] iter = 1640000 loss = -0.3754 grad_norm = 3.3644 grad_penalty = 0.0557 regularization = 0.0000 true_logits = -0.6204 fake_logits = -1.0515 true_prob = 0.3710 fake_prob = 0.2909 
2022-05-01 14:22:58.907593 - gail/main.py:132 - [Evaluate] iter = 1640000 episode={ returns = 3472.9274 lengths = 968 } discounted_episode={ returns = 2212.2440 lengths = 1000 } 
2022-05-01 14:23:08.716850 - gail/main.py:164 - [TRPO] iter = 1641000 dist_mean = 0.0312 dist_std = 0.1420 vf_loss = 0.0209 grad_norm = 2.8212 nat_grad_norm = 0.0706 cg_residual = 1.0670 step_size = 0.5124 reward = -0.0000 fps = 7 mse_loss = 0.9459 
2022-05-01 14:23:18.439479 - gail/main.py:164 - [TRPO] iter = 1642000 dist_mean = 0.0350 dist_std = 0.1420 vf_loss = 0.0584 grad_norm = 2.7365 nat_grad_norm = 0.1213 cg_residual = 3.2133 step_size = 0.3304 reward = -0.0000 fps = 6 mse_loss = 0.9269 
2022-05-01 14:23:28.104312 - gail/main.py:164 - [TRPO] iter = 1643000 dist_mean = 0.0106 dist_std = 0.1420 vf_loss = 0.0632 grad_norm = 4.0264 nat_grad_norm = 0.0587 cg_residual = 0.6782 step_size = 0.5538 reward = 0.0000 fps = 6 mse_loss = 0.9477 
2022-05-01 14:23:37.491638 - gail/main.py:164 - [TRPO] iter = 1644000 dist_mean = 0.0167 dist_std = 0.1417 vf_loss = 0.0504 grad_norm = 4.6299 nat_grad_norm = 0.0720 cg_residual = 1.9541 step_size = 0.4586 reward = -0.0000 fps = 6 mse_loss = 0.8872 
2022-05-01 14:23:47.029047 - gail/main.py:164 - [TRPO] iter = 1645000 dist_mean = 0.0278 dist_std = 0.1418 vf_loss = 0.0366 grad_norm = 3.2641 nat_grad_norm = 0.0600 cg_residual = 1.4639 step_size = 0.4991 reward = 0.0000 fps = 5 mse_loss = 0.8610 
2022-05-01 14:23:47.257684 - gail/main.py:191 - [Discriminator] iter = 1645000 loss = -0.3813 grad_norm = 5.3432 grad_penalty = 0.0558 regularization = 0.0000 true_logits = -0.6083 fake_logits = -1.0454 true_prob = 0.3795 fake_prob = 0.2982 
2022-05-01 14:26:02.516951 - gail/main.py:132 - [Evaluate] iter = 1645000 episode={ returns = 3584.5474 lengths = 1000 } discounted_episode={ returns = 2208.7615 lengths = 1000 } 
2022-05-01 14:26:12.659786 - gail/main.py:164 - [TRPO] iter = 1646000 dist_mean = 0.0369 dist_std = 0.1418 vf_loss = 0.0868 grad_norm = 3.3804 nat_grad_norm = 0.0628 cg_residual = 0.8108 step_size = 0.5448 reward = 0.0000 fps = 6 mse_loss = 0.9513 
2022-05-01 14:26:22.444505 - gail/main.py:164 - [TRPO] iter = 1647000 dist_mean = 0.0728 dist_std = 0.1413 vf_loss = 0.0581 grad_norm = 2.2289 nat_grad_norm = 0.0544 cg_residual = 0.6681 step_size = 0.6781 reward = -0.0000 fps = 6 mse_loss = 0.8297 
2022-05-01 14:26:32.548017 - gail/main.py:164 - [TRPO] iter = 1648000 dist_mean = 0.0621 dist_std = 0.1413 vf_loss = 0.0816 grad_norm = 3.3092 nat_grad_norm = 0.0715 cg_residual = 0.9692 step_size = 0.5075 reward = 0.0000 fps = 6 mse_loss = 0.9522 
2022-05-01 14:26:42.421096 - gail/main.py:164 - [TRPO] iter = 1649000 dist_mean = 0.0392 dist_std = 0.1413 vf_loss = 0.2322 grad_norm = 1.8735 nat_grad_norm = 0.0469 cg_residual = 0.7234 step_size = 0.7063 reward = -0.0000 fps = 5 mse_loss = 0.8606 
2022-05-01 14:26:52.242727 - gail/main.py:164 - [TRPO] iter = 1650000 dist_mean = 0.0846 dist_std = 0.1412 vf_loss = 0.0708 grad_norm = 4.1255 nat_grad_norm = 0.0760 cg_residual = 1.1020 step_size = 0.4920 reward = 0.0000 fps = 5 mse_loss = 0.8638 
2022-05-01 14:26:52.462661 - gail/main.py:191 - [Discriminator] iter = 1650000 loss = -0.3492 grad_norm = 5.8285 grad_penalty = 0.0543 regularization = 0.0000 true_logits = -0.5707 fake_logits = -0.9743 true_prob = 0.3886 fake_prob = 0.3094 
2022-05-01 14:29:03.741728 - gail/main.py:132 - [Evaluate] iter = 1650000 episode={ returns = 3515.2952 lengths = 1000 } discounted_episode={ returns = 2168.7839 lengths = 1000 } 
2022-05-01 14:29:13.598944 - gail/main.py:164 - [TRPO] iter = 1651000 dist_mean = 0.0347 dist_std = 0.1413 vf_loss = 0.1250 grad_norm = 6.3811 nat_grad_norm = 0.0740 cg_residual = 1.7359 step_size = 0.4117 reward = 0.0000 fps = 7 mse_loss = 0.9217 
2022-05-01 14:29:23.306736 - gail/main.py:164 - [TRPO] iter = 1652000 dist_mean = 0.1055 dist_std = 0.1412 vf_loss = 0.0555 grad_norm = 2.6988 nat_grad_norm = 0.0526 cg_residual = 1.4602 step_size = 0.5991 reward = -0.0000 fps = 6 mse_loss = 0.9557 
2022-05-01 14:29:32.935808 - gail/main.py:164 - [TRPO] iter = 1653000 dist_mean = 0.0725 dist_std = 0.1411 vf_loss = 0.2084 grad_norm = 3.0654 nat_grad_norm = 0.0522 cg_residual = 0.9395 step_size = 0.6623 reward = -0.0000 fps = 6 mse_loss = 0.8473 
2022-05-01 14:29:42.890153 - gail/main.py:164 - [TRPO] iter = 1654000 dist_mean = 0.0880 dist_std = 0.1409 vf_loss = 0.2223 grad_norm = 4.7189 nat_grad_norm = 0.0665 cg_residual = 0.8821 step_size = 0.4794 reward = -0.0000 fps = 5 mse_loss = 0.8503 
2022-05-01 14:29:52.088106 - gail/main.py:164 - [TRPO] iter = 1655000 dist_mean = 0.0839 dist_std = 0.1408 vf_loss = 0.2234 grad_norm = 2.9659 nat_grad_norm = 0.0552 cg_residual = 0.6603 step_size = 0.5904 reward = 0.0000 fps = 5 mse_loss = 0.9356 
2022-05-01 14:29:52.322772 - gail/main.py:191 - [Discriminator] iter = 1655000 loss = -0.3221 grad_norm = 4.2122 grad_penalty = 0.0539 regularization = 0.0000 true_logits = -0.5561 fake_logits = -0.9322 true_prob = 0.3880 fake_prob = 0.3166 
2022-05-01 14:32:00.930921 - gail/main.py:132 - [Evaluate] iter = 1655000 episode={ returns = 3486.4229 lengths = 1000 } discounted_episode={ returns = 2152.6321 lengths = 1000 } 
2022-05-01 14:32:10.376131 - gail/main.py:164 - [TRPO] iter = 1656000 dist_mean = 0.0934 dist_std = 0.1410 vf_loss = 0.1061 grad_norm = 2.9968 nat_grad_norm = 0.0613 cg_residual = 2.1459 step_size = 0.5456 reward = -0.0000 fps = 7 mse_loss = 0.9231 
2022-05-01 14:32:20.024284 - gail/main.py:164 - [TRPO] iter = 1657000 dist_mean = 0.0756 dist_std = 0.1407 vf_loss = 0.1885 grad_norm = 2.1122 nat_grad_norm = 0.0570 cg_residual = 0.8583 step_size = 0.6282 reward = 0.0000 fps = 6 mse_loss = 0.8813 
2022-05-01 14:32:29.176693 - gail/main.py:164 - [TRPO] iter = 1658000 dist_mean = 0.0871 dist_std = 0.1407 vf_loss = 0.1750 grad_norm = 3.4461 nat_grad_norm = 0.0600 cg_residual = 1.5631 step_size = 0.5280 reward = -0.0000 fps = 6 mse_loss = 0.9496 
2022-05-01 14:32:38.664087 - gail/main.py:164 - [TRPO] iter = 1659000 dist_mean = 0.0259 dist_std = 0.1408 vf_loss = 0.0441 grad_norm = 3.4507 nat_grad_norm = 0.0736 cg_residual = 1.6840 step_size = 0.4823 reward = -0.0000 fps = 6 mse_loss = 0.9154 
2022-05-01 14:32:48.094682 - gail/main.py:164 - [TRPO] iter = 1660000 dist_mean = 0.0724 dist_std = 0.1409 vf_loss = 0.0304 grad_norm = 2.7508 nat_grad_norm = 0.0768 cg_residual = 1.5321 step_size = 0.4212 reward = -0.0000 fps = 5 mse_loss = 0.9062 
2022-05-01 14:32:48.310446 - gail/main.py:191 - [Discriminator] iter = 1660000 loss = -0.3596 grad_norm = 3.8695 grad_penalty = 0.0479 regularization = 0.0000 true_logits = -0.6263 fake_logits = -1.0338 true_prob = 0.3742 fake_prob = 0.2962 
2022-05-01 14:35:01.784896 - gail/main.py:132 - [Evaluate] iter = 1660000 episode={ returns = 3485.4992 lengths = 1000 } discounted_episode={ returns = 2156.6345 lengths = 1000 } 
2022-05-01 14:35:11.878506 - gail/main.py:164 - [TRPO] iter = 1661000 dist_mean = 0.0911 dist_std = 0.1409 vf_loss = 0.0868 grad_norm = 3.2191 nat_grad_norm = 0.0698 cg_residual = 1.5895 step_size = 0.5215 reward = 0.0000 fps = 6 mse_loss = 0.9353 
2022-05-01 14:35:21.840023 - gail/main.py:164 - [TRPO] iter = 1662000 dist_mean = 0.0864 dist_std = 0.1405 vf_loss = 0.0388 grad_norm = 2.9662 nat_grad_norm = 0.0669 cg_residual = 2.3793 step_size = 0.4769 reward = -0.0000 fps = 6 mse_loss = 0.9433 
2022-05-01 14:35:31.784338 - gail/main.py:164 - [TRPO] iter = 1663000 dist_mean = 0.1148 dist_std = 0.1403 vf_loss = 0.0930 grad_norm = 1.7552 nat_grad_norm = 0.0572 cg_residual = 1.4121 step_size = 0.6621 reward = 0.0000 fps = 6 mse_loss = 0.8084 
2022-05-01 14:35:41.721367 - gail/main.py:164 - [TRPO] iter = 1664000 dist_mean = 0.0992 dist_std = 0.1404 vf_loss = 0.1052 grad_norm = 3.7663 nat_grad_norm = 0.0641 cg_residual = 3.0894 step_size = 0.4816 reward = 0.0000 fps = 5 mse_loss = 0.9386 
2022-05-01 14:35:51.396196 - gail/main.py:164 - [TRPO] iter = 1665000 dist_mean = 0.0731 dist_std = 0.1406 vf_loss = 0.1541 grad_norm = 2.9994 nat_grad_norm = 0.0958 cg_residual = 4.2363 step_size = 0.3876 reward = -0.0000 fps = 5 mse_loss = 0.9121 
2022-05-01 14:35:51.619049 - gail/main.py:191 - [Discriminator] iter = 1665000 loss = -0.5458 grad_norm = 3.0764 grad_penalty = 0.0467 regularization = 0.0000 true_logits = -0.7101 fake_logits = -1.3026 true_prob = 0.3565 fake_prob = 0.2560 
2022-05-01 14:38:02.804743 - gail/main.py:132 - [Evaluate] iter = 1665000 episode={ returns = 3464.8487 lengths = 1000 } discounted_episode={ returns = 2143.5190 lengths = 1000 } 
2022-05-01 14:38:12.559010 - gail/main.py:164 - [TRPO] iter = 1666000 dist_mean = 0.0469 dist_std = 0.1404 vf_loss = 0.0228 grad_norm = 4.2800 nat_grad_norm = 0.0645 cg_residual = 1.0019 step_size = 0.5242 reward = 0.0000 fps = 7 mse_loss = 0.9587 
2022-05-01 14:38:22.247622 - gail/main.py:164 - [TRPO] iter = 1667000 dist_mean = 0.0959 dist_std = 0.1401 vf_loss = 0.0328 grad_norm = 3.2556 nat_grad_norm = 0.0742 cg_residual = 1.8881 step_size = 0.5005 reward = -0.0000 fps = 6 mse_loss = 0.9205 
2022-05-01 14:38:31.813158 - gail/main.py:164 - [TRPO] iter = 1668000 dist_mean = 0.0799 dist_std = 0.1401 vf_loss = 0.1503 grad_norm = 3.6044 nat_grad_norm = 0.0686 cg_residual = 1.9950 step_size = 0.5203 reward = -0.0000 fps = 6 mse_loss = 0.9628 
2022-05-01 14:38:41.642319 - gail/main.py:164 - [TRPO] iter = 1669000 dist_mean = 0.1124 dist_std = 0.1400 vf_loss = 0.1210 grad_norm = 3.8230 nat_grad_norm = 0.0417 cg_residual = 1.1776 step_size = 0.6562 reward = -0.0000 fps = 5 mse_loss = 0.8526 
2022-05-01 14:38:50.880511 - gail/main.py:164 - [TRPO] iter = 1670000 dist_mean = 0.1052 dist_std = 0.1402 vf_loss = 0.0792 grad_norm = 2.6358 nat_grad_norm = 0.0910 cg_residual = 4.8895 step_size = 0.4292 reward = -0.0000 fps = 5 mse_loss = 0.9206 
2022-05-01 14:38:51.102345 - gail/main.py:191 - [Discriminator] iter = 1670000 loss = -0.3900 grad_norm = 3.7123 grad_penalty = 0.0553 regularization = 0.0000 true_logits = -0.7818 fake_logits = -1.2271 true_prob = 0.3491 fake_prob = 0.2661 
2022-05-01 14:41:02.171964 - gail/main.py:132 - [Evaluate] iter = 1670000 episode={ returns = 3503.6612 lengths = 1000 } discounted_episode={ returns = 2162.1251 lengths = 1000 } 
2022-05-01 14:41:12.407682 - gail/main.py:164 - [TRPO] iter = 1671000 dist_mean = 0.1022 dist_std = 0.1400 vf_loss = 0.1180 grad_norm = 4.1480 nat_grad_norm = 0.0528 cg_residual = 2.8378 step_size = 0.4891 reward = 0.0000 fps = 7 mse_loss = 0.8857 
2022-05-01 14:41:22.426583 - gail/main.py:164 - [TRPO] iter = 1672000 dist_mean = 0.0775 dist_std = 0.1398 vf_loss = 0.0256 grad_norm = 4.7321 nat_grad_norm = 0.0726 cg_residual = 1.4102 step_size = 0.4739 reward = 0.0000 fps = 6 mse_loss = 0.8636 
2022-05-01 14:41:32.542655 - gail/main.py:164 - [TRPO] iter = 1673000 dist_mean = 0.0905 dist_std = 0.1399 vf_loss = 0.0190 grad_norm = 5.6448 nat_grad_norm = 0.0857 cg_residual = 1.8123 step_size = 0.3995 reward = -0.0000 fps = 6 mse_loss = 0.8748 
2022-05-01 14:41:42.498254 - gail/main.py:164 - [TRPO] iter = 1674000 dist_mean = 0.0514 dist_std = 0.1401 vf_loss = 0.0197 grad_norm = 3.3761 nat_grad_norm = 0.0742 cg_residual = 2.2119 step_size = 0.4596 reward = -0.0000 fps = 5 mse_loss = 0.9336 
2022-05-01 14:41:52.131420 - gail/main.py:164 - [TRPO] iter = 1675000 dist_mean = 0.1103 dist_std = 0.1400 vf_loss = 0.0845 grad_norm = 3.4804 nat_grad_norm = 0.0477 cg_residual = 1.8683 step_size = 0.6556 reward = -0.0000 fps = 5 mse_loss = 0.8764 
2022-05-01 14:41:52.407486 - gail/main.py:191 - [Discriminator] iter = 1675000 loss = -0.4559 grad_norm = 3.3108 grad_penalty = 0.0423 regularization = 0.0000 true_logits = -0.7648 fake_logits = -1.2630 true_prob = 0.3528 fake_prob = 0.2626 
2022-05-01 14:44:04.542724 - gail/main.py:132 - [Evaluate] iter = 1675000 episode={ returns = 3578.2258 lengths = 1000 } discounted_episode={ returns = 2204.1443 lengths = 1000 } 
2022-05-01 14:44:14.365475 - gail/main.py:164 - [TRPO] iter = 1676000 dist_mean = 0.0610 dist_std = 0.1401 vf_loss = 0.0773 grad_norm = 2.6836 nat_grad_norm = 0.0581 cg_residual = 0.8084 step_size = 0.5143 reward = -0.0000 fps = 7 mse_loss = 0.9955 
2022-05-01 14:44:23.991456 - gail/main.py:164 - [TRPO] iter = 1677000 dist_mean = 0.0736 dist_std = 0.1399 vf_loss = 0.0139 grad_norm = 4.9634 nat_grad_norm = 0.0922 cg_residual = 2.5908 step_size = 0.4112 reward = -0.0000 fps = 6 mse_loss = 0.9495 
2022-05-01 14:44:33.754460 - gail/main.py:164 - [TRPO] iter = 1678000 dist_mean = 0.0381 dist_std = 0.1399 vf_loss = 0.0909 grad_norm = 3.2180 nat_grad_norm = 0.0667 cg_residual = 2.1835 step_size = 0.4768 reward = -0.0000 fps = 6 mse_loss = 0.9000 
2022-05-01 14:44:42.806184 - gail/main.py:164 - [TRPO] iter = 1679000 dist_mean = 0.0333 dist_std = 0.1398 vf_loss = 0.0584 grad_norm = 5.3593 nat_grad_norm = 0.0675 cg_residual = 2.2470 step_size = 0.4489 reward = 0.0000 fps = 5 mse_loss = 0.9454 
2022-05-01 14:44:52.271637 - gail/main.py:164 - [TRPO] iter = 1680000 dist_mean = 0.0468 dist_std = 0.1398 vf_loss = 0.0577 grad_norm = 4.5062 nat_grad_norm = 0.0760 cg_residual = 2.8009 step_size = 0.4350 reward = -0.0000 fps = 5 mse_loss = 0.9244 
2022-05-01 14:44:52.505008 - gail/main.py:191 - [Discriminator] iter = 1680000 loss = -0.4279 grad_norm = 3.6838 grad_penalty = 0.0455 regularization = 0.0000 true_logits = -0.7557 fake_logits = -1.2291 true_prob = 0.3544 fake_prob = 0.2722 
2022-05-01 14:46:58.987520 - gail/main.py:132 - [Evaluate] iter = 1680000 episode={ returns = 3444.6984 lengths = 946 } discounted_episode={ returns = 2215.0336 lengths = 988 } 
2022-05-01 14:47:08.487772 - gail/main.py:164 - [TRPO] iter = 1681000 dist_mean = 0.0275 dist_std = 0.1399 vf_loss = 0.0454 grad_norm = 5.4434 nat_grad_norm = 0.0924 cg_residual = 2.1092 step_size = 0.3606 reward = -0.0000 fps = 7 mse_loss = 0.8897 
2022-05-01 14:47:17.924552 - gail/main.py:164 - [TRPO] iter = 1682000 dist_mean = 0.0045 dist_std = 0.1398 vf_loss = 0.0220 grad_norm = 4.1546 nat_grad_norm = 0.1073 cg_residual = 5.8527 step_size = 0.3496 reward = 0.0000 fps = 6 mse_loss = 0.8893 
2022-05-01 14:47:27.442483 - gail/main.py:164 - [TRPO] iter = 1683000 dist_mean = 0.0303 dist_std = 0.1397 vf_loss = 0.0200 grad_norm = 2.5684 nat_grad_norm = 0.0584 cg_residual = 0.8207 step_size = 0.5733 reward = 0.0000 fps = 6 mse_loss = 0.9020 
2022-05-01 14:47:37.050420 - gail/main.py:164 - [TRPO] iter = 1684000 dist_mean = 0.0144 dist_std = 0.1399 vf_loss = 0.0255 grad_norm = 4.5383 nat_grad_norm = 0.1220 cg_residual = 2.2112 step_size = 0.3442 reward = -0.0000 fps = 6 mse_loss = 0.8672 
2022-05-01 14:47:46.265875 - gail/main.py:164 - [TRPO] iter = 1685000 dist_mean = 0.0410 dist_std = 0.1397 vf_loss = 0.0251 grad_norm = 4.5110 nat_grad_norm = 0.1004 cg_residual = 1.9981 step_size = 0.3589 reward = -0.0000 fps = 5 mse_loss = 0.8419 
2022-05-01 14:47:46.500241 - gail/main.py:191 - [Discriminator] iter = 1685000 loss = -0.3298 grad_norm = 3.6755 grad_penalty = 0.0517 regularization = 0.0000 true_logits = -0.8536 fake_logits = -1.2351 true_prob = 0.3371 fake_prob = 0.2723 
2022-05-01 14:49:11.533512 - gail/main.py:132 - [Evaluate] iter = 1685000 episode={ returns = 2617.0760 lengths = 724 } discounted_episode={ returns = 1553.8314 lengths = 588 } 
2022-05-01 14:49:21.466510 - gail/main.py:164 - [TRPO] iter = 1686000 dist_mean = -0.0073 dist_std = 0.1397 vf_loss = 0.0262 grad_norm = 3.6155 nat_grad_norm = 0.0552 cg_residual = 0.7248 step_size = 0.5071 reward = 0.0000 fps = 10 mse_loss = 0.8737 
2022-05-01 14:49:31.105670 - gail/main.py:164 - [TRPO] iter = 1687000 dist_mean = 0.0369 dist_std = 0.1397 vf_loss = 0.0187 grad_norm = 5.3742 nat_grad_norm = 0.1036 cg_residual = 6.2094 step_size = 0.3433 reward = 0.0000 fps = 9 mse_loss = 0.8904 
2022-05-01 14:49:40.704728 - gail/main.py:164 - [TRPO] iter = 1688000 dist_mean = -0.0178 dist_std = 0.1400 vf_loss = 0.0202 grad_norm = 2.7560 nat_grad_norm = 0.0622 cg_residual = 1.8341 step_size = 0.5470 reward = 0.0000 fps = 8 mse_loss = 0.8540 
2022-05-01 14:49:50.429254 - gail/main.py:164 - [TRPO] iter = 1689000 dist_mean = 0.0051 dist_std = 0.1402 vf_loss = 0.0259 grad_norm = 7.4560 nat_grad_norm = 0.1195 cg_residual = 6.8350 step_size = 0.2429 reward = 0.0000 fps = 8 mse_loss = 0.8586 
2022-05-01 14:49:59.981965 - gail/main.py:164 - [TRPO] iter = 1690000 dist_mean = -0.0107 dist_std = 0.1403 vf_loss = 0.0213 grad_norm = 4.0943 nat_grad_norm = 0.0702 cg_residual = 1.5090 step_size = 0.4924 reward = 0.0000 fps = 7 mse_loss = 0.8694 
2022-05-01 14:50:00.205728 - gail/main.py:191 - [Discriminator] iter = 1690000 loss = -0.4394 grad_norm = 4.4050 grad_penalty = 0.0530 regularization = 0.0000 true_logits = -0.8117 fake_logits = -1.3041 true_prob = 0.3399 fake_prob = 0.2567 
2022-05-01 14:52:11.358764 - gail/main.py:132 - [Evaluate] iter = 1690000 episode={ returns = 3558.5551 lengths = 1000 } discounted_episode={ returns = 2200.3924 lengths = 1000 } 
2022-05-01 14:52:21.474986 - gail/main.py:164 - [TRPO] iter = 1691000 dist_mean = -0.0098 dist_std = 0.1401 vf_loss = 0.0289 grad_norm = 4.6975 nat_grad_norm = 0.0890 cg_residual = 2.6669 step_size = 0.3814 reward = 0.0000 fps = 7 mse_loss = 0.8672 
2022-05-01 14:52:31.080168 - gail/main.py:164 - [TRPO] iter = 1692000 dist_mean = -0.0191 dist_std = 0.1402 vf_loss = 0.0643 grad_norm = 3.4714 nat_grad_norm = 0.0750 cg_residual = 1.2656 step_size = 0.4555 reward = 0.0000 fps = 6 mse_loss = 0.9299 
2022-05-01 14:52:40.894400 - gail/main.py:164 - [TRPO] iter = 1693000 dist_mean = 0.0026 dist_std = 0.1400 vf_loss = 0.0302 grad_norm = 4.3652 nat_grad_norm = 0.0852 cg_residual = 1.4575 step_size = 0.4062 reward = 0.0000 fps = 6 mse_loss = 0.8147 
2022-05-01 14:52:50.521168 - gail/main.py:164 - [TRPO] iter = 1694000 dist_mean = 0.0165 dist_std = 0.1399 vf_loss = 0.0321 grad_norm = 4.9482 nat_grad_norm = 0.1195 cg_residual = 3.2534 step_size = 0.3654 reward = 0.0000 fps = 5 mse_loss = 0.8059 
2022-05-01 14:52:59.951125 - gail/main.py:164 - [TRPO] iter = 1695000 dist_mean = -0.0042 dist_std = 0.1398 vf_loss = 0.0197 grad_norm = 4.9395 nat_grad_norm = 0.0655 cg_residual = 1.7450 step_size = 0.4669 reward = 0.0000 fps = 5 mse_loss = 0.8643 
2022-05-01 14:53:00.157191 - gail/main.py:191 - [Discriminator] iter = 1695000 loss = -0.4923 grad_norm = 3.6734 grad_penalty = 0.0555 regularization = 0.0000 true_logits = -0.7918 fake_logits = -1.3396 true_prob = 0.3367 fake_prob = 0.2413 
2022-05-01 14:54:14.529125 - gail/main.py:132 - [Evaluate] iter = 1695000 episode={ returns = 2104.5286 lengths = 583 } discounted_episode={ returns = 1479.4319 lengths = 563 } 
2022-05-01 14:54:24.223242 - gail/main.py:164 - [TRPO] iter = 1696000 dist_mean = 0.0042 dist_std = 0.1399 vf_loss = 0.0207 grad_norm = 3.2987 nat_grad_norm = 0.0905 cg_residual = 1.0089 step_size = 0.3974 reward = -0.0000 fps = 11 mse_loss = 0.8111 
2022-05-01 14:54:33.904653 - gail/main.py:164 - [TRPO] iter = 1697000 dist_mean = 0.0097 dist_std = 0.1400 vf_loss = 0.0258 grad_norm = 4.6481 nat_grad_norm = 0.0672 cg_residual = 1.2624 step_size = 0.4820 reward = 0.0000 fps = 10 mse_loss = 0.8606 
2022-05-01 14:54:43.395551 - gail/main.py:164 - [TRPO] iter = 1698000 dist_mean = 0.0120 dist_std = 0.1400 vf_loss = 0.0294 grad_norm = 3.4399 nat_grad_norm = 0.0815 cg_residual = 1.8697 step_size = 0.4521 reward = -0.0000 fps = 9 mse_loss = 0.8671 
2022-05-01 14:54:53.031136 - gail/main.py:164 - [TRPO] iter = 1699000 dist_mean = 0.0364 dist_std = 0.1400 vf_loss = 0.0561 grad_norm = 3.6502 nat_grad_norm = 0.0718 cg_residual = 1.7337 step_size = 0.5102 reward = 0.0000 fps = 8 mse_loss = 0.8885 
2022-05-01 14:55:02.451660 - gail/main.py:164 - [TRPO] iter = 1700000 dist_mean = 0.0283 dist_std = 0.1402 vf_loss = 0.0227 grad_norm = 5.1450 nat_grad_norm = 0.0996 cg_residual = 2.4399 step_size = 0.3461 reward = -0.0000 fps = 8 mse_loss = 0.8550 
2022-05-01 14:55:02.662684 - gail/main.py:191 - [Discriminator] iter = 1700000 loss = -0.5878 grad_norm = 3.5610 grad_penalty = 0.0637 regularization = 0.0000 true_logits = -0.6937 fake_logits = -1.3452 true_prob = 0.3570 fake_prob = 0.2397 
2022-05-01 14:57:02.083009 - gail/main.py:132 - [Evaluate] iter = 1700000 episode={ returns = 3259.1674 lengths = 901 } discounted_episode={ returns = 2070.4174 lengths = 902 } 
2022-05-01 14:57:11.752640 - gail/main.py:164 - [TRPO] iter = 1701000 dist_mean = 0.0234 dist_std = 0.1401 vf_loss = 0.0374 grad_norm = 4.3775 nat_grad_norm = 0.0868 cg_residual = 2.1176 step_size = 0.4443 reward = 0.0000 fps = 7 mse_loss = 0.8148 
2022-05-01 14:57:21.095714 - gail/main.py:164 - [TRPO] iter = 1702000 dist_mean = 0.0148 dist_std = 0.1401 vf_loss = 0.0421 grad_norm = 6.0306 nat_grad_norm = 0.0715 cg_residual = 2.0543 step_size = 0.4611 reward = -0.0000 fps = 7 mse_loss = 0.8578 
2022-05-01 14:57:30.652161 - gail/main.py:164 - [TRPO] iter = 1703000 dist_mean = 0.0732 dist_std = 0.1402 vf_loss = 0.1602 grad_norm = 3.8208 nat_grad_norm = 0.0571 cg_residual = 1.8872 step_size = 0.5622 reward = 0.0000 fps = 6 mse_loss = 0.7964 
2022-05-01 14:57:40.129398 - gail/main.py:164 - [TRPO] iter = 1704000 dist_mean = 0.0192 dist_std = 0.1402 vf_loss = 0.0453 grad_norm = 4.9164 nat_grad_norm = 0.0673 cg_residual = 1.2048 step_size = 0.4523 reward = -0.0000 fps = 6 mse_loss = 0.9032 
2022-05-01 14:57:50.036626 - gail/main.py:164 - [TRPO] iter = 1705000 dist_mean = 0.0711 dist_std = 0.1404 vf_loss = 0.1390 grad_norm = 3.7848 nat_grad_norm = 0.0716 cg_residual = 1.1724 step_size = 0.5174 reward = 0.0000 fps = 5 mse_loss = 0.8721 
2022-05-01 14:57:50.293680 - gail/main.py:191 - [Discriminator] iter = 1705000 loss = -0.3398 grad_norm = 4.0256 grad_penalty = 0.0584 regularization = 0.0000 true_logits = -0.7368 fake_logits = -1.1350 true_prob = 0.3464 fake_prob = 0.2729 
2022-05-01 14:59:59.313463 - gail/main.py:132 - [Evaluate] iter = 1705000 episode={ returns = 3564.8932 lengths = 1000 } discounted_episode={ returns = 2204.2738 lengths = 1000 } 
2022-05-01 15:00:09.101246 - gail/main.py:164 - [TRPO] iter = 1706000 dist_mean = 0.0526 dist_std = 0.1405 vf_loss = 0.2288 grad_norm = 3.7607 nat_grad_norm = 0.0754 cg_residual = 1.7668 step_size = 0.4567 reward = 0.0000 fps = 7 mse_loss = 0.8923 
2022-05-01 15:00:19.211958 - gail/main.py:164 - [TRPO] iter = 1707000 dist_mean = 0.0643 dist_std = 0.1402 vf_loss = 0.2404 grad_norm = 3.3148 nat_grad_norm = 0.0604 cg_residual = 1.5901 step_size = 0.5350 reward = 0.0000 fps = 6 mse_loss = 0.8519 
2022-05-01 15:00:28.953804 - gail/main.py:164 - [TRPO] iter = 1708000 dist_mean = 0.0651 dist_std = 0.1398 vf_loss = 0.1810 grad_norm = 3.5094 nat_grad_norm = 0.0616 cg_residual = 1.0678 step_size = 0.4959 reward = -0.0000 fps = 6 mse_loss = 0.8931 
2022-05-01 15:00:38.745322 - gail/main.py:164 - [TRPO] iter = 1709000 dist_mean = 0.0896 dist_std = 0.1400 vf_loss = 0.1612 grad_norm = 3.2329 nat_grad_norm = 0.0438 cg_residual = 1.0709 step_size = 0.7293 reward = -0.0000 fps = 5 mse_loss = 0.9028 
2022-05-01 15:00:48.488392 - gail/main.py:164 - [TRPO] iter = 1710000 dist_mean = 0.0823 dist_std = 0.1399 vf_loss = 0.2256 grad_norm = 5.7695 nat_grad_norm = 0.0655 cg_residual = 2.3801 step_size = 0.4891 reward = -0.0000 fps = 5 mse_loss = 0.8307 
2022-05-01 15:00:48.727293 - gail/main.py:191 - [Discriminator] iter = 1710000 loss = -0.4190 grad_norm = 3.5724 grad_penalty = 0.0579 regularization = 0.0000 true_logits = -0.7918 fake_logits = -1.2687 true_prob = 0.3369 fake_prob = 0.2488 
2022-05-01 15:02:59.384400 - gail/main.py:132 - [Evaluate] iter = 1710000 episode={ returns = 3543.3259 lengths = 1000 } discounted_episode={ returns = 2190.2298 lengths = 1000 } 
2022-05-01 15:03:09.135658 - gail/main.py:164 - [TRPO] iter = 1711000 dist_mean = 0.0797 dist_std = 0.1393 vf_loss = 0.2580 grad_norm = 4.1041 nat_grad_norm = 0.0911 cg_residual = 2.0479 step_size = 0.4075 reward = -0.0000 fps = 7 mse_loss = 0.8611 
2022-05-01 15:03:19.080241 - gail/main.py:164 - [TRPO] iter = 1712000 dist_mean = 0.0822 dist_std = 0.1391 vf_loss = 0.1078 grad_norm = 2.7050 nat_grad_norm = 0.0675 cg_residual = 1.2623 step_size = 0.5609 reward = -0.0000 fps = 6 mse_loss = 0.8556 
2022-05-01 15:03:28.565980 - gail/main.py:164 - [TRPO] iter = 1713000 dist_mean = 0.0760 dist_std = 0.1393 vf_loss = 0.0403 grad_norm = 2.4772 nat_grad_norm = 0.0587 cg_residual = 0.7133 step_size = 0.6317 reward = 0.0000 fps = 6 mse_loss = 0.8697 
2022-05-01 15:03:38.435686 - gail/main.py:164 - [TRPO] iter = 1714000 dist_mean = 0.0816 dist_std = 0.1394 vf_loss = 0.2163 grad_norm = 4.4801 nat_grad_norm = 0.0732 cg_residual = 1.3266 step_size = 0.4569 reward = 0.0000 fps = 5 mse_loss = 0.8126 
2022-05-01 15:03:48.157697 - gail/main.py:164 - [TRPO] iter = 1715000 dist_mean = 0.0595 dist_std = 0.1392 vf_loss = 0.1165 grad_norm = 2.9748 nat_grad_norm = 0.0667 cg_residual = 1.7372 step_size = 0.5084 reward = 0.0000 fps = 5 mse_loss = 0.7609 
2022-05-01 15:03:48.419262 - gail/main.py:191 - [Discriminator] iter = 1715000 loss = -0.4599 grad_norm = 3.6358 grad_penalty = 0.0563 regularization = 0.0000 true_logits = -0.8221 fake_logits = -1.3383 true_prob = 0.3323 fake_prob = 0.2412 
2022-05-01 15:05:57.778138 - gail/main.py:132 - [Evaluate] iter = 1715000 episode={ returns = 3545.0935 lengths = 1000 } discounted_episode={ returns = 2191.7886 lengths = 1000 } 
2022-05-01 15:06:07.376758 - gail/main.py:164 - [TRPO] iter = 1716000 dist_mean = 0.0407 dist_std = 0.1394 vf_loss = 0.0380 grad_norm = 3.8038 nat_grad_norm = 0.0896 cg_residual = 2.0678 step_size = 0.4430 reward = 0.0000 fps = 7 mse_loss = 0.7965 
2022-05-01 15:06:16.801628 - gail/main.py:164 - [TRPO] iter = 1717000 dist_mean = 0.0959 dist_std = 0.1393 vf_loss = 0.0491 grad_norm = 3.2371 nat_grad_norm = 0.0641 cg_residual = 1.8334 step_size = 0.5807 reward = -0.0000 fps = 6 mse_loss = 0.7994 
2022-05-01 15:06:26.236753 - gail/main.py:164 - [TRPO] iter = 1718000 dist_mean = 0.0731 dist_std = 0.1395 vf_loss = 0.0396 grad_norm = 3.7732 nat_grad_norm = 0.0528 cg_residual = 0.9567 step_size = 0.6612 reward = 0.0000 fps = 6 mse_loss = 0.7891 
2022-05-01 15:06:36.429805 - gail/main.py:164 - [TRPO] iter = 1719000 dist_mean = 0.0572 dist_std = 0.1396 vf_loss = 0.0289 grad_norm = 6.0341 nat_grad_norm = 0.0809 cg_residual = 1.5935 step_size = 0.4255 reward = 0.0000 fps = 5 mse_loss = 0.8013 
2022-05-01 15:06:46.049373 - gail/main.py:164 - [TRPO] iter = 1720000 dist_mean = 0.0712 dist_std = 0.1394 vf_loss = 0.1287 grad_norm = 5.4826 nat_grad_norm = 0.0511 cg_residual = 0.7725 step_size = 0.5414 reward = -0.0000 fps = 5 mse_loss = 0.7979 
2022-05-01 15:06:46.283983 - gail/main.py:191 - [Discriminator] iter = 1720000 loss = -0.4194 grad_norm = 3.0568 grad_penalty = 0.0530 regularization = 0.0000 true_logits = -0.7815 fake_logits = -1.2540 true_prob = 0.3408 fake_prob = 0.2581 
2022-05-01 15:08:57.604912 - gail/main.py:132 - [Evaluate] iter = 1720000 episode={ returns = 3542.2691 lengths = 1000 } discounted_episode={ returns = 2186.3786 lengths = 1000 } 
2022-05-01 15:09:07.504587 - gail/main.py:164 - [TRPO] iter = 1721000 dist_mean = 0.0659 dist_std = 0.1395 vf_loss = 0.1158 grad_norm = 3.5321 nat_grad_norm = 0.0715 cg_residual = 1.3796 step_size = 0.4828 reward = -0.0000 fps = 7 mse_loss = 0.7755 
2022-05-01 15:09:17.167704 - gail/main.py:164 - [TRPO] iter = 1722000 dist_mean = 0.0796 dist_std = 0.1395 vf_loss = 0.1122 grad_norm = 3.6567 nat_grad_norm = 0.0521 cg_residual = 1.2856 step_size = 0.6435 reward = -0.0000 fps = 6 mse_loss = 0.7844 
2022-05-01 15:09:26.661946 - gail/main.py:164 - [TRPO] iter = 1723000 dist_mean = 0.0637 dist_std = 0.1396 vf_loss = 0.1007 grad_norm = 4.9808 nat_grad_norm = 0.0635 cg_residual = 1.3680 step_size = 0.4186 reward = -0.0000 fps = 6 mse_loss = 0.7515 
2022-05-01 15:09:36.313815 - gail/main.py:164 - [TRPO] iter = 1724000 dist_mean = 0.0774 dist_std = 0.1395 vf_loss = 0.0907 grad_norm = 2.9873 nat_grad_norm = 0.0536 cg_residual = 1.5456 step_size = 0.5964 reward = -0.0000 fps = 5 mse_loss = 0.7734 
2022-05-01 15:09:46.204177 - gail/main.py:164 - [TRPO] iter = 1725000 dist_mean = 0.0685 dist_std = 0.1393 vf_loss = 0.0714 grad_norm = 3.4094 nat_grad_norm = 0.0613 cg_residual = 1.1364 step_size = 0.5576 reward = -0.0000 fps = 5 mse_loss = 0.8043 
2022-05-01 15:09:46.424236 - gail/main.py:191 - [Discriminator] iter = 1725000 loss = -0.4685 grad_norm = 2.9476 grad_penalty = 0.0482 regularization = 0.0000 true_logits = -0.6853 fake_logits = -1.2020 true_prob = 0.3611 fake_prob = 0.2635 
2022-05-01 15:11:56.955748 - gail/main.py:132 - [Evaluate] iter = 1725000 episode={ returns = 3543.2338 lengths = 1000 } discounted_episode={ returns = 2184.7244 lengths = 1000 } 
2022-05-01 15:12:06.675586 - gail/main.py:164 - [TRPO] iter = 1726000 dist_mean = 0.0506 dist_std = 0.1394 vf_loss = 0.0649 grad_norm = 3.0481 nat_grad_norm = 0.0503 cg_residual = 0.6819 step_size = 0.6452 reward = 0.0000 fps = 7 mse_loss = 0.7860 
2022-05-01 15:12:16.367557 - gail/main.py:164 - [TRPO] iter = 1727000 dist_mean = 0.0648 dist_std = 0.1390 vf_loss = 0.0592 grad_norm = 4.6832 nat_grad_norm = 0.0867 cg_residual = 1.5919 step_size = 0.4552 reward = 0.0000 fps = 6 mse_loss = 0.7963 
2022-05-01 15:12:25.659047 - gail/main.py:164 - [TRPO] iter = 1728000 dist_mean = 0.0828 dist_std = 0.1391 vf_loss = 0.0670 grad_norm = 3.3468 nat_grad_norm = 0.0542 cg_residual = 1.5953 step_size = 0.5542 reward = 0.0000 fps = 6 mse_loss = 0.7136 
2022-05-01 15:12:34.907217 - gail/main.py:164 - [TRPO] iter = 1729000 dist_mean = 0.0697 dist_std = 0.1395 vf_loss = 0.0553 grad_norm = 3.3132 nat_grad_norm = 0.0753 cg_residual = 1.0559 step_size = 0.5111 reward = 0.0000 fps = 5 mse_loss = 0.7691 
2022-05-01 15:12:44.987855 - gail/main.py:164 - [TRPO] iter = 1730000 dist_mean = 0.0730 dist_std = 0.1395 vf_loss = 0.1008 grad_norm = 3.6748 nat_grad_norm = 0.0451 cg_residual = 0.9971 step_size = 0.6973 reward = -0.0000 fps = 5 mse_loss = 0.7485 
2022-05-01 15:12:45.279304 - gail/main.py:191 - [Discriminator] iter = 1730000 loss = -0.4661 grad_norm = 3.9983 grad_penalty = 0.0558 regularization = 0.0000 true_logits = -0.6417 fake_logits = -1.1636 true_prob = 0.3671 fake_prob = 0.2704 
2022-05-01 15:14:55.573017 - gail/main.py:132 - [Evaluate] iter = 1730000 episode={ returns = 3527.9544 lengths = 1000 } discounted_episode={ returns = 2171.9898 lengths = 1000 } 
2022-05-01 15:15:05.384314 - gail/main.py:164 - [TRPO] iter = 1731000 dist_mean = 0.0704 dist_std = 0.1394 vf_loss = 0.0498 grad_norm = 3.9817 nat_grad_norm = 0.0748 cg_residual = 2.1106 step_size = 0.4662 reward = 0.0000 fps = 7 mse_loss = 0.7164 
2022-05-01 15:15:15.116206 - gail/main.py:164 - [TRPO] iter = 1732000 dist_mean = 0.0700 dist_std = 0.1393 vf_loss = 0.0326 grad_norm = 4.7740 nat_grad_norm = 0.0614 cg_residual = 1.1354 step_size = 0.5099 reward = -0.0000 fps = 6 mse_loss = 0.7500 
2022-05-01 15:15:24.645879 - gail/main.py:164 - [TRPO] iter = 1733000 dist_mean = 0.0602 dist_std = 0.1393 vf_loss = 0.0498 grad_norm = 2.3803 nat_grad_norm = 0.0769 cg_residual = 0.8097 step_size = 0.5438 reward = 0.0000 fps = 6 mse_loss = 0.7073 
2022-05-01 15:15:34.085941 - gail/main.py:164 - [TRPO] iter = 1734000 dist_mean = 0.0557 dist_std = 0.1393 vf_loss = 0.0290 grad_norm = 2.3303 nat_grad_norm = 0.0561 cg_residual = 0.9863 step_size = 0.5688 reward = -0.0000 fps = 5 mse_loss = 0.7612 
2022-05-01 15:15:43.657100 - gail/main.py:164 - [TRPO] iter = 1735000 dist_mean = 0.0604 dist_std = 0.1393 vf_loss = 0.0280 grad_norm = 2.6883 nat_grad_norm = 0.0621 cg_residual = 1.0368 step_size = 0.5540 reward = -0.0000 fps = 5 mse_loss = 0.7040 
2022-05-01 15:15:43.883667 - gail/main.py:191 - [Discriminator] iter = 1735000 loss = -0.4975 grad_norm = 4.2141 grad_penalty = 0.0636 regularization = 0.0000 true_logits = -0.5613 fake_logits = -1.1224 true_prob = 0.3833 fake_prob = 0.2783 
2022-05-01 15:17:52.468878 - gail/main.py:132 - [Evaluate] iter = 1735000 episode={ returns = 3552.6835 lengths = 1000 } discounted_episode={ returns = 2191.0607 lengths = 1000 } 
2022-05-01 15:18:02.434245 - gail/main.py:164 - [TRPO] iter = 1736000 dist_mean = 0.0542 dist_std = 0.1395 vf_loss = 0.0204 grad_norm = 3.0655 nat_grad_norm = 0.0636 cg_residual = 1.0798 step_size = 0.5337 reward = -0.0000 fps = 7 mse_loss = 0.7144 
2022-05-01 15:18:12.311381 - gail/main.py:164 - [TRPO] iter = 1737000 dist_mean = 0.0603 dist_std = 0.1395 vf_loss = 0.0427 grad_norm = 3.1467 nat_grad_norm = 0.0695 cg_residual = 2.2454 step_size = 0.4738 reward = -0.0000 fps = 6 mse_loss = 0.6927 
2022-05-01 15:18:22.071917 - gail/main.py:164 - [TRPO] iter = 1738000 dist_mean = 0.0551 dist_std = 0.1396 vf_loss = 0.0532 grad_norm = 3.9548 nat_grad_norm = 0.0669 cg_residual = 1.0998 step_size = 0.5559 reward = -0.0000 fps = 6 mse_loss = 0.7468 
2022-05-01 15:18:31.745360 - gail/main.py:164 - [TRPO] iter = 1739000 dist_mean = 0.0654 dist_std = 0.1395 vf_loss = 0.0404 grad_norm = 2.7828 nat_grad_norm = 0.0772 cg_residual = 1.6413 step_size = 0.5033 reward = -0.0000 fps = 5 mse_loss = 0.7740 
2022-05-01 15:18:41.304229 - gail/main.py:164 - [TRPO] iter = 1740000 dist_mean = 0.0490 dist_std = 0.1387 vf_loss = 0.0254 grad_norm = 2.9263 nat_grad_norm = 0.0675 cg_residual = 2.8879 step_size = 0.5068 reward = 0.0000 fps = 5 mse_loss = 0.7806 
2022-05-01 15:18:41.519056 - gail/main.py:191 - [Discriminator] iter = 1740000 loss = -0.4012 grad_norm = 3.3676 grad_penalty = 0.0616 regularization = 0.0000 true_logits = -0.6309 fake_logits = -1.0938 true_prob = 0.3677 fake_prob = 0.2831 
2022-05-01 15:20:49.663453 - gail/main.py:132 - [Evaluate] iter = 1740000 episode={ returns = 3566.6808 lengths = 1000 } discounted_episode={ returns = 2195.6284 lengths = 1000 } 
2022-05-01 15:20:58.899047 - gail/main.py:164 - [TRPO] iter = 1741000 dist_mean = 0.0416 dist_std = 0.1388 vf_loss = 0.0267 grad_norm = 3.1184 nat_grad_norm = 0.0598 cg_residual = 0.8426 step_size = 0.5158 reward = -0.0000 fps = 7 mse_loss = 0.6794 
2022-05-01 15:21:08.325765 - gail/main.py:164 - [TRPO] iter = 1742000 dist_mean = 0.0460 dist_std = 0.1388 vf_loss = 0.0332 grad_norm = 2.7558 nat_grad_norm = 0.0735 cg_residual = 1.3857 step_size = 0.4615 reward = -0.0000 fps = 6 mse_loss = 0.7191 
2022-05-01 15:21:18.063059 - gail/main.py:164 - [TRPO] iter = 1743000 dist_mean = 0.0407 dist_std = 0.1386 vf_loss = 0.0205 grad_norm = 4.5567 nat_grad_norm = 0.0697 cg_residual = 1.7551 step_size = 0.4771 reward = 0.0000 fps = 6 mse_loss = 0.7574 
2022-05-01 15:21:27.436265 - gail/main.py:164 - [TRPO] iter = 1744000 dist_mean = 0.0186 dist_std = 0.1386 vf_loss = 0.0428 grad_norm = 2.7845 nat_grad_norm = 0.0990 cg_residual = 2.0719 step_size = 0.4120 reward = 0.0000 fps = 6 mse_loss = 0.7017 
2022-05-01 15:21:37.062646 - gail/main.py:164 - [TRPO] iter = 1745000 dist_mean = 0.0361 dist_std = 0.1385 vf_loss = 0.0546 grad_norm = 3.8716 nat_grad_norm = 0.0773 cg_residual = 2.6047 step_size = 0.4688 reward = -0.0000 fps = 5 mse_loss = 0.7735 
2022-05-01 15:21:37.283704 - gail/main.py:191 - [Discriminator] iter = 1745000 loss = -0.4093 grad_norm = 4.8292 grad_penalty = 0.0618 regularization = 0.0000 true_logits = -0.5082 fake_logits = -0.9794 true_prob = 0.3891 fake_prob = 0.3011 
2022-05-01 15:23:52.699739 - gail/main.py:132 - [Evaluate] iter = 1745000 episode={ returns = 3564.9248 lengths = 1000 } discounted_episode={ returns = 2190.7325 lengths = 1000 } 
2022-05-01 15:24:02.337913 - gail/main.py:164 - [TRPO] iter = 1746000 dist_mean = 0.0097 dist_std = 0.1387 vf_loss = 0.0256 grad_norm = 3.4680 nat_grad_norm = 0.0741 cg_residual = 1.6567 step_size = 0.4637 reward = -0.0000 fps = 6 mse_loss = 0.6986 
2022-05-01 15:24:11.980186 - gail/main.py:164 - [TRPO] iter = 1747000 dist_mean = 0.0536 dist_std = 0.1386 vf_loss = 0.0291 grad_norm = 3.3867 nat_grad_norm = 0.0763 cg_residual = 2.4865 step_size = 0.4537 reward = 0.0000 fps = 6 mse_loss = 0.7151 
2022-05-01 15:24:21.642848 - gail/main.py:164 - [TRPO] iter = 1748000 dist_mean = 0.0518 dist_std = 0.1389 vf_loss = 0.0335 grad_norm = 3.0330 nat_grad_norm = 0.0777 cg_residual = 1.5282 step_size = 0.4968 reward = 0.0000 fps = 6 mse_loss = 0.6978 
2022-05-01 15:24:31.385226 - gail/main.py:164 - [TRPO] iter = 1749000 dist_mean = 0.0433 dist_std = 0.1392 vf_loss = 0.0255 grad_norm = 3.6243 nat_grad_norm = 0.0795 cg_residual = 1.7458 step_size = 0.4382 reward = 0.0000 fps = 5 mse_loss = 0.7026 
2022-05-01 15:24:41.116103 - gail/main.py:164 - [TRPO] iter = 1750000 dist_mean = 0.0318 dist_std = 0.1393 vf_loss = 0.0172 grad_norm = 2.8747 nat_grad_norm = 0.0672 cg_residual = 1.2282 step_size = 0.4660 reward = 0.0000 fps = 5 mse_loss = 0.7275 
2022-05-01 15:24:41.283755 - gail/main.py:191 - [Discriminator] iter = 1750000 loss = -0.4558 grad_norm = 5.5686 grad_penalty = 0.0693 regularization = 0.0000 true_logits = -0.3974 fake_logits = -0.9225 true_prob = 0.4112 fake_prob = 0.3089 
2022-05-01 15:26:55.215443 - gail/main.py:132 - [Evaluate] iter = 1750000 episode={ returns = 3553.7730 lengths = 1000 } discounted_episode={ returns = 2191.0314 lengths = 1000 } 
2022-05-01 15:27:04.848744 - gail/main.py:164 - [TRPO] iter = 1751000 dist_mean = 0.0253 dist_std = 0.1395 vf_loss = 0.0171 grad_norm = 3.7978 nat_grad_norm = 0.0667 cg_residual = 0.9328 step_size = 0.5196 reward = -0.0000 fps = 6 mse_loss = 0.6701 
2022-05-01 15:27:14.583907 - gail/main.py:164 - [TRPO] iter = 1752000 dist_mean = 0.0068 dist_std = 0.1395 vf_loss = 0.0149 grad_norm = 2.8492 nat_grad_norm = 0.0769 cg_residual = 2.0512 step_size = 0.4831 reward = -0.0000 fps = 6 mse_loss = 0.6533 
2022-05-01 15:27:24.285233 - gail/main.py:164 - [TRPO] iter = 1753000 dist_mean = 0.0489 dist_std = 0.1398 vf_loss = 0.0232 grad_norm = 6.1985 nat_grad_norm = 0.0817 cg_residual = 3.7223 step_size = 0.3728 reward = 0.0000 fps = 6 mse_loss = 0.6518 
2022-05-01 15:27:34.252027 - gail/main.py:164 - [TRPO] iter = 1754000 dist_mean = 0.0230 dist_std = 0.1398 vf_loss = 0.0164 grad_norm = 4.1462 nat_grad_norm = 0.0943 cg_residual = 1.7708 step_size = 0.3859 reward = -0.0000 fps = 5 mse_loss = 0.6932 
2022-05-01 15:27:43.782072 - gail/main.py:164 - [TRPO] iter = 1755000 dist_mean = 0.0300 dist_std = 0.1398 vf_loss = 0.0180 grad_norm = 4.0084 nat_grad_norm = 0.1563 cg_residual = 4.3275 step_size = 0.2550 reward = 0.0000 fps = 5 mse_loss = 0.6530 
2022-05-01 15:27:44.018434 - gail/main.py:191 - [Discriminator] iter = 1755000 loss = -0.4000 grad_norm = 4.3228 grad_penalty = 0.0713 regularization = 0.0000 true_logits = -0.4526 fake_logits = -0.9240 true_prob = 0.3977 fake_prob = 0.3110 
2022-05-01 15:29:53.665737 - gail/main.py:132 - [Evaluate] iter = 1755000 episode={ returns = 3494.2307 lengths = 1000 } discounted_episode={ returns = 2149.9017 lengths = 1000 } 
2022-05-01 15:30:03.535288 - gail/main.py:164 - [TRPO] iter = 1756000 dist_mean = 0.0028 dist_std = 0.1399 vf_loss = 0.0263 grad_norm = 3.1087 nat_grad_norm = 0.0834 cg_residual = 2.1384 step_size = 0.4520 reward = -0.0000 fps = 7 mse_loss = 0.6308 
2022-05-01 15:30:13.529692 - gail/main.py:164 - [TRPO] iter = 1757000 dist_mean = 0.0391 dist_std = 0.1400 vf_loss = 0.0396 grad_norm = 3.0353 nat_grad_norm = 0.0806 cg_residual = 2.4197 step_size = 0.4588 reward = -0.0000 fps = 6 mse_loss = 0.6663 
2022-05-01 15:30:22.962850 - gail/main.py:164 - [TRPO] iter = 1758000 dist_mean = 0.0203 dist_std = 0.1398 vf_loss = 0.0205 grad_norm = 3.9673 nat_grad_norm = 0.0841 cg_residual = 2.3528 step_size = 0.4368 reward = -0.0000 fps = 6 mse_loss = 0.6574 
2022-05-01 15:30:32.723510 - gail/main.py:164 - [TRPO] iter = 1759000 dist_mean = 0.0168 dist_std = 0.1395 vf_loss = 0.0301 grad_norm = 3.5216 nat_grad_norm = 0.0934 cg_residual = 1.8625 step_size = 0.4295 reward = 0.0000 fps = 5 mse_loss = 0.7207 
2022-05-01 15:30:42.833250 - gail/main.py:164 - [TRPO] iter = 1760000 dist_mean = 0.0015 dist_std = 0.1397 vf_loss = 0.0303 grad_norm = 2.3951 nat_grad_norm = 0.0869 cg_residual = 1.9647 step_size = 0.4638 reward = -0.0000 fps = 5 mse_loss = 0.6784 
2022-05-01 15:30:43.051366 - gail/main.py:191 - [Discriminator] iter = 1760000 loss = -0.4139 grad_norm = 3.4844 grad_penalty = 0.0684 regularization = 0.0000 true_logits = -0.6003 fake_logits = -1.0826 true_prob = 0.3707 fake_prob = 0.2805 
2022-05-01 15:32:54.084615 - gail/main.py:132 - [Evaluate] iter = 1760000 episode={ returns = 3455.6966 lengths = 1000 } discounted_episode={ returns = 2106.6576 lengths = 1000 } 
2022-05-01 15:33:04.074333 - gail/main.py:164 - [TRPO] iter = 1761000 dist_mean = 0.0243 dist_std = 0.1397 vf_loss = 0.0162 grad_norm = 3.2629 nat_grad_norm = 0.0904 cg_residual = 1.4513 step_size = 0.4584 reward = 0.0000 fps = 7 mse_loss = 0.6155 
2022-05-01 15:33:14.037486 - gail/main.py:164 - [TRPO] iter = 1762000 dist_mean = 0.0043 dist_std = 0.1396 vf_loss = 0.0530 grad_norm = 3.6675 nat_grad_norm = 0.0829 cg_residual = 1.5898 step_size = 0.4617 reward = 0.0000 fps = 6 mse_loss = 0.6689 
2022-05-01 15:33:24.360673 - gail/main.py:164 - [TRPO] iter = 1763000 dist_mean = 0.0375 dist_std = 0.1394 vf_loss = 0.0329 grad_norm = 3.5525 nat_grad_norm = 0.0812 cg_residual = 2.4303 step_size = 0.4373 reward = 0.0000 fps = 6 mse_loss = 0.7106 
2022-05-01 15:33:34.173252 - gail/main.py:164 - [TRPO] iter = 1764000 dist_mean = 0.0360 dist_std = 0.1395 vf_loss = 0.0407 grad_norm = 4.7632 nat_grad_norm = 0.0998 cg_residual = 3.5978 step_size = 0.3517 reward = -0.0000 fps = 5 mse_loss = 0.6393 
2022-05-01 15:33:44.163187 - gail/main.py:164 - [TRPO] iter = 1765000 dist_mean = 0.0131 dist_std = 0.1396 vf_loss = 0.0141 grad_norm = 4.0549 nat_grad_norm = 0.0860 cg_residual = 1.4164 step_size = 0.4219 reward = -0.0000 fps = 5 mse_loss = 0.6863 
2022-05-01 15:33:44.373242 - gail/main.py:191 - [Discriminator] iter = 1765000 loss = -0.4932 grad_norm = 3.4776 grad_penalty = 0.0579 regularization = 0.0000 true_logits = -0.6938 fake_logits = -1.2448 true_prob = 0.3548 fake_prob = 0.2543 
2022-05-01 15:35:54.744555 - gail/main.py:132 - [Evaluate] iter = 1765000 episode={ returns = 3480.7600 lengths = 1000 } discounted_episode={ returns = 2142.4677 lengths = 1000 } 
2022-05-01 15:36:04.448186 - gail/main.py:164 - [TRPO] iter = 1766000 dist_mean = 0.0067 dist_std = 0.1397 vf_loss = 0.0187 grad_norm = 2.4501 nat_grad_norm = 0.0832 cg_residual = 1.1121 step_size = 0.5188 reward = -0.0000 fps = 7 mse_loss = 0.6615 
2022-05-01 15:36:14.044361 - gail/main.py:164 - [TRPO] iter = 1767000 dist_mean = 0.0246 dist_std = 0.1398 vf_loss = 0.0210 grad_norm = 3.8119 nat_grad_norm = 0.0680 cg_residual = 1.3817 step_size = 0.4919 reward = -0.0000 fps = 6 mse_loss = 0.6575 
2022-05-01 15:36:23.681330 - gail/main.py:164 - [TRPO] iter = 1768000 dist_mean = 0.0203 dist_std = 0.1398 vf_loss = 0.0445 grad_norm = 2.9614 nat_grad_norm = 0.0613 cg_residual = 0.9784 step_size = 0.5376 reward = -0.0000 fps = 6 mse_loss = 0.6663 
2022-05-01 15:36:33.208899 - gail/main.py:164 - [TRPO] iter = 1769000 dist_mean = 0.0512 dist_std = 0.1399 vf_loss = 0.1211 grad_norm = 3.9603 nat_grad_norm = 0.0625 cg_residual = 1.4805 step_size = 0.4704 reward = -0.0000 fps = 5 mse_loss = 0.6571 
2022-05-01 15:36:43.206113 - gail/main.py:164 - [TRPO] iter = 1770000 dist_mean = 0.0210 dist_std = 0.1398 vf_loss = 0.0228 grad_norm = 4.4952 nat_grad_norm = 0.1004 cg_residual = 2.9068 step_size = 0.3882 reward = -0.0000 fps = 5 mse_loss = 0.6916 
2022-05-01 15:36:43.421629 - gail/main.py:191 - [Discriminator] iter = 1770000 loss = -0.4340 grad_norm = 3.9844 grad_penalty = 0.0507 regularization = 0.0000 true_logits = -0.8038 fake_logits = -1.2886 true_prob = 0.3351 fake_prob = 0.2475 
2022-05-01 15:38:53.695468 - gail/main.py:132 - [Evaluate] iter = 1770000 episode={ returns = 3566.5828 lengths = 1000 } discounted_episode={ returns = 2192.4286 lengths = 1000 } 
2022-05-01 15:39:03.311937 - gail/main.py:164 - [TRPO] iter = 1771000 dist_mean = -0.0112 dist_std = 0.1395 vf_loss = 0.0276 grad_norm = 4.5718 nat_grad_norm = 0.0694 cg_residual = 1.4969 step_size = 0.4664 reward = 0.0000 fps = 7 mse_loss = 0.6528 
2022-05-01 15:39:13.238697 - gail/main.py:164 - [TRPO] iter = 1772000 dist_mean = 0.0340 dist_std = 0.1396 vf_loss = 0.1577 grad_norm = 2.8065 nat_grad_norm = 0.0735 cg_residual = 1.3293 step_size = 0.4643 reward = -0.0000 fps = 6 mse_loss = 0.6841 
2022-05-01 15:39:22.495129 - gail/main.py:164 - [TRPO] iter = 1773000 dist_mean = -0.0061 dist_std = 0.1397 vf_loss = 0.0736 grad_norm = 3.2787 nat_grad_norm = 0.0606 cg_residual = 1.0452 step_size = 0.5362 reward = -0.0000 fps = 6 mse_loss = 0.6318 
2022-05-01 15:39:32.222796 - gail/main.py:164 - [TRPO] iter = 1774000 dist_mean = -0.0020 dist_std = 0.1397 vf_loss = 0.1800 grad_norm = 3.8365 nat_grad_norm = 0.0708 cg_residual = 1.3417 step_size = 0.4326 reward = -0.0000 fps = 5 mse_loss = 0.6308 
2022-05-01 15:39:42.065505 - gail/main.py:164 - [TRPO] iter = 1775000 dist_mean = 0.0619 dist_std = 0.1398 vf_loss = 0.1389 grad_norm = 4.8967 nat_grad_norm = 0.0672 cg_residual = 1.4289 step_size = 0.4279 reward = -0.0000 fps = 5 mse_loss = 0.6998 
2022-05-01 15:39:42.238562 - gail/main.py:191 - [Discriminator] iter = 1775000 loss = -0.7494 grad_norm = 3.6779 grad_penalty = 0.0940 regularization = 0.0000 true_logits = -0.7374 fake_logits = -1.5807 true_prob = 0.3475 fake_prob = 0.2132 
2022-05-01 15:39:57.829957 - gail/main.py:132 - [Evaluate] iter = 1775000 episode={ returns = 293.0895 lengths = 119 } discounted_episode={ returns = 274.1313 lengths = 119 } 
2022-05-01 15:40:07.573061 - gail/main.py:164 - [TRPO] iter = 1776000 dist_mean = 0.0972 dist_std = 0.1396 vf_loss = 0.0258 grad_norm = 3.1643 nat_grad_norm = 0.1022 cg_residual = 1.7938 step_size = 0.4437 reward = -0.0000 fps = 39 mse_loss = 0.6188 
2022-05-01 15:40:17.505828 - gail/main.py:164 - [TRPO] iter = 1777000 dist_mean = -0.0098 dist_std = 0.1402 vf_loss = 0.0392 grad_norm = 2.7923 nat_grad_norm = 0.0795 cg_residual = 2.0585 step_size = 0.4777 reward = -0.0000 fps = 28 mse_loss = 0.6830 
2022-05-01 15:40:26.921430 - gail/main.py:164 - [TRPO] iter = 1778000 dist_mean = 0.0025 dist_std = 0.1404 vf_loss = 0.1198 grad_norm = 4.0649 nat_grad_norm = 0.1136 cg_residual = 1.9109 step_size = 0.3681 reward = -0.0000 fps = 22 mse_loss = 0.6729 
2022-05-01 15:40:36.938728 - gail/main.py:164 - [TRPO] iter = 1779000 dist_mean = 0.0381 dist_std = 0.1403 vf_loss = 0.2242 grad_norm = 4.3124 nat_grad_norm = 0.0722 cg_residual = 1.4085 step_size = 0.5081 reward = -0.0000 fps = 18 mse_loss = 0.6353 
2022-05-01 15:40:46.968175 - gail/main.py:164 - [TRPO] iter = 1780000 dist_mean = 0.0842 dist_std = 0.1399 vf_loss = 0.0747 grad_norm = 3.5811 nat_grad_norm = 0.1150 cg_residual = 2.3956 step_size = 0.3617 reward = -0.0000 fps = 15 mse_loss = 0.6529 
2022-05-01 15:40:47.191920 - gail/main.py:191 - [Discriminator] iter = 1780000 loss = -1.1838 grad_norm = 4.3871 grad_penalty = 0.2120 regularization = 0.0000 true_logits = -0.5171 fake_logits = -1.9129 true_prob = 0.3898 fake_prob = 0.1837 
2022-05-01 15:40:58.197936 - gail/main.py:132 - [Evaluate] iter = 1780000 episode={ returns = 165.2230 lengths = 79 } discounted_episode={ returns = 158.1081 lengths = 79 } 
2022-05-01 15:41:07.959993 - gail/main.py:164 - [TRPO] iter = 1781000 dist_mean = 0.0443 dist_std = 0.1400 vf_loss = 0.0584 grad_norm = 4.3826 nat_grad_norm = 0.0759 cg_residual = 1.6975 step_size = 0.4092 reward = -0.0000 fps = 48 mse_loss = 0.6342 
2022-05-01 15:41:17.721832 - gail/main.py:164 - [TRPO] iter = 1782000 dist_mean = 0.0852 dist_std = 0.1404 vf_loss = 0.4362 grad_norm = 2.6289 nat_grad_norm = 0.0931 cg_residual = 3.9924 step_size = 0.4084 reward = 0.0000 fps = 32 mse_loss = 0.6506 
2022-05-01 15:41:27.516904 - gail/main.py:164 - [TRPO] iter = 1783000 dist_mean = 0.0971 dist_std = 0.1404 vf_loss = 0.0715 grad_norm = 3.3511 nat_grad_norm = 0.0622 cg_residual = 2.1389 step_size = 0.6051 reward = -0.0000 fps = 24 mse_loss = 0.5942 
2022-05-01 15:41:37.405952 - gail/main.py:164 - [TRPO] iter = 1784000 dist_mean = 0.0301 dist_std = 0.1403 vf_loss = 0.0975 grad_norm = 3.2564 nat_grad_norm = 0.1072 cg_residual = 2.2270 step_size = 0.4052 reward = -0.0000 fps = 19 mse_loss = 0.6715 
2022-05-01 15:41:47.175243 - gail/main.py:164 - [TRPO] iter = 1785000 dist_mean = 0.0358 dist_std = 0.1406 vf_loss = 0.1676 grad_norm = 4.3138 nat_grad_norm = 0.1098 cg_residual = 2.8749 step_size = 0.3339 reward = -0.0000 fps = 16 mse_loss = 0.6315 
2022-05-01 15:41:47.392322 - gail/main.py:191 - [Discriminator] iter = 1785000 loss = -0.6624 grad_norm = 3.4112 grad_penalty = 0.0880 regularization = 0.0000 true_logits = -0.0892 fake_logits = -0.8396 true_prob = 0.4841 fake_prob = 0.3433 
2022-05-01 15:41:58.120042 - gail/main.py:132 - [Evaluate] iter = 1785000 episode={ returns = 168.7716 lengths = 81 } discounted_episode={ returns = 160.9964 lengths = 81 } 
2022-05-01 15:42:07.946485 - gail/main.py:164 - [TRPO] iter = 1786000 dist_mean = 0.0448 dist_std = 0.1406 vf_loss = 0.7343 grad_norm = 3.1090 nat_grad_norm = 0.0809 cg_residual = 1.3299 step_size = 0.4197 reward = -0.0000 fps = 48 mse_loss = 0.6379 
2022-05-01 15:42:17.847195 - gail/main.py:164 - [TRPO] iter = 1787000 dist_mean = 0.0368 dist_std = 0.1404 vf_loss = 0.0847 grad_norm = 5.6505 nat_grad_norm = 0.1067 cg_residual = 2.3370 step_size = 0.3151 reward = 0.0000 fps = 32 mse_loss = 0.6621 
2022-05-01 15:42:27.483925 - gail/main.py:164 - [TRPO] iter = 1788000 dist_mean = 0.0262 dist_std = 0.1404 vf_loss = 0.9446 grad_norm = 2.5489 nat_grad_norm = 0.0585 cg_residual = 0.9591 step_size = 0.6112 reward = 0.0000 fps = 24 mse_loss = 0.6852 
2022-05-01 15:42:36.882415 - gail/main.py:164 - [TRPO] iter = 1789000 dist_mean = 0.0211 dist_std = 0.1408 vf_loss = 0.3031 grad_norm = 3.0193 nat_grad_norm = 0.0696 cg_residual = 1.1744 step_size = 0.5628 reward = 0.0000 fps = 20 mse_loss = 0.6244 
2022-05-01 15:42:46.567712 - gail/main.py:164 - [TRPO] iter = 1790000 dist_mean = 0.0461 dist_std = 0.1404 vf_loss = 0.6636 grad_norm = 4.5359 nat_grad_norm = 0.0628 cg_residual = 1.2959 step_size = 0.4515 reward = -0.0000 fps = 16 mse_loss = 0.5825 
2022-05-01 15:42:46.789448 - gail/main.py:191 - [Discriminator] iter = 1790000 loss = -0.4918 grad_norm = 2.8828 grad_penalty = 0.0681 regularization = 0.0000 true_logits = -0.0067 fake_logits = -0.5666 true_prob = 0.5002 fake_prob = 0.3898 
2022-05-01 15:44:24.813772 - gail/main.py:132 - [Evaluate] iter = 1790000 episode={ returns = 2862.4479 lengths = 817 } discounted_episode={ returns = 1577.6186 lengths = 725 } 
2022-05-01 15:44:34.162882 - gail/main.py:164 - [TRPO] iter = 1791000 dist_mean = 0.0138 dist_std = 0.1406 vf_loss = 0.3326 grad_norm = 3.4258 nat_grad_norm = 0.0835 cg_residual = 2.1556 step_size = 0.4157 reward = 0.0000 fps = 9 mse_loss = 0.5816 
2022-05-01 15:44:43.842580 - gail/main.py:164 - [TRPO] iter = 1792000 dist_mean = 0.0262 dist_std = 0.1406 vf_loss = 0.2841 grad_norm = 5.1435 nat_grad_norm = 0.1031 cg_residual = 3.8714 step_size = 0.3537 reward = -0.0000 fps = 8 mse_loss = 0.6018 
2022-05-01 15:44:53.314768 - gail/main.py:164 - [TRPO] iter = 1793000 dist_mean = 0.0386 dist_std = 0.1405 vf_loss = 0.1631 grad_norm = 4.4224 nat_grad_norm = 0.0562 cg_residual = 1.5927 step_size = 0.5264 reward = 0.0000 fps = 7 mse_loss = 0.6204 
2022-05-01 15:45:02.891781 - gail/main.py:164 - [TRPO] iter = 1794000 dist_mean = 0.0532 dist_std = 0.1405 vf_loss = 0.4091 grad_norm = 4.4701 nat_grad_norm = 0.0656 cg_residual = 1.4558 step_size = 0.4832 reward = -0.0000 fps = 7 mse_loss = 0.6109 
2022-05-01 15:45:12.931967 - gail/main.py:164 - [TRPO] iter = 1795000 dist_mean = 0.0334 dist_std = 0.1405 vf_loss = 0.1267 grad_norm = 4.6353 nat_grad_norm = 0.0873 cg_residual = 2.9236 step_size = 0.4009 reward = 0.0000 fps = 6 mse_loss = 0.6704 
2022-05-01 15:45:13.230003 - gail/main.py:191 - [Discriminator] iter = 1795000 loss = -0.5104 grad_norm = 3.9461 grad_penalty = 0.0502 regularization = 0.0000 true_logits = -0.0456 fake_logits = -0.6062 true_prob = 0.4915 fake_prob = 0.3792 
2022-05-01 15:47:22.124258 - gail/main.py:132 - [Evaluate] iter = 1795000 episode={ returns = 3548.3662 lengths = 1000 } discounted_episode={ returns = 2183.8230 lengths = 1000 } 
2022-05-01 15:47:32.023522 - gail/main.py:164 - [TRPO] iter = 1796000 dist_mean = 0.0229 dist_std = 0.1404 vf_loss = 0.0676 grad_norm = 3.7869 nat_grad_norm = 0.1234 cg_residual = 2.4525 step_size = 0.3203 reward = 0.0000 fps = 7 mse_loss = 0.6477 
2022-05-01 15:47:41.580446 - gail/main.py:164 - [TRPO] iter = 1797000 dist_mean = 0.0410 dist_std = 0.1406 vf_loss = 0.1658 grad_norm = 3.3071 nat_grad_norm = 0.0837 cg_residual = 1.5846 step_size = 0.4589 reward = 0.0000 fps = 6 mse_loss = 0.6026 
2022-05-01 15:47:50.868107 - gail/main.py:164 - [TRPO] iter = 1798000 dist_mean = 0.0484 dist_std = 0.1408 vf_loss = 0.1429 grad_norm = 4.2392 nat_grad_norm = 0.0985 cg_residual = 4.0339 step_size = 0.4034 reward = -0.0000 fps = 6 mse_loss = 0.5905 
2022-05-01 15:48:00.180322 - gail/main.py:164 - [TRPO] iter = 1799000 dist_mean = 0.0578 dist_std = 0.1406 vf_loss = 0.1761 grad_norm = 4.1934 nat_grad_norm = 0.0898 cg_residual = 3.0313 step_size = 0.4080 reward = 0.0000 fps = 5 mse_loss = 0.5797 
2022-05-01 15:48:09.797828 - gail/main.py:164 - [TRPO] iter = 1800000 dist_mean = 0.0471 dist_std = 0.1407 vf_loss = 0.2114 grad_norm = 2.7903 nat_grad_norm = 0.0860 cg_residual = 1.6168 step_size = 0.4848 reward = 0.0000 fps = 5 mse_loss = 0.5988 
2022-05-01 15:48:10.079880 - gail/main.py:191 - [Discriminator] iter = 1800000 loss = -0.4457 grad_norm = 4.8504 grad_penalty = 0.0569 regularization = 0.0000 true_logits = -0.0652 fake_logits = -0.5679 true_prob = 0.4871 fake_prob = 0.3842 
2022-05-01 15:49:59.652664 - gail/main.py:132 - [Evaluate] iter = 1800000 episode={ returns = 3192.8279 lengths = 904 } discounted_episode={ returns = 1755.0738 lengths = 807 } 
2022-05-01 15:50:09.107654 - gail/main.py:164 - [TRPO] iter = 1801000 dist_mean = 0.0620 dist_std = 0.1408 vf_loss = 0.2973 grad_norm = 3.0562 nat_grad_norm = 0.0577 cg_residual = 1.0504 step_size = 0.5754 reward = 0.0000 fps = 8 mse_loss = 0.6027 
2022-05-01 15:50:18.221669 - gail/main.py:164 - [TRPO] iter = 1802000 dist_mean = 0.0631 dist_std = 0.1406 vf_loss = 0.2900 grad_norm = 3.3982 nat_grad_norm = 0.1032 cg_residual = 2.2184 step_size = 0.4473 reward = -0.0000 fps = 7 mse_loss = 0.6033 
2022-05-01 15:50:27.758775 - gail/main.py:164 - [TRPO] iter = 1803000 dist_mean = 0.0385 dist_std = 0.1405 vf_loss = 0.4365 grad_norm = 2.7633 nat_grad_norm = 0.0739 cg_residual = 1.6445 step_size = 0.5504 reward = 0.0000 fps = 7 mse_loss = 0.5608 
2022-05-01 15:50:37.441552 - gail/main.py:164 - [TRPO] iter = 1804000 dist_mean = 0.0999 dist_std = 0.1404 vf_loss = 0.4007 grad_norm = 3.1533 nat_grad_norm = 0.0925 cg_residual = 1.6324 step_size = 0.3914 reward = -0.0000 fps = 6 mse_loss = 0.5974 
2022-05-01 15:50:46.962312 - gail/main.py:164 - [TRPO] iter = 1805000 dist_mean = 0.0976 dist_std = 0.1406 vf_loss = 0.6293 grad_norm = 2.9471 nat_grad_norm = 0.0959 cg_residual = 2.0627 step_size = 0.4061 reward = 0.0000 fps = 6 mse_loss = 0.6439 
2022-05-01 15:50:47.205185 - gail/main.py:191 - [Discriminator] iter = 1805000 loss = -0.7293 grad_norm = 2.8059 grad_penalty = 0.0602 regularization = 0.0000 true_logits = -0.1740 fake_logits = -0.9634 true_prob = 0.4651 fake_prob = 0.3277 
2022-05-01 15:50:52.197779 - gail/main.py:132 - [Evaluate] iter = 1805000 episode={ returns = 64.1719 lengths = 39 } discounted_episode={ returns = 62.8576 lengths = 39 } 
2022-05-01 15:51:01.750615 - gail/main.py:164 - [TRPO] iter = 1806000 dist_mean = 0.1218 dist_std = 0.1406 vf_loss = 0.2010 grad_norm = 3.1105 nat_grad_norm = 0.0991 cg_residual = 3.2783 step_size = 0.3990 reward = 0.0000 fps = 68 mse_loss = 0.5757 
2022-05-01 15:51:11.345103 - gail/main.py:164 - [TRPO] iter = 1807000 dist_mean = 0.0664 dist_std = 0.1405 vf_loss = 0.6757 grad_norm = 3.7369 nat_grad_norm = 0.1055 cg_residual = 3.0120 step_size = 0.3955 reward = 0.0000 fps = 41 mse_loss = 0.5872 
2022-05-01 15:51:21.059691 - gail/main.py:164 - [TRPO] iter = 1808000 dist_mean = 0.0602 dist_std = 0.1404 vf_loss = 0.5104 grad_norm = 3.1748 nat_grad_norm = 0.0767 cg_residual = 1.8509 step_size = 0.4892 reward = -0.0000 fps = 29 mse_loss = 0.5827 
2022-05-01 15:51:30.769422 - gail/main.py:164 - [TRPO] iter = 1809000 dist_mean = 0.0587 dist_std = 0.1404 vf_loss = 0.0514 grad_norm = 3.4409 nat_grad_norm = 0.0889 cg_residual = 2.8788 step_size = 0.4539 reward = 0.0000 fps = 22 mse_loss = 0.5519 
2022-05-01 15:51:40.475070 - gail/main.py:164 - [TRPO] iter = 1810000 dist_mean = 0.1823 dist_std = 0.1402 vf_loss = 0.6060 grad_norm = 4.1165 nat_grad_norm = 0.0833 cg_residual = 6.2415 step_size = 0.4109 reward = 0.0000 fps = 18 mse_loss = 0.6041 
2022-05-01 15:51:40.682422 - gail/main.py:191 - [Discriminator] iter = 1810000 loss = -2.8135 grad_norm = 4.3301 grad_penalty = 0.2792 regularization = 0.0000 true_logits = -0.1511 fake_logits = -3.2437 true_prob = 0.4734 fake_prob = 0.0676 
2022-05-01 15:51:45.993923 - gail/main.py:132 - [Evaluate] iter = 1810000 episode={ returns = 64.2530 lengths = 39 } discounted_episode={ returns = 63.8360 lengths = 39 } 
2022-05-01 15:51:55.239028 - gail/main.py:164 - [TRPO] iter = 1811000 dist_mean = 0.0737 dist_std = 0.1403 vf_loss = 0.1083 grad_norm = 3.9134 nat_grad_norm = 0.0798 cg_residual = 1.8353 step_size = 0.4379 reward = -0.0000 fps = 68 mse_loss = 0.6013 
2022-05-01 15:52:04.861592 - gail/main.py:164 - [TRPO] iter = 1812000 dist_mean = 0.0775 dist_std = 0.1408 vf_loss = 0.7341 grad_norm = 4.0830 nat_grad_norm = 0.0725 cg_residual = 1.6706 step_size = 0.4109 reward = -0.0000 fps = 41 mse_loss = 0.5877 
2022-05-01 15:52:14.682047 - gail/main.py:164 - [TRPO] iter = 1813000 dist_mean = 0.0649 dist_std = 0.1406 vf_loss = 0.6016 grad_norm = 2.7760 nat_grad_norm = 0.0777 cg_residual = 1.1336 step_size = 0.4903 reward = 0.0000 fps = 29 mse_loss = 0.6008 
2022-05-01 15:52:24.171824 - gail/main.py:164 - [TRPO] iter = 1814000 dist_mean = 0.0654 dist_std = 0.1404 vf_loss = 0.5485 grad_norm = 2.4316 nat_grad_norm = 0.0695 cg_residual = 1.4792 step_size = 0.5739 reward = 0.0000 fps = 23 mse_loss = 0.5674 
2022-05-01 15:52:33.674397 - gail/main.py:164 - [TRPO] iter = 1815000 dist_mean = 0.0498 dist_std = 0.1405 vf_loss = 0.5117 grad_norm = 3.8895 nat_grad_norm = 0.0977 cg_residual = 3.8246 step_size = 0.3464 reward = -0.0000 fps = 18 mse_loss = 0.5911 
2022-05-01 15:52:33.874835 - gail/main.py:191 - [Discriminator] iter = 1815000 loss = -0.4415 grad_norm = 3.5271 grad_penalty = 0.1028 regularization = 0.0000 true_logits = -0.0526 fake_logits = -0.5969 true_prob = 0.4848 fake_prob = 0.3957 
2022-05-01 15:52:39.194879 - gail/main.py:132 - [Evaluate] iter = 1815000 episode={ returns = 67.7793 lengths = 41 } discounted_episode={ returns = 66.7772 lengths = 41 } 
2022-05-01 15:52:49.055131 - gail/main.py:164 - [TRPO] iter = 1816000 dist_mean = 0.0858 dist_std = 0.1403 vf_loss = 0.8144 grad_norm = 5.2613 nat_grad_norm = 0.0811 cg_residual = 2.7904 step_size = 0.3695 reward = 0.0000 fps = 65 mse_loss = 0.5876 
2022-05-01 15:52:58.361560 - gail/main.py:164 - [TRPO] iter = 1817000 dist_mean = 0.0451 dist_std = 0.1402 vf_loss = 0.4067 grad_norm = 3.3355 nat_grad_norm = 0.0856 cg_residual = 3.2409 step_size = 0.3996 reward = 0.0000 fps = 40 mse_loss = 0.5996 
2022-05-01 15:53:08.162069 - gail/main.py:164 - [TRPO] iter = 1818000 dist_mean = 0.1101 dist_std = 0.1400 vf_loss = 0.8035 grad_norm = 3.1429 nat_grad_norm = 0.0837 cg_residual = 2.4732 step_size = 0.4482 reward = -0.0000 fps = 29 mse_loss = 0.5715 
2022-05-01 15:53:17.549234 - gail/main.py:164 - [TRPO] iter = 1819000 dist_mean = 0.0423 dist_std = 0.1396 vf_loss = 0.4959 grad_norm = 6.0657 nat_grad_norm = 0.0751 cg_residual = 1.6602 step_size = 0.4148 reward = -0.0000 fps = 22 mse_loss = 0.6295 
2022-05-01 15:53:26.870538 - gail/main.py:164 - [TRPO] iter = 1820000 dist_mean = 0.0452 dist_std = 0.1396 vf_loss = 0.1356 grad_norm = 2.5648 nat_grad_norm = 0.1039 cg_residual = 4.0959 step_size = 0.3948 reward = 0.0000 fps = 18 mse_loss = 0.6601 
2022-05-01 15:53:27.069764 - gail/main.py:191 - [Discriminator] iter = 1820000 loss = -0.3617 grad_norm = 3.5589 grad_penalty = 0.0809 regularization = 0.0000 true_logits = 0.1055 fake_logits = -0.3371 true_prob = 0.5101 fake_prob = 0.4323 
2022-05-01 15:55:31.388004 - gail/main.py:132 - [Evaluate] iter = 1820000 episode={ returns = 3540.0842 lengths = 1000 } discounted_episode={ returns = 1983.7195 lengths = 911 } 
2022-05-01 15:55:41.212084 - gail/main.py:164 - [TRPO] iter = 1821000 dist_mean = 0.0342 dist_std = 0.1397 vf_loss = 0.1742 grad_norm = 2.4031 nat_grad_norm = 0.0785 cg_residual = 1.9781 step_size = 0.4875 reward = -0.0000 fps = 7 mse_loss = 0.6675 
2022-05-01 15:55:50.882371 - gail/main.py:164 - [TRPO] iter = 1822000 dist_mean = 0.0100 dist_std = 0.1399 vf_loss = 0.2150 grad_norm = 3.1163 nat_grad_norm = 0.1018 cg_residual = 1.7603 step_size = 0.3652 reward = 0.0000 fps = 6 mse_loss = 0.6423 
2022-05-01 15:56:00.843148 - gail/main.py:164 - [TRPO] iter = 1823000 dist_mean = 0.0411 dist_std = 0.1400 vf_loss = 0.1803 grad_norm = 3.9646 nat_grad_norm = 0.0786 cg_residual = 1.8723 step_size = 0.4329 reward = -0.0000 fps = 6 mse_loss = 0.6183 
2022-05-01 15:56:10.531036 - gail/main.py:164 - [TRPO] iter = 1824000 dist_mean = 0.0282 dist_std = 0.1400 vf_loss = 0.0524 grad_norm = 3.1752 nat_grad_norm = 0.0990 cg_residual = 2.4395 step_size = 0.4316 reward = 0.0000 fps = 6 mse_loss = 0.6097 
2022-05-01 15:56:20.214368 - gail/main.py:164 - [TRPO] iter = 1825000 dist_mean = 0.0375 dist_std = 0.1403 vf_loss = 0.2425 grad_norm = 4.2711 nat_grad_norm = 0.0707 cg_residual = 1.5101 step_size = 0.4673 reward = 0.0000 fps = 5 mse_loss = 0.5998 
2022-05-01 15:56:20.459959 - gail/main.py:191 - [Discriminator] iter = 1825000 loss = -0.3767 grad_norm = 3.9492 grad_penalty = 0.0579 regularization = 0.0000 true_logits = 0.1943 fake_logits = -0.2403 true_prob = 0.5269 fake_prob = 0.4492 
2022-05-01 15:57:38.591342 - gail/main.py:132 - [Evaluate] iter = 1825000 episode={ returns = 1935.9121 lengths = 557 } discounted_episode={ returns = 1432.9924 lengths = 646 } 
2022-05-01 15:57:48.110611 - gail/main.py:164 - [TRPO] iter = 1826000 dist_mean = 0.0194 dist_std = 0.1401 vf_loss = 0.2835 grad_norm = 3.4219 nat_grad_norm = 0.0895 cg_residual = 1.4347 step_size = 0.4685 reward = -0.0000 fps = 11 mse_loss = 0.5862 
2022-05-01 15:57:57.598039 - gail/main.py:164 - [TRPO] iter = 1827000 dist_mean = 0.0313 dist_std = 0.1400 vf_loss = 0.0512 grad_norm = 4.1064 nat_grad_norm = 0.1045 cg_residual = 2.5874 step_size = 0.3523 reward = 0.0000 fps = 10 mse_loss = 0.6237 
2022-05-01 15:58:07.412234 - gail/main.py:164 - [TRPO] iter = 1828000 dist_mean = 0.0482 dist_std = 0.1399 vf_loss = 0.2863 grad_norm = 3.7297 nat_grad_norm = 0.0800 cg_residual = 3.0828 step_size = 0.4715 reward = -0.0000 fps = 9 mse_loss = 0.6491 
2022-05-01 15:58:16.635788 - gail/main.py:164 - [TRPO] iter = 1829000 dist_mean = 0.0196 dist_std = 0.1402 vf_loss = 0.2269 grad_norm = 2.7932 nat_grad_norm = 0.0767 cg_residual = 1.3201 step_size = 0.4771 reward = 0.0000 fps = 8 mse_loss = 0.6209 
2022-05-01 15:58:26.151007 - gail/main.py:164 - [TRPO] iter = 1830000 dist_mean = 0.0205 dist_std = 0.1405 vf_loss = 0.2399 grad_norm = 3.6165 nat_grad_norm = 0.0886 cg_residual = 2.1643 step_size = 0.4201 reward = -0.0000 fps = 7 mse_loss = 0.5617 
2022-05-01 15:58:26.422897 - gail/main.py:191 - [Discriminator] iter = 1830000 loss = -0.4308 grad_norm = 3.6312 grad_penalty = 0.0590 regularization = 0.0000 true_logits = 0.1731 fake_logits = -0.3168 true_prob = 0.5227 fake_prob = 0.4355 
2022-05-01 16:00:00.455037 - gail/main.py:132 - [Evaluate] iter = 1830000 episode={ returns = 3233.6972 lengths = 911 } discounted_episode={ returns = 1241.6277 lengths = 559 } 
2022-05-01 16:00:10.462573 - gail/main.py:164 - [TRPO] iter = 1831000 dist_mean = 0.0333 dist_std = 0.1406 vf_loss = 0.0548 grad_norm = 3.0286 nat_grad_norm = 0.0676 cg_residual = 1.6339 step_size = 0.5100 reward = 0.0000 fps = 9 mse_loss = 0.6253 
2022-05-01 16:00:20.054134 - gail/main.py:164 - [TRPO] iter = 1832000 dist_mean = 0.0690 dist_std = 0.1404 vf_loss = 0.4013 grad_norm = 2.6881 nat_grad_norm = 0.0486 cg_residual = 0.9645 step_size = 0.6425 reward = -0.0000 fps = 8 mse_loss = 0.5774 
2022-05-01 16:00:29.698800 - gail/main.py:164 - [TRPO] iter = 1833000 dist_mean = 0.0501 dist_std = 0.1408 vf_loss = 0.2757 grad_norm = 3.4369 nat_grad_norm = 0.0728 cg_residual = 2.8002 step_size = 0.5433 reward = -0.0000 fps = 8 mse_loss = 0.5808 
2022-05-01 16:00:39.220668 - gail/main.py:164 - [TRPO] iter = 1834000 dist_mean = 0.0057 dist_std = 0.1407 vf_loss = 0.0421 grad_norm = 5.6893 nat_grad_norm = 0.0838 cg_residual = 1.4385 step_size = 0.3758 reward = 0.0000 fps = 7 mse_loss = 0.5950 
2022-05-01 16:00:48.830301 - gail/main.py:164 - [TRPO] iter = 1835000 dist_mean = 0.0312 dist_std = 0.1407 vf_loss = 0.3196 grad_norm = 3.1534 nat_grad_norm = 0.0718 cg_residual = 1.4702 step_size = 0.4993 reward = 0.0000 fps = 7 mse_loss = 0.5646 
2022-05-01 16:00:49.054187 - gail/main.py:191 - [Discriminator] iter = 1835000 loss = -0.5138 grad_norm = 3.1347 grad_penalty = 0.0525 regularization = 0.0000 true_logits = 0.1366 fake_logits = -0.4297 true_prob = 0.5155 fake_prob = 0.4172 
2022-05-01 16:02:58.767824 - gail/main.py:132 - [Evaluate] iter = 1835000 episode={ returns = 3559.5320 lengths = 1000 } discounted_episode={ returns = 2201.5648 lengths = 1000 } 
2022-05-01 16:03:08.407585 - gail/main.py:164 - [TRPO] iter = 1836000 dist_mean = 0.0246 dist_std = 0.1410 vf_loss = 0.2024 grad_norm = 5.4080 nat_grad_norm = 0.0736 cg_residual = 1.4909 step_size = 0.4693 reward = 0.0000 fps = 7 mse_loss = 0.5922 
2022-05-01 16:03:18.087363 - gail/main.py:164 - [TRPO] iter = 1837000 dist_mean = 0.0325 dist_std = 0.1407 vf_loss = 0.1843 grad_norm = 3.1345 nat_grad_norm = 0.0629 cg_residual = 1.3210 step_size = 0.5036 reward = 0.0000 fps = 6 mse_loss = 0.5775 
2022-05-01 16:03:27.459876 - gail/main.py:164 - [TRPO] iter = 1838000 dist_mean = 0.0335 dist_std = 0.1410 vf_loss = 0.2097 grad_norm = 1.8210 nat_grad_norm = 0.0522 cg_residual = 0.8956 step_size = 0.6546 reward = -0.0000 fps = 6 mse_loss = 0.5884 
2022-05-01 16:03:37.086745 - gail/main.py:164 - [TRPO] iter = 1839000 dist_mean = 0.0618 dist_std = 0.1411 vf_loss = 0.1412 grad_norm = 3.9291 nat_grad_norm = 0.0707 cg_residual = 1.7104 step_size = 0.4852 reward = 0.0000 fps = 5 mse_loss = 0.5703 
2022-05-01 16:03:46.804202 - gail/main.py:164 - [TRPO] iter = 1840000 dist_mean = 0.0256 dist_std = 0.1410 vf_loss = 0.1311 grad_norm = 3.0261 nat_grad_norm = 0.0597 cg_residual = 0.8703 step_size = 0.5763 reward = 0.0000 fps = 5 mse_loss = 0.5981 
2022-05-01 16:03:47.090177 - gail/main.py:191 - [Discriminator] iter = 1840000 loss = -0.3714 grad_norm = 2.8978 grad_penalty = 0.0502 regularization = 0.0000 true_logits = 0.1490 fake_logits = -0.2726 true_prob = 0.5204 fake_prob = 0.4461 
2022-05-01 16:04:07.898346 - gail/main.py:132 - [Evaluate] iter = 1840000 episode={ returns = 621.5879 lengths = 202 } discounted_episode={ returns = 275.7769 lengths = 113 } 
2022-05-01 16:04:17.558105 - gail/main.py:164 - [TRPO] iter = 1841000 dist_mean = 0.0521 dist_std = 0.1410 vf_loss = 0.3325 grad_norm = 2.9068 nat_grad_norm = 0.0577 cg_residual = 1.7037 step_size = 0.6095 reward = -0.0000 fps = 32 mse_loss = 0.5787 
2022-05-01 16:04:27.091811 - gail/main.py:164 - [TRPO] iter = 1842000 dist_mean = 0.0015 dist_std = 0.1409 vf_loss = 0.0276 grad_norm = 4.6075 nat_grad_norm = 0.0892 cg_residual = 2.3100 step_size = 0.3950 reward = 0.0000 fps = 25 mse_loss = 0.5262 
2022-05-01 16:04:36.590978 - gail/main.py:164 - [TRPO] iter = 1843000 dist_mean = 0.0086 dist_std = 0.1408 vf_loss = 0.0712 grad_norm = 2.9058 nat_grad_norm = 0.0684 cg_residual = 0.5818 step_size = 0.5017 reward = -0.0000 fps = 20 mse_loss = 0.5879 
2022-05-01 16:04:46.355229 - gail/main.py:164 - [TRPO] iter = 1844000 dist_mean = 0.0192 dist_std = 0.1408 vf_loss = 0.0330 grad_norm = 3.4019 nat_grad_norm = 0.0901 cg_residual = 2.1014 step_size = 0.4664 reward = 0.0000 fps = 16 mse_loss = 0.5920 
2022-05-01 16:04:55.978541 - gail/main.py:164 - [TRPO] iter = 1845000 dist_mean = 0.0207 dist_std = 0.1405 vf_loss = 0.1151 grad_norm = 2.0556 nat_grad_norm = 0.0561 cg_residual = 0.6671 step_size = 0.6521 reward = -0.0000 fps = 14 mse_loss = 0.5532 
2022-05-01 16:04:56.169886 - gail/main.py:191 - [Discriminator] iter = 1845000 loss = -0.3562 grad_norm = 3.3217 grad_penalty = 0.0497 regularization = 0.0000 true_logits = 0.0858 fake_logits = -0.3201 true_prob = 0.5099 fake_prob = 0.4333 
2022-05-01 16:07:05.170194 - gail/main.py:132 - [Evaluate] iter = 1845000 episode={ returns = 3556.3300 lengths = 1000 } discounted_episode={ returns = 2196.8868 lengths = 1000 } 
2022-05-01 16:07:14.346117 - gail/main.py:164 - [TRPO] iter = 1846000 dist_mean = 0.0210 dist_std = 0.1409 vf_loss = 0.0679 grad_norm = 4.8989 nat_grad_norm = 0.0771 cg_residual = 2.3476 step_size = 0.4190 reward = 0.0000 fps = 7 mse_loss = 0.6031 
2022-05-01 16:07:24.120990 - gail/main.py:164 - [TRPO] iter = 1847000 dist_mean = 0.0201 dist_std = 0.1407 vf_loss = 0.0875 grad_norm = 5.9760 nat_grad_norm = 0.0716 cg_residual = 1.7570 step_size = 0.4060 reward = 0.0000 fps = 6 mse_loss = 0.5624 
2022-05-01 16:07:34.491385 - gail/main.py:164 - [TRPO] iter = 1848000 dist_mean = 0.0447 dist_std = 0.1407 vf_loss = 0.1994 grad_norm = 5.2185 nat_grad_norm = 0.0707 cg_residual = 1.8202 step_size = 0.4331 reward = -0.0000 fps = 6 mse_loss = 0.5788 
2022-05-01 16:07:44.196289 - gail/main.py:164 - [TRPO] iter = 1849000 dist_mean = 0.0451 dist_std = 0.1408 vf_loss = 0.1721 grad_norm = 2.0495 nat_grad_norm = 0.0566 cg_residual = 0.3953 step_size = 0.6497 reward = 0.0000 fps = 5 mse_loss = 0.5929 
2022-05-01 16:07:53.911829 - gail/main.py:164 - [TRPO] iter = 1850000 dist_mean = 0.0453 dist_std = 0.1410 vf_loss = 0.1634 grad_norm = 4.6932 nat_grad_norm = 0.0536 cg_residual = 0.7257 step_size = 0.5405 reward = -0.0000 fps = 5 mse_loss = 0.5570 
2022-05-01 16:07:54.195510 - gail/main.py:191 - [Discriminator] iter = 1850000 loss = -0.3331 grad_norm = 3.9333 grad_penalty = 0.0458 regularization = 0.0000 true_logits = 0.1018 fake_logits = -0.2771 true_prob = 0.5137 fake_prob = 0.4433 
2022-05-01 16:10:03.872329 - gail/main.py:132 - [Evaluate] iter = 1850000 episode={ returns = 3536.3350 lengths = 1000 } discounted_episode={ returns = 2185.8476 lengths = 1000 } 
2022-05-01 16:10:13.775061 - gail/main.py:164 - [TRPO] iter = 1851000 dist_mean = 0.0367 dist_std = 0.1412 vf_loss = 0.0875 grad_norm = 2.9942 nat_grad_norm = 0.0727 cg_residual = 1.5944 step_size = 0.5290 reward = -0.0000 fps = 7 mse_loss = 0.5881 
2022-05-01 16:10:23.530094 - gail/main.py:164 - [TRPO] iter = 1852000 dist_mean = 0.0247 dist_std = 0.1413 vf_loss = 0.0560 grad_norm = 4.8254 nat_grad_norm = 0.0650 cg_residual = 1.0653 step_size = 0.4873 reward = 0.0000 fps = 6 mse_loss = 0.5702 
2022-05-01 16:10:33.355823 - gail/main.py:164 - [TRPO] iter = 1853000 dist_mean = 0.0469 dist_std = 0.1414 vf_loss = 0.1096 grad_norm = 4.0183 nat_grad_norm = 0.0565 cg_residual = 0.7552 step_size = 0.5800 reward = 0.0000 fps = 6 mse_loss = 0.5518 
2022-05-01 16:10:43.141264 - gail/main.py:164 - [TRPO] iter = 1854000 dist_mean = 0.0400 dist_std = 0.1413 vf_loss = 0.1350 grad_norm = 4.8578 nat_grad_norm = 0.0678 cg_residual = 1.0462 step_size = 0.5157 reward = 0.0000 fps = 5 mse_loss = 0.5529 
2022-05-01 16:10:52.604804 - gail/main.py:164 - [TRPO] iter = 1855000 dist_mean = 0.0522 dist_std = 0.1409 vf_loss = 0.1024 grad_norm = 3.3291 nat_grad_norm = 0.0566 cg_residual = 1.6711 step_size = 0.5237 reward = 0.0000 fps = 5 mse_loss = 0.5832 
2022-05-01 16:10:52.832902 - gail/main.py:191 - [Discriminator] iter = 1855000 loss = -0.3099 grad_norm = 3.8481 grad_penalty = 0.0477 regularization = 0.0000 true_logits = 0.0985 fake_logits = -0.2590 true_prob = 0.5130 fake_prob = 0.4478 
2022-05-01 16:13:01.432726 - gail/main.py:132 - [Evaluate] iter = 1855000 episode={ returns = 3533.2680 lengths = 1000 } discounted_episode={ returns = 2183.0216 lengths = 1000 } 
2022-05-01 16:13:11.253554 - gail/main.py:164 - [TRPO] iter = 1856000 dist_mean = 0.0563 dist_std = 0.1411 vf_loss = 0.0794 grad_norm = 4.1468 nat_grad_norm = 0.0694 cg_residual = 1.1750 step_size = 0.4358 reward = -0.0000 fps = 7 mse_loss = 0.5151 
2022-05-01 16:13:20.809258 - gail/main.py:164 - [TRPO] iter = 1857000 dist_mean = 0.0390 dist_std = 0.1411 vf_loss = 0.0926 grad_norm = 2.8223 nat_grad_norm = 0.0715 cg_residual = 1.0396 step_size = 0.5749 reward = 0.0000 fps = 6 mse_loss = 0.5470 
2022-05-01 16:13:30.518776 - gail/main.py:164 - [TRPO] iter = 1858000 dist_mean = 0.0454 dist_std = 0.1412 vf_loss = 0.1606 grad_norm = 3.4411 nat_grad_norm = 0.0929 cg_residual = 1.9664 step_size = 0.4085 reward = -0.0000 fps = 6 mse_loss = 0.5407 
2022-05-01 16:13:40.010888 - gail/main.py:164 - [TRPO] iter = 1859000 dist_mean = 0.0571 dist_std = 0.1409 vf_loss = 0.1540 grad_norm = 3.7472 nat_grad_norm = 0.0952 cg_residual = 2.2590 step_size = 0.4102 reward = -0.0000 fps = 5 mse_loss = 0.5626 
2022-05-01 16:13:49.714747 - gail/main.py:164 - [TRPO] iter = 1860000 dist_mean = 0.0591 dist_std = 0.1408 vf_loss = 0.1607 grad_norm = 3.0346 nat_grad_norm = 0.0599 cg_residual = 1.2939 step_size = 0.5448 reward = -0.0000 fps = 5 mse_loss = 0.5773 
2022-05-01 16:13:49.943102 - gail/main.py:191 - [Discriminator] iter = 1860000 loss = -0.7359 grad_norm = 3.3241 grad_penalty = 0.0589 regularization = 0.0000 true_logits = 0.0982 fake_logits = -0.6966 true_prob = 0.5153 fake_prob = 0.3670 
2022-05-01 16:14:20.491503 - gail/main.py:132 - [Evaluate] iter = 1860000 episode={ returns = 519.6096 lengths = 187 } discounted_episode={ returns = 637.7148 lengths = 269 } 
2022-05-01 16:14:30.378631 - gail/main.py:164 - [TRPO] iter = 1861000 dist_mean = 0.0527 dist_std = 0.1404 vf_loss = 0.0479 grad_norm = 3.1834 nat_grad_norm = 0.0767 cg_residual = 2.1036 step_size = 0.4910 reward = -0.0000 fps = 24 mse_loss = 0.5717 
2022-05-01 16:14:40.181053 - gail/main.py:164 - [TRPO] iter = 1862000 dist_mean = 0.0354 dist_std = 0.1403 vf_loss = 0.1189 grad_norm = 3.9084 nat_grad_norm = 0.0666 cg_residual = 1.7352 step_size = 0.5354 reward = 0.0000 fps = 19 mse_loss = 0.5372 
2022-05-01 16:14:49.932584 - gail/main.py:164 - [TRPO] iter = 1863000 dist_mean = 0.0436 dist_std = 0.1405 vf_loss = 0.1778 grad_norm = 3.6200 nat_grad_norm = 0.1017 cg_residual = 1.9575 step_size = 0.4164 reward = 0.0000 fps = 16 mse_loss = 0.5777 
2022-05-01 16:14:59.368186 - gail/main.py:164 - [TRPO] iter = 1864000 dist_mean = 0.0533 dist_std = 0.1403 vf_loss = 0.1557 grad_norm = 4.2580 nat_grad_norm = 0.0889 cg_residual = 2.6778 step_size = 0.4143 reward = -0.0000 fps = 14 mse_loss = 0.5792 
2022-05-01 16:15:08.947243 - gail/main.py:164 - [TRPO] iter = 1865000 dist_mean = 0.0515 dist_std = 0.1404 vf_loss = 0.0671 grad_norm = 4.0952 nat_grad_norm = 0.0926 cg_residual = 2.1202 step_size = 0.4122 reward = -0.0000 fps = 12 mse_loss = 0.5650 
2022-05-01 16:15:09.156263 - gail/main.py:191 - [Discriminator] iter = 1865000 loss = -0.4992 grad_norm = 3.0320 grad_penalty = 0.0738 regularization = 0.0000 true_logits = 0.0266 fake_logits = -0.5464 true_prob = 0.4986 fake_prob = 0.3999 
2022-05-01 16:15:49.652784 - gail/main.py:132 - [Evaluate] iter = 1865000 episode={ returns = 1123.9103 lengths = 351 } discounted_episode={ returns = 641.9662 lengths = 270 } 
2022-05-01 16:15:59.216357 - gail/main.py:164 - [TRPO] iter = 1866000 dist_mean = 0.0581 dist_std = 0.1405 vf_loss = 0.2448 grad_norm = 4.6184 nat_grad_norm = 0.1406 cg_residual = 3.4774 step_size = 0.3098 reward = -0.0000 fps = 19 mse_loss = 0.5582 
2022-05-01 16:16:09.182752 - gail/main.py:164 - [TRPO] iter = 1867000 dist_mean = 0.0907 dist_std = 0.1404 vf_loss = 0.0861 grad_norm = 3.7418 nat_grad_norm = 0.0868 cg_residual = 4.2316 step_size = 0.4016 reward = -0.0000 fps = 16 mse_loss = 0.5363 
2022-05-01 16:16:18.997324 - gail/main.py:164 - [TRPO] iter = 1868000 dist_mean = 0.0531 dist_std = 0.1405 vf_loss = 0.2019 grad_norm = 4.0294 nat_grad_norm = 0.0656 cg_residual = 1.7682 step_size = 0.4865 reward = 0.0000 fps = 14 mse_loss = 0.5262 
2022-05-01 16:16:28.726200 - gail/main.py:164 - [TRPO] iter = 1869000 dist_mean = 0.0524 dist_std = 0.1401 vf_loss = 0.0494 grad_norm = 3.6055 nat_grad_norm = 0.0582 cg_residual = 1.8577 step_size = 0.5155 reward = 0.0000 fps = 12 mse_loss = 0.5571 
2022-05-01 16:16:38.553788 - gail/main.py:164 - [TRPO] iter = 1870000 dist_mean = 0.0399 dist_std = 0.1401 vf_loss = 0.0938 grad_norm = 2.5003 nat_grad_norm = 0.0932 cg_residual = 1.9871 step_size = 0.4326 reward = -0.0000 fps = 11 mse_loss = 0.5356 
2022-05-01 16:16:38.793808 - gail/main.py:191 - [Discriminator] iter = 1870000 loss = -0.5836 grad_norm = 2.8921 grad_penalty = 0.0640 regularization = 0.0000 true_logits = -0.0318 fake_logits = -0.6794 true_prob = 0.4883 fake_prob = 0.3721 
2022-05-01 16:17:24.556707 - gail/main.py:132 - [Evaluate] iter = 1870000 episode={ returns = 819.5252 lengths = 270 } discounted_episode={ returns = 984.7076 lengths = 433 } 
2022-05-01 16:17:34.281076 - gail/main.py:164 - [TRPO] iter = 1871000 dist_mean = 0.0588 dist_std = 0.1403 vf_loss = 0.3366 grad_norm = 4.0412 nat_grad_norm = 0.0810 cg_residual = 2.3084 step_size = 0.4262 reward = -0.0000 fps = 18 mse_loss = 0.5622 
2022-05-01 16:17:44.236663 - gail/main.py:164 - [TRPO] iter = 1872000 dist_mean = 0.0524 dist_std = 0.1402 vf_loss = 0.2973 grad_norm = 4.3734 nat_grad_norm = 0.0895 cg_residual = 1.7025 step_size = 0.4345 reward = 0.0000 fps = 15 mse_loss = 0.5286 
2022-05-01 16:17:53.718156 - gail/main.py:164 - [TRPO] iter = 1873000 dist_mean = 0.0496 dist_std = 0.1401 vf_loss = 0.0272 grad_norm = 4.0498 nat_grad_norm = 0.0797 cg_residual = 1.7187 step_size = 0.4406 reward = 0.0000 fps = 13 mse_loss = 0.5522 
2022-05-01 16:18:03.683265 - gail/main.py:164 - [TRPO] iter = 1874000 dist_mean = 0.0383 dist_std = 0.1404 vf_loss = 0.3217 grad_norm = 4.0126 nat_grad_norm = 0.0680 cg_residual = 1.3663 step_size = 0.5054 reward = 0.0000 fps = 11 mse_loss = 0.5638 
2022-05-01 16:18:13.443469 - gail/main.py:164 - [TRPO] iter = 1875000 dist_mean = 0.0550 dist_std = 0.1405 vf_loss = 0.1477 grad_norm = 2.9793 nat_grad_norm = 0.0826 cg_residual = 1.2598 step_size = 0.4883 reward = -0.0000 fps = 10 mse_loss = 0.5762 
2022-05-01 16:18:13.678396 - gail/main.py:191 - [Discriminator] iter = 1875000 loss = -0.7260 grad_norm = 3.6757 grad_penalty = 0.0643 regularization = 0.0000 true_logits = 0.0852 fake_logits = -0.7051 true_prob = 0.5123 fake_prob = 0.3702 
2022-05-01 16:19:21.025579 - gail/main.py:132 - [Evaluate] iter = 1875000 episode={ returns = 1411.8708 lengths = 428 } discounted_episode={ returns = 1336.1799 lengths = 595 } 
2022-05-01 16:19:30.984067 - gail/main.py:164 - [TRPO] iter = 1876000 dist_mean = 0.0666 dist_std = 0.1402 vf_loss = 0.1837 grad_norm = 3.1462 nat_grad_norm = 0.0654 cg_residual = 0.9112 step_size = 0.5859 reward = -0.0000 fps = 12 mse_loss = 0.5878 
2022-05-01 16:19:40.714179 - gail/main.py:164 - [TRPO] iter = 1877000 dist_mean = 0.0254 dist_std = 0.1404 vf_loss = 0.0371 grad_norm = 3.4515 nat_grad_norm = 0.0781 cg_residual = 2.0314 step_size = 0.4610 reward = -0.0000 fps = 11 mse_loss = 0.5639 
2022-05-01 16:19:50.607269 - gail/main.py:164 - [TRPO] iter = 1878000 dist_mean = 0.0236 dist_std = 0.1402 vf_loss = 0.2469 grad_norm = 3.2129 nat_grad_norm = 0.0908 cg_residual = 2.1332 step_size = 0.4280 reward = 0.0000 fps = 10 mse_loss = 0.5613 
2022-05-01 16:20:00.392704 - gail/main.py:164 - [TRPO] iter = 1879000 dist_mean = 0.0712 dist_std = 0.1404 vf_loss = 0.2935 grad_norm = 3.5248 nat_grad_norm = 0.0540 cg_residual = 1.0370 step_size = 0.5218 reward = 0.0000 fps = 9 mse_loss = 0.5965 
2022-05-01 16:20:09.778170 - gail/main.py:164 - [TRPO] iter = 1880000 dist_mean = 0.0469 dist_std = 0.1406 vf_loss = 0.1929 grad_norm = 3.7859 nat_grad_norm = 0.0579 cg_residual = 1.4289 step_size = 0.4948 reward = 0.0000 fps = 8 mse_loss = 0.5811 
2022-05-01 16:20:09.980457 - gail/main.py:191 - [Discriminator] iter = 1880000 loss = -0.6641 grad_norm = 2.9318 grad_penalty = 0.0494 regularization = 0.0000 true_logits = 0.0323 fake_logits = -0.6811 true_prob = 0.5036 fake_prob = 0.3813 
2022-05-01 16:21:14.305131 - gail/main.py:132 - [Evaluate] iter = 1880000 episode={ returns = 2047.0352 lengths = 597 } discounted_episode={ returns = 917.5439 lengths = 388 } 
2022-05-01 16:21:23.576111 - gail/main.py:164 - [TRPO] iter = 1881000 dist_mean = 0.0369 dist_std = 0.1406 vf_loss = 0.0757 grad_norm = 2.7713 nat_grad_norm = 0.0850 cg_residual = 2.4358 step_size = 0.4629 reward = -0.0000 fps = 13 mse_loss = 0.6125 
2022-05-01 16:21:33.001364 - gail/main.py:164 - [TRPO] iter = 1882000 dist_mean = 0.0400 dist_std = 0.1408 vf_loss = 0.2663 grad_norm = 4.1195 nat_grad_norm = 0.0696 cg_residual = 1.9134 step_size = 0.5014 reward = -0.0000 fps = 12 mse_loss = 0.5944 
2022-05-01 16:21:42.420504 - gail/main.py:164 - [TRPO] iter = 1883000 dist_mean = 0.0648 dist_std = 0.1410 vf_loss = 0.0441 grad_norm = 2.9962 nat_grad_norm = 0.0610 cg_residual = 1.4441 step_size = 0.5253 reward = 0.0000 fps = 10 mse_loss = 0.5757 
2022-05-01 16:21:52.057678 - gail/main.py:164 - [TRPO] iter = 1884000 dist_mean = 0.0504 dist_std = 0.1412 vf_loss = 0.1549 grad_norm = 2.5163 nat_grad_norm = 0.0642 cg_residual = 1.3274 step_size = 0.5665 reward = 0.0000 fps = 9 mse_loss = 0.5461 
2022-05-01 16:22:01.870463 - gail/main.py:164 - [TRPO] iter = 1885000 dist_mean = 0.0300 dist_std = 0.1413 vf_loss = 0.1769 grad_norm = 4.2190 nat_grad_norm = 0.0601 cg_residual = 0.9857 step_size = 0.5414 reward = -0.0000 fps = 8 mse_loss = 0.5951 
2022-05-01 16:22:02.141793 - gail/main.py:191 - [Discriminator] iter = 1885000 loss = -0.3894 grad_norm = 3.2814 grad_penalty = 0.0518 regularization = 0.0000 true_logits = -0.1389 fake_logits = -0.5802 true_prob = 0.4661 fake_prob = 0.4011 
2022-05-01 16:24:15.194754 - gail/main.py:132 - [Evaluate] iter = 1885000 episode={ returns = 3559.5901 lengths = 1000 } discounted_episode={ returns = 2201.5201 lengths = 1000 } 
2022-05-01 16:24:25.101717 - gail/main.py:164 - [TRPO] iter = 1886000 dist_mean = 0.0383 dist_std = 0.1413 vf_loss = 0.0876 grad_norm = 4.5659 nat_grad_norm = 0.0964 cg_residual = 3.7456 step_size = 0.4059 reward = -0.0000 fps = 6 mse_loss = 0.5494 
2022-05-01 16:24:34.887055 - gail/main.py:164 - [TRPO] iter = 1887000 dist_mean = 0.0438 dist_std = 0.1412 vf_loss = 0.0264 grad_norm = 3.9487 nat_grad_norm = 0.1129 cg_residual = 2.7373 step_size = 0.3853 reward = 0.0000 fps = 6 mse_loss = 0.5505 
2022-05-01 16:24:44.849679 - gail/main.py:164 - [TRPO] iter = 1888000 dist_mean = 0.0383 dist_std = 0.1413 vf_loss = 0.1578 grad_norm = 3.3573 nat_grad_norm = 0.0613 cg_residual = 1.1189 step_size = 0.5650 reward = -0.0000 fps = 6 mse_loss = 0.5640 
2022-05-01 16:24:54.665531 - gail/main.py:164 - [TRPO] iter = 1889000 dist_mean = 0.0330 dist_std = 0.1411 vf_loss = 0.2026 grad_norm = 2.3299 nat_grad_norm = 0.0607 cg_residual = 1.4655 step_size = 0.6161 reward = 0.0000 fps = 5 mse_loss = 0.5867 
2022-05-01 16:25:04.615887 - gail/main.py:164 - [TRPO] iter = 1890000 dist_mean = 0.0389 dist_std = 0.1411 vf_loss = 0.0202 grad_norm = 3.2626 nat_grad_norm = 0.0738 cg_residual = 1.2252 step_size = 0.4995 reward = 0.0000 fps = 5 mse_loss = 0.5634 
2022-05-01 16:25:04.841520 - gail/main.py:191 - [Discriminator] iter = 1890000 loss = -0.4844 grad_norm = 3.3986 grad_penalty = 0.0553 regularization = 0.0000 true_logits = -0.1372 fake_logits = -0.6769 true_prob = 0.4726 fake_prob = 0.3859 
2022-05-01 16:27:13.671960 - gail/main.py:132 - [Evaluate] iter = 1890000 episode={ returns = 3234.3578 lengths = 912 } discounted_episode={ returns = 2200.6948 lengths = 1000 } 
2022-05-01 16:27:23.055110 - gail/main.py:164 - [TRPO] iter = 1891000 dist_mean = 0.0546 dist_std = 0.1411 vf_loss = 0.1863 grad_norm = 4.9183 nat_grad_norm = 0.0865 cg_residual = 1.4474 step_size = 0.3687 reward = 0.0000 fps = 7 mse_loss = 0.5603 
2022-05-01 16:27:32.660925 - gail/main.py:164 - [TRPO] iter = 1892000 dist_mean = 0.0464 dist_std = 0.1411 vf_loss = 0.0989 grad_norm = 4.4043 nat_grad_norm = 0.0711 cg_residual = 1.8013 step_size = 0.4432 reward = -0.0000 fps = 6 mse_loss = 0.6033 
2022-05-01 16:27:42.113446 - gail/main.py:164 - [TRPO] iter = 1893000 dist_mean = 0.0395 dist_std = 0.1412 vf_loss = 0.1660 grad_norm = 2.3015 nat_grad_norm = 0.0802 cg_residual = 1.8609 step_size = 0.5039 reward = -0.0000 fps = 6 mse_loss = 0.5613 
2022-05-01 16:27:51.651861 - gail/main.py:164 - [TRPO] iter = 1894000 dist_mean = 0.0343 dist_std = 0.1414 vf_loss = 0.1197 grad_norm = 4.6209 nat_grad_norm = 0.0824 cg_residual = 1.9226 step_size = 0.4811 reward = -0.0000 fps = 5 mse_loss = 0.5521 
2022-05-01 16:28:01.219906 - gail/main.py:164 - [TRPO] iter = 1895000 dist_mean = 0.0392 dist_std = 0.1414 vf_loss = 0.1125 grad_norm = 3.3158 nat_grad_norm = 0.0789 cg_residual = 2.4594 step_size = 0.5096 reward = 0.0000 fps = 5 mse_loss = 0.5824 
2022-05-01 16:28:01.430241 - gail/main.py:191 - [Discriminator] iter = 1895000 loss = -0.5145 grad_norm = 2.9788 grad_penalty = 0.0478 regularization = 0.0000 true_logits = -0.1874 fake_logits = -0.7497 true_prob = 0.4671 fake_prob = 0.3745 
2022-05-01 16:29:39.310309 - gail/main.py:132 - [Evaluate] iter = 1895000 episode={ returns = 2575.2488 lengths = 736 } discounted_episode={ returns = 1623.8799 lengths = 736 } 
2022-05-01 16:29:48.832703 - gail/main.py:164 - [TRPO] iter = 1896000 dist_mean = 0.0453 dist_std = 0.1414 vf_loss = 0.1041 grad_norm = 3.6037 nat_grad_norm = 0.0586 cg_residual = 1.6972 step_size = 0.5321 reward = -0.0000 fps = 9 mse_loss = 0.5751 
2022-05-01 16:29:58.316690 - gail/main.py:164 - [TRPO] iter = 1897000 dist_mean = 0.0368 dist_std = 0.1417 vf_loss = 0.0189 grad_norm = 3.5063 nat_grad_norm = 0.0993 cg_residual = 3.5678 step_size = 0.3603 reward = -0.0000 fps = 8 mse_loss = 0.5871 
2022-05-01 16:30:08.435536 - gail/main.py:164 - [TRPO] iter = 1898000 dist_mean = 0.0393 dist_std = 0.1418 vf_loss = 0.2276 grad_norm = 4.3082 nat_grad_norm = 0.0567 cg_residual = 1.2565 step_size = 0.4618 reward = 0.0000 fps = 7 mse_loss = 0.6762 
2022-05-01 16:30:18.014248 - gail/main.py:164 - [TRPO] iter = 1899000 dist_mean = 0.0547 dist_std = 0.1420 vf_loss = 0.0794 grad_norm = 4.6174 nat_grad_norm = 0.0731 cg_residual = 0.8626 step_size = 0.4335 reward = 0.0000 fps = 7 mse_loss = 0.5817 
2022-05-01 16:30:27.754488 - gail/main.py:164 - [TRPO] iter = 1900000 dist_mean = 0.0318 dist_std = 0.1421 vf_loss = 0.2013 grad_norm = 3.3519 nat_grad_norm = 0.0817 cg_residual = 1.6474 step_size = 0.4897 reward = -0.0000 fps = 6 mse_loss = 0.6100 
2022-05-01 16:30:27.994197 - gail/main.py:191 - [Discriminator] iter = 1900000 loss = -0.5514 grad_norm = 3.1269 grad_penalty = 0.0519 regularization = 0.0000 true_logits = -0.3888 fake_logits = -0.9920 true_prob = 0.4276 fake_prob = 0.3379 
2022-05-01 16:32:38.149941 - gail/main.py:132 - [Evaluate] iter = 1900000 episode={ returns = 3563.4643 lengths = 1000 } discounted_episode={ returns = 2205.8765 lengths = 1000 } 
2022-05-01 16:32:47.880271 - gail/main.py:164 - [TRPO] iter = 1901000 dist_mean = 0.0374 dist_std = 0.1419 vf_loss = 0.1825 grad_norm = 2.9869 nat_grad_norm = 0.0679 cg_residual = 1.3714 step_size = 0.5142 reward = 0.0000 fps = 7 mse_loss = 0.5872 
2022-05-01 16:32:57.754379 - gail/main.py:164 - [TRPO] iter = 1902000 dist_mean = 0.0182 dist_std = 0.1419 vf_loss = 0.0563 grad_norm = 5.4487 nat_grad_norm = 0.1285 cg_residual = 8.2181 step_size = 0.3194 reward = -0.0000 fps = 6 mse_loss = 0.6131 
2022-05-01 16:33:07.651617 - gail/main.py:164 - [TRPO] iter = 1903000 dist_mean = 0.0383 dist_std = 0.1419 vf_loss = 0.1065 grad_norm = 3.3840 nat_grad_norm = 0.0818 cg_residual = 2.7134 step_size = 0.4804 reward = -0.0000 fps = 6 mse_loss = 0.6012 
2022-05-01 16:33:17.645900 - gail/main.py:164 - [TRPO] iter = 1904000 dist_mean = 0.0578 dist_std = 0.1417 vf_loss = 0.1648 grad_norm = 4.4926 nat_grad_norm = 0.0707 cg_residual = 1.2856 step_size = 0.4888 reward = 0.0000 fps = 5 mse_loss = 0.6420 
2022-05-01 16:33:27.273184 - gail/main.py:164 - [TRPO] iter = 1905000 dist_mean = 0.0458 dist_std = 0.1419 vf_loss = 0.0739 grad_norm = 3.7722 nat_grad_norm = 0.0815 cg_residual = 1.5074 step_size = 0.4533 reward = -0.0000 fps = 5 mse_loss = 0.6494 
2022-05-01 16:33:27.480874 - gail/main.py:191 - [Discriminator] iter = 1905000 loss = -0.5432 grad_norm = 3.3176 grad_penalty = 0.0534 regularization = 0.0000 true_logits = -0.3442 fake_logits = -0.9408 true_prob = 0.4362 fake_prob = 0.3455 
2022-05-01 16:35:40.348024 - gail/main.py:132 - [Evaluate] iter = 1905000 episode={ returns = 3565.3586 lengths = 1000 } discounted_episode={ returns = 2207.8273 lengths = 1000 } 
2022-05-01 16:35:50.370267 - gail/main.py:164 - [TRPO] iter = 1906000 dist_mean = 0.0416 dist_std = 0.1420 vf_loss = 0.1202 grad_norm = 3.4945 nat_grad_norm = 0.0677 cg_residual = 0.8898 step_size = 0.4830 reward = -0.0000 fps = 6 mse_loss = 0.6187 
2022-05-01 16:36:00.193647 - gail/main.py:164 - [TRPO] iter = 1907000 dist_mean = 0.0432 dist_std = 0.1422 vf_loss = 0.0329 grad_norm = 5.1929 nat_grad_norm = 0.1019 cg_residual = 4.5195 step_size = 0.3636 reward = -0.0000 fps = 6 mse_loss = 0.6547 
2022-05-01 16:36:10.064706 - gail/main.py:164 - [TRPO] iter = 1908000 dist_mean = 0.0594 dist_std = 0.1422 vf_loss = 0.0973 grad_norm = 3.6375 nat_grad_norm = 0.0771 cg_residual = 2.0028 step_size = 0.4270 reward = -0.0000 fps = 6 mse_loss = 0.6405 
2022-05-01 16:36:20.000050 - gail/main.py:164 - [TRPO] iter = 1909000 dist_mean = 0.0374 dist_std = 0.1421 vf_loss = 0.1864 grad_norm = 3.1696 nat_grad_norm = 0.0830 cg_residual = 2.3215 step_size = 0.4770 reward = -0.0000 fps = 5 mse_loss = 0.5966 
2022-05-01 16:36:29.724538 - gail/main.py:164 - [TRPO] iter = 1910000 dist_mean = 0.0478 dist_std = 0.1423 vf_loss = 0.1300 grad_norm = 2.8379 nat_grad_norm = 0.0884 cg_residual = 1.8029 step_size = 0.4874 reward = 0.0000 fps = 5 mse_loss = 0.6457 
2022-05-01 16:36:29.952277 - gail/main.py:191 - [Discriminator] iter = 1910000 loss = -0.4990 grad_norm = 3.5349 grad_penalty = 0.0540 regularization = 0.0000 true_logits = -0.4110 fake_logits = -0.9640 true_prob = 0.4293 fake_prob = 0.3412 
2022-05-01 16:38:41.781074 - gail/main.py:132 - [Evaluate] iter = 1910000 episode={ returns = 3571.8800 lengths = 1000 } discounted_episode={ returns = 2204.2914 lengths = 1000 } 
2022-05-01 16:38:52.322773 - gail/main.py:164 - [TRPO] iter = 1911000 dist_mean = 0.0458 dist_std = 0.1422 vf_loss = 0.0930 grad_norm = 3.0137 nat_grad_norm = 0.0624 cg_residual = 0.6485 step_size = 0.5100 reward = 0.0000 fps = 7 mse_loss = 0.6728 
2022-05-01 16:39:02.231040 - gail/main.py:164 - [TRPO] iter = 1912000 dist_mean = 0.0358 dist_std = 0.1422 vf_loss = 0.0755 grad_norm = 4.5557 nat_grad_norm = 0.0819 cg_residual = 2.0655 step_size = 0.4206 reward = -0.0000 fps = 6 mse_loss = 0.6672 
2022-05-01 16:39:12.375138 - gail/main.py:164 - [TRPO] iter = 1913000 dist_mean = 0.0341 dist_std = 0.1418 vf_loss = 0.1397 grad_norm = 2.4962 nat_grad_norm = 0.0820 cg_residual = 2.2256 step_size = 0.5047 reward = -0.0000 fps = 6 mse_loss = 0.6873 
2022-05-01 16:39:22.043108 - gail/main.py:164 - [TRPO] iter = 1914000 dist_mean = 0.0280 dist_std = 0.1416 vf_loss = 0.1174 grad_norm = 3.9715 nat_grad_norm = 0.0801 cg_residual = 1.3036 step_size = 0.4534 reward = -0.0000 fps = 5 mse_loss = 0.6522 
2022-05-01 16:39:31.805818 - gail/main.py:164 - [TRPO] iter = 1915000 dist_mean = 0.0467 dist_std = 0.1418 vf_loss = 0.1493 grad_norm = 4.4864 nat_grad_norm = 0.0573 cg_residual = 0.6052 step_size = 0.4575 reward = -0.0000 fps = 5 mse_loss = 0.6466 
2022-05-01 16:39:32.063808 - gail/main.py:191 - [Discriminator] iter = 1915000 loss = -0.3939 grad_norm = 3.8598 grad_penalty = 0.0558 regularization = 0.0000 true_logits = -0.4751 fake_logits = -0.9247 true_prob = 0.4191 fake_prob = 0.3461 
2022-05-01 16:41:44.401980 - gail/main.py:132 - [Evaluate] iter = 1915000 episode={ returns = 3577.0374 lengths = 1000 } discounted_episode={ returns = 2213.1746 lengths = 1000 } 
2022-05-01 16:41:54.064725 - gail/main.py:164 - [TRPO] iter = 1916000 dist_mean = 0.0580 dist_std = 0.1416 vf_loss = 0.1089 grad_norm = 3.8664 nat_grad_norm = 0.0799 cg_residual = 1.7278 step_size = 0.4389 reward = -0.0000 fps = 7 mse_loss = 0.6557 
2022-05-01 16:42:04.065167 - gail/main.py:164 - [TRPO] iter = 1917000 dist_mean = 0.0405 dist_std = 0.1414 vf_loss = 0.1127 grad_norm = 2.0152 nat_grad_norm = 0.0644 cg_residual = 1.5817 step_size = 0.5444 reward = 0.0000 fps = 6 mse_loss = 0.6209 
2022-05-01 16:42:14.188869 - gail/main.py:164 - [TRPO] iter = 1918000 dist_mean = 0.0295 dist_std = 0.1411 vf_loss = 0.0172 grad_norm = 3.0614 nat_grad_norm = 0.0698 cg_residual = 1.5331 step_size = 0.4785 reward = -0.0000 fps = 6 mse_loss = 0.6701 
2022-05-01 16:42:24.062424 - gail/main.py:164 - [TRPO] iter = 1919000 dist_mean = 0.0345 dist_std = 0.1413 vf_loss = 0.0744 grad_norm = 2.9912 nat_grad_norm = 0.0678 cg_residual = 2.1906 step_size = 0.5629 reward = 0.0000 fps = 5 mse_loss = 0.6797 
2022-05-01 16:42:33.980754 - gail/main.py:164 - [TRPO] iter = 1920000 dist_mean = 0.0453 dist_std = 0.1410 vf_loss = 0.0231 grad_norm = 2.9725 nat_grad_norm = 0.0813 cg_residual = 2.2071 step_size = 0.4301 reward = 0.0000 fps = 5 mse_loss = 0.6232 
2022-05-01 16:42:34.209957 - gail/main.py:191 - [Discriminator] iter = 1920000 loss = -0.4732 grad_norm = 2.8821 grad_penalty = 0.0560 regularization = 0.0000 true_logits = -0.4935 fake_logits = -1.0228 true_prob = 0.4153 fake_prob = 0.3302 
2022-05-01 16:44:49.494269 - gail/main.py:132 - [Evaluate] iter = 1920000 episode={ returns = 3588.0358 lengths = 1000 } discounted_episode={ returns = 2223.0822 lengths = 1000 } 
2022-05-01 16:45:00.153053 - gail/main.py:164 - [TRPO] iter = 1921000 dist_mean = 0.0361 dist_std = 0.1410 vf_loss = 0.1410 grad_norm = 3.3819 nat_grad_norm = 0.1074 cg_residual = 5.7379 step_size = 0.3767 reward = 0.0000 fps = 6 mse_loss = 0.6511 
2022-05-01 16:45:10.448165 - gail/main.py:164 - [TRPO] iter = 1922000 dist_mean = 0.0296 dist_std = 0.1409 vf_loss = 0.0840 grad_norm = 1.7586 nat_grad_norm = 0.0645 cg_residual = 1.1589 step_size = 0.5948 reward = 0.0000 fps = 6 mse_loss = 0.7015 
2022-05-01 16:45:20.732409 - gail/main.py:164 - [TRPO] iter = 1923000 dist_mean = 0.0137 dist_std = 0.1409 vf_loss = 0.0112 grad_norm = 4.2991 nat_grad_norm = 0.0787 cg_residual = 1.9799 step_size = 0.4976 reward = 0.0000 fps = 6 mse_loss = 0.6399 
2022-05-01 16:45:30.854760 - gail/main.py:164 - [TRPO] iter = 1924000 dist_mean = 0.0156 dist_std = 0.1408 vf_loss = 0.0244 grad_norm = 4.9987 nat_grad_norm = 0.0679 cg_residual = 1.4318 step_size = 0.4619 reward = 0.0000 fps = 5 mse_loss = 0.6529 
2022-05-01 16:45:40.839238 - gail/main.py:164 - [TRPO] iter = 1925000 dist_mean = 0.0133 dist_std = 0.1407 vf_loss = 0.0780 grad_norm = 3.1254 nat_grad_norm = 0.0783 cg_residual = 1.2946 step_size = 0.5051 reward = -0.0000 fps = 5 mse_loss = 0.6282 
2022-05-01 16:45:41.117085 - gail/main.py:191 - [Discriminator] iter = 1925000 loss = -0.4726 grad_norm = 2.9926 grad_penalty = 0.0548 regularization = 0.0000 true_logits = -0.4557 fake_logits = -0.9830 true_prob = 0.4161 fake_prob = 0.3298 
2022-05-01 16:47:56.590401 - gail/main.py:132 - [Evaluate] iter = 1925000 episode={ returns = 3584.7345 lengths = 1000 } discounted_episode={ returns = 2218.5915 lengths = 1000 } 
2022-05-01 16:48:06.358617 - gail/main.py:164 - [TRPO] iter = 1926000 dist_mean = 0.0158 dist_std = 0.1407 vf_loss = 0.0646 grad_norm = 3.0491 nat_grad_norm = 0.0585 cg_residual = 1.5751 step_size = 0.6087 reward = 0.0000 fps = 6 mse_loss = 0.5995 
2022-05-01 16:48:16.291747 - gail/main.py:164 - [TRPO] iter = 1927000 dist_mean = 0.0011 dist_std = 0.1407 vf_loss = 0.0216 grad_norm = 4.1406 nat_grad_norm = 0.0674 cg_residual = 1.6515 step_size = 0.4824 reward = -0.0000 fps = 6 mse_loss = 0.6499 
2022-05-01 16:48:26.013132 - gail/main.py:164 - [TRPO] iter = 1928000 dist_mean = 0.0280 dist_std = 0.1405 vf_loss = 0.0215 grad_norm = 3.2036 nat_grad_norm = 0.0800 cg_residual = 2.1763 step_size = 0.4611 reward = -0.0000 fps = 6 mse_loss = 0.6425 
2022-05-01 16:48:35.681011 - gail/main.py:164 - [TRPO] iter = 1929000 dist_mean = 0.0178 dist_std = 0.1407 vf_loss = 0.0311 grad_norm = 4.8840 nat_grad_norm = 0.0622 cg_residual = 1.3249 step_size = 0.4541 reward = 0.0000 fps = 5 mse_loss = 0.5987 
2022-05-01 16:48:45.159826 - gail/main.py:164 - [TRPO] iter = 1930000 dist_mean = -0.0017 dist_std = 0.1408 vf_loss = 0.0127 grad_norm = 3.5716 nat_grad_norm = 0.0552 cg_residual = 0.7268 step_size = 0.5042 reward = 0.0000 fps = 5 mse_loss = 0.6469 
2022-05-01 16:48:45.382878 - gail/main.py:191 - [Discriminator] iter = 1930000 loss = -0.4947 grad_norm = 3.3039 grad_penalty = 0.0551 regularization = 0.0000 true_logits = -0.4329 fake_logits = -0.9828 true_prob = 0.4207 fake_prob = 0.3281 
2022-05-01 16:50:56.675758 - gail/main.py:132 - [Evaluate] iter = 1930000 episode={ returns = 3600.9701 lengths = 1000 } discounted_episode={ returns = 2216.5280 lengths = 1000 } 
2022-05-01 16:51:06.464408 - gail/main.py:164 - [TRPO] iter = 1931000 dist_mean = 0.0137 dist_std = 0.1406 vf_loss = 0.0857 grad_norm = 3.9217 nat_grad_norm = 0.0808 cg_residual = 1.2826 step_size = 0.4494 reward = 0.0000 fps = 7 mse_loss = 0.6058 
2022-05-01 16:51:16.286058 - gail/main.py:164 - [TRPO] iter = 1932000 dist_mean = -0.0025 dist_std = 0.1404 vf_loss = 0.0183 grad_norm = 4.9881 nat_grad_norm = 0.0661 cg_residual = 1.1950 step_size = 0.4575 reward = 0.0000 fps = 6 mse_loss = 0.6337 
2022-05-01 16:51:25.815819 - gail/main.py:164 - [TRPO] iter = 1933000 dist_mean = -0.0109 dist_std = 0.1402 vf_loss = 0.0160 grad_norm = 4.9447 nat_grad_norm = 0.0785 cg_residual = 2.1255 step_size = 0.4187 reward = 0.0000 fps = 6 mse_loss = 0.6267 
2022-05-01 16:51:35.456481 - gail/main.py:164 - [TRPO] iter = 1934000 dist_mean = 0.0296 dist_std = 0.1401 vf_loss = 0.0164 grad_norm = 4.2772 nat_grad_norm = 0.0799 cg_residual = 1.8296 step_size = 0.4296 reward = -0.0000 fps = 5 mse_loss = 0.6203 
2022-05-01 16:51:45.018944 - gail/main.py:164 - [TRPO] iter = 1935000 dist_mean = -0.0078 dist_std = 0.1403 vf_loss = 0.0184 grad_norm = 5.3558 nat_grad_norm = 0.0840 cg_residual = 2.5039 step_size = 0.3802 reward = -0.0000 fps = 5 mse_loss = 0.6185 
2022-05-01 16:51:45.264752 - gail/main.py:191 - [Discriminator] iter = 1935000 loss = -0.3065 grad_norm = 3.6368 grad_penalty = 0.0604 regularization = 0.0000 true_logits = -0.6714 fake_logits = -1.0384 true_prob = 0.3822 fake_prob = 0.3242 
2022-05-01 16:53:54.734743 - gail/main.py:132 - [Evaluate] iter = 1935000 episode={ returns = 3558.8795 lengths = 1000 } discounted_episode={ returns = 2186.5109 lengths = 1000 } 
2022-05-01 16:54:04.274243 - gail/main.py:164 - [TRPO] iter = 1936000 dist_mean = -0.0143 dist_std = 0.1403 vf_loss = 0.0258 grad_norm = 5.3958 nat_grad_norm = 0.0752 cg_residual = 1.4979 step_size = 0.4536 reward = 0.0000 fps = 7 mse_loss = 0.6072 
2022-05-01 16:54:13.902620 - gail/main.py:164 - [TRPO] iter = 1937000 dist_mean = 0.0081 dist_std = 0.1402 vf_loss = 0.0175 grad_norm = 3.5560 nat_grad_norm = 0.0697 cg_residual = 1.7841 step_size = 0.4573 reward = 0.0000 fps = 6 mse_loss = 0.6459 
2022-05-01 16:54:23.611535 - gail/main.py:164 - [TRPO] iter = 1938000 dist_mean = 0.0231 dist_std = 0.1400 vf_loss = 0.0200 grad_norm = 4.2197 nat_grad_norm = 0.0673 cg_residual = 0.8267 step_size = 0.4796 reward = -0.0000 fps = 6 mse_loss = 0.5962 
2022-05-01 16:54:33.249983 - gail/main.py:164 - [TRPO] iter = 1939000 dist_mean = -0.0213 dist_std = 0.1400 vf_loss = 0.0358 grad_norm = 4.3671 nat_grad_norm = 0.1041 cg_residual = 4.3056 step_size = 0.3824 reward = 0.0000 fps = 5 mse_loss = 0.6145 
2022-05-01 16:54:42.925510 - gail/main.py:164 - [TRPO] iter = 1940000 dist_mean = -0.0138 dist_std = 0.1398 vf_loss = 0.0191 grad_norm = 3.6701 nat_grad_norm = 0.0585 cg_residual = 1.3228 step_size = 0.5018 reward = -0.0000 fps = 5 mse_loss = 0.6131 
2022-05-01 16:54:43.178925 - gail/main.py:191 - [Discriminator] iter = 1940000 loss = -0.4396 grad_norm = 4.4387 grad_penalty = 0.0626 regularization = 0.0000 true_logits = -0.6612 fake_logits = -1.1634 true_prob = 0.3820 fake_prob = 0.2954 
2022-05-01 16:56:52.363654 - gail/main.py:132 - [Evaluate] iter = 1940000 episode={ returns = 3583.0273 lengths = 1000 } discounted_episode={ returns = 2219.4851 lengths = 1000 } 
2022-05-01 16:57:02.106901 - gail/main.py:164 - [TRPO] iter = 1941000 dist_mean = -0.0133 dist_std = 0.1399 vf_loss = 0.0171 grad_norm = 5.4847 nat_grad_norm = 0.0697 cg_residual = 2.0833 step_size = 0.4538 reward = 0.0000 fps = 7 mse_loss = 0.6407 
2022-05-01 16:57:11.570492 - gail/main.py:164 - [TRPO] iter = 1942000 dist_mean = -0.0048 dist_std = 0.1401 vf_loss = 0.0164 grad_norm = 5.2923 nat_grad_norm = 0.0888 cg_residual = 3.5449 step_size = 0.4578 reward = -0.0000 fps = 6 mse_loss = 0.6152 
2022-05-01 16:57:20.888496 - gail/main.py:164 - [TRPO] iter = 1943000 dist_mean = -0.0036 dist_std = 0.1401 vf_loss = 0.0131 grad_norm = 3.9315 nat_grad_norm = 0.0901 cg_residual = 1.7867 step_size = 0.4418 reward = 0.0000 fps = 6 mse_loss = 0.6335 
2022-05-01 16:57:30.010152 - gail/main.py:164 - [TRPO] iter = 1944000 dist_mean = 0.0041 dist_std = 0.1404 vf_loss = 0.0227 grad_norm = 4.3358 nat_grad_norm = 0.0719 cg_residual = 1.1317 step_size = 0.4477 reward = 0.0000 fps = 5 mse_loss = 0.6870 
2022-05-01 16:57:39.541079 - gail/main.py:164 - [TRPO] iter = 1945000 dist_mean = 0.0183 dist_std = 0.1404 vf_loss = 0.0255 grad_norm = 5.3655 nat_grad_norm = 0.0939 cg_residual = 1.5041 step_size = 0.3914 reward = 0.0000 fps = 5 mse_loss = 0.6134 
2022-05-01 16:57:39.743114 - gail/main.py:191 - [Discriminator] iter = 1945000 loss = -0.3647 grad_norm = 4.0463 grad_penalty = 0.0671 regularization = 0.0000 true_logits = -0.6979 fake_logits = -1.1296 true_prob = 0.3783 fake_prob = 0.3029 
2022-05-01 16:59:46.828154 - gail/main.py:132 - [Evaluate] iter = 1945000 episode={ returns = 3576.5668 lengths = 1000 } discounted_episode={ returns = 2214.9296 lengths = 1000 } 
2022-05-01 16:59:56.292834 - gail/main.py:164 - [TRPO] iter = 1946000 dist_mean = 0.0142 dist_std = 0.1402 vf_loss = 0.0331 grad_norm = 4.7407 nat_grad_norm = 0.0740 cg_residual = 1.0644 step_size = 0.4492 reward = 0.0000 fps = 7 mse_loss = 0.6184 
2022-05-01 17:00:06.596935 - gail/main.py:164 - [TRPO] iter = 1947000 dist_mean = 0.0107 dist_std = 0.1404 vf_loss = 0.0194 grad_norm = 3.7441 nat_grad_norm = 0.0765 cg_residual = 2.2884 step_size = 0.4909 reward = 0.0000 fps = 6 mse_loss = 0.6150 
2022-05-01 17:00:16.531327 - gail/main.py:164 - [TRPO] iter = 1948000 dist_mean = 0.0096 dist_std = 0.1401 vf_loss = 0.0193 grad_norm = 4.7141 nat_grad_norm = 0.0802 cg_residual = 1.5130 step_size = 0.4611 reward = -0.0000 fps = 6 mse_loss = 0.6443 
2022-05-01 17:00:26.196814 - gail/main.py:164 - [TRPO] iter = 1949000 dist_mean = -0.0027 dist_std = 0.1401 vf_loss = 0.0534 grad_norm = 3.2827 nat_grad_norm = 0.0599 cg_residual = 1.6222 step_size = 0.4962 reward = 0.0000 fps = 6 mse_loss = 0.6589 
2022-05-01 17:00:35.861934 - gail/main.py:164 - [TRPO] iter = 1950000 dist_mean = 0.0179 dist_std = 0.1400 vf_loss = 0.0300 grad_norm = 5.9979 nat_grad_norm = 0.0624 cg_residual = 0.9321 step_size = 0.4585 reward = 0.0000 fps = 5 mse_loss = 0.5785 
2022-05-01 17:00:36.122758 - gail/main.py:191 - [Discriminator] iter = 1950000 loss = -0.4521 grad_norm = 3.6708 grad_penalty = 0.0671 regularization = 0.0000 true_logits = -0.6954 fake_logits = -1.2146 true_prob = 0.3745 fake_prob = 0.2882 
2022-05-01 17:02:43.997241 - gail/main.py:132 - [Evaluate] iter = 1950000 episode={ returns = 3571.5793 lengths = 1000 } discounted_episode={ returns = 2208.4289 lengths = 1000 } 
2022-05-01 17:02:53.547270 - gail/main.py:164 - [TRPO] iter = 1951000 dist_mean = 0.0042 dist_std = 0.1401 vf_loss = 0.0298 grad_norm = 3.3076 nat_grad_norm = 0.0635 cg_residual = 1.0538 step_size = 0.4844 reward = -0.0000 fps = 7 mse_loss = 0.6921 
2022-05-01 17:03:02.807317 - gail/main.py:164 - [TRPO] iter = 1952000 dist_mean = -0.0051 dist_std = 0.1400 vf_loss = 0.0181 grad_norm = 5.6907 nat_grad_norm = 0.0919 cg_residual = 1.1841 step_size = 0.4257 reward = -0.0000 fps = 6 mse_loss = 0.6558 
2022-05-01 17:03:12.265052 - gail/main.py:164 - [TRPO] iter = 1953000 dist_mean = 0.0100 dist_std = 0.1399 vf_loss = 0.0177 grad_norm = 4.0058 nat_grad_norm = 0.0745 cg_residual = 2.1729 step_size = 0.4749 reward = 0.0000 fps = 6 mse_loss = 0.6207 
2022-05-01 17:03:21.657201 - gail/main.py:164 - [TRPO] iter = 1954000 dist_mean = 0.0206 dist_std = 0.1400 vf_loss = 0.0194 grad_norm = 6.1950 nat_grad_norm = 0.0566 cg_residual = 1.0170 step_size = 0.5393 reward = 0.0000 fps = 6 mse_loss = 0.6646 
2022-05-01 17:03:30.995734 - gail/main.py:164 - [TRPO] iter = 1955000 dist_mean = 0.0193 dist_std = 0.1402 vf_loss = 0.0190 grad_norm = 4.4371 nat_grad_norm = 0.0810 cg_residual = 1.3979 step_size = 0.4494 reward = -0.0000 fps = 5 mse_loss = 0.5567 
2022-05-01 17:03:31.225466 - gail/main.py:191 - [Discriminator] iter = 1955000 loss = -0.4503 grad_norm = 3.6177 grad_penalty = 0.0576 regularization = 0.0000 true_logits = -0.5721 fake_logits = -1.0800 true_prob = 0.3970 fake_prob = 0.3111 
2022-05-01 17:04:03.990826 - gail/main.py:132 - [Evaluate] iter = 1955000 episode={ returns = 130.9621 lengths = 66 } discounted_episode={ returns = 962.9883 lengths = 439 } 
2022-05-01 17:04:13.490224 - gail/main.py:164 - [TRPO] iter = 1956000 dist_mean = 0.0345 dist_std = 0.1408 vf_loss = 0.0236 grad_norm = 4.7617 nat_grad_norm = 0.0897 cg_residual = 2.2666 step_size = 0.4244 reward = -0.0000 fps = 23 mse_loss = 0.5933 
2022-05-01 17:04:22.973085 - gail/main.py:164 - [TRPO] iter = 1957000 dist_mean = 0.0253 dist_std = 0.1408 vf_loss = 0.0171 grad_norm = 3.8965 nat_grad_norm = 0.0813 cg_residual = 1.5549 step_size = 0.4361 reward = -0.0000 fps = 19 mse_loss = 0.5966 
2022-05-01 17:04:32.177134 - gail/main.py:164 - [TRPO] iter = 1958000 dist_mean = 0.0183 dist_std = 0.1405 vf_loss = 0.0245 grad_norm = 5.1444 nat_grad_norm = 0.0789 cg_residual = 0.8290 step_size = 0.4453 reward = 0.0000 fps = 16 mse_loss = 0.6136 
2022-05-01 17:04:41.607904 - gail/main.py:164 - [TRPO] iter = 1959000 dist_mean = 0.0150 dist_std = 0.1404 vf_loss = 0.0273 grad_norm = 5.8958 nat_grad_norm = 0.0737 cg_residual = 0.8525 step_size = 0.4308 reward = 0.0000 fps = 14 mse_loss = 0.6268 
2022-05-01 17:04:51.319131 - gail/main.py:164 - [TRPO] iter = 1960000 dist_mean = 0.0608 dist_std = 0.1402 vf_loss = 0.0297 grad_norm = 4.6271 nat_grad_norm = 0.0826 cg_residual = 2.1362 step_size = 0.3808 reward = 0.0000 fps = 12 mse_loss = 0.5590 
2022-05-01 17:04:51.574140 - gail/main.py:191 - [Discriminator] iter = 1960000 loss = -0.4442 grad_norm = 3.9383 grad_penalty = 0.0696 regularization = 0.0000 true_logits = -0.6671 fake_logits = -1.1809 true_prob = 0.3765 fake_prob = 0.3059 
2022-05-01 17:07:00.599111 - gail/main.py:132 - [Evaluate] iter = 1960000 episode={ returns = 3556.8984 lengths = 1000 } discounted_episode={ returns = 2201.2841 lengths = 1000 } 
2022-05-01 17:07:10.391117 - gail/main.py:164 - [TRPO] iter = 1961000 dist_mean = 0.0350 dist_std = 0.1399 vf_loss = 0.0839 grad_norm = 4.8411 nat_grad_norm = 0.0704 cg_residual = 1.0828 step_size = 0.4554 reward = -0.0000 fps = 7 mse_loss = 0.6125 
2022-05-01 17:07:20.162520 - gail/main.py:164 - [TRPO] iter = 1962000 dist_mean = 0.0416 dist_std = 0.1398 vf_loss = 0.0410 grad_norm = 4.9741 nat_grad_norm = 0.0826 cg_residual = 1.5309 step_size = 0.4515 reward = 0.0000 fps = 6 mse_loss = 0.6461 
2022-05-01 17:07:29.626022 - gail/main.py:164 - [TRPO] iter = 1963000 dist_mean = 0.0572 dist_std = 0.1401 vf_loss = 0.0111 grad_norm = 4.1823 nat_grad_norm = 0.1174 cg_residual = 5.3504 step_size = 0.3011 reward = 0.0000 fps = 6 mse_loss = 0.5795 
2022-05-01 17:07:39.000326 - gail/main.py:164 - [TRPO] iter = 1964000 dist_mean = 0.0392 dist_std = 0.1401 vf_loss = 0.0386 grad_norm = 2.9982 nat_grad_norm = 0.0824 cg_residual = 1.3920 step_size = 0.4565 reward = -0.0000 fps = 5 mse_loss = 0.5273 
2022-05-01 17:07:48.674274 - gail/main.py:164 - [TRPO] iter = 1965000 dist_mean = 0.0543 dist_std = 0.1400 vf_loss = 0.0152 grad_norm = 5.0498 nat_grad_norm = 0.1201 cg_residual = 2.4341 step_size = 0.3382 reward = -0.0000 fps = 5 mse_loss = 0.6331 
2022-05-01 17:07:48.912144 - gail/main.py:191 - [Discriminator] iter = 1965000 loss = -0.4143 grad_norm = 4.4508 grad_penalty = 0.0606 regularization = 0.0000 true_logits = -0.5847 fake_logits = -1.0596 true_prob = 0.3981 fake_prob = 0.3242 
2022-05-01 17:09:58.605937 - gail/main.py:132 - [Evaluate] iter = 1965000 episode={ returns = 3595.6041 lengths = 1000 } discounted_episode={ returns = 2222.2583 lengths = 1000 } 
2022-05-01 17:10:08.186270 - gail/main.py:164 - [TRPO] iter = 1966000 dist_mean = 0.0876 dist_std = 0.1398 vf_loss = 0.1083 grad_norm = 4.9222 nat_grad_norm = 0.0636 cg_residual = 1.6007 step_size = 0.5525 reward = 0.0000 fps = 7 mse_loss = 0.5121 
2022-05-01 17:10:17.533336 - gail/main.py:164 - [TRPO] iter = 1967000 dist_mean = 0.0552 dist_std = 0.1398 vf_loss = 0.0577 grad_norm = 1.6344 nat_grad_norm = 0.1092 cg_residual = 1.9917 step_size = 0.4261 reward = 0.0000 fps = 6 mse_loss = 0.5372 
2022-05-01 17:10:26.797582 - gail/main.py:164 - [TRPO] iter = 1968000 dist_mean = 0.0478 dist_std = 0.1401 vf_loss = 0.0318 grad_norm = 3.5452 nat_grad_norm = 0.0647 cg_residual = 1.8635 step_size = 0.4874 reward = 0.0000 fps = 6 mse_loss = 0.5478 
2022-05-01 17:10:36.537225 - gail/main.py:164 - [TRPO] iter = 1969000 dist_mean = 0.0549 dist_std = 0.1401 vf_loss = 0.0929 grad_norm = 3.7344 nat_grad_norm = 0.0729 cg_residual = 1.7441 step_size = 0.4604 reward = 0.0000 fps = 5 mse_loss = 0.5530 
2022-05-01 17:10:46.105906 - gail/main.py:164 - [TRPO] iter = 1970000 dist_mean = 0.0671 dist_std = 0.1402 vf_loss = 0.0995 grad_norm = 2.6164 nat_grad_norm = 0.0440 cg_residual = 0.7536 step_size = 0.7131 reward = -0.0000 fps = 5 mse_loss = 0.5140 
2022-05-01 17:10:46.364009 - gail/main.py:191 - [Discriminator] iter = 1970000 loss = -0.3984 grad_norm = 4.4586 grad_penalty = 0.0649 regularization = 0.0000 true_logits = -0.5255 fake_logits = -0.9888 true_prob = 0.4058 fake_prob = 0.3401 
2022-05-01 17:12:55.207870 - gail/main.py:132 - [Evaluate] iter = 1970000 episode={ returns = 3602.1006 lengths = 1000 } discounted_episode={ returns = 2228.4716 lengths = 1000 } 
2022-05-01 17:13:04.820830 - gail/main.py:164 - [TRPO] iter = 1971000 dist_mean = 0.0662 dist_std = 0.1401 vf_loss = 0.0981 grad_norm = 2.6266 nat_grad_norm = 0.0627 cg_residual = 1.0102 step_size = 0.5591 reward = 0.0000 fps = 7 mse_loss = 0.5232 
2022-05-01 17:13:14.558752 - gail/main.py:164 - [TRPO] iter = 1972000 dist_mean = 0.0578 dist_std = 0.1402 vf_loss = 0.1218 grad_norm = 3.0458 nat_grad_norm = 0.0578 cg_residual = 0.6673 step_size = 0.6269 reward = -0.0000 fps = 6 mse_loss = 0.5089 
2022-05-01 17:13:24.264059 - gail/main.py:164 - [TRPO] iter = 1973000 dist_mean = 0.0559 dist_std = 0.1402 vf_loss = 0.0902 grad_norm = 2.8971 nat_grad_norm = 0.0547 cg_residual = 0.4092 step_size = 0.6056 reward = 0.0000 fps = 6 mse_loss = 0.5261 
2022-05-01 17:13:33.573862 - gail/main.py:164 - [TRPO] iter = 1974000 dist_mean = 0.0784 dist_std = 0.1398 vf_loss = 0.1129 grad_norm = 3.3383 nat_grad_norm = 0.0444 cg_residual = 0.6211 step_size = 0.7407 reward = -0.0000 fps = 5 mse_loss = 0.5456 
2022-05-01 17:13:43.299305 - gail/main.py:164 - [TRPO] iter = 1975000 dist_mean = 0.0724 dist_std = 0.1399 vf_loss = 0.1198 grad_norm = 2.1419 nat_grad_norm = 0.0542 cg_residual = 0.5901 step_size = 0.6906 reward = -0.0000 fps = 5 mse_loss = 0.5324 
2022-05-01 17:13:43.560719 - gail/main.py:191 - [Discriminator] iter = 1975000 loss = -0.5163 grad_norm = 4.5398 grad_penalty = 0.0650 regularization = 0.0000 true_logits = -0.3654 fake_logits = -0.9467 true_prob = 0.4326 fake_prob = 0.3435 
2022-05-01 17:15:53.087321 - gail/main.py:132 - [Evaluate] iter = 1975000 episode={ returns = 3578.8368 lengths = 1000 } discounted_episode={ returns = 2216.5884 lengths = 1000 } 
2022-05-01 17:16:02.822046 - gail/main.py:164 - [TRPO] iter = 1976000 dist_mean = 0.0649 dist_std = 0.1400 vf_loss = 0.0748 grad_norm = 4.4811 nat_grad_norm = 0.0588 cg_residual = 1.3275 step_size = 0.5287 reward = 0.0000 fps = 7 mse_loss = 0.5652 
2022-05-01 17:16:12.445727 - gail/main.py:164 - [TRPO] iter = 1977000 dist_mean = 0.0605 dist_std = 0.1401 vf_loss = 0.0980 grad_norm = 3.4727 nat_grad_norm = 0.0435 cg_residual = 0.5474 step_size = 0.6804 reward = -0.0000 fps = 6 mse_loss = 0.5965 
2022-05-01 17:16:21.905643 - gail/main.py:164 - [TRPO] iter = 1978000 dist_mean = 0.0777 dist_std = 0.1401 vf_loss = 0.0791 grad_norm = 3.6706 nat_grad_norm = 0.0594 cg_residual = 1.2381 step_size = 0.5531 reward = 0.0000 fps = 6 mse_loss = 0.5767 
2022-05-01 17:16:31.484816 - gail/main.py:164 - [TRPO] iter = 1979000 dist_mean = 0.0784 dist_std = 0.1402 vf_loss = 0.1022 grad_norm = 3.6643 nat_grad_norm = 0.0623 cg_residual = 0.9541 step_size = 0.5466 reward = 0.0000 fps = 5 mse_loss = 0.5992 
2022-05-01 17:16:40.961362 - gail/main.py:164 - [TRPO] iter = 1980000 dist_mean = 0.0750 dist_std = 0.1396 vf_loss = 0.1061 grad_norm = 3.9891 nat_grad_norm = 0.0517 cg_residual = 0.9185 step_size = 0.6483 reward = -0.0000 fps = 5 mse_loss = 0.6062 
2022-05-01 17:16:41.193457 - gail/main.py:191 - [Discriminator] iter = 1980000 loss = -0.4525 grad_norm = 4.3915 grad_penalty = 0.0668 regularization = 0.0000 true_logits = -0.4136 fake_logits = -0.9329 true_prob = 0.4205 fake_prob = 0.3418 
2022-05-01 17:18:48.513580 - gail/main.py:132 - [Evaluate] iter = 1980000 episode={ returns = 3579.0189 lengths = 1000 } discounted_episode={ returns = 2219.7662 lengths = 1000 } 
2022-05-01 17:18:58.156166 - gail/main.py:164 - [TRPO] iter = 1981000 dist_mean = 0.0605 dist_std = 0.1398 vf_loss = 0.0226 grad_norm = 3.8720 nat_grad_norm = 0.0836 cg_residual = 1.5254 step_size = 0.4314 reward = -0.0000 fps = 7 mse_loss = 0.6223 
2022-05-01 17:19:07.489097 - gail/main.py:164 - [TRPO] iter = 1982000 dist_mean = 0.0822 dist_std = 0.1398 vf_loss = 0.0785 grad_norm = 3.4379 nat_grad_norm = 0.0648 cg_residual = 1.1853 step_size = 0.5460 reward = -0.0000 fps = 6 mse_loss = 0.6297 
2022-05-01 17:19:16.935002 - gail/main.py:164 - [TRPO] iter = 1983000 dist_mean = 0.0760 dist_std = 0.1399 vf_loss = 0.0811 grad_norm = 5.8224 nat_grad_norm = 0.0532 cg_residual = 0.8924 step_size = 0.5102 reward = 0.0000 fps = 6 mse_loss = 0.6490 
2022-05-01 17:19:26.257625 - gail/main.py:164 - [TRPO] iter = 1984000 dist_mean = 0.0792 dist_std = 0.1397 vf_loss = 0.0573 grad_norm = 5.9158 nat_grad_norm = 0.0550 cg_residual = 0.8281 step_size = 0.5016 reward = -0.0000 fps = 6 mse_loss = 0.5942 
2022-05-01 17:19:35.780917 - gail/main.py:164 - [TRPO] iter = 1985000 dist_mean = 0.0591 dist_std = 0.1398 vf_loss = 0.0678 grad_norm = 4.3090 nat_grad_norm = 0.0894 cg_residual = 2.6999 step_size = 0.4159 reward = 0.0000 fps = 5 mse_loss = 0.5998 
2022-05-01 17:19:36.011539 - gail/main.py:191 - [Discriminator] iter = 1985000 loss = -0.3950 grad_norm = 3.3944 grad_penalty = 0.0638 regularization = 0.0000 true_logits = -0.4319 fake_logits = -0.8907 true_prob = 0.4124 fake_prob = 0.3422 
2022-05-01 17:21:45.265807 - gail/main.py:132 - [Evaluate] iter = 1985000 episode={ returns = 3568.0848 lengths = 1000 } discounted_episode={ returns = 2210.0763 lengths = 1000 } 
2022-05-01 17:21:54.640716 - gail/main.py:164 - [TRPO] iter = 1986000 dist_mean = 0.0822 dist_std = 0.1398 vf_loss = 0.0796 grad_norm = 4.3121 nat_grad_norm = 0.0471 cg_residual = 1.1432 step_size = 0.5892 reward = 0.0000 fps = 7 mse_loss = 0.5605 
2022-05-01 17:22:04.036897 - gail/main.py:164 - [TRPO] iter = 1987000 dist_mean = 0.0717 dist_std = 0.1401 vf_loss = 0.0873 grad_norm = 6.0636 nat_grad_norm = 0.0629 cg_residual = 0.8796 step_size = 0.5015 reward = 0.0000 fps = 6 mse_loss = 0.5750 
2022-05-01 17:22:13.343075 - gail/main.py:164 - [TRPO] iter = 1988000 dist_mean = 0.0663 dist_std = 0.1402 vf_loss = 0.0512 grad_norm = 3.8784 nat_grad_norm = 0.0530 cg_residual = 0.7126 step_size = 0.5637 reward = 0.0000 fps = 6 mse_loss = 0.5320 
2022-05-01 17:22:22.851165 - gail/main.py:164 - [TRPO] iter = 1989000 dist_mean = 0.0752 dist_std = 0.1402 vf_loss = 0.0507 grad_norm = 5.3087 nat_grad_norm = 0.0849 cg_residual = 2.2458 step_size = 0.4043 reward = 0.0000 fps = 5 mse_loss = 0.5797 
2022-05-01 17:22:32.513284 - gail/main.py:164 - [TRPO] iter = 1990000 dist_mean = 0.0138 dist_std = 0.1402 vf_loss = 0.0264 grad_norm = 3.5997 nat_grad_norm = 0.0761 cg_residual = 0.8936 step_size = 0.4628 reward = -0.0000 fps = 5 mse_loss = 0.5936 
2022-05-01 17:22:32.774518 - gail/main.py:191 - [Discriminator] iter = 1990000 loss = -0.4245 grad_norm = 4.0987 grad_penalty = 0.0685 regularization = 0.0000 true_logits = -0.3210 fake_logits = -0.8140 true_prob = 0.4324 fake_prob = 0.3453 
2022-05-01 17:24:42.420279 - gail/main.py:132 - [Evaluate] iter = 1990000 episode={ returns = 3580.0464 lengths = 1000 } discounted_episode={ returns = 2217.0383 lengths = 1000 } 
2022-05-01 17:24:51.976470 - gail/main.py:164 - [TRPO] iter = 1991000 dist_mean = 0.0599 dist_std = 0.1400 vf_loss = 0.0250 grad_norm = 4.7246 nat_grad_norm = 0.0773 cg_residual = 1.4392 step_size = 0.4352 reward = -0.0000 fps = 7 mse_loss = 0.5532 
2022-05-01 17:25:01.720595 - gail/main.py:164 - [TRPO] iter = 1992000 dist_mean = 0.0577 dist_std = 0.1404 vf_loss = 0.0240 grad_norm = 5.8805 nat_grad_norm = 0.0872 cg_residual = 1.4057 step_size = 0.4112 reward = -0.0000 fps = 6 mse_loss = 0.5921 
2022-05-01 17:25:11.227225 - gail/main.py:164 - [TRPO] iter = 1993000 dist_mean = 0.0616 dist_std = 0.1408 vf_loss = 0.0246 grad_norm = 5.9340 nat_grad_norm = 0.0602 cg_residual = 1.1931 step_size = 0.4663 reward = -0.0000 fps = 6 mse_loss = 0.6134 
2022-05-01 17:25:20.797340 - gail/main.py:164 - [TRPO] iter = 1994000 dist_mean = 0.0265 dist_std = 0.1406 vf_loss = 0.0288 grad_norm = 4.9202 nat_grad_norm = 0.0763 cg_residual = 1.4872 step_size = 0.4371 reward = -0.0000 fps = 5 mse_loss = 0.5959 
2022-05-01 17:25:30.086033 - gail/main.py:164 - [TRPO] iter = 1995000 dist_mean = 0.0728 dist_std = 0.1409 vf_loss = 0.0188 grad_norm = 5.0830 nat_grad_norm = 0.0665 cg_residual = 1.0647 step_size = 0.4609 reward = -0.0000 fps = 5 mse_loss = 0.5786 
2022-05-01 17:25:30.369261 - gail/main.py:191 - [Discriminator] iter = 1995000 loss = -0.4598 grad_norm = 4.3201 grad_penalty = 0.0628 regularization = 0.0000 true_logits = -0.2430 fake_logits = -0.7657 true_prob = 0.4402 fake_prob = 0.3561 
2022-05-01 17:27:41.016249 - gail/main.py:132 - [Evaluate] iter = 1995000 episode={ returns = 3560.4311 lengths = 1000 } discounted_episode={ returns = 2209.7529 lengths = 1000 } 
2022-05-01 17:27:50.424915 - gail/main.py:164 - [TRPO] iter = 1996000 dist_mean = 0.0083 dist_std = 0.1406 vf_loss = 0.0467 grad_norm = 4.5979 nat_grad_norm = 0.0895 cg_residual = 1.2651 step_size = 0.4173 reward = 0.0000 fps = 7 mse_loss = 0.5942 
2022-05-01 17:27:59.556366 - gail/main.py:164 - [TRPO] iter = 1997000 dist_mean = 0.0511 dist_std = 0.1405 vf_loss = 0.0164 grad_norm = 3.2583 nat_grad_norm = 0.0704 cg_residual = 1.4796 step_size = 0.4185 reward = 0.0000 fps = 6 mse_loss = 0.5913 
2022-05-01 17:28:09.430007 - gail/main.py:164 - [TRPO] iter = 1998000 dist_mean = 0.0438 dist_std = 0.1401 vf_loss = 0.0402 grad_norm = 3.6280 nat_grad_norm = 0.0623 cg_residual = 1.3425 step_size = 0.4923 reward = 0.0000 fps = 6 mse_loss = 0.6082 
2022-05-01 17:28:18.746820 - gail/main.py:164 - [TRPO] iter = 1999000 dist_mean = 0.0820 dist_std = 0.1402 vf_loss = 0.0397 grad_norm = 4.2359 nat_grad_norm = 0.0899 cg_residual = 2.2284 step_size = 0.3953 reward = -0.0000 fps = 5 mse_loss = 0.6191 
2022-05-01 17:28:27.622106 - gail/main.py:164 - [TRPO] iter = 2000000 dist_mean = 0.0529 dist_std = 0.1403 vf_loss = 0.0258 grad_norm = 3.6854 nat_grad_norm = 0.0658 cg_residual = 1.3170 step_size = 0.5085 reward = 0.0000 fps = 5 mse_loss = 0.6130 
2022-05-01 17:28:27.857163 - gail/main.py:191 - [Discriminator] iter = 2000000 loss = -0.3043 grad_norm = 3.8363 grad_penalty = 0.0651 regularization = 0.0000 true_logits = -0.4160 fake_logits = -0.7855 true_prob = 0.4101 fake_prob = 0.3514 
2022-05-01 17:30:36.408557 - gail/main.py:132 - [Evaluate] iter = 2000000 episode={ returns = 3546.6732 lengths = 1000 } discounted_episode={ returns = 2199.6284 lengths = 1000 } 
2022-05-01 17:30:46.058017 - gail/main.py:164 - [TRPO] iter = 2001000 dist_mean = 0.0548 dist_std = 0.1403 vf_loss = 0.0306 grad_norm = 3.4283 nat_grad_norm = 0.0707 cg_residual = 1.9779 step_size = 0.4757 reward = 0.0000 fps = 7 mse_loss = 0.6049 
2022-05-01 17:30:55.631678 - gail/main.py:164 - [TRPO] iter = 2002000 dist_mean = 0.0346 dist_std = 0.1405 vf_loss = 0.0479 grad_norm = 3.3438 nat_grad_norm = 0.0558 cg_residual = 0.7970 step_size = 0.5836 reward = -0.0000 fps = 6 mse_loss = 0.5814 
2022-05-01 17:31:05.258174 - gail/main.py:164 - [TRPO] iter = 2003000 dist_mean = 0.0501 dist_std = 0.1402 vf_loss = 0.0295 grad_norm = 4.7424 nat_grad_norm = 0.0957 cg_residual = 2.9122 step_size = 0.4007 reward = 0.0000 fps = 6 mse_loss = 0.5658 
2022-05-01 17:31:14.788243 - gail/main.py:164 - [TRPO] iter = 2004000 dist_mean = 0.0629 dist_std = 0.1400 vf_loss = 0.0140 grad_norm = 5.1956 nat_grad_norm = 0.0448 cg_residual = 1.0662 step_size = 0.5171 reward = 0.0000 fps = 5 mse_loss = 0.5547 
2022-05-01 17:31:24.026866 - gail/main.py:164 - [TRPO] iter = 2005000 dist_mean = 0.0627 dist_std = 0.1401 vf_loss = 0.0242 grad_norm = 4.4919 nat_grad_norm = 0.0830 cg_residual = 3.1429 step_size = 0.3791 reward = 0.0000 fps = 5 mse_loss = 0.5528 
2022-05-01 17:31:24.283387 - gail/main.py:191 - [Discriminator] iter = 2005000 loss = -0.3408 grad_norm = 5.1130 grad_penalty = 0.0663 regularization = 0.0000 true_logits = -0.5254 fake_logits = -0.9326 true_prob = 0.3866 fake_prob = 0.3263 
2022-05-01 17:33:31.511157 - gail/main.py:132 - [Evaluate] iter = 2005000 episode={ returns = 3545.4392 lengths = 1000 } discounted_episode={ returns = 2202.0638 lengths = 1000 } 
2022-05-01 17:33:40.993974 - gail/main.py:164 - [TRPO] iter = 2006000 dist_mean = 0.0658 dist_std = 0.1402 vf_loss = 0.0337 grad_norm = 3.4904 nat_grad_norm = 0.0537 cg_residual = 1.5805 step_size = 0.5218 reward = 0.0000 fps = 7 mse_loss = 0.5345 
2022-05-01 17:33:50.832178 - gail/main.py:164 - [TRPO] iter = 2007000 dist_mean = 0.0472 dist_std = 0.1403 vf_loss = 0.0251 grad_norm = 3.0091 nat_grad_norm = 0.0630 cg_residual = 2.4637 step_size = 0.5204 reward = 0.0000 fps = 6 mse_loss = 0.5760 
2022-05-01 17:34:00.258386 - gail/main.py:164 - [TRPO] iter = 2008000 dist_mean = 0.0675 dist_std = 0.1403 vf_loss = 0.0370 grad_norm = 3.1003 nat_grad_norm = 0.0925 cg_residual = 1.8187 step_size = 0.4082 reward = -0.0000 fps = 6 mse_loss = 0.5591 
2022-05-01 17:34:10.046825 - gail/main.py:164 - [TRPO] iter = 2009000 dist_mean = 0.0593 dist_std = 0.1404 vf_loss = 0.0424 grad_norm = 3.9793 nat_grad_norm = 0.0803 cg_residual = 2.4561 step_size = 0.4440 reward = -0.0000 fps = 6 mse_loss = 0.5756 
2022-05-01 17:34:19.546521 - gail/main.py:164 - [TRPO] iter = 2010000 dist_mean = 0.0592 dist_std = 0.1403 vf_loss = 0.0178 grad_norm = 5.0334 nat_grad_norm = 0.0873 cg_residual = 4.0478 step_size = 0.3844 reward = 0.0000 fps = 5 mse_loss = 0.6072 
2022-05-01 17:34:19.765172 - gail/main.py:191 - [Discriminator] iter = 2010000 loss = -0.4180 grad_norm = 4.5893 grad_penalty = 0.0596 regularization = 0.0000 true_logits = -0.5717 fake_logits = -1.0493 true_prob = 0.3759 fake_prob = 0.3008 
2022-05-01 17:36:29.458823 - gail/main.py:132 - [Evaluate] iter = 2010000 episode={ returns = 3553.0578 lengths = 1000 } discounted_episode={ returns = 2206.4210 lengths = 1000 } 
2022-05-01 17:36:39.207005 - gail/main.py:164 - [TRPO] iter = 2011000 dist_mean = 0.0460 dist_std = 0.1404 vf_loss = 0.0204 grad_norm = 3.0658 nat_grad_norm = 0.1002 cg_residual = 2.1046 step_size = 0.4264 reward = -0.0000 fps = 7 mse_loss = 0.5617 
2022-05-01 17:36:48.624461 - gail/main.py:164 - [TRPO] iter = 2012000 dist_mean = 0.0498 dist_std = 0.1406 vf_loss = 0.0145 grad_norm = 3.9514 nat_grad_norm = 0.0660 cg_residual = 2.8179 step_size = 0.4542 reward = -0.0000 fps = 6 mse_loss = 0.5473 
2022-05-01 17:36:58.160920 - gail/main.py:164 - [TRPO] iter = 2013000 dist_mean = 0.0565 dist_std = 0.1407 vf_loss = 0.0132 grad_norm = 4.5656 nat_grad_norm = 0.0705 cg_residual = 3.3944 step_size = 0.4724 reward = -0.0000 fps = 6 mse_loss = 0.5537 
2022-05-01 17:37:07.972333 - gail/main.py:164 - [TRPO] iter = 2014000 dist_mean = 0.0569 dist_std = 0.1404 vf_loss = 0.0681 grad_norm = 3.9136 nat_grad_norm = 0.0792 cg_residual = 1.1062 step_size = 0.4495 reward = 0.0000 fps = 5 mse_loss = 0.5376 
2022-05-01 17:37:17.348206 - gail/main.py:164 - [TRPO] iter = 2015000 dist_mean = 0.0527 dist_std = 0.1403 vf_loss = 0.0214 grad_norm = 4.6570 nat_grad_norm = 0.0641 cg_residual = 1.5259 step_size = 0.5082 reward = -0.0000 fps = 5 mse_loss = 0.5146 
2022-05-01 17:37:17.556828 - gail/main.py:191 - [Discriminator] iter = 2015000 loss = -0.3967 grad_norm = 4.6296 grad_penalty = 0.0629 regularization = 0.0000 true_logits = -0.6592 fake_logits = -1.1187 true_prob = 0.3649 fake_prob = 0.2880 
2022-05-01 17:39:22.288905 - gail/main.py:132 - [Evaluate] iter = 2015000 episode={ returns = 3528.1281 lengths = 1000 } discounted_episode={ returns = 2189.8504 lengths = 1000 } 
2022-05-01 17:39:31.237805 - gail/main.py:164 - [TRPO] iter = 2016000 dist_mean = 0.0439 dist_std = 0.1403 vf_loss = 0.0171 grad_norm = 4.5022 nat_grad_norm = 0.0698 cg_residual = 2.1249 step_size = 0.4372 reward = -0.0000 fps = 7 mse_loss = 0.5354 
2022-05-01 17:39:40.428263 - gail/main.py:164 - [TRPO] iter = 2017000 dist_mean = 0.0458 dist_std = 0.1404 vf_loss = 0.0189 grad_norm = 3.0622 nat_grad_norm = 0.0798 cg_residual = 1.2888 step_size = 0.4314 reward = 0.0000 fps = 7 mse_loss = 0.5488 
2022-05-01 17:39:49.466267 - gail/main.py:164 - [TRPO] iter = 2018000 dist_mean = 0.0254 dist_std = 0.1404 vf_loss = 0.0124 grad_norm = 5.5046 nat_grad_norm = 0.1081 cg_residual = 3.3924 step_size = 0.3639 reward = -0.0000 fps = 6 mse_loss = 0.5323 
2022-05-01 17:39:59.015231 - gail/main.py:164 - [TRPO] iter = 2019000 dist_mean = 0.0205 dist_std = 0.1400 vf_loss = 0.0153 grad_norm = 4.5831 nat_grad_norm = 0.0843 cg_residual = 2.7238 step_size = 0.4240 reward = -0.0000 fps = 6 mse_loss = 0.5491 
2022-05-01 17:40:08.541107 - gail/main.py:164 - [TRPO] iter = 2020000 dist_mean = -0.0067 dist_std = 0.1403 vf_loss = 0.0271 grad_norm = 4.2187 nat_grad_norm = 0.0816 cg_residual = 2.5638 step_size = 0.4220 reward = -0.0000 fps = 5 mse_loss = 0.6114 
2022-05-01 17:40:08.749223 - gail/main.py:191 - [Discriminator] iter = 2020000 loss = -0.4289 grad_norm = 4.8337 grad_penalty = 0.0594 regularization = 0.0000 true_logits = -0.8089 fake_logits = -1.2972 true_prob = 0.3402 fake_prob = 0.2555 
2022-05-01 17:42:14.278547 - gail/main.py:132 - [Evaluate] iter = 2020000 episode={ returns = 3539.8671 lengths = 1000 } discounted_episode={ returns = 2197.6505 lengths = 1000 } 
2022-05-01 17:42:23.599681 - gail/main.py:164 - [TRPO] iter = 2021000 dist_mean = 0.0343 dist_std = 0.1401 vf_loss = 0.0180 grad_norm = 4.1509 nat_grad_norm = 0.0563 cg_residual = 1.3176 step_size = 0.5661 reward = 0.0000 fps = 7 mse_loss = 0.5314 
2022-05-01 17:42:33.173920 - gail/main.py:164 - [TRPO] iter = 2022000 dist_mean = 0.0369 dist_std = 0.1400 vf_loss = 0.0134 grad_norm = 4.2821 nat_grad_norm = 0.0653 cg_residual = 1.0855 step_size = 0.4501 reward = 0.0000 fps = 6 mse_loss = 0.5350 
2022-05-01 17:42:42.665287 - gail/main.py:164 - [TRPO] iter = 2023000 dist_mean = 0.0628 dist_std = 0.1398 vf_loss = 0.0274 grad_norm = 3.7909 nat_grad_norm = 0.0924 cg_residual = 2.1795 step_size = 0.3854 reward = -0.0000 fps = 6 mse_loss = 0.5498 
2022-05-01 17:42:52.100004 - gail/main.py:164 - [TRPO] iter = 2024000 dist_mean = 0.0268 dist_std = 0.1398 vf_loss = 0.0255 grad_norm = 3.5380 nat_grad_norm = 0.0617 cg_residual = 1.2856 step_size = 0.5103 reward = 0.0000 fps = 6 mse_loss = 0.5117 
2022-05-01 17:43:01.288862 - gail/main.py:164 - [TRPO] iter = 2025000 dist_mean = 0.0379 dist_std = 0.1397 vf_loss = 0.0330 grad_norm = 3.9371 nat_grad_norm = 0.0602 cg_residual = 0.9263 step_size = 0.4958 reward = 0.0000 fps = 5 mse_loss = 0.5884 
2022-05-01 17:43:01.494884 - gail/main.py:191 - [Discriminator] iter = 2025000 loss = -0.4043 grad_norm = 4.5650 grad_penalty = 0.0615 regularization = 0.0000 true_logits = -0.8655 fake_logits = -1.3314 true_prob = 0.3285 fake_prob = 0.2450 
2022-05-01 17:45:07.240246 - gail/main.py:132 - [Evaluate] iter = 2025000 episode={ returns = 3581.1780 lengths = 1000 } discounted_episode={ returns = 2218.4538 lengths = 1000 } 
2022-05-01 17:45:16.730627 - gail/main.py:164 - [TRPO] iter = 2026000 dist_mean = 0.0583 dist_std = 0.1398 vf_loss = 0.0276 grad_norm = 3.8066 nat_grad_norm = 0.0609 cg_residual = 1.3272 step_size = 0.5172 reward = 0.0000 fps = 7 mse_loss = 0.5566 
2022-05-01 17:45:26.308771 - gail/main.py:164 - [TRPO] iter = 2027000 dist_mean = 0.0588 dist_std = 0.1399 vf_loss = 0.0386 grad_norm = 3.9738 nat_grad_norm = 0.0668 cg_residual = 1.4316 step_size = 0.4784 reward = -0.0000 fps = 6 mse_loss = 0.5431 
2022-05-01 17:45:35.313394 - gail/main.py:164 - [TRPO] iter = 2028000 dist_mean = 0.0363 dist_std = 0.1399 vf_loss = 0.0125 grad_norm = 2.6656 nat_grad_norm = 0.0686 cg_residual = 1.8845 step_size = 0.4697 reward = 0.0000 fps = 6 mse_loss = 0.5726 
2022-05-01 17:45:44.627948 - gail/main.py:164 - [TRPO] iter = 2029000 dist_mean = 0.0379 dist_std = 0.1398 vf_loss = 0.0211 grad_norm = 1.8106 nat_grad_norm = 0.0777 cg_residual = 1.8025 step_size = 0.5447 reward = -0.0000 fps = 6 mse_loss = 0.5640 
2022-05-01 17:45:54.396452 - gail/main.py:164 - [TRPO] iter = 2030000 dist_mean = 0.0487 dist_std = 0.1400 vf_loss = 0.0128 grad_norm = 4.1474 nat_grad_norm = 0.0574 cg_residual = 1.3427 step_size = 0.4634 reward = -0.0000 fps = 5 mse_loss = 0.6078 
2022-05-01 17:45:54.627862 - gail/main.py:191 - [Discriminator] iter = 2030000 loss = -0.3052 grad_norm = 4.5491 grad_penalty = 0.0587 regularization = 0.0000 true_logits = -0.9276 fake_logits = -1.2916 true_prob = 0.3154 fake_prob = 0.2490 
2022-05-01 17:47:59.531351 - gail/main.py:132 - [Evaluate] iter = 2030000 episode={ returns = 3573.4853 lengths = 1000 } discounted_episode={ returns = 2215.6270 lengths = 1000 } 
2022-05-01 17:48:09.095918 - gail/main.py:164 - [TRPO] iter = 2031000 dist_mean = 0.0095 dist_std = 0.1403 vf_loss = 0.0219 grad_norm = 4.1588 nat_grad_norm = 0.0707 cg_residual = 2.0871 step_size = 0.4702 reward = 0.0000 fps = 7 mse_loss = 0.5585 
2022-05-01 17:48:18.533340 - gail/main.py:164 - [TRPO] iter = 2032000 dist_mean = 0.0590 dist_std = 0.1403 vf_loss = 0.0646 grad_norm = 3.8074 nat_grad_norm = 0.0584 cg_residual = 1.1501 step_size = 0.5197 reward = -0.0000 fps = 6 mse_loss = 0.5515 
2022-05-01 17:48:27.673091 - gail/main.py:164 - [TRPO] iter = 2033000 dist_mean = -0.0081 dist_std = 0.1403 vf_loss = 0.0250 grad_norm = 4.8479 nat_grad_norm = 0.0907 cg_residual = 2.1610 step_size = 0.3881 reward = -0.0000 fps = 6 mse_loss = 0.5688 
2022-05-01 17:48:37.135907 - gail/main.py:164 - [TRPO] iter = 2034000 dist_mean = 0.0555 dist_std = 0.1403 vf_loss = 0.0140 grad_norm = 2.7330 nat_grad_norm = 0.0979 cg_residual = 1.9410 step_size = 0.4712 reward = 0.0000 fps = 6 mse_loss = 0.5595 
2022-05-01 17:48:46.884982 - gail/main.py:164 - [TRPO] iter = 2035000 dist_mean = 0.0186 dist_std = 0.1403 vf_loss = 0.0189 grad_norm = 4.5681 nat_grad_norm = 0.0979 cg_residual = 2.1610 step_size = 0.3618 reward = 0.0000 fps = 5 mse_loss = 0.5546 
2022-05-01 17:48:47.136991 - gail/main.py:191 - [Discriminator] iter = 2035000 loss = -0.3881 grad_norm = 3.7189 grad_penalty = 0.0502 regularization = 0.0000 true_logits = -0.7863 fake_logits = -1.2247 true_prob = 0.3365 fake_prob = 0.2549 
2022-05-01 17:50:51.774223 - gail/main.py:132 - [Evaluate] iter = 2035000 episode={ returns = 3588.9698 lengths = 1000 } discounted_episode={ returns = 2222.0660 lengths = 1000 } 
2022-05-01 17:51:01.184799 - gail/main.py:164 - [TRPO] iter = 2036000 dist_mean = 0.0507 dist_std = 0.1404 vf_loss = 0.0224 grad_norm = 3.7213 nat_grad_norm = 0.0663 cg_residual = 1.5722 step_size = 0.4736 reward = 0.0000 fps = 7 mse_loss = 0.6340 
2022-05-01 17:51:11.214348 - gail/main.py:164 - [TRPO] iter = 2037000 dist_mean = 0.0448 dist_std = 0.1405 vf_loss = 0.0254 grad_norm = 2.8751 nat_grad_norm = 0.0669 cg_residual = 0.8737 step_size = 0.5514 reward = 0.0000 fps = 6 mse_loss = 0.5786 
2022-05-01 17:51:20.802020 - gail/main.py:164 - [TRPO] iter = 2038000 dist_mean = 0.0580 dist_std = 0.1406 vf_loss = 0.0231 grad_norm = 3.4912 nat_grad_norm = 0.0654 cg_residual = 1.6675 step_size = 0.4975 reward = -0.0000 fps = 6 mse_loss = 0.6267 
2022-05-01 17:51:29.672023 - gail/main.py:164 - [TRPO] iter = 2039000 dist_mean = 0.0556 dist_std = 0.1407 vf_loss = 0.0776 grad_norm = 3.3907 nat_grad_norm = 0.0808 cg_residual = 0.8919 step_size = 0.4304 reward = 0.0000 fps = 6 mse_loss = 0.5601 
2022-05-01 17:51:39.011570 - gail/main.py:164 - [TRPO] iter = 2040000 dist_mean = 0.0642 dist_std = 0.1408 vf_loss = 0.0300 grad_norm = 4.1458 nat_grad_norm = 0.0729 cg_residual = 1.9303 step_size = 0.5034 reward = -0.0000 fps = 5 mse_loss = 0.5402 
2022-05-01 17:51:39.236088 - gail/main.py:191 - [Discriminator] iter = 2040000 loss = -0.3718 grad_norm = 5.1688 grad_penalty = 0.0550 regularization = 0.0000 true_logits = -0.6560 fake_logits = -1.0828 true_prob = 0.3601 fake_prob = 0.2753 
2022-05-01 17:53:42.846702 - gail/main.py:132 - [Evaluate] iter = 2040000 episode={ returns = 3599.8791 lengths = 1000 } discounted_episode={ returns = 2228.2571 lengths = 1000 } 
2022-05-01 17:53:52.472544 - gail/main.py:164 - [TRPO] iter = 2041000 dist_mean = 0.0598 dist_std = 0.1407 vf_loss = 0.0376 grad_norm = 3.9491 nat_grad_norm = 0.0724 cg_residual = 0.8817 step_size = 0.4785 reward = 0.0000 fps = 7 mse_loss = 0.5640 
2022-05-01 17:54:01.729731 - gail/main.py:164 - [TRPO] iter = 2042000 dist_mean = 0.0632 dist_std = 0.1406 vf_loss = 0.0668 grad_norm = 2.7716 nat_grad_norm = 0.0648 cg_residual = 1.7274 step_size = 0.6104 reward = -0.0000 fps = 7 mse_loss = 0.5487 
2022-05-01 17:54:11.053222 - gail/main.py:164 - [TRPO] iter = 2043000 dist_mean = 0.0499 dist_std = 0.1407 vf_loss = 0.0153 grad_norm = 3.6978 nat_grad_norm = 0.0621 cg_residual = 1.0311 step_size = 0.5209 reward = -0.0000 fps = 6 mse_loss = 0.5272 
2022-05-01 17:54:20.804375 - gail/main.py:164 - [TRPO] iter = 2044000 dist_mean = 0.0562 dist_std = 0.1406 vf_loss = 0.0835 grad_norm = 3.4408 nat_grad_norm = 0.0586 cg_residual = 0.8014 step_size = 0.5925 reward = 0.0000 fps = 6 mse_loss = 0.5868 
2022-05-01 17:54:30.363080 - gail/main.py:164 - [TRPO] iter = 2045000 dist_mean = 0.0547 dist_std = 0.1408 vf_loss = 0.0463 grad_norm = 2.4174 nat_grad_norm = 0.0832 cg_residual = 1.5638 step_size = 0.5046 reward = -0.0000 fps = 5 mse_loss = 0.5551 
2022-05-01 17:54:30.580646 - gail/main.py:191 - [Discriminator] iter = 2045000 loss = -0.3086 grad_norm = 4.4344 grad_penalty = 0.0541 regularization = 0.0000 true_logits = -0.6566 fake_logits = -1.0192 true_prob = 0.3610 fake_prob = 0.2882 
2022-05-01 17:56:40.280156 - gail/main.py:132 - [Evaluate] iter = 2045000 episode={ returns = 3602.0988 lengths = 1000 } discounted_episode={ returns = 2230.2569 lengths = 1000 } 
2022-05-01 17:56:49.910624 - gail/main.py:164 - [TRPO] iter = 2046000 dist_mean = 0.0543 dist_std = 0.1409 vf_loss = 0.0118 grad_norm = 4.6642 nat_grad_norm = 0.0797 cg_residual = 2.5215 step_size = 0.4069 reward = 0.0000 fps = 7 mse_loss = 0.5887 
2022-05-01 17:56:59.436990 - gail/main.py:164 - [TRPO] iter = 2047000 dist_mean = 0.0556 dist_std = 0.1408 vf_loss = 0.0397 grad_norm = 2.7252 nat_grad_norm = 0.0493 cg_residual = 0.4967 step_size = 0.6444 reward = -0.0000 fps = 6 mse_loss = 0.5917 
2022-05-01 17:57:09.057452 - gail/main.py:164 - [TRPO] iter = 2048000 dist_mean = 0.0442 dist_std = 0.1411 vf_loss = 0.0588 grad_norm = 3.6188 nat_grad_norm = 0.1397 cg_residual = 4.4185 step_size = 0.2752 reward = 0.0000 fps = 6 mse_loss = 0.5812 
2022-05-01 17:57:18.546679 - gail/main.py:164 - [TRPO] iter = 2049000 dist_mean = 0.0658 dist_std = 0.1413 vf_loss = 0.0848 grad_norm = 2.6640 nat_grad_norm = 0.0618 cg_residual = 1.0174 step_size = 0.5742 reward = -0.0000 fps = 5 mse_loss = 0.5729 
2022-05-01 17:57:27.660020 - gail/main.py:164 - [TRPO] iter = 2050000 dist_mean = 0.0558 dist_std = 0.1409 vf_loss = 0.0501 grad_norm = 2.7282 nat_grad_norm = 0.0565 cg_residual = 1.4344 step_size = 0.6070 reward = 0.0000 fps = 5 mse_loss = 0.5763 
2022-05-01 17:57:27.911406 - gail/main.py:191 - [Discriminator] iter = 2050000 loss = -0.4254 grad_norm = 4.4046 grad_penalty = 0.0546 regularization = 0.0000 true_logits = -0.5577 fake_logits = -1.0377 true_prob = 0.3759 fake_prob = 0.2825 
2022-05-01 17:59:34.975011 - gail/main.py:132 - [Evaluate] iter = 2050000 episode={ returns = 3599.4440 lengths = 1000 } discounted_episode={ returns = 2228.7910 lengths = 1000 } 
2022-05-01 17:59:44.791440 - gail/main.py:164 - [TRPO] iter = 2051000 dist_mean = 0.0462 dist_std = 0.1411 vf_loss = 0.0099 grad_norm = 4.1923 nat_grad_norm = 0.0672 cg_residual = 1.3464 step_size = 0.4802 reward = 0.0000 fps = 7 mse_loss = 0.5411 
2022-05-01 17:59:54.134927 - gail/main.py:164 - [TRPO] iter = 2052000 dist_mean = 0.0601 dist_std = 0.1413 vf_loss = 0.0218 grad_norm = 2.8532 nat_grad_norm = 0.0770 cg_residual = 1.8462 step_size = 0.4980 reward = -0.0000 fps = 6 mse_loss = 0.5816 
2022-05-01 18:00:03.480756 - gail/main.py:164 - [TRPO] iter = 2053000 dist_mean = 0.0640 dist_std = 0.1412 vf_loss = 0.0522 grad_norm = 2.1393 nat_grad_norm = 0.0537 cg_residual = 1.0933 step_size = 0.6496 reward = 0.0000 fps = 6 mse_loss = 0.5577 
2022-05-01 18:00:12.715759 - gail/main.py:164 - [TRPO] iter = 2054000 dist_mean = 0.0646 dist_std = 0.1414 vf_loss = 0.0323 grad_norm = 2.5048 nat_grad_norm = 0.0710 cg_residual = 1.9300 step_size = 0.5124 reward = 0.0000 fps = 6 mse_loss = 0.5712 
2022-05-01 18:00:22.644793 - gail/main.py:164 - [TRPO] iter = 2055000 dist_mean = 0.0629 dist_std = 0.1411 vf_loss = 0.0384 grad_norm = 3.9245 nat_grad_norm = 0.0528 cg_residual = 0.9086 step_size = 0.5372 reward = -0.0000 fps = 5 mse_loss = 0.5505 
2022-05-01 18:00:22.908015 - gail/main.py:191 - [Discriminator] iter = 2055000 loss = -0.3613 grad_norm = 4.0965 grad_penalty = 0.0560 regularization = 0.0000 true_logits = -0.5464 fake_logits = -0.9637 true_prob = 0.3773 fake_prob = 0.2947 
2022-05-01 18:02:25.950140 - gail/main.py:132 - [Evaluate] iter = 2055000 episode={ returns = 3590.8026 lengths = 1000 } discounted_episode={ returns = 2221.4096 lengths = 1000 } 
2022-05-01 18:02:35.198483 - gail/main.py:164 - [TRPO] iter = 2056000 dist_mean = 0.0507 dist_std = 0.1414 vf_loss = 0.0194 grad_norm = 3.9425 nat_grad_norm = 0.0553 cg_residual = 1.4868 step_size = 0.5003 reward = 0.0000 fps = 7 mse_loss = 0.5524 
2022-05-01 18:02:44.542768 - gail/main.py:164 - [TRPO] iter = 2057000 dist_mean = 0.0595 dist_std = 0.1414 vf_loss = 0.0398 grad_norm = 3.3190 nat_grad_norm = 0.0536 cg_residual = 0.7557 step_size = 0.5732 reward = -0.0000 fps = 7 mse_loss = 0.5119 
2022-05-01 18:02:54.194500 - gail/main.py:164 - [TRPO] iter = 2058000 dist_mean = 0.0685 dist_std = 0.1416 vf_loss = 0.0147 grad_norm = 2.7808 nat_grad_norm = 0.0770 cg_residual = 2.0170 step_size = 0.5009 reward = -0.0000 fps = 6 mse_loss = 0.6036 
2022-05-01 18:03:03.985474 - gail/main.py:164 - [TRPO] iter = 2059000 dist_mean = 0.0625 dist_std = 0.1416 vf_loss = 0.0235 grad_norm = 4.6799 nat_grad_norm = 0.0704 cg_residual = 1.3011 step_size = 0.4866 reward = -0.0000 fps = 6 mse_loss = 0.5521 
2022-05-01 18:03:13.526721 - gail/main.py:164 - [TRPO] iter = 2060000 dist_mean = 0.0292 dist_std = 0.1416 vf_loss = 0.0186 grad_norm = 4.0984 nat_grad_norm = 0.0725 cg_residual = 2.1765 step_size = 0.4162 reward = -0.0000 fps = 5 mse_loss = 0.5396 
2022-05-01 18:03:13.767190 - gail/main.py:191 - [Discriminator] iter = 2060000 loss = -0.4040 grad_norm = 6.2999 grad_penalty = 0.0577 regularization = 0.0000 true_logits = -0.4158 fake_logits = -0.8774 true_prob = 0.4017 fake_prob = 0.3093 
2022-05-01 18:05:20.477528 - gail/main.py:132 - [Evaluate] iter = 2060000 episode={ returns = 3590.7122 lengths = 1000 } discounted_episode={ returns = 2219.5283 lengths = 1000 } 
2022-05-01 18:05:29.364493 - gail/main.py:164 - [TRPO] iter = 2061000 dist_mean = 0.0386 dist_std = 0.1416 vf_loss = 0.0451 grad_norm = 2.9359 nat_grad_norm = 0.0689 cg_residual = 1.8232 step_size = 0.4820 reward = 0.0000 fps = 7 mse_loss = 0.5937 
2022-05-01 18:05:39.048279 - gail/main.py:164 - [TRPO] iter = 2062000 dist_mean = 0.0190 dist_std = 0.1416 vf_loss = 0.0280 grad_norm = 5.3670 nat_grad_norm = 0.0708 cg_residual = 1.7974 step_size = 0.4256 reward = 0.0000 fps = 6 mse_loss = 0.6004 
2022-05-01 18:05:48.292766 - gail/main.py:164 - [TRPO] iter = 2063000 dist_mean = 0.0402 dist_std = 0.1417 vf_loss = 0.0285 grad_norm = 3.5713 nat_grad_norm = 0.0737 cg_residual = 1.9867 step_size = 0.4562 reward = -0.0000 fps = 6 mse_loss = 0.5518 
2022-05-01 18:05:57.861642 - gail/main.py:164 - [TRPO] iter = 2064000 dist_mean = 0.0088 dist_std = 0.1415 vf_loss = 0.0259 grad_norm = 4.8097 nat_grad_norm = 0.0605 cg_residual = 2.0238 step_size = 0.4276 reward = 0.0000 fps = 6 mse_loss = 0.5313 
2022-05-01 18:06:07.208020 - gail/main.py:164 - [TRPO] iter = 2065000 dist_mean = -0.0195 dist_std = 0.1414 vf_loss = 0.0249 grad_norm = 3.3947 nat_grad_norm = 0.0884 cg_residual = 1.6011 step_size = 0.4086 reward = 0.0000 fps = 5 mse_loss = 0.5375 
2022-05-01 18:06:07.413662 - gail/main.py:191 - [Discriminator] iter = 2065000 loss = -0.4107 grad_norm = 5.3215 grad_penalty = 0.0688 regularization = 0.0000 true_logits = -0.4050 fake_logits = -0.8846 true_prob = 0.4047 fake_prob = 0.3125 
2022-05-01 18:08:11.906706 - gail/main.py:132 - [Evaluate] iter = 2065000 episode={ returns = 3580.3944 lengths = 1000 } discounted_episode={ returns = 2212.0286 lengths = 1000 } 
2022-05-01 18:08:21.331621 - gail/main.py:164 - [TRPO] iter = 2066000 dist_mean = 0.0053 dist_std = 0.1412 vf_loss = 0.0222 grad_norm = 4.0502 nat_grad_norm = 0.0907 cg_residual = 2.2507 step_size = 0.4221 reward = -0.0000 fps = 7 mse_loss = 0.5558 
2022-05-01 18:08:31.134182 - gail/main.py:164 - [TRPO] iter = 2067000 dist_mean = -0.0280 dist_std = 0.1414 vf_loss = 0.0174 grad_norm = 3.8190 nat_grad_norm = 0.0609 cg_residual = 1.5004 step_size = 0.4522 reward = -0.0000 fps = 6 mse_loss = 0.5292 
2022-05-01 18:08:40.557536 - gail/main.py:164 - [TRPO] iter = 2068000 dist_mean = 0.0094 dist_std = 0.1414 vf_loss = 0.0197 grad_norm = 5.4568 nat_grad_norm = 0.0765 cg_residual = 2.7174 step_size = 0.3806 reward = 0.0000 fps = 6 mse_loss = 0.5983 
2022-05-01 18:08:50.178551 - gail/main.py:164 - [TRPO] iter = 2069000 dist_mean = 0.0008 dist_std = 0.1415 vf_loss = 0.0152 grad_norm = 3.5788 nat_grad_norm = 0.1091 cg_residual = 3.2299 step_size = 0.3605 reward = -0.0000 fps = 6 mse_loss = 0.5922 
2022-05-01 18:08:59.778636 - gail/main.py:164 - [TRPO] iter = 2070000 dist_mean = 0.0178 dist_std = 0.1414 vf_loss = 0.0135 grad_norm = 2.8190 nat_grad_norm = 0.0947 cg_residual = 1.6695 step_size = 0.3916 reward = 0.0000 fps = 5 mse_loss = 0.5503 
2022-05-01 18:09:00.006060 - gail/main.py:191 - [Discriminator] iter = 2070000 loss = -0.3216 grad_norm = 5.4495 grad_penalty = 0.0671 regularization = 0.0000 true_logits = -0.3204 fake_logits = -0.7091 true_prob = 0.4254 fake_prob = 0.3465 
2022-05-01 18:11:06.864776 - gail/main.py:132 - [Evaluate] iter = 2070000 episode={ returns = 3582.2659 lengths = 1000 } discounted_episode={ returns = 2209.2713 lengths = 1000 } 
2022-05-01 18:11:16.717030 - gail/main.py:164 - [TRPO] iter = 2071000 dist_mean = 0.0015 dist_std = 0.1414 vf_loss = 0.0204 grad_norm = 4.0486 nat_grad_norm = 0.0837 cg_residual = 2.5159 step_size = 0.4161 reward = -0.0000 fps = 7 mse_loss = 0.5493 
2022-05-01 18:11:26.178457 - gail/main.py:164 - [TRPO] iter = 2072000 dist_mean = 0.0153 dist_std = 0.1411 vf_loss = 0.0241 grad_norm = 3.8681 nat_grad_norm = 0.1073 cg_residual = 3.1736 step_size = 0.3311 reward = 0.0000 fps = 6 mse_loss = 0.5360 
2022-05-01 18:11:35.916746 - gail/main.py:164 - [TRPO] iter = 2073000 dist_mean = 0.0006 dist_std = 0.1409 vf_loss = 0.0278 grad_norm = 5.2713 nat_grad_norm = 0.0844 cg_residual = 3.3527 step_size = 0.3805 reward = 0.0000 fps = 6 mse_loss = 0.5847 
2022-05-01 18:11:45.124964 - gail/main.py:164 - [TRPO] iter = 2074000 dist_mean = -0.0052 dist_std = 0.1410 vf_loss = 0.0603 grad_norm = 3.0273 nat_grad_norm = 0.0685 cg_residual = 0.8668 step_size = 0.5392 reward = -0.0000 fps = 6 mse_loss = 0.5239 
2022-05-01 18:11:54.441604 - gail/main.py:164 - [TRPO] iter = 2075000 dist_mean = -0.0287 dist_std = 0.1411 vf_loss = 0.0430 grad_norm = 4.1427 nat_grad_norm = 0.0858 cg_residual = 2.5215 step_size = 0.3980 reward = 0.0000 fps = 5 mse_loss = 0.5677 
2022-05-01 18:11:54.689608 - gail/main.py:191 - [Discriminator] iter = 2075000 loss = -0.5402 grad_norm = 4.1571 grad_penalty = 0.0697 regularization = 0.0000 true_logits = -0.1964 fake_logits = -0.8062 true_prob = 0.4538 fake_prob = 0.3301 
2022-05-01 18:14:00.918726 - gail/main.py:132 - [Evaluate] iter = 2075000 episode={ returns = 3595.3043 lengths = 1000 } discounted_episode={ returns = 2215.1897 lengths = 1000 } 
2022-05-01 18:14:10.615201 - gail/main.py:164 - [TRPO] iter = 2076000 dist_mean = 0.0245 dist_std = 0.1413 vf_loss = 0.0785 grad_norm = 4.2781 nat_grad_norm = 0.0570 cg_residual = 0.9723 step_size = 0.4813 reward = 0.0000 fps = 7 mse_loss = 0.5699 
2022-05-01 18:14:20.146782 - gail/main.py:164 - [TRPO] iter = 2077000 dist_mean = 0.0110 dist_std = 0.1414 vf_loss = 0.0193 grad_norm = 3.1077 nat_grad_norm = 0.0804 cg_residual = 2.8279 step_size = 0.4876 reward = 0.0000 fps = 6 mse_loss = 0.5608 
2022-05-01 18:14:29.426750 - gail/main.py:164 - [TRPO] iter = 2078000 dist_mean = 0.0074 dist_std = 0.1414 vf_loss = 0.0563 grad_norm = 3.6149 nat_grad_norm = 0.0604 cg_residual = 0.9500 step_size = 0.5183 reward = -0.0000 fps = 6 mse_loss = 0.6049 
2022-05-01 18:14:38.583611 - gail/main.py:164 - [TRPO] iter = 2079000 dist_mean = -0.0247 dist_std = 0.1415 vf_loss = 0.0146 grad_norm = 4.0451 nat_grad_norm = 0.1103 cg_residual = 3.8424 step_size = 0.3378 reward = -0.0000 fps = 6 mse_loss = 0.5526 
2022-05-01 18:14:48.174922 - gail/main.py:164 - [TRPO] iter = 2080000 dist_mean = -0.0081 dist_std = 0.1413 vf_loss = 0.0312 grad_norm = 3.5269 nat_grad_norm = 0.0834 cg_residual = 2.1131 step_size = 0.4516 reward = 0.0000 fps = 5 mse_loss = 0.5223 
2022-05-01 18:14:48.381124 - gail/main.py:191 - [Discriminator] iter = 2080000 loss = -0.4156 grad_norm = 4.0544 grad_penalty = 0.0628 regularization = 0.0000 true_logits = -0.2672 fake_logits = -0.7457 true_prob = 0.4384 fake_prob = 0.3398 
2022-05-01 18:16:55.990242 - gail/main.py:132 - [Evaluate] iter = 2080000 episode={ returns = 3607.6674 lengths = 1000 } discounted_episode={ returns = 2221.9126 lengths = 1000 } 
2022-05-01 18:17:05.387921 - gail/main.py:164 - [TRPO] iter = 2081000 dist_mean = -0.0337 dist_std = 0.1413 vf_loss = 0.0368 grad_norm = 3.8932 nat_grad_norm = 0.0706 cg_residual = 1.5703 step_size = 0.4535 reward = 0.0000 fps = 7 mse_loss = 0.4895 
2022-05-01 18:17:15.205191 - gail/main.py:164 - [TRPO] iter = 2082000 dist_mean = -0.0139 dist_std = 0.1414 vf_loss = 0.0383 grad_norm = 3.4530 nat_grad_norm = 0.0799 cg_residual = 1.2572 step_size = 0.4678 reward = -0.0000 fps = 6 mse_loss = 0.5317 
2022-05-01 18:17:24.693642 - gail/main.py:164 - [TRPO] iter = 2083000 dist_mean = -0.0120 dist_std = 0.1413 vf_loss = 0.0403 grad_norm = 3.8211 nat_grad_norm = 0.1040 cg_residual = 4.6523 step_size = 0.3602 reward = -0.0000 fps = 6 mse_loss = 0.5250 
2022-05-01 18:17:34.110773 - gail/main.py:164 - [TRPO] iter = 2084000 dist_mean = -0.0150 dist_std = 0.1410 vf_loss = 0.1217 grad_norm = 3.7724 nat_grad_norm = 0.0877 cg_residual = 1.3960 step_size = 0.4088 reward = 0.0000 fps = 6 mse_loss = 0.5074 
2022-05-01 18:17:43.576801 - gail/main.py:164 - [TRPO] iter = 2085000 dist_mean = -0.0068 dist_std = 0.1411 vf_loss = 0.0572 grad_norm = 3.8379 nat_grad_norm = 0.0811 cg_residual = 1.1034 step_size = 0.4583 reward = -0.0000 fps = 5 mse_loss = 0.5448 
2022-05-01 18:17:43.810734 - gail/main.py:191 - [Discriminator] iter = 2085000 loss = -0.3937 grad_norm = 3.4625 grad_penalty = 0.0592 regularization = 0.0000 true_logits = -0.3242 fake_logits = -0.7771 true_prob = 0.4286 fake_prob = 0.3344 
2022-05-01 18:19:02.847493 - gail/main.py:132 - [Evaluate] iter = 2085000 episode={ returns = 2805.8410 lengths = 783 } discounted_episode={ returns = 1250.3685 lengths = 472 } 
2022-05-01 18:19:12.255715 - gail/main.py:164 - [TRPO] iter = 2086000 dist_mean = -0.0328 dist_std = 0.1406 vf_loss = 0.0768 grad_norm = 3.1517 nat_grad_norm = 0.0675 cg_residual = 0.9956 step_size = 0.5320 reward = -0.0000 fps = 11 mse_loss = 0.5585 
2022-05-01 18:19:21.752007 - gail/main.py:164 - [TRPO] iter = 2087000 dist_mean = -0.0281 dist_std = 0.1406 vf_loss = 0.0436 grad_norm = 4.3193 nat_grad_norm = 0.0879 cg_residual = 1.7636 step_size = 0.4153 reward = 0.0000 fps = 10 mse_loss = 0.5152 
2022-05-01 18:19:31.134803 - gail/main.py:164 - [TRPO] iter = 2088000 dist_mean = 0.0255 dist_std = 0.1406 vf_loss = 0.1224 grad_norm = 3.5239 nat_grad_norm = 0.0685 cg_residual = 1.3743 step_size = 0.5250 reward = 0.0000 fps = 9 mse_loss = 0.5602 
2022-05-01 18:19:40.403126 - gail/main.py:164 - [TRPO] iter = 2089000 dist_mean = 0.0051 dist_std = 0.1407 vf_loss = 0.0814 grad_norm = 3.9209 nat_grad_norm = 0.0786 cg_residual = 1.1838 step_size = 0.4317 reward = -0.0000 fps = 8 mse_loss = 0.5276 
2022-05-01 18:19:49.681782 - gail/main.py:164 - [TRPO] iter = 2090000 dist_mean = -0.0060 dist_std = 0.1405 vf_loss = 0.0684 grad_norm = 5.1342 nat_grad_norm = 0.0935 cg_residual = 2.3781 step_size = 0.3942 reward = 0.0000 fps = 7 mse_loss = 0.5678 
2022-05-01 18:19:49.960227 - gail/main.py:191 - [Discriminator] iter = 2090000 loss = -0.5433 grad_norm = 4.1073 grad_penalty = 0.0593 regularization = 0.0000 true_logits = -0.3669 fake_logits = -0.9695 true_prob = 0.4226 fake_prob = 0.3049 
2022-05-01 18:21:57.417488 - gail/main.py:132 - [Evaluate] iter = 2090000 episode={ returns = 3566.4209 lengths = 1000 } discounted_episode={ returns = 2201.1482 lengths = 1000 } 
2022-05-01 18:22:07.416705 - gail/main.py:164 - [TRPO] iter = 2091000 dist_mean = 0.0461 dist_std = 0.1403 vf_loss = 0.2034 grad_norm = 2.5762 nat_grad_norm = 0.0636 cg_residual = 1.2092 step_size = 0.5241 reward = -0.0000 fps = 7 mse_loss = 0.5469 
2022-05-01 18:22:16.827887 - gail/main.py:164 - [TRPO] iter = 2092000 dist_mean = 0.0323 dist_std = 0.1403 vf_loss = 0.1405 grad_norm = 4.7057 nat_grad_norm = 0.0970 cg_residual = 2.1265 step_size = 0.3854 reward = -0.0000 fps = 6 mse_loss = 0.5373 
2022-05-01 18:22:26.104193 - gail/main.py:164 - [TRPO] iter = 2093000 dist_mean = 0.0369 dist_std = 0.1403 vf_loss = 0.1473 grad_norm = 2.4037 nat_grad_norm = 0.0499 cg_residual = 0.5463 step_size = 0.7033 reward = 0.0000 fps = 6 mse_loss = 0.5444 
2022-05-01 18:22:35.649242 - gail/main.py:164 - [TRPO] iter = 2094000 dist_mean = 0.0520 dist_std = 0.1402 vf_loss = 0.1504 grad_norm = 3.2437 nat_grad_norm = 0.0672 cg_residual = 1.0322 step_size = 0.5254 reward = -0.0000 fps = 6 mse_loss = 0.5875 
2022-05-01 18:22:45.245151 - gail/main.py:164 - [TRPO] iter = 2095000 dist_mean = 0.0618 dist_std = 0.1402 vf_loss = 0.1484 grad_norm = 2.9981 nat_grad_norm = 0.0727 cg_residual = 2.3600 step_size = 0.4895 reward = 0.0000 fps = 5 mse_loss = 0.5353 
2022-05-01 18:22:45.522413 - gail/main.py:191 - [Discriminator] iter = 2095000 loss = -0.2916 grad_norm = 4.2624 grad_penalty = 0.0525 regularization = 0.0000 true_logits = -0.3245 fake_logits = -0.6686 true_prob = 0.4320 fake_prob = 0.3610 
2022-05-01 18:24:56.342853 - gail/main.py:132 - [Evaluate] iter = 2095000 episode={ returns = 3565.4957 lengths = 1000 } discounted_episode={ returns = 2195.2829 lengths = 1000 } 
2022-05-01 18:25:06.238371 - gail/main.py:164 - [TRPO] iter = 2096000 dist_mean = 0.0455 dist_std = 0.1401 vf_loss = 0.0560 grad_norm = 3.3891 nat_grad_norm = 0.0716 cg_residual = 1.6955 step_size = 0.4661 reward = 0.0000 fps = 7 mse_loss = 0.5435 
2022-05-01 18:25:16.194691 - gail/main.py:164 - [TRPO] iter = 2097000 dist_mean = 0.0574 dist_std = 0.1401 vf_loss = 0.1613 grad_norm = 4.5117 nat_grad_norm = 0.0697 cg_residual = 2.0501 step_size = 0.4790 reward = 0.0000 fps = 6 mse_loss = 0.4975 
2022-05-01 18:25:25.529632 - gail/main.py:164 - [TRPO] iter = 2098000 dist_mean = 0.0367 dist_std = 0.1396 vf_loss = 0.1120 grad_norm = 2.8957 nat_grad_norm = 0.0606 cg_residual = 1.0323 step_size = 0.5335 reward = -0.0000 fps = 6 mse_loss = 0.5648 
2022-05-01 18:25:35.432243 - gail/main.py:164 - [TRPO] iter = 2099000 dist_mean = 0.0736 dist_std = 0.1397 vf_loss = 0.1753 grad_norm = 6.0964 nat_grad_norm = 0.0617 cg_residual = 0.7349 step_size = 0.5136 reward = 0.0000 fps = 5 mse_loss = 0.5852 
2022-05-01 18:25:45.438679 - gail/main.py:164 - [TRPO] iter = 2100000 dist_mean = 0.0593 dist_std = 0.1394 vf_loss = 0.1508 grad_norm = 3.1980 nat_grad_norm = 0.1167 cg_residual = 1.8516 step_size = 0.3622 reward = -0.0000 fps = 5 mse_loss = 0.6049 
2022-05-01 18:25:45.641459 - gail/main.py:191 - [Discriminator] iter = 2100000 loss = -0.3376 grad_norm = 5.3349 grad_penalty = 0.0581 regularization = 0.0000 true_logits = -0.2758 fake_logits = -0.6715 true_prob = 0.4409 fake_prob = 0.3576 
2022-05-01 18:27:52.624284 - gail/main.py:132 - [Evaluate] iter = 2100000 episode={ returns = 3599.7889 lengths = 1000 } discounted_episode={ returns = 2221.7808 lengths = 1000 } 
2022-05-01 18:28:01.936631 - gail/main.py:164 - [TRPO] iter = 2101000 dist_mean = 0.0570 dist_std = 0.1396 vf_loss = 0.0164 grad_norm = 4.6754 nat_grad_norm = 0.0953 cg_residual = 3.4638 step_size = 0.3393 reward = -0.0000 fps = 7 mse_loss = 0.5931 
2022-05-01 18:28:11.248307 - gail/main.py:164 - [TRPO] iter = 2102000 dist_mean = 0.0688 dist_std = 0.1397 vf_loss = 0.1060 grad_norm = 2.8530 nat_grad_norm = 0.0703 cg_residual = 1.5723 step_size = 0.5671 reward = 0.0000 fps = 6 mse_loss = 0.6417 
2022-05-01 18:28:20.444443 - gail/main.py:164 - [TRPO] iter = 2103000 dist_mean = 0.0412 dist_std = 0.1399 vf_loss = 0.0853 grad_norm = 1.8810 nat_grad_norm = 0.0648 cg_residual = 1.1992 step_size = 0.6250 reward = 0.0000 fps = 6 mse_loss = 0.6294 
2022-05-01 18:28:29.511702 - gail/main.py:164 - [TRPO] iter = 2104000 dist_mean = 0.0569 dist_std = 0.1397 vf_loss = 0.0668 grad_norm = 4.0685 nat_grad_norm = 0.0730 cg_residual = 1.7143 step_size = 0.4630 reward = -0.0000 fps = 6 mse_loss = 0.6095 
2022-05-01 18:28:38.860985 - gail/main.py:164 - [TRPO] iter = 2105000 dist_mean = 0.0676 dist_std = 0.1400 vf_loss = 0.0580 grad_norm = 4.5183 nat_grad_norm = 0.0635 cg_residual = 1.1046 step_size = 0.4744 reward = -0.0000 fps = 5 mse_loss = 0.6508 
2022-05-01 18:28:39.106099 - gail/main.py:191 - [Discriminator] iter = 2105000 loss = -0.3886 grad_norm = 3.4026 grad_penalty = 0.0554 regularization = 0.0000 true_logits = -0.2063 fake_logits = -0.6503 true_prob = 0.4549 fake_prob = 0.3627 
2022-05-01 18:30:44.631771 - gail/main.py:132 - [Evaluate] iter = 2105000 episode={ returns = 3601.2850 lengths = 1000 } discounted_episode={ returns = 2221.5845 lengths = 1000 } 
2022-05-01 18:30:54.030873 - gail/main.py:164 - [TRPO] iter = 2106000 dist_mean = 0.0557 dist_std = 0.1398 vf_loss = 0.0958 grad_norm = 3.7565 nat_grad_norm = 0.0810 cg_residual = 1.4053 step_size = 0.4455 reward = -0.0000 fps = 7 mse_loss = 0.6065 
2022-05-01 18:31:03.285074 - gail/main.py:164 - [TRPO] iter = 2107000 dist_mean = 0.0695 dist_std = 0.1401 vf_loss = 0.0412 grad_norm = 3.1444 nat_grad_norm = 0.0871 cg_residual = 1.5329 step_size = 0.4181 reward = 0.0000 fps = 6 mse_loss = 0.5671 
2022-05-01 18:31:12.136547 - gail/main.py:164 - [TRPO] iter = 2108000 dist_mean = 0.0718 dist_std = 0.1398 vf_loss = 0.0507 grad_norm = 3.8893 nat_grad_norm = 0.0740 cg_residual = 1.8249 step_size = 0.4138 reward = 0.0000 fps = 6 mse_loss = 0.5822 
2022-05-01 18:31:21.974755 - gail/main.py:164 - [TRPO] iter = 2109000 dist_mean = 0.0399 dist_std = 0.1400 vf_loss = 0.0772 grad_norm = 3.1233 nat_grad_norm = 0.0658 cg_residual = 1.5739 step_size = 0.5166 reward = 0.0000 fps = 6 mse_loss = 0.6269 
2022-05-01 18:31:31.043848 - gail/main.py:164 - [TRPO] iter = 2110000 dist_mean = 0.0555 dist_std = 0.1400 vf_loss = 0.1009 grad_norm = 3.1448 nat_grad_norm = 0.0871 cg_residual = 1.1625 step_size = 0.4353 reward = 0.0000 fps = 5 mse_loss = 0.6008 
2022-05-01 18:31:31.275305 - gail/main.py:191 - [Discriminator] iter = 2110000 loss = -0.3783 grad_norm = 3.3851 grad_penalty = 0.0551 regularization = 0.0000 true_logits = -0.1918 fake_logits = -0.6252 true_prob = 0.4578 fake_prob = 0.3680 
2022-05-01 18:33:36.981798 - gail/main.py:132 - [Evaluate] iter = 2110000 episode={ returns = 3608.6320 lengths = 1000 } discounted_episode={ returns = 2228.4369 lengths = 1000 } 
2022-05-01 18:33:46.392489 - gail/main.py:164 - [TRPO] iter = 2111000 dist_mean = 0.0262 dist_std = 0.1400 vf_loss = 0.0901 grad_norm = 3.6903 nat_grad_norm = 0.1114 cg_residual = 2.1259 step_size = 0.3567 reward = 0.0000 fps = 7 mse_loss = 0.6320 
2022-05-01 18:33:55.765107 - gail/main.py:164 - [TRPO] iter = 2112000 dist_mean = 0.0596 dist_std = 0.1399 vf_loss = 0.0642 grad_norm = 3.2508 nat_grad_norm = 0.0657 cg_residual = 1.8240 step_size = 0.4726 reward = -0.0000 fps = 6 mse_loss = 0.6137 
2022-05-01 18:34:05.148144 - gail/main.py:164 - [TRPO] iter = 2113000 dist_mean = 0.0456 dist_std = 0.1401 vf_loss = 0.0494 grad_norm = 4.1314 nat_grad_norm = 0.0553 cg_residual = 1.1772 step_size = 0.5241 reward = 0.0000 fps = 6 mse_loss = 0.5814 
2022-05-01 18:34:14.572418 - gail/main.py:164 - [TRPO] iter = 2114000 dist_mean = 0.0307 dist_std = 0.1401 vf_loss = 0.1042 grad_norm = 3.5202 nat_grad_norm = 0.0722 cg_residual = 0.8618 step_size = 0.4721 reward = 0.0000 fps = 6 mse_loss = 0.5988 
2022-05-01 18:34:23.697815 - gail/main.py:164 - [TRPO] iter = 2115000 dist_mean = 0.0339 dist_std = 0.1404 vf_loss = 0.1018 grad_norm = 3.5682 nat_grad_norm = 0.0708 cg_residual = 2.3430 step_size = 0.4565 reward = 0.0000 fps = 5 mse_loss = 0.6300 
2022-05-01 18:34:23.966565 - gail/main.py:191 - [Discriminator] iter = 2115000 loss = -0.4852 grad_norm = 3.3370 grad_penalty = 0.0566 regularization = 0.0000 true_logits = -0.1705 fake_logits = -0.7122 true_prob = 0.4617 fake_prob = 0.3493 
2022-05-01 18:36:29.451368 - gail/main.py:132 - [Evaluate] iter = 2115000 episode={ returns = 3619.7800 lengths = 1000 } discounted_episode={ returns = 2237.1264 lengths = 1000 } 
2022-05-01 18:36:38.667844 - gail/main.py:164 - [TRPO] iter = 2116000 dist_mean = 0.0575 dist_std = 0.1401 vf_loss = 0.0422 grad_norm = 3.2418 nat_grad_norm = 0.0710 cg_residual = 2.4554 step_size = 0.4622 reward = -0.0000 fps = 7 mse_loss = 0.6166 
2022-05-01 18:36:48.498494 - gail/main.py:164 - [TRPO] iter = 2117000 dist_mean = 0.0546 dist_std = 0.1399 vf_loss = 0.0512 grad_norm = 4.7917 nat_grad_norm = 0.0846 cg_residual = 2.3703 step_size = 0.3675 reward = 0.0000 fps = 6 mse_loss = 0.5369 
2022-05-01 18:36:57.915430 - gail/main.py:164 - [TRPO] iter = 2118000 dist_mean = 0.0108 dist_std = 0.1399 vf_loss = 0.0281 grad_norm = 3.7626 nat_grad_norm = 0.0634 cg_residual = 1.1825 step_size = 0.4898 reward = 0.0000 fps = 6 mse_loss = 0.5909 
2022-05-01 18:37:07.428859 - gail/main.py:164 - [TRPO] iter = 2119000 dist_mean = 0.0517 dist_std = 0.1398 vf_loss = 0.0430 grad_norm = 4.0431 nat_grad_norm = 0.0614 cg_residual = 1.4539 step_size = 0.5138 reward = -0.0000 fps = 6 mse_loss = 0.5553 
2022-05-01 18:37:17.039613 - gail/main.py:164 - [TRPO] iter = 2120000 dist_mean = 0.0598 dist_std = 0.1397 vf_loss = 0.0359 grad_norm = 3.6022 nat_grad_norm = 0.0958 cg_residual = 4.1445 step_size = 0.3731 reward = 0.0000 fps = 5 mse_loss = 0.6150 
2022-05-01 18:37:17.295926 - gail/main.py:191 - [Discriminator] iter = 2120000 loss = -0.3578 grad_norm = 3.8670 grad_penalty = 0.0539 regularization = 0.0000 true_logits = -0.2865 fake_logits = -0.6981 true_prob = 0.4364 fake_prob = 0.3533 
2022-05-01 18:39:23.146927 - gail/main.py:132 - [Evaluate] iter = 2120000 episode={ returns = 3610.5321 lengths = 1000 } discounted_episode={ returns = 2224.6634 lengths = 1000 } 
2022-05-01 18:39:32.329086 - gail/main.py:164 - [TRPO] iter = 2121000 dist_mean = 0.0206 dist_std = 0.1393 vf_loss = 0.0656 grad_norm = 4.2584 nat_grad_norm = 0.0589 cg_residual = 0.7881 step_size = 0.4766 reward = -0.0000 fps = 7 mse_loss = 0.5878 
2022-05-01 18:39:41.407571 - gail/main.py:164 - [TRPO] iter = 2122000 dist_mean = 0.0500 dist_std = 0.1393 vf_loss = 0.0874 grad_norm = 4.2445 nat_grad_norm = 0.0766 cg_residual = 1.3013 step_size = 0.3883 reward = 0.0000 fps = 6 mse_loss = 0.6038 
2022-05-01 18:39:50.890493 - gail/main.py:164 - [TRPO] iter = 2123000 dist_mean = -0.0002 dist_std = 0.1392 vf_loss = 0.0207 grad_norm = 3.0009 nat_grad_norm = 0.0800 cg_residual = 2.5172 step_size = 0.4518 reward = -0.0000 fps = 6 mse_loss = 0.5670 
2022-05-01 18:40:00.171406 - gail/main.py:164 - [TRPO] iter = 2124000 dist_mean = 0.0279 dist_std = 0.1391 vf_loss = 0.0274 grad_norm = 3.4765 nat_grad_norm = 0.0849 cg_residual = 1.8792 step_size = 0.4574 reward = -0.0000 fps = 6 mse_loss = 0.5686 
2022-05-01 18:40:09.616027 - gail/main.py:164 - [TRPO] iter = 2125000 dist_mean = 0.0222 dist_std = 0.1390 vf_loss = 0.1210 grad_norm = 2.4113 nat_grad_norm = 0.0906 cg_residual = 2.1519 step_size = 0.4283 reward = -0.0000 fps = 5 mse_loss = 0.6122 
2022-05-01 18:40:09.835384 - gail/main.py:191 - [Discriminator] iter = 2125000 loss = -0.5022 grad_norm = 3.9240 grad_penalty = 0.0597 regularization = 0.0000 true_logits = -0.3607 fake_logits = -0.9226 true_prob = 0.4198 fake_prob = 0.3053 
2022-05-01 18:41:30.802006 - gail/main.py:132 - [Evaluate] iter = 2125000 episode={ returns = 2329.0711 lengths = 666 } discounted_episode={ returns = 1414.5612 lengths = 597 } 
2022-05-01 18:41:40.415873 - gail/main.py:164 - [TRPO] iter = 2126000 dist_mean = 0.0127 dist_std = 0.1392 vf_loss = 0.0987 grad_norm = 4.1324 nat_grad_norm = 0.0734 cg_residual = 2.0174 step_size = 0.4567 reward = -0.0000 fps = 11 mse_loss = 0.5755 
2022-05-01 18:41:50.362426 - gail/main.py:164 - [TRPO] iter = 2127000 dist_mean = -0.0112 dist_std = 0.1390 vf_loss = 0.0496 grad_norm = 4.7723 nat_grad_norm = 0.0823 cg_residual = 1.8091 step_size = 0.4427 reward = 0.0000 fps = 9 mse_loss = 0.5358 
2022-05-01 18:41:59.864253 - gail/main.py:164 - [TRPO] iter = 2128000 dist_mean = -0.0102 dist_std = 0.1390 vf_loss = 0.0554 grad_norm = 4.5489 nat_grad_norm = 0.0858 cg_residual = 1.6690 step_size = 0.3218 reward = -0.0000 fps = 9 mse_loss = 0.5668 
2022-05-01 18:42:09.580848 - gail/main.py:164 - [TRPO] iter = 2129000 dist_mean = -0.0050 dist_std = 0.1392 vf_loss = 0.5551 grad_norm = 2.2245 nat_grad_norm = 0.0589 cg_residual = 1.1747 step_size = 0.6203 reward = -0.0000 fps = 8 mse_loss = 0.5347 
2022-05-01 18:42:18.827148 - gail/main.py:164 - [TRPO] iter = 2130000 dist_mean = 0.0228 dist_std = 0.1393 vf_loss = 0.7048 grad_norm = 4.3664 nat_grad_norm = 0.0503 cg_residual = 1.9606 step_size = 0.5856 reward = -0.0000 fps = 7 mse_loss = 0.5334 
2022-05-01 18:42:19.075138 - gail/main.py:191 - [Discriminator] iter = 2130000 loss = -0.9159 grad_norm = 4.6200 grad_penalty = 0.1167 regularization = 0.0000 true_logits = -0.3806 fake_logits = -1.4132 true_prob = 0.4176 fake_prob = 0.2498 
2022-05-01 18:42:22.082795 - gail/main.py:132 - [Evaluate] iter = 2130000 episode={ returns = 25.1867 lengths = 22 } discounted_episode={ returns = 25.8675 lengths = 23 } 
2022-05-01 18:42:31.818823 - gail/main.py:164 - [TRPO] iter = 2131000 dist_mean = 0.0258 dist_std = 0.1391 vf_loss = 0.1703 grad_norm = 4.1931 nat_grad_norm = 0.0708 cg_residual = 2.0635 step_size = 0.4679 reward = 0.0000 fps = 78 mse_loss = 0.5255 
2022-05-01 18:42:41.287010 - gail/main.py:164 - [TRPO] iter = 2132000 dist_mean = 0.0075 dist_std = 0.1387 vf_loss = 0.2637 grad_norm = 2.6964 nat_grad_norm = 0.0571 cg_residual = 3.7150 step_size = 0.5702 reward = -0.0000 fps = 45 mse_loss = 0.5670 
2022-05-01 18:42:50.657487 - gail/main.py:164 - [TRPO] iter = 2133000 dist_mean = 0.0375 dist_std = 0.1385 vf_loss = 0.0817 grad_norm = 2.4340 nat_grad_norm = 0.1010 cg_residual = 7.2811 step_size = 0.3764 reward = -0.0000 fps = 31 mse_loss = 0.5511 
2022-05-01 18:43:00.051170 - gail/main.py:164 - [TRPO] iter = 2134000 dist_mean = -0.0298 dist_std = 0.1386 vf_loss = 0.1532 grad_norm = 3.7620 nat_grad_norm = 0.0714 cg_residual = 2.8550 step_size = 0.4709 reward = -0.0000 fps = 24 mse_loss = 0.5244 
2022-05-01 18:43:09.882786 - gail/main.py:164 - [TRPO] iter = 2135000 dist_mean = 0.0082 dist_std = 0.1388 vf_loss = 0.9601 grad_norm = 4.7566 nat_grad_norm = 0.0804 cg_residual = 11.3104 step_size = 0.3624 reward = -0.0000 fps = 19 mse_loss = 0.5460 
2022-05-01 18:43:10.102098 - gail/main.py:191 - [Discriminator] iter = 2135000 loss = -1.8560 grad_norm = 4.8183 grad_penalty = 0.2558 regularization = 0.0000 true_logits = -0.1616 fake_logits = -2.2734 true_prob = 0.4699 fake_prob = 0.1955 
2022-05-01 18:43:13.162850 - gail/main.py:132 - [Evaluate] iter = 2135000 episode={ returns = 24.3251 lengths = 22 } discounted_episode={ returns = 24.6984 lengths = 22 } 
2022-05-01 18:43:22.627570 - gail/main.py:164 - [TRPO] iter = 2136000 dist_mean = -0.0179 dist_std = 0.1388 vf_loss = 0.3398 grad_norm = 3.4787 nat_grad_norm = 0.0671 cg_residual = 2.1032 step_size = 0.4846 reward = 0.0000 fps = 79 mse_loss = 0.5356 
2022-05-01 18:43:31.739411 - gail/main.py:164 - [TRPO] iter = 2137000 dist_mean = -0.0009 dist_std = 0.1388 vf_loss = 1.1352 grad_norm = 2.6891 nat_grad_norm = 0.0732 cg_residual = 1.5098 step_size = 0.5012 reward = -0.0000 fps = 46 mse_loss = 0.5482 
2022-05-01 18:43:41.361099 - gail/main.py:164 - [TRPO] iter = 2138000 dist_mean = -0.0013 dist_std = 0.1387 vf_loss = 0.5226 grad_norm = 4.0798 nat_grad_norm = 0.0780 cg_residual = 1.1345 step_size = 0.5003 reward = 0.0000 fps = 32 mse_loss = 0.5252 
2022-05-01 18:43:51.083635 - gail/main.py:164 - [TRPO] iter = 2139000 dist_mean = 0.0024 dist_std = 0.1388 vf_loss = 0.4601 grad_norm = 4.3242 nat_grad_norm = 0.0822 cg_residual = 1.8455 step_size = 0.4463 reward = -0.0000 fps = 24 mse_loss = 0.5213 
2022-05-01 18:44:00.541430 - gail/main.py:164 - [TRPO] iter = 2140000 dist_mean = -0.0117 dist_std = 0.1386 vf_loss = 1.1517 grad_norm = 3.3920 nat_grad_norm = 0.0649 cg_residual = 1.4804 step_size = 0.4812 reward = 0.0000 fps = 19 mse_loss = 0.5433 
2022-05-01 18:44:00.764922 - gail/main.py:191 - [Discriminator] iter = 2140000 loss = -0.4717 grad_norm = 5.0770 grad_penalty = 0.1172 regularization = 0.0000 true_logits = 0.0582 fake_logits = -0.5307 true_prob = 0.5118 fake_prob = 0.4143 
2022-05-01 18:44:46.740268 - gail/main.py:132 - [Evaluate] iter = 2140000 episode={ returns = 1314.1111 lengths = 378 } discounted_episode={ returns = 983.3331 lengths = 363 } 
2022-05-01 18:44:56.238674 - gail/main.py:164 - [TRPO] iter = 2141000 dist_mean = -0.0153 dist_std = 0.1384 vf_loss = 0.1477 grad_norm = 3.5742 nat_grad_norm = 0.0924 cg_residual = 1.8896 step_size = 0.3777 reward = -0.0000 fps = 18 mse_loss = 0.5610 
2022-05-01 18:45:05.622963 - gail/main.py:164 - [TRPO] iter = 2142000 dist_mean = -0.0102 dist_std = 0.1384 vf_loss = 0.2632 grad_norm = 5.5036 nat_grad_norm = 0.0876 cg_residual = 2.2068 step_size = 0.3631 reward = -0.0000 fps = 15 mse_loss = 0.4964 
2022-05-01 18:45:14.988601 - gail/main.py:164 - [TRPO] iter = 2143000 dist_mean = 0.0113 dist_std = 0.1385 vf_loss = 0.0912 grad_norm = 4.1117 nat_grad_norm = 0.0951 cg_residual = 3.4761 step_size = 0.4098 reward = 0.0000 fps = 13 mse_loss = 0.5574 
2022-05-01 18:45:24.349632 - gail/main.py:164 - [TRPO] iter = 2144000 dist_mean = 0.0153 dist_std = 0.1386 vf_loss = 0.7110 grad_norm = 4.7338 nat_grad_norm = 0.0774 cg_residual = 1.6966 step_size = 0.4065 reward = -0.0000 fps = 11 mse_loss = 0.5505 
2022-05-01 18:45:33.777217 - gail/main.py:164 - [TRPO] iter = 2145000 dist_mean = -0.0103 dist_std = 0.1385 vf_loss = 0.0932 grad_norm = 3.1654 nat_grad_norm = 0.0545 cg_residual = 1.2947 step_size = 0.5312 reward = 0.0000 fps = 10 mse_loss = 0.4833 
2022-05-01 18:45:33.992229 - gail/main.py:191 - [Discriminator] iter = 2145000 loss = -0.5449 grad_norm = 3.4988 grad_penalty = 0.0873 regularization = 0.0000 true_logits = 0.1112 fake_logits = -0.5209 true_prob = 0.5236 fake_prob = 0.4084 
2022-05-01 18:46:53.449230 - gail/main.py:132 - [Evaluate] iter = 2145000 episode={ returns = 1830.7331 lengths = 513 } discounted_episode={ returns = 1773.4059 lengths = 753 } 
2022-05-01 18:47:02.632277 - gail/main.py:164 - [TRPO] iter = 2146000 dist_mean = 0.0149 dist_std = 0.1384 vf_loss = 0.3971 grad_norm = 2.1751 nat_grad_norm = 0.0553 cg_residual = 1.0500 step_size = 0.6225 reward = 0.0000 fps = 11 mse_loss = 0.5152 
2022-05-01 18:47:11.941185 - gail/main.py:164 - [TRPO] iter = 2147000 dist_mean = 0.0014 dist_std = 0.1383 vf_loss = 0.5760 grad_norm = 3.2822 nat_grad_norm = 0.0750 cg_residual = 1.1102 step_size = 0.5088 reward = -0.0000 fps = 10 mse_loss = 0.5292 
2022-05-01 18:47:21.491993 - gail/main.py:164 - [TRPO] iter = 2148000 dist_mean = 0.0357 dist_std = 0.1382 vf_loss = 0.3093 grad_norm = 3.9801 nat_grad_norm = 0.0482 cg_residual = 1.2843 step_size = 0.5323 reward = 0.0000 fps = 9 mse_loss = 0.4706 
2022-05-01 18:47:30.855865 - gail/main.py:164 - [TRPO] iter = 2149000 dist_mean = 0.0199 dist_std = 0.1382 vf_loss = 0.2123 grad_norm = 3.3127 nat_grad_norm = 0.0767 cg_residual = 1.4854 step_size = 0.4374 reward = 0.0000 fps = 8 mse_loss = 0.4990 
2022-05-01 18:47:40.230219 - gail/main.py:164 - [TRPO] iter = 2150000 dist_mean = 0.0382 dist_std = 0.1382 vf_loss = 0.0777 grad_norm = 3.4147 nat_grad_norm = 0.0681 cg_residual = 1.4550 step_size = 0.4249 reward = -0.0000 fps = 7 mse_loss = 0.5053 
2022-05-01 18:47:40.469561 - gail/main.py:191 - [Discriminator] iter = 2150000 loss = -0.2598 grad_norm = 3.9563 grad_penalty = 0.0670 regularization = 0.0000 true_logits = 0.0102 fake_logits = -0.3167 true_prob = 0.5032 fake_prob = 0.4376 
2022-05-01 18:49:49.128764 - gail/main.py:132 - [Evaluate] iter = 2150000 episode={ returns = 3603.5325 lengths = 1000 } discounted_episode={ returns = 2223.7283 lengths = 1000 } 
2022-05-01 18:49:58.061632 - gail/main.py:164 - [TRPO] iter = 2151000 dist_mean = 0.0413 dist_std = 0.1382 vf_loss = 0.1761 grad_norm = 5.9358 nat_grad_norm = 0.0571 cg_residual = 1.0690 step_size = 0.4868 reward = 0.0000 fps = 7 mse_loss = 0.4978 
2022-05-01 18:50:07.621203 - gail/main.py:164 - [TRPO] iter = 2152000 dist_mean = 0.0396 dist_std = 0.1383 vf_loss = 0.1408 grad_norm = 3.8369 nat_grad_norm = 0.0616 cg_residual = 1.1024 step_size = 0.4313 reward = -0.0000 fps = 6 mse_loss = 0.5009 
2022-05-01 18:50:17.138715 - gail/main.py:164 - [TRPO] iter = 2153000 dist_mean = 0.0294 dist_std = 0.1383 vf_loss = 0.1316 grad_norm = 4.9295 nat_grad_norm = 0.0889 cg_residual = 1.6484 step_size = 0.3500 reward = -0.0000 fps = 6 mse_loss = 0.4943 
2022-05-01 18:50:26.864462 - gail/main.py:164 - [TRPO] iter = 2154000 dist_mean = 0.0633 dist_std = 0.1383 vf_loss = 0.5846 grad_norm = 3.4574 nat_grad_norm = 0.0661 cg_residual = 14.5535 step_size = 0.4091 reward = -0.0000 fps = 6 mse_loss = 0.4887 
2022-05-01 18:50:36.683229 - gail/main.py:164 - [TRPO] iter = 2155000 dist_mean = 0.0661 dist_std = 0.1385 vf_loss = 0.0867 grad_norm = 2.6034 nat_grad_norm = 0.0159 cg_residual = 0.0504 step_size = 1.1983 reward = 0.0000 fps = 5 mse_loss = 0.4287 
2022-05-01 18:50:36.897803 - gail/main.py:191 - [Discriminator] iter = 2155000 loss = -4.8059 grad_norm = 9.6793 grad_penalty = 0.5841 regularization = 0.0000 true_logits = -0.0057 fake_logits = -5.3957 true_prob = 0.5042 fake_prob = 0.0087 
2022-05-01 18:50:38.714483 - gail/main.py:132 - [Evaluate] iter = 2155000 episode={ returns = 11.8452 lengths = 13 } discounted_episode={ returns = 11.8033 lengths = 13 } 
2022-05-01 18:50:48.348458 - gail/main.py:164 - [TRPO] iter = 2156000 dist_mean = 0.0686 dist_std = 0.1387 vf_loss = 0.2277 grad_norm = 12.4197 nat_grad_norm = 0.0281 cg_residual = 0.5677 step_size = 0.5388 reward = 0.0000 fps = 87 mse_loss = 0.4526 
2022-05-01 18:50:58.291045 - gail/main.py:164 - [TRPO] iter = 2157000 dist_mean = 0.0612 dist_std = 0.1386 vf_loss = 0.2800 grad_norm = 11.7113 nat_grad_norm = 0.0368 cg_residual = 0.7999 step_size = 0.4902 reward = -0.0000 fps = 46 mse_loss = 0.4692 
2022-05-01 18:51:08.164234 - gail/main.py:164 - [TRPO] iter = 2158000 dist_mean = 0.0576 dist_std = 0.1384 vf_loss = 0.1884 grad_norm = 12.0522 nat_grad_norm = 0.0342 cg_residual = 0.4978 step_size = 0.5063 reward = -0.0000 fps = 32 mse_loss = 0.5091 
2022-05-01 18:51:17.860121 - gail/main.py:164 - [TRPO] iter = 2159000 dist_mean = 0.0569 dist_std = 0.1385 vf_loss = 0.3110 grad_norm = 14.8478 nat_grad_norm = 0.0592 cg_residual = 3.2175 step_size = 0.3769 reward = 0.0000 fps = 24 mse_loss = 0.4383 
2022-05-01 18:51:28.062774 - gail/main.py:164 - [TRPO] iter = 2160000 dist_mean = 0.0548 dist_std = 0.1386 vf_loss = 0.3494 grad_norm = 14.1739 nat_grad_norm = 0.0287 cg_residual = 0.1781 step_size = 0.4715 reward = -0.0000 fps = 19 mse_loss = 0.5126 
2022-05-01 18:51:28.306387 - gail/main.py:191 - [Discriminator] iter = 2160000 loss = -5.3824 grad_norm = 6.2985 grad_penalty = 0.6058 regularization = 0.0000 true_logits = 0.5547 fake_logits = -5.4336 true_prob = 0.5750 fake_prob = 0.0099 
2022-05-01 18:51:30.609322 - gail/main.py:132 - [Evaluate] iter = 2160000 episode={ returns = 16.7503 lengths = 16 } discounted_episode={ returns = 17.3914 lengths = 17 } 
2022-05-01 18:51:40.190769 - gail/main.py:164 - [TRPO] iter = 2161000 dist_mean = 0.0412 dist_std = 0.1388 vf_loss = 0.2871 grad_norm = 4.5437 nat_grad_norm = 0.1327 cg_residual = 1.6375 step_size = 0.2696 reward = -0.0000 fps = 84 mse_loss = 0.5112 
2022-05-01 18:51:49.680406 - gail/main.py:164 - [TRPO] iter = 2162000 dist_mean = 0.0316 dist_std = 0.1390 vf_loss = 0.9903 grad_norm = 2.7321 nat_grad_norm = 0.0549 cg_residual = 0.7608 step_size = 0.6720 reward = -0.0000 fps = 46 mse_loss = 0.4949 
2022-05-01 18:51:59.109028 - gail/main.py:164 - [TRPO] iter = 2163000 dist_mean = 0.0360 dist_std = 0.1390 vf_loss = 0.6755 grad_norm = 4.1245 nat_grad_norm = 0.0835 cg_residual = 1.7301 step_size = 0.3989 reward = 0.0000 fps = 32 mse_loss = 0.4894 
2022-05-01 18:52:08.496519 - gail/main.py:164 - [TRPO] iter = 2164000 dist_mean = -0.0027 dist_std = 0.1389 vf_loss = 0.3298 grad_norm = 4.1231 nat_grad_norm = 0.0936 cg_residual = 2.1810 step_size = 0.4052 reward = -0.0000 fps = 24 mse_loss = 0.5366 
2022-05-01 18:52:17.947193 - gail/main.py:164 - [TRPO] iter = 2165000 dist_mean = 0.0112 dist_std = 0.1390 vf_loss = 0.7355 grad_norm = 5.7055 nat_grad_norm = 0.0538 cg_residual = 6.1161 step_size = 0.5048 reward = 0.0000 fps = 20 mse_loss = 0.5344 
2022-05-01 18:52:18.168264 - gail/main.py:191 - [Discriminator] iter = 2165000 loss = -2.4482 grad_norm = 4.1965 grad_penalty = 0.2695 regularization = 0.0000 true_logits = 0.8223 fake_logits = -1.8954 true_prob = 0.5832 fake_prob = 0.3240 
2022-05-01 18:52:20.555176 - gail/main.py:132 - [Evaluate] iter = 2165000 episode={ returns = 19.5389 lengths = 18 } discounted_episode={ returns = 18.8253 lengths = 18 } 
2022-05-01 18:52:29.860763 - gail/main.py:164 - [TRPO] iter = 2166000 dist_mean = -0.0017 dist_std = 0.1390 vf_loss = 0.6345 grad_norm = 4.7360 nat_grad_norm = 0.0885 cg_residual = 4.8472 step_size = 0.3805 reward = 0.0000 fps = 85 mse_loss = 0.5456 
2022-05-01 18:52:39.282113 - gail/main.py:164 - [TRPO] iter = 2167000 dist_mean = 0.0046 dist_std = 0.1389 vf_loss = 0.8136 grad_norm = 4.0473 nat_grad_norm = 0.0940 cg_residual = 2.9816 step_size = 0.3545 reward = 0.0000 fps = 47 mse_loss = 0.5419 
2022-05-01 18:52:48.547103 - gail/main.py:164 - [TRPO] iter = 2168000 dist_mean = 0.0378 dist_std = 0.1387 vf_loss = 0.6148 grad_norm = 2.9439 nat_grad_norm = 0.0751 cg_residual = 1.2917 step_size = 0.5261 reward = 0.0000 fps = 32 mse_loss = 0.4972 
2022-05-01 18:52:57.635276 - gail/main.py:164 - [TRPO] iter = 2169000 dist_mean = 0.0023 dist_std = 0.1387 vf_loss = 0.5373 grad_norm = 4.3980 nat_grad_norm = 0.0676 cg_residual = 1.4006 step_size = 0.5096 reward = -0.0000 fps = 25 mse_loss = 0.5735 
2022-05-01 18:53:06.767475 - gail/main.py:164 - [TRPO] iter = 2170000 dist_mean = -0.0008 dist_std = 0.1388 vf_loss = 0.0948 grad_norm = 3.5782 nat_grad_norm = 0.0930 cg_residual = 1.1590 step_size = 0.4648 reward = -0.0000 fps = 20 mse_loss = 0.5192 
2022-05-01 18:53:07.009581 - gail/main.py:191 - [Discriminator] iter = 2170000 loss = -0.1808 grad_norm = 3.9112 grad_penalty = 0.0997 regularization = 0.0000 true_logits = 0.5920 fake_logits = 0.3116 true_prob = 0.5330 fake_prob = 0.5066 
2022-05-01 18:55:06.231724 - gail/main.py:132 - [Evaluate] iter = 2170000 episode={ returns = 3634.1385 lengths = 1000 } discounted_episode={ returns = 2063.9391 lengths = 898 } 
2022-05-01 18:55:15.600262 - gail/main.py:164 - [TRPO] iter = 2171000 dist_mean = 0.0291 dist_std = 0.1387 vf_loss = 0.6259 grad_norm = 2.5226 nat_grad_norm = 0.0446 cg_residual = 0.3560 step_size = 0.7413 reward = 0.0000 fps = 7 mse_loss = 0.5135 
2022-05-01 18:55:24.721554 - gail/main.py:164 - [TRPO] iter = 2172000 dist_mean = -0.0053 dist_std = 0.1390 vf_loss = 0.0924 grad_norm = 4.0420 nat_grad_norm = 0.0614 cg_residual = 1.3687 step_size = 0.5278 reward = -0.0000 fps = 7 mse_loss = 0.5237 
2022-05-01 18:55:33.619789 - gail/main.py:164 - [TRPO] iter = 2173000 dist_mean = 0.0197 dist_std = 0.1388 vf_loss = 0.4575 grad_norm = 2.7383 nat_grad_norm = 0.0376 cg_residual = 0.4981 step_size = 0.7544 reward = -0.0000 fps = 6 mse_loss = 0.5571 
2022-05-01 18:55:42.944982 - gail/main.py:164 - [TRPO] iter = 2174000 dist_mean = 0.0631 dist_std = 0.1389 vf_loss = 0.3530 grad_norm = 3.3549 nat_grad_norm = 0.0707 cg_residual = 1.3146 step_size = 0.4936 reward = 0.0000 fps = 6 mse_loss = 0.5451 
2022-05-01 18:55:52.422738 - gail/main.py:164 - [TRPO] iter = 2175000 dist_mean = 0.0419 dist_std = 0.1392 vf_loss = 0.3917 grad_norm = 4.4491 nat_grad_norm = 0.0570 cg_residual = 1.0845 step_size = 0.4770 reward = -0.0000 fps = 6 mse_loss = 0.5560 
2022-05-01 18:55:52.630008 - gail/main.py:191 - [Discriminator] iter = 2175000 loss = -0.3371 grad_norm = 4.1145 grad_penalty = 0.0587 regularization = 0.0000 true_logits = 0.8476 fake_logits = 0.4518 true_prob = 0.5714 fake_prob = 0.5194 
2022-05-01 18:55:54.834755 - gail/main.py:132 - [Evaluate] iter = 2175000 episode={ returns = 16.4578 lengths = 16 } discounted_episode={ returns = 15.7453 lengths = 15 } 
2022-05-01 18:56:04.316405 - gail/main.py:164 - [TRPO] iter = 2176000 dist_mean = 0.0604 dist_std = 0.1391 vf_loss = 0.4168 grad_norm = 2.9588 nat_grad_norm = 0.0483 cg_residual = 0.8863 step_size = 0.6586 reward = -0.0000 fps = 85 mse_loss = 0.5119 
2022-05-01 18:56:13.588473 - gail/main.py:164 - [TRPO] iter = 2177000 dist_mean = 0.0261 dist_std = 0.1392 vf_loss = 0.4206 grad_norm = 2.9453 nat_grad_norm = 0.0424 cg_residual = 0.8372 step_size = 0.6934 reward = 0.0000 fps = 47 mse_loss = 0.5451 
2022-05-01 18:56:23.030483 - gail/main.py:164 - [TRPO] iter = 2178000 dist_mean = 0.0428 dist_std = 0.1392 vf_loss = 0.3995 grad_norm = 4.3400 nat_grad_norm = 0.0467 cg_residual = 1.0892 step_size = 0.5669 reward = -0.0000 fps = 32 mse_loss = 0.5308 
2022-05-01 18:56:32.539974 - gail/main.py:164 - [TRPO] iter = 2179000 dist_mean = 0.0463 dist_std = 0.1391 vf_loss = 0.0699 grad_norm = 5.1060 nat_grad_norm = 0.1043 cg_residual = 3.1216 step_size = 0.3249 reward = -0.0000 fps = 25 mse_loss = 0.5297 
2022-05-01 18:56:42.273559 - gail/main.py:164 - [TRPO] iter = 2180000 dist_mean = 0.0483 dist_std = 0.1390 vf_loss = 0.2874 grad_norm = 3.7946 nat_grad_norm = 0.1154 cg_residual = 13.5981 step_size = 0.2691 reward = 0.0000 fps = 20 mse_loss = 0.5601 
2022-05-01 18:56:42.512406 - gail/main.py:191 - [Discriminator] iter = 2180000 loss = -5.8997 grad_norm = 14.5324 grad_penalty = 0.7318 regularization = 0.0000 true_logits = 0.7646 fake_logits = -5.8668 true_prob = 0.5570 fake_prob = 0.0433 
2022-05-01 18:56:44.163060 - gail/main.py:132 - [Evaluate] iter = 2180000 episode={ returns = 10.5888 lengths = 12 } discounted_episode={ returns = 10.3164 lengths = 11 } 
2022-05-01 18:56:53.993538 - gail/main.py:164 - [TRPO] iter = 2181000 dist_mean = 0.0573 dist_std = 0.1390 vf_loss = 0.0746 grad_norm = 12.4906 nat_grad_norm = 0.0303 cg_residual = 1.1757 step_size = 0.4395 reward = 0.0000 fps = 87 mse_loss = 0.5363 
2022-05-01 18:57:03.599405 - gail/main.py:164 - [TRPO] iter = 2182000 dist_mean = 0.0505 dist_std = 0.1391 vf_loss = 0.1556 grad_norm = 16.7274 nat_grad_norm = 0.0580 cg_residual = 1.6810 step_size = 0.3370 reward = 0.0000 fps = 47 mse_loss = 0.5477 
2022-05-01 18:57:13.309601 - gail/main.py:164 - [TRPO] iter = 2183000 dist_mean = 0.0478 dist_std = 0.1393 vf_loss = 0.2308 grad_norm = 16.3334 nat_grad_norm = 0.0291 cg_residual = 2.6718 step_size = 0.4025 reward = 0.0000 fps = 32 mse_loss = 0.5327 
2022-05-01 18:57:22.738430 - gail/main.py:164 - [TRPO] iter = 2184000 dist_mean = 0.0509 dist_std = 0.1394 vf_loss = 0.2093 grad_norm = 17.6730 nat_grad_norm = 0.0592 cg_residual = 2.3011 step_size = 0.4039 reward = 0.0000 fps = 24 mse_loss = 0.5422 
2022-05-01 18:57:32.243668 - gail/main.py:164 - [TRPO] iter = 2185000 dist_mean = 0.0490 dist_std = 0.1391 vf_loss = 0.2063 grad_norm = 13.9373 nat_grad_norm = 0.0329 cg_residual = 3.9719 step_size = 0.4302 reward = -0.0000 fps = 20 mse_loss = 0.6137 
2022-05-01 18:57:32.445099 - gail/main.py:191 - [Discriminator] iter = 2185000 loss = -6.6453 grad_norm = 9.1906 grad_penalty = 0.7234 regularization = 0.0000 true_logits = 1.3451 fake_logits = -6.0236 true_prob = 0.5991 fake_prob = 0.0096 
2022-05-01 18:57:34.518266 - gail/main.py:132 - [Evaluate] iter = 2185000 episode={ returns = 14.5815 lengths = 15 } discounted_episode={ returns = 14.4995 lengths = 15 } 
2022-05-01 18:57:44.314768 - gail/main.py:164 - [TRPO] iter = 2186000 dist_mean = 0.0395 dist_std = 0.1393 vf_loss = 0.3684 grad_norm = 5.7989 nat_grad_norm = 0.1163 cg_residual = 28.2996 step_size = 0.3113 reward = -0.0000 fps = 84 mse_loss = 0.4962 
2022-05-01 18:57:53.613495 - gail/main.py:164 - [TRPO] iter = 2187000 dist_mean = 0.0723 dist_std = 0.1394 vf_loss = 0.5797 grad_norm = 2.9151 nat_grad_norm = 0.0530 cg_residual = 1.1243 step_size = 0.5933 reward = -0.0000 fps = 47 mse_loss = 0.5511 
2022-05-01 18:58:03.188328 - gail/main.py:164 - [TRPO] iter = 2188000 dist_mean = 0.0435 dist_std = 0.1394 vf_loss = 0.6970 grad_norm = 3.7242 nat_grad_norm = 0.0847 cg_residual = 1.8805 step_size = 0.4803 reward = 0.0000 fps = 32 mse_loss = 0.5468 
2022-05-01 18:58:12.524534 - gail/main.py:164 - [TRPO] iter = 2189000 dist_mean = 0.0428 dist_std = 0.1393 vf_loss = 0.9142 grad_norm = 3.9475 nat_grad_norm = 0.0545 cg_residual = 1.1823 step_size = 0.5096 reward = 0.0000 fps = 24 mse_loss = 0.5434 
2022-05-01 18:58:21.745405 - gail/main.py:164 - [TRPO] iter = 2190000 dist_mean = 0.0798 dist_std = 0.1395 vf_loss = 0.6730 grad_norm = 2.9551 nat_grad_norm = 0.0708 cg_residual = 1.3734 step_size = 0.4836 reward = 0.0000 fps = 20 mse_loss = 0.5797 
2022-05-01 18:58:21.994061 - gail/main.py:191 - [Discriminator] iter = 2190000 loss = -0.3085 grad_norm = 6.2760 grad_penalty = 0.1841 regularization = 0.0000 true_logits = 1.6573 fake_logits = 1.1647 true_prob = 0.6194 fake_prob = 0.5549 
2022-05-01 18:59:27.448724 - gail/main.py:132 - [Evaluate] iter = 2190000 episode={ returns = 1812.8884 lengths = 509 } discounted_episode={ returns = 1118.7155 lengths = 509 } 
2022-05-01 18:59:36.748523 - gail/main.py:164 - [TRPO] iter = 2191000 dist_mean = 0.0425 dist_std = 0.1390 vf_loss = 0.7858 grad_norm = 3.2016 nat_grad_norm = 0.0583 cg_residual = 1.2407 step_size = 0.5540 reward = -0.0000 fps = 13 mse_loss = 0.5835 
2022-05-01 18:59:46.210933 - gail/main.py:164 - [TRPO] iter = 2192000 dist_mean = 0.0682 dist_std = 0.1390 vf_loss = 0.3845 grad_norm = 3.8129 nat_grad_norm = 0.0610 cg_residual = 0.9185 step_size = 0.5146 reward = -0.0000 fps = 11 mse_loss = 0.5292 
2022-05-01 18:59:55.554939 - gail/main.py:164 - [TRPO] iter = 2193000 dist_mean = 0.0401 dist_std = 0.1390 vf_loss = 0.4219 grad_norm = 2.6747 nat_grad_norm = 0.0540 cg_residual = 0.6472 step_size = 0.5884 reward = -0.0000 fps = 10 mse_loss = 0.5360 
2022-05-01 19:00:04.892268 - gail/main.py:164 - [TRPO] iter = 2194000 dist_mean = 0.0565 dist_std = 0.1391 vf_loss = 0.3509 grad_norm = 3.6095 nat_grad_norm = 0.0606 cg_residual = 1.2066 step_size = 0.4903 reward = -0.0000 fps = 9 mse_loss = 0.5730 
2022-05-01 19:00:14.798713 - gail/main.py:164 - [TRPO] iter = 2195000 dist_mean = 0.0685 dist_std = 0.1393 vf_loss = 0.2053 grad_norm = 3.2752 nat_grad_norm = 0.0624 cg_residual = 0.9411 step_size = 0.5289 reward = 0.0000 fps = 8 mse_loss = 0.5891 
2022-05-01 19:00:14.986278 - gail/main.py:191 - [Discriminator] iter = 2195000 loss = -0.1817 grad_norm = 4.8612 grad_penalty = 0.0653 regularization = 0.0000 true_logits = 1.4588 fake_logits = 1.2117 true_prob = 0.5881 fake_prob = 0.5469 
2022-05-01 19:02:20.757813 - gail/main.py:132 - [Evaluate] iter = 2195000 episode={ returns = 3595.0859 lengths = 1000 } discounted_episode={ returns = 2205.7683 lengths = 1000 } 
2022-05-01 19:02:30.296468 - gail/main.py:164 - [TRPO] iter = 2196000 dist_mean = 0.0322 dist_std = 0.1395 vf_loss = 0.0711 grad_norm = 4.4203 nat_grad_norm = 0.1176 cg_residual = 3.3252 step_size = 0.3547 reward = 0.0000 fps = 7 mse_loss = 0.5954 
2022-05-01 19:02:39.412971 - gail/main.py:164 - [TRPO] iter = 2197000 dist_mean = 0.0779 dist_std = 0.1394 vf_loss = 0.4076 grad_norm = 2.9180 nat_grad_norm = 0.0520 cg_residual = 0.5530 step_size = 0.5908 reward = 0.0000 fps = 6 mse_loss = 0.5383 
2022-05-01 19:02:48.778518 - gail/main.py:164 - [TRPO] iter = 2198000 dist_mean = 0.0533 dist_std = 0.1393 vf_loss = 0.0713 grad_norm = 2.5333 nat_grad_norm = 0.0879 cg_residual = 1.2217 step_size = 0.4601 reward = -0.0000 fps = 6 mse_loss = 0.5490 
2022-05-01 19:02:57.998470 - gail/main.py:164 - [TRPO] iter = 2199000 dist_mean = 0.0471 dist_std = 0.1394 vf_loss = 0.3311 grad_norm = 3.9550 nat_grad_norm = 0.0641 cg_residual = 1.1117 step_size = 0.4395 reward = 0.0000 fps = 6 mse_loss = 0.5575 
2022-05-01 19:03:07.330943 - gail/main.py:164 - [TRPO] iter = 2200000 dist_mean = 0.0643 dist_std = 0.1396 vf_loss = 0.2872 grad_norm = 5.3525 nat_grad_norm = 0.0523 cg_residual = 0.9516 step_size = 0.4716 reward = 0.0000 fps = 5 mse_loss = 0.5069 
2022-05-01 19:03:07.625350 - gail/main.py:191 - [Discriminator] iter = 2200000 loss = -1.0780 grad_norm = 3.8498 grad_penalty = 0.0670 regularization = 0.0000 true_logits = 1.3105 fake_logits = 0.1655 true_prob = 0.5682 fake_prob = 0.4515 
2022-05-01 19:03:09.412157 - gail/main.py:132 - [Evaluate] iter = 2200000 episode={ returns = 13.5812 lengths = 14 } discounted_episode={ returns = 13.5543 lengths = 14 } 
2022-05-01 19:03:18.582906 - gail/main.py:164 - [TRPO] iter = 2201000 dist_mean = 0.0505 dist_std = 0.1398 vf_loss = 0.1101 grad_norm = 4.4600 nat_grad_norm = 0.0962 cg_residual = 2.9105 step_size = 0.3361 reward = -0.0000 fps = 91 mse_loss = 0.5173 
2022-05-01 19:03:27.790884 - gail/main.py:164 - [TRPO] iter = 2202000 dist_mean = 0.0663 dist_std = 0.1399 vf_loss = 0.3891 grad_norm = 3.8200 nat_grad_norm = 0.0613 cg_residual = 1.3875 step_size = 0.4522 reward = -0.0000 fps = 49 mse_loss = 0.5219 
2022-05-01 19:03:37.602190 - gail/main.py:164 - [TRPO] iter = 2203000 dist_mean = 0.0452 dist_std = 0.1400 vf_loss = 0.3107 grad_norm = 11.4600 nat_grad_norm = 0.0376 cg_residual = 1.9175 step_size = 0.3610 reward = 0.0000 fps = 33 mse_loss = 0.5257 
2022-05-01 19:03:47.024652 - gail/main.py:164 - [TRPO] iter = 2204000 dist_mean = 0.0409 dist_std = 0.1402 vf_loss = 0.2650 grad_norm = 14.1827 nat_grad_norm = 0.0389 cg_residual = 2.3056 step_size = 0.4560 reward = -0.0000 fps = 25 mse_loss = 0.5072 
2022-05-01 19:03:56.253828 - gail/main.py:164 - [TRPO] iter = 2205000 dist_mean = 0.0712 dist_std = 0.1403 vf_loss = 0.1038 grad_norm = 2.8268 nat_grad_norm = 0.0541 cg_residual = 0.9083 step_size = 0.6280 reward = -0.0000 fps = 20 mse_loss = 0.5375 
2022-05-01 19:03:56.458498 - gail/main.py:191 - [Discriminator] iter = 2205000 loss = -1.0644 grad_norm = 3.1872 grad_penalty = 0.1042 regularization = 0.0000 true_logits = 1.3038 fake_logits = 0.1352 true_prob = 0.5819 fake_prob = 0.4596 
2022-05-01 19:03:58.509621 - gail/main.py:132 - [Evaluate] iter = 2205000 episode={ returns = 12.9167 lengths = 14 } discounted_episode={ returns = 13.0461 lengths = 14 } 
2022-05-01 19:04:08.163871 - gail/main.py:164 - [TRPO] iter = 2206000 dist_mean = 0.0501 dist_std = 0.1400 vf_loss = 0.7863 grad_norm = 3.9490 nat_grad_norm = 0.1010 cg_residual = 3.0211 step_size = 0.3630 reward = -0.0000 fps = 85 mse_loss = 0.5466 
2022-05-01 19:04:17.672846 - gail/main.py:164 - [TRPO] iter = 2207000 dist_mean = 0.0292 dist_std = 0.1399 vf_loss = 0.6763 grad_norm = 3.9979 nat_grad_norm = 0.0909 cg_residual = 1.7682 step_size = 0.3718 reward = 0.0000 fps = 47 mse_loss = 0.5551 
2022-05-01 19:04:27.055654 - gail/main.py:164 - [TRPO] iter = 2208000 dist_mean = 0.0291 dist_std = 0.1398 vf_loss = 1.3089 grad_norm = 6.5546 nat_grad_norm = 0.0939 cg_residual = 3.7537 step_size = 0.3571 reward = 0.0000 fps = 32 mse_loss = 0.5720 
2022-05-01 19:04:36.419924 - gail/main.py:164 - [TRPO] iter = 2209000 dist_mean = 0.0919 dist_std = 0.1398 vf_loss = 1.0698 grad_norm = 5.2164 nat_grad_norm = 0.0642 cg_residual = 1.9038 step_size = 0.4546 reward = -0.0000 fps = 25 mse_loss = 0.5289 
2022-05-01 19:04:45.679471 - gail/main.py:164 - [TRPO] iter = 2210000 dist_mean = 0.0641 dist_std = 0.1398 vf_loss = 0.2265 grad_norm = 4.5543 nat_grad_norm = 0.0784 cg_residual = 2.4841 step_size = 0.3857 reward = -0.0000 fps = 20 mse_loss = 0.5294 
2022-05-01 19:04:45.914608 - gail/main.py:191 - [Discriminator] iter = 2210000 loss = -0.3730 grad_norm = 3.1975 grad_penalty = 0.0637 regularization = 0.0000 true_logits = 1.2694 fake_logits = 0.8327 true_prob = 0.5688 fake_prob = 0.5070 
2022-05-01 19:06:51.616436 - gail/main.py:132 - [Evaluate] iter = 2210000 episode={ returns = 3619.5492 lengths = 1000 } discounted_episode={ returns = 2229.1018 lengths = 1000 } 
2022-05-01 19:07:01.461643 - gail/main.py:164 - [TRPO] iter = 2211000 dist_mean = 0.0654 dist_std = 0.1396 vf_loss = 0.4052 grad_norm = 4.2551 nat_grad_norm = 0.0787 cg_residual = 2.3445 step_size = 0.3848 reward = 0.0000 fps = 7 mse_loss = 0.5604 
2022-05-01 19:07:11.005873 - gail/main.py:164 - [TRPO] iter = 2212000 dist_mean = 0.0909 dist_std = 0.1397 vf_loss = 0.3894 grad_norm = 2.6154 nat_grad_norm = 0.0427 cg_residual = 0.5868 step_size = 0.7380 reward = -0.0000 fps = 6 mse_loss = 0.5370 
2022-05-01 19:07:20.239161 - gail/main.py:164 - [TRPO] iter = 2213000 dist_mean = 0.0844 dist_std = 0.1395 vf_loss = 0.2450 grad_norm = 5.8299 nat_grad_norm = 0.0704 cg_residual = 1.1481 step_size = 0.3925 reward = -0.0000 fps = 6 mse_loss = 0.5478 
2022-05-01 19:07:29.745411 - gail/main.py:164 - [TRPO] iter = 2214000 dist_mean = 0.0802 dist_std = 0.1397 vf_loss = 0.2010 grad_norm = 3.4296 nat_grad_norm = 0.0595 cg_residual = 0.9328 step_size = 0.5619 reward = -0.0000 fps = 6 mse_loss = 0.5724 
2022-05-01 19:07:39.341192 - gail/main.py:164 - [TRPO] iter = 2215000 dist_mean = 0.0852 dist_std = 0.1397 vf_loss = 0.2149 grad_norm = 4.2256 nat_grad_norm = 0.0506 cg_residual = 1.1746 step_size = 0.5855 reward = 0.0000 fps = 5 mse_loss = 0.5570 
2022-05-01 19:07:39.564211 - gail/main.py:191 - [Discriminator] iter = 2215000 loss = -0.3975 grad_norm = 3.7111 grad_penalty = 0.0638 regularization = 0.0000 true_logits = 1.2692 fake_logits = 0.8080 true_prob = 0.5813 fake_prob = 0.5016 
2022-05-01 19:09:47.292653 - gail/main.py:132 - [Evaluate] iter = 2215000 episode={ returns = 3646.7442 lengths = 1000 } discounted_episode={ returns = 2250.3863 lengths = 1000 } 
2022-05-01 19:09:56.597746 - gail/main.py:164 - [TRPO] iter = 2216000 dist_mean = 0.0907 dist_std = 0.1398 vf_loss = 0.3909 grad_norm = 3.0058 nat_grad_norm = 0.0633 cg_residual = 1.8330 step_size = 0.4645 reward = 0.0000 fps = 7 mse_loss = 0.6145 
2022-05-01 19:10:06.067332 - gail/main.py:164 - [TRPO] iter = 2217000 dist_mean = 0.0921 dist_std = 0.1397 vf_loss = 0.0853 grad_norm = 4.6295 nat_grad_norm = 0.0858 cg_residual = 2.5829 step_size = 0.3906 reward = 0.0000 fps = 6 mse_loss = 0.5695 
2022-05-01 19:10:15.457719 - gail/main.py:164 - [TRPO] iter = 2218000 dist_mean = 0.0973 dist_std = 0.1397 vf_loss = 0.1060 grad_norm = 3.6226 nat_grad_norm = 0.0773 cg_residual = 2.5839 step_size = 0.4326 reward = 0.0000 fps = 6 mse_loss = 0.5694 
2022-05-01 19:10:24.679531 - gail/main.py:164 - [TRPO] iter = 2219000 dist_mean = 0.0850 dist_std = 0.1396 vf_loss = 0.0690 grad_norm = 4.6990 nat_grad_norm = 0.0690 cg_residual = 1.2519 step_size = 0.4508 reward = -0.0000 fps = 6 mse_loss = 0.5440 
2022-05-01 19:10:34.077053 - gail/main.py:164 - [TRPO] iter = 2220000 dist_mean = 0.0881 dist_std = 0.1396 vf_loss = 0.0726 grad_norm = 3.1039 nat_grad_norm = 0.0778 cg_residual = 1.3899 step_size = 0.4659 reward = 0.0000 fps = 5 mse_loss = 0.5376 
2022-05-01 19:10:34.284981 - gail/main.py:191 - [Discriminator] iter = 2220000 loss = -0.1959 grad_norm = 4.7376 grad_penalty = 0.0685 regularization = 0.0000 true_logits = 1.1050 fake_logits = 0.8405 true_prob = 0.5623 fake_prob = 0.5103 
2022-05-01 19:12:41.464936 - gail/main.py:132 - [Evaluate] iter = 2220000 episode={ returns = 3652.2748 lengths = 1000 } discounted_episode={ returns = 2253.2167 lengths = 1000 } 
2022-05-01 19:12:50.610180 - gail/main.py:164 - [TRPO] iter = 2221000 dist_mean = 0.0650 dist_std = 0.1395 vf_loss = 0.0849 grad_norm = 2.9908 nat_grad_norm = 0.0788 cg_residual = 1.6886 step_size = 0.5314 reward = 0.0000 fps = 7 mse_loss = 0.5253 
2022-05-01 19:13:00.046029 - gail/main.py:164 - [TRPO] iter = 2222000 dist_mean = 0.0673 dist_std = 0.1400 vf_loss = 0.0571 grad_norm = 6.6543 nat_grad_norm = 0.0611 cg_residual = 1.6740 step_size = 0.4352 reward = -0.0000 fps = 6 mse_loss = 0.5924 
2022-05-01 19:13:09.410282 - gail/main.py:164 - [TRPO] iter = 2223000 dist_mean = 0.0945 dist_std = 0.1398 vf_loss = 0.0359 grad_norm = 4.7237 nat_grad_norm = 0.0715 cg_residual = 2.1633 step_size = 0.4069 reward = -0.0000 fps = 6 mse_loss = 0.5112 
2022-05-01 19:13:19.073662 - gail/main.py:164 - [TRPO] iter = 2224000 dist_mean = 0.0745 dist_std = 0.1394 vf_loss = 0.0291 grad_norm = 3.1287 nat_grad_norm = 0.0628 cg_residual = 1.6323 step_size = 0.5126 reward = 0.0000 fps = 6 mse_loss = 0.5698 
2022-05-01 19:13:28.572624 - gail/main.py:164 - [TRPO] iter = 2225000 dist_mean = 0.0323 dist_std = 0.1393 vf_loss = 0.0385 grad_norm = 3.9234 nat_grad_norm = 0.0705 cg_residual = 1.1341 step_size = 0.4986 reward = -0.0000 fps = 5 mse_loss = 0.5513 
2022-05-01 19:13:28.817108 - gail/main.py:191 - [Discriminator] iter = 2225000 loss = -0.4336 grad_norm = 4.1771 grad_penalty = 0.0640 regularization = 0.0000 true_logits = 1.2273 fake_logits = 0.7297 true_prob = 0.5833 fake_prob = 0.5066 
2022-05-01 19:15:38.349252 - gail/main.py:132 - [Evaluate] iter = 2225000 episode={ returns = 3664.8782 lengths = 1000 } discounted_episode={ returns = 2262.5307 lengths = 1000 } 
2022-05-01 19:15:48.229480 - gail/main.py:164 - [TRPO] iter = 2226000 dist_mean = 0.0872 dist_std = 0.1394 vf_loss = 0.1206 grad_norm = 4.3425 nat_grad_norm = 0.0571 cg_residual = 0.8971 step_size = 0.5114 reward = -0.0000 fps = 7 mse_loss = 0.5881 
2022-05-01 19:15:57.865184 - gail/main.py:164 - [TRPO] iter = 2227000 dist_mean = 0.0808 dist_std = 0.1391 vf_loss = 0.0355 grad_norm = 3.9036 nat_grad_norm = 0.0798 cg_residual = 2.3931 step_size = 0.4133 reward = 0.0000 fps = 6 mse_loss = 0.5761 
2022-05-01 19:16:07.200761 - gail/main.py:164 - [TRPO] iter = 2228000 dist_mean = 0.0703 dist_std = 0.1391 vf_loss = 0.0483 grad_norm = 5.3695 nat_grad_norm = 0.0595 cg_residual = 0.8706 step_size = 0.4611 reward = 0.0000 fps = 6 mse_loss = 0.5467 
2022-05-01 19:16:16.685582 - gail/main.py:164 - [TRPO] iter = 2229000 dist_mean = 0.0540 dist_std = 0.1389 vf_loss = 0.0297 grad_norm = 2.5103 nat_grad_norm = 0.0752 cg_residual = 1.1795 step_size = 0.5000 reward = 0.0000 fps = 5 mse_loss = 0.5185 
2022-05-01 19:16:26.051414 - gail/main.py:164 - [TRPO] iter = 2230000 dist_mean = 0.0337 dist_std = 0.1389 vf_loss = 0.0219 grad_norm = 2.4587 nat_grad_norm = 0.0790 cg_residual = 1.8995 step_size = 0.5018 reward = 0.0000 fps = 5 mse_loss = 0.5934 
2022-05-01 19:16:26.282498 - gail/main.py:191 - [Discriminator] iter = 2230000 loss = -0.3335 grad_norm = 4.3429 grad_penalty = 0.0615 regularization = 0.0000 true_logits = 1.0488 fake_logits = 0.6538 true_prob = 0.5785 fake_prob = 0.5052 
2022-05-01 19:18:33.734909 - gail/main.py:132 - [Evaluate] iter = 2230000 episode={ returns = 3665.7969 lengths = 1000 } discounted_episode={ returns = 2263.0685 lengths = 1000 } 
2022-05-01 19:18:43.223151 - gail/main.py:164 - [TRPO] iter = 2231000 dist_mean = 0.0589 dist_std = 0.1390 vf_loss = 0.0241 grad_norm = 5.4106 nat_grad_norm = 0.0790 cg_residual = 1.7057 step_size = 0.4346 reward = 0.0000 fps = 7 mse_loss = 0.4968 
2022-05-01 19:18:52.186792 - gail/main.py:164 - [TRPO] iter = 2232000 dist_mean = 0.0640 dist_std = 0.1389 vf_loss = 0.0398 grad_norm = 4.0479 nat_grad_norm = 0.0742 cg_residual = 2.1133 step_size = 0.4188 reward = 0.0000 fps = 6 mse_loss = 0.5331 
2022-05-01 19:19:01.756541 - gail/main.py:164 - [TRPO] iter = 2233000 dist_mean = 0.0588 dist_std = 0.1389 vf_loss = 0.0291 grad_norm = 3.7880 nat_grad_norm = 0.0831 cg_residual = 1.9045 step_size = 0.4175 reward = -0.0000 fps = 6 mse_loss = 0.6012 
2022-05-01 19:19:11.159397 - gail/main.py:164 - [TRPO] iter = 2234000 dist_mean = 0.0680 dist_std = 0.1389 vf_loss = 0.0336 grad_norm = 3.5914 nat_grad_norm = 0.0886 cg_residual = 2.9947 step_size = 0.4318 reward = 0.0000 fps = 6 mse_loss = 0.5205 
2022-05-01 19:19:20.643247 - gail/main.py:164 - [TRPO] iter = 2235000 dist_mean = 0.0410 dist_std = 0.1388 vf_loss = 0.0576 grad_norm = 3.8486 nat_grad_norm = 0.0982 cg_residual = 2.4541 step_size = 0.3872 reward = 0.0000 fps = 5 mse_loss = 0.5718 
2022-05-01 19:19:20.882453 - gail/main.py:191 - [Discriminator] iter = 2235000 loss = -0.2355 grad_norm = 4.4872 grad_penalty = 0.0699 regularization = 0.0000 true_logits = 0.8291 fake_logits = 0.5238 true_prob = 0.5639 fake_prob = 0.4961 
2022-05-01 19:21:29.879344 - gail/main.py:132 - [Evaluate] iter = 2235000 episode={ returns = 3664.7110 lengths = 1000 } discounted_episode={ returns = 2263.5512 lengths = 1000 } 
2022-05-01 19:21:39.625225 - gail/main.py:164 - [TRPO] iter = 2236000 dist_mean = 0.0847 dist_std = 0.1391 vf_loss = 0.0304 grad_norm = 6.1509 nat_grad_norm = 0.0799 cg_residual = 2.6125 step_size = 0.4488 reward = -0.0000 fps = 7 mse_loss = 0.5797 
2022-05-01 19:21:49.114332 - gail/main.py:164 - [TRPO] iter = 2237000 dist_mean = 0.0945 dist_std = 0.1388 vf_loss = 0.0309 grad_norm = 5.2889 nat_grad_norm = 0.0624 cg_residual = 1.5365 step_size = 0.4211 reward = 0.0000 fps = 6 mse_loss = 0.6092 
2022-05-01 19:21:58.367096 - gail/main.py:164 - [TRPO] iter = 2238000 dist_mean = 0.1006 dist_std = 0.1389 vf_loss = 0.0354 grad_norm = 5.3055 nat_grad_norm = 0.0683 cg_residual = 1.5719 step_size = 0.4629 reward = 0.0000 fps = 6 mse_loss = 0.5423 
2022-05-01 19:22:08.309424 - gail/main.py:164 - [TRPO] iter = 2239000 dist_mean = 0.0843 dist_std = 0.1388 vf_loss = 0.0262 grad_norm = 3.2538 nat_grad_norm = 0.0627 cg_residual = 2.1033 step_size = 0.4998 reward = 0.0000 fps = 5 mse_loss = 0.5587 
2022-05-01 19:22:17.671954 - gail/main.py:164 - [TRPO] iter = 2240000 dist_mean = 0.0783 dist_std = 0.1387 vf_loss = 0.0294 grad_norm = 4.5274 nat_grad_norm = 0.0831 cg_residual = 1.6130 step_size = 0.4031 reward = -0.0000 fps = 5 mse_loss = 0.5864 
2022-05-01 19:22:17.887703 - gail/main.py:191 - [Discriminator] iter = 2240000 loss = -0.3632 grad_norm = 3.7465 grad_penalty = 0.0656 regularization = 0.0000 true_logits = 0.8813 fake_logits = 0.4524 true_prob = 0.5647 fake_prob = 0.4983 
2022-05-01 19:24:25.574619 - gail/main.py:132 - [Evaluate] iter = 2240000 episode={ returns = 3632.0405 lengths = 1000 } discounted_episode={ returns = 2242.6405 lengths = 1000 } 
2022-05-01 19:24:34.990948 - gail/main.py:164 - [TRPO] iter = 2241000 dist_mean = 0.0649 dist_std = 0.1385 vf_loss = 0.0210 grad_norm = 3.2335 nat_grad_norm = 0.0748 cg_residual = 1.8499 step_size = 0.5013 reward = -0.0000 fps = 7 mse_loss = 0.5398 
2022-05-01 19:24:44.621215 - gail/main.py:164 - [TRPO] iter = 2242000 dist_mean = 0.0794 dist_std = 0.1383 vf_loss = 0.0241 grad_norm = 3.7571 nat_grad_norm = 0.0584 cg_residual = 1.0033 step_size = 0.5472 reward = 0.0000 fps = 6 mse_loss = 0.5329 
2022-05-01 19:24:54.298689 - gail/main.py:164 - [TRPO] iter = 2243000 dist_mean = 0.0684 dist_std = 0.1381 vf_loss = 0.0270 grad_norm = 3.5190 nat_grad_norm = 0.0822 cg_residual = 2.7768 step_size = 0.3900 reward = -0.0000 fps = 6 mse_loss = 0.5959 
2022-05-01 19:25:03.950496 - gail/main.py:164 - [TRPO] iter = 2244000 dist_mean = 0.0600 dist_std = 0.1383 vf_loss = 0.0272 grad_norm = 4.2606 nat_grad_norm = 0.0787 cg_residual = 2.6938 step_size = 0.3938 reward = 0.0000 fps = 6 mse_loss = 0.5902 
2022-05-01 19:25:13.552784 - gail/main.py:164 - [TRPO] iter = 2245000 dist_mean = 0.0437 dist_std = 0.1382 vf_loss = 0.0357 grad_norm = 3.8803 nat_grad_norm = 0.0819 cg_residual = 2.5630 step_size = 0.4008 reward = -0.0000 fps = 5 mse_loss = 0.6261 
2022-05-01 19:25:13.795124 - gail/main.py:191 - [Discriminator] iter = 2245000 loss = -0.4697 grad_norm = 3.5343 grad_penalty = 0.0721 regularization = 0.0000 true_logits = 0.8577 fake_logits = 0.3159 true_prob = 0.5590 fake_prob = 0.4798 
2022-05-01 19:27:25.790632 - gail/main.py:132 - [Evaluate] iter = 2245000 episode={ returns = 3600.7985 lengths = 1000 } discounted_episode={ returns = 2223.3449 lengths = 1000 } 
2022-05-01 19:27:35.650910 - gail/main.py:164 - [TRPO] iter = 2246000 dist_mean = 0.0712 dist_std = 0.1385 vf_loss = 0.0313 grad_norm = 3.5831 nat_grad_norm = 0.0743 cg_residual = 2.8415 step_size = 0.4508 reward = -0.0000 fps = 7 mse_loss = 0.5655 
2022-05-01 19:27:45.377802 - gail/main.py:164 - [TRPO] iter = 2247000 dist_mean = 0.0596 dist_std = 0.1385 vf_loss = 0.0264 grad_norm = 5.3493 nat_grad_norm = 0.0738 cg_residual = 1.8744 step_size = 0.4156 reward = 0.0000 fps = 6 mse_loss = 0.5350 
2022-05-01 19:27:55.030459 - gail/main.py:164 - [TRPO] iter = 2248000 dist_mean = 0.0654 dist_std = 0.1382 vf_loss = 0.0381 grad_norm = 3.4809 nat_grad_norm = 0.0986 cg_residual = 2.1913 step_size = 0.3730 reward = -0.0000 fps = 6 mse_loss = 0.5556 
2022-05-01 19:28:04.796092 - gail/main.py:164 - [TRPO] iter = 2249000 dist_mean = 0.0803 dist_std = 0.1381 vf_loss = 0.0530 grad_norm = 4.8207 nat_grad_norm = 0.0742 cg_residual = 1.8106 step_size = 0.4247 reward = 0.0000 fps = 5 mse_loss = 0.5774 
2022-05-01 19:28:14.396759 - gail/main.py:164 - [TRPO] iter = 2250000 dist_mean = 0.0827 dist_std = 0.1380 vf_loss = 0.0253 grad_norm = 4.0690 nat_grad_norm = 0.0882 cg_residual = 2.8390 step_size = 0.4040 reward = 0.0000 fps = 5 mse_loss = 0.5626 
2022-05-01 19:28:14.608748 - gail/main.py:191 - [Discriminator] iter = 2250000 loss = -0.2013 grad_norm = 3.7610 grad_penalty = 0.0695 regularization = 0.0000 true_logits = 0.6688 fake_logits = 0.3981 true_prob = 0.5378 fake_prob = 0.4956 
2022-05-01 19:30:24.742590 - gail/main.py:132 - [Evaluate] iter = 2250000 episode={ returns = 3569.3156 lengths = 1000 } discounted_episode={ returns = 2201.3505 lengths = 1000 } 
2022-05-01 19:30:33.984521 - gail/main.py:164 - [TRPO] iter = 2251000 dist_mean = 0.0903 dist_std = 0.1380 vf_loss = 0.1326 grad_norm = 3.6393 nat_grad_norm = 0.0645 cg_residual = 1.0273 step_size = 0.5293 reward = -0.0000 fps = 7 mse_loss = 0.5513 
2022-05-01 19:30:43.565456 - gail/main.py:164 - [TRPO] iter = 2252000 dist_mean = 0.0987 dist_std = 0.1380 vf_loss = 0.0289 grad_norm = 2.9152 nat_grad_norm = 0.0539 cg_residual = 1.4126 step_size = 0.5606 reward = -0.0000 fps = 6 mse_loss = 0.5861 
2022-05-01 19:30:53.164996 - gail/main.py:164 - [TRPO] iter = 2253000 dist_mean = 0.0995 dist_std = 0.1381 vf_loss = 0.0155 grad_norm = 4.6282 nat_grad_norm = 0.0706 cg_residual = 1.8485 step_size = 0.4146 reward = 0.0000 fps = 6 mse_loss = 0.6052 
2022-05-01 19:31:02.329751 - gail/main.py:164 - [TRPO] iter = 2254000 dist_mean = 0.0885 dist_std = 0.1380 vf_loss = 0.0273 grad_norm = 5.9353 nat_grad_norm = 0.0788 cg_residual = 1.7947 step_size = 0.4387 reward = -0.0000 fps = 5 mse_loss = 0.5501 
2022-05-01 19:31:11.449179 - gail/main.py:164 - [TRPO] iter = 2255000 dist_mean = 0.0815 dist_std = 0.1383 vf_loss = 0.0200 grad_norm = 4.0444 nat_grad_norm = 0.0630 cg_residual = 0.8970 step_size = 0.5131 reward = 0.0000 fps = 5 mse_loss = 0.5356 
2022-05-01 19:31:11.667014 - gail/main.py:191 - [Discriminator] iter = 2255000 loss = -0.2218 grad_norm = 3.5227 grad_penalty = 0.0687 regularization = 0.0000 true_logits = 0.4742 fake_logits = 0.1837 true_prob = 0.5178 fake_prob = 0.4741 
2022-05-01 19:33:19.704249 - gail/main.py:132 - [Evaluate] iter = 2255000 episode={ returns = 3551.1339 lengths = 1000 } discounted_episode={ returns = 2185.8087 lengths = 1000 } 
2022-05-01 19:33:29.295870 - gail/main.py:164 - [TRPO] iter = 2256000 dist_mean = 0.0921 dist_std = 0.1383 vf_loss = 0.0549 grad_norm = 2.6568 nat_grad_norm = 0.0698 cg_residual = 1.4115 step_size = 0.4707 reward = -0.0000 fps = 7 mse_loss = 0.5120 
2022-05-01 19:33:38.699212 - gail/main.py:164 - [TRPO] iter = 2257000 dist_mean = 0.1027 dist_std = 0.1381 vf_loss = 0.0142 grad_norm = 5.0656 nat_grad_norm = 0.0651 cg_residual = 1.8105 step_size = 0.4557 reward = 0.0000 fps = 6 mse_loss = 0.5393 
2022-05-01 19:33:48.416890 - gail/main.py:164 - [TRPO] iter = 2258000 dist_mean = 0.0429 dist_std = 0.1379 vf_loss = 0.0309 grad_norm = 4.0855 nat_grad_norm = 0.0836 cg_residual = 1.2734 step_size = 0.4231 reward = -0.0000 fps = 6 mse_loss = 0.5050 
2022-05-01 19:33:57.473404 - gail/main.py:164 - [TRPO] iter = 2259000 dist_mean = 0.0870 dist_std = 0.1381 vf_loss = 0.0253 grad_norm = 3.4108 nat_grad_norm = 0.0985 cg_residual = 3.0038 step_size = 0.4065 reward = -0.0000 fps = 6 mse_loss = 0.5880 
2022-05-01 19:34:07.050398 - gail/main.py:164 - [TRPO] iter = 2260000 dist_mean = 0.0987 dist_std = 0.1382 vf_loss = 0.0448 grad_norm = 3.5692 nat_grad_norm = 0.0708 cg_residual = 0.6766 step_size = 0.5094 reward = -0.0000 fps = 5 mse_loss = 0.6003 
2022-05-01 19:34:07.248598 - gail/main.py:191 - [Discriminator] iter = 2260000 loss = -0.1703 grad_norm = 3.3563 grad_penalty = 0.0737 regularization = 0.0000 true_logits = 0.1508 fake_logits = -0.0931 true_prob = 0.4760 fake_prob = 0.4356 
2022-05-01 19:36:16.903076 - gail/main.py:132 - [Evaluate] iter = 2260000 episode={ returns = 3529.9508 lengths = 1000 } discounted_episode={ returns = 2194.3364 lengths = 1000 } 
2022-05-01 19:36:26.378979 - gail/main.py:164 - [TRPO] iter = 2261000 dist_mean = 0.0770 dist_std = 0.1380 vf_loss = 0.0317 grad_norm = 3.7710 nat_grad_norm = 0.0799 cg_residual = 2.2471 step_size = 0.4578 reward = 0.0000 fps = 7 mse_loss = 0.5603 
2022-05-01 19:36:36.099615 - gail/main.py:164 - [TRPO] iter = 2262000 dist_mean = 0.1041 dist_std = 0.1381 vf_loss = 0.1308 grad_norm = 4.0279 nat_grad_norm = 0.1068 cg_residual = 3.7944 step_size = 0.3586 reward = -0.0000 fps = 6 mse_loss = 0.5658 
2022-05-01 19:36:45.668356 - gail/main.py:164 - [TRPO] iter = 2263000 dist_mean = 0.0715 dist_std = 0.1381 vf_loss = 0.0614 grad_norm = 3.3878 nat_grad_norm = 0.0976 cg_residual = 2.0570 step_size = 0.4162 reward = 0.0000 fps = 6 mse_loss = 0.5303 
2022-05-01 19:36:55.443136 - gail/main.py:164 - [TRPO] iter = 2264000 dist_mean = 0.0834 dist_std = 0.1379 vf_loss = 0.0669 grad_norm = 3.3342 nat_grad_norm = 0.1325 cg_residual = 5.3317 step_size = 0.3049 reward = 0.0000 fps = 5 mse_loss = 0.5245 
2022-05-01 19:37:05.057274 - gail/main.py:164 - [TRPO] iter = 2265000 dist_mean = 0.0633 dist_std = 0.1379 vf_loss = 0.1653 grad_norm = 3.0254 nat_grad_norm = 0.0894 cg_residual = 2.9776 step_size = 0.4475 reward = 0.0000 fps = 5 mse_loss = 0.5265 
2022-05-01 19:37:05.218168 - gail/main.py:191 - [Discriminator] iter = 2265000 loss = -0.3201 grad_norm = 3.5895 grad_penalty = 0.0671 regularization = 0.0000 true_logits = 0.0866 fake_logits = -0.3007 true_prob = 0.4692 fake_prob = 0.4171 
2022-05-01 19:38:43.697835 - gail/main.py:132 - [Evaluate] iter = 2265000 episode={ returns = 2152.8077 lengths = 625 } discounted_episode={ returns = 2022.4658 lengths = 920 } 
2022-05-01 19:38:53.785816 - gail/main.py:164 - [TRPO] iter = 2266000 dist_mean = 0.0833 dist_std = 0.1373 vf_loss = 0.0182 grad_norm = 3.3999 nat_grad_norm = 0.0859 cg_residual = 3.3205 step_size = 0.3960 reward = 0.0000 fps = 9 mse_loss = 0.5108 
2022-05-01 19:39:03.357523 - gail/main.py:164 - [TRPO] iter = 2267000 dist_mean = 0.0979 dist_std = 0.1374 vf_loss = 0.0617 grad_norm = 4.0989 nat_grad_norm = 0.0618 cg_residual = 1.4623 step_size = 0.5018 reward = 0.0000 fps = 8 mse_loss = 0.5400 
2022-05-01 19:39:12.957406 - gail/main.py:164 - [TRPO] iter = 2268000 dist_mean = 0.0707 dist_std = 0.1374 vf_loss = 0.0153 grad_norm = 2.3942 nat_grad_norm = 0.0823 cg_residual = 2.7170 step_size = 0.4427 reward = 0.0000 fps = 7 mse_loss = 0.5521 
2022-05-01 19:39:22.604112 - gail/main.py:164 - [TRPO] iter = 2269000 dist_mean = 0.0953 dist_std = 0.1373 vf_loss = 0.0264 grad_norm = 3.8372 nat_grad_norm = 0.0977 cg_residual = 1.3192 step_size = 0.4378 reward = 0.0000 fps = 7 mse_loss = 0.5610 
2022-05-01 19:39:31.894521 - gail/main.py:164 - [TRPO] iter = 2270000 dist_mean = 0.0812 dist_std = 0.1372 vf_loss = 0.0148 grad_norm = 6.5336 nat_grad_norm = 0.0849 cg_residual = 2.2747 step_size = 0.3595 reward = 0.0000 fps = 6 mse_loss = 0.5456 
2022-05-01 19:39:32.119250 - gail/main.py:191 - [Discriminator] iter = 2270000 loss = -0.4276 grad_norm = 4.0732 grad_penalty = 0.0650 regularization = 0.0000 true_logits = -0.0627 fake_logits = -0.5553 true_prob = 0.4490 fake_prob = 0.3776 
2022-05-01 19:41:40.505493 - gail/main.py:132 - [Evaluate] iter = 2270000 episode={ returns = 3489.9470 lengths = 1000 } discounted_episode={ returns = 2156.4908 lengths = 1000 } 
2022-05-01 19:41:50.127926 - gail/main.py:164 - [TRPO] iter = 2271000 dist_mean = 0.0718 dist_std = 0.1370 vf_loss = 0.0240 grad_norm = 3.9463 nat_grad_norm = 0.0604 cg_residual = 0.9608 step_size = 0.5092 reward = 0.0000 fps = 7 mse_loss = 0.5733 
2022-05-01 19:41:59.436627 - gail/main.py:164 - [TRPO] iter = 2272000 dist_mean = 0.0544 dist_std = 0.1369 vf_loss = 0.0946 grad_norm = 2.5664 nat_grad_norm = 0.0740 cg_residual = 2.1194 step_size = 0.5136 reward = -0.0000 fps = 6 mse_loss = 0.5736 
2022-05-01 19:42:09.073880 - gail/main.py:164 - [TRPO] iter = 2273000 dist_mean = 0.0879 dist_std = 0.1368 vf_loss = 0.0199 grad_norm = 2.7604 nat_grad_norm = 0.0619 cg_residual = 0.9342 step_size = 0.5582 reward = 0.0000 fps = 6 mse_loss = 0.5377 
2022-05-01 19:42:18.709280 - gail/main.py:164 - [TRPO] iter = 2274000 dist_mean = 0.0869 dist_std = 0.1367 vf_loss = 0.1070 grad_norm = 3.2374 nat_grad_norm = 0.0435 cg_residual = 0.7848 step_size = 0.7014 reward = -0.0000 fps = 6 mse_loss = 0.5433 
2022-05-01 19:42:27.909881 - gail/main.py:164 - [TRPO] iter = 2275000 dist_mean = 0.0929 dist_std = 0.1367 vf_loss = 0.0167 grad_norm = 3.6194 nat_grad_norm = 0.0619 cg_residual = 1.2999 step_size = 0.5230 reward = -0.0000 fps = 5 mse_loss = 0.5493 
2022-05-01 19:42:28.192959 - gail/main.py:191 - [Discriminator] iter = 2275000 loss = -0.4804 grad_norm = 3.5879 grad_penalty = 0.0646 regularization = 0.0000 true_logits = -0.1726 fake_logits = -0.7176 true_prob = 0.4311 fake_prob = 0.3589 
2022-05-01 19:44:34.566365 - gail/main.py:132 - [Evaluate] iter = 2275000 episode={ returns = 3492.1648 lengths = 1000 } discounted_episode={ returns = 2154.1711 lengths = 1000 } 
2022-05-01 19:44:43.698167 - gail/main.py:164 - [TRPO] iter = 2276000 dist_mean = 0.0553 dist_std = 0.1368 vf_loss = 0.0781 grad_norm = 3.8210 nat_grad_norm = 0.0756 cg_residual = 1.6783 step_size = 0.4114 reward = 0.0000 fps = 7 mse_loss = 0.5706 
2022-05-01 19:44:53.406558 - gail/main.py:164 - [TRPO] iter = 2277000 dist_mean = 0.0841 dist_std = 0.1366 vf_loss = 0.1501 grad_norm = 4.4182 nat_grad_norm = 0.0654 cg_residual = 1.1033 step_size = 0.4668 reward = 0.0000 fps = 6 mse_loss = 0.5024 
2022-05-01 19:45:02.961100 - gail/main.py:164 - [TRPO] iter = 2278000 dist_mean = 0.0893 dist_std = 0.1367 vf_loss = 0.0236 grad_norm = 5.2014 nat_grad_norm = 0.0556 cg_residual = 1.5387 step_size = 0.4609 reward = 0.0000 fps = 6 mse_loss = 0.5318 
2022-05-01 19:45:12.168963 - gail/main.py:164 - [TRPO] iter = 2279000 dist_mean = 0.0925 dist_std = 0.1367 vf_loss = 0.0189 grad_norm = 4.2257 nat_grad_norm = 0.0703 cg_residual = 1.5262 step_size = 0.4303 reward = -0.0000 fps = 6 mse_loss = 0.5234 
2022-05-01 19:45:21.326219 - gail/main.py:164 - [TRPO] iter = 2280000 dist_mean = 0.0382 dist_std = 0.1367 vf_loss = 0.1074 grad_norm = 5.1082 nat_grad_norm = 0.0581 cg_residual = 0.9824 step_size = 0.4919 reward = 0.0000 fps = 5 mse_loss = 0.5532 
2022-05-01 19:45:21.574560 - gail/main.py:191 - [Discriminator] iter = 2280000 loss = -0.3555 grad_norm = 2.9841 grad_penalty = 0.0616 regularization = 0.0000 true_logits = -0.3102 fake_logits = -0.7273 true_prob = 0.4070 fake_prob = 0.3543 
2022-05-01 19:47:25.542698 - gail/main.py:132 - [Evaluate] iter = 2280000 episode={ returns = 3485.4337 lengths = 1000 } discounted_episode={ returns = 2155.7816 lengths = 1000 } 
2022-05-01 19:47:34.984441 - gail/main.py:164 - [TRPO] iter = 2281000 dist_mean = 0.0623 dist_std = 0.1369 vf_loss = 0.0425 grad_norm = 6.2235 nat_grad_norm = 0.0797 cg_residual = 2.9975 step_size = 0.4004 reward = -0.0000 fps = 7 mse_loss = 0.5236 
2022-05-01 19:47:44.152787 - gail/main.py:164 - [TRPO] iter = 2282000 dist_mean = 0.0596 dist_std = 0.1367 vf_loss = 0.0277 grad_norm = 5.9443 nat_grad_norm = 0.0549 cg_residual = 1.8201 step_size = 0.4715 reward = 0.0000 fps = 7 mse_loss = 0.5312 
2022-05-01 19:47:53.424187 - gail/main.py:164 - [TRPO] iter = 2283000 dist_mean = 0.0583 dist_std = 0.1365 vf_loss = 0.0861 grad_norm = 3.8447 nat_grad_norm = 0.0783 cg_residual = 2.1229 step_size = 0.4860 reward = 0.0000 fps = 6 mse_loss = 0.5620 
2022-05-01 19:48:02.655014 - gail/main.py:164 - [TRPO] iter = 2284000 dist_mean = 0.0645 dist_std = 0.1363 vf_loss = 0.1372 grad_norm = 5.0612 nat_grad_norm = 0.0609 cg_residual = 1.3453 step_size = 0.4655 reward = 0.0000 fps = 6 mse_loss = 0.5681 
2022-05-01 19:48:12.018116 - gail/main.py:164 - [TRPO] iter = 2285000 dist_mean = 0.0272 dist_std = 0.1363 vf_loss = 0.0295 grad_norm = 3.6409 nat_grad_norm = 0.0667 cg_residual = 0.6359 step_size = 0.5069 reward = 0.0000 fps = 5 mse_loss = 0.5589 
2022-05-01 19:48:12.232427 - gail/main.py:191 - [Discriminator] iter = 2285000 loss = -0.4370 grad_norm = 3.2680 grad_penalty = 0.0523 regularization = 0.0000 true_logits = -0.2849 fake_logits = -0.7741 true_prob = 0.4125 fake_prob = 0.3524 
2022-05-01 19:50:17.210848 - gail/main.py:132 - [Evaluate] iter = 2285000 episode={ returns = 3468.7697 lengths = 1000 } discounted_episode={ returns = 2150.1910 lengths = 1000 } 
2022-05-01 19:50:26.216763 - gail/main.py:164 - [TRPO] iter = 2286000 dist_mean = 0.0745 dist_std = 0.1366 vf_loss = 0.1186 grad_norm = 3.3906 nat_grad_norm = 0.0446 cg_residual = 0.7193 step_size = 0.6176 reward = 0.0000 fps = 7 mse_loss = 0.5030 
2022-05-01 19:50:35.651062 - gail/main.py:164 - [TRPO] iter = 2287000 dist_mean = 0.0244 dist_std = 0.1367 vf_loss = 0.0232 grad_norm = 2.7150 nat_grad_norm = 0.0737 cg_residual = 2.7644 step_size = 0.4698 reward = -0.0000 fps = 6 mse_loss = 0.5254 
2022-05-01 19:50:44.850353 - gail/main.py:164 - [TRPO] iter = 2288000 dist_mean = 0.0517 dist_std = 0.1367 vf_loss = 0.0216 grad_norm = 4.0910 nat_grad_norm = 0.0707 cg_residual = 1.2671 step_size = 0.4470 reward = 0.0000 fps = 6 mse_loss = 0.4784 
2022-05-01 19:50:54.368122 - gail/main.py:164 - [TRPO] iter = 2289000 dist_mean = 0.0465 dist_std = 0.1367 vf_loss = 0.0867 grad_norm = 5.1375 nat_grad_norm = 0.0563 cg_residual = 1.0264 step_size = 0.5187 reward = 0.0000 fps = 6 mse_loss = 0.5414 
2022-05-01 19:51:03.713511 - gail/main.py:164 - [TRPO] iter = 2290000 dist_mean = 0.0261 dist_std = 0.1364 vf_loss = 0.0892 grad_norm = 3.8076 nat_grad_norm = 0.0614 cg_residual = 0.9702 step_size = 0.5047 reward = -0.0000 fps = 5 mse_loss = 0.5020 
2022-05-01 19:51:03.930486 - gail/main.py:191 - [Discriminator] iter = 2290000 loss = -0.4081 grad_norm = 3.9744 grad_penalty = 0.0516 regularization = 0.0000 true_logits = -0.2885 fake_logits = -0.7482 true_prob = 0.4136 fake_prob = 0.3471 
2022-05-01 19:53:08.329231 - gail/main.py:132 - [Evaluate] iter = 2290000 episode={ returns = 3457.4771 lengths = 1000 } discounted_episode={ returns = 2142.5519 lengths = 1000 } 
2022-05-01 19:53:17.783653 - gail/main.py:164 - [TRPO] iter = 2291000 dist_mean = 0.0188 dist_std = 0.1363 vf_loss = 0.0292 grad_norm = 5.2919 nat_grad_norm = 0.0864 cg_residual = 1.7036 step_size = 0.4438 reward = -0.0000 fps = 7 mse_loss = 0.5528 
2022-05-01 19:53:27.140545 - gail/main.py:164 - [TRPO] iter = 2292000 dist_mean = 0.0705 dist_std = 0.1363 vf_loss = 0.1075 grad_norm = 3.5434 nat_grad_norm = 0.0607 cg_residual = 0.8022 step_size = 0.5574 reward = -0.0000 fps = 6 mse_loss = 0.5332 
2022-05-01 19:53:36.332356 - gail/main.py:164 - [TRPO] iter = 2293000 dist_mean = 0.0547 dist_std = 0.1368 vf_loss = 0.0872 grad_norm = 4.3481 nat_grad_norm = 0.0825 cg_residual = 2.2982 step_size = 0.4310 reward = -0.0000 fps = 6 mse_loss = 0.5161 
2022-05-01 19:53:45.314479 - gail/main.py:164 - [TRPO] iter = 2294000 dist_mean = 0.0561 dist_std = 0.1366 vf_loss = 0.1035 grad_norm = 2.8067 nat_grad_norm = 0.0807 cg_residual = 2.3526 step_size = 0.5133 reward = 0.0000 fps = 6 mse_loss = 0.5072 
2022-05-01 19:53:54.943731 - gail/main.py:164 - [TRPO] iter = 2295000 dist_mean = 0.0223 dist_std = 0.1367 vf_loss = 0.0295 grad_norm = 3.6475 nat_grad_norm = 0.0640 cg_residual = 0.8041 step_size = 0.4758 reward = 0.0000 fps = 5 mse_loss = 0.5192 
2022-05-01 19:53:55.165653 - gail/main.py:191 - [Discriminator] iter = 2295000 loss = -0.4158 grad_norm = 3.5294 grad_penalty = 0.0528 regularization = 0.0000 true_logits = -0.3334 fake_logits = -0.8019 true_prob = 0.4019 fake_prob = 0.3434 
2022-05-01 19:56:00.695186 - gail/main.py:132 - [Evaluate] iter = 2295000 episode={ returns = 3466.3385 lengths = 1000 } discounted_episode={ returns = 2146.7818 lengths = 1000 } 
2022-05-01 19:56:10.180169 - gail/main.py:164 - [TRPO] iter = 2296000 dist_mean = -0.0034 dist_std = 0.1370 vf_loss = 0.0344 grad_norm = 3.6788 nat_grad_norm = 0.0588 cg_residual = 1.1009 step_size = 0.5372 reward = -0.0000 fps = 7 mse_loss = 0.5337 
2022-05-01 19:56:19.630202 - gail/main.py:164 - [TRPO] iter = 2297000 dist_mean = 0.0224 dist_std = 0.1371 vf_loss = 0.0247 grad_norm = 4.4585 nat_grad_norm = 0.0798 cg_residual = 1.6373 step_size = 0.4576 reward = 0.0000 fps = 6 mse_loss = 0.5382 
2022-05-01 19:56:29.251608 - gail/main.py:164 - [TRPO] iter = 2298000 dist_mean = 0.0236 dist_std = 0.1370 vf_loss = 0.0682 grad_norm = 2.4934 nat_grad_norm = 0.0719 cg_residual = 1.8227 step_size = 0.5231 reward = 0.0000 fps = 6 mse_loss = 0.5409 
2022-05-01 19:56:38.737330 - gail/main.py:164 - [TRPO] iter = 2299000 dist_mean = 0.0029 dist_std = 0.1370 vf_loss = 0.0173 grad_norm = 3.0864 nat_grad_norm = 0.0826 cg_residual = 3.7842 step_size = 0.4180 reward = 0.0000 fps = 6 mse_loss = 0.5046 
2022-05-01 19:56:48.467801 - gail/main.py:164 - [TRPO] iter = 2300000 dist_mean = 0.0493 dist_std = 0.1372 vf_loss = 0.0805 grad_norm = 2.2366 nat_grad_norm = 0.1251 cg_residual = 4.0485 step_size = 0.3843 reward = 0.0000 fps = 5 mse_loss = 0.5324 
2022-05-01 19:56:48.672931 - gail/main.py:191 - [Discriminator] iter = 2300000 loss = -0.4605 grad_norm = 3.3694 grad_penalty = 0.0513 regularization = 0.0000 true_logits = -0.2602 fake_logits = -0.7720 true_prob = 0.4126 fake_prob = 0.3437 
2022-05-01 19:58:55.827743 - gail/main.py:132 - [Evaluate] iter = 2300000 episode={ returns = 3464.9435 lengths = 1000 } discounted_episode={ returns = 2142.1097 lengths = 1000 } 
2022-05-01 19:59:05.399109 - gail/main.py:164 - [TRPO] iter = 2301000 dist_mean = 0.0292 dist_std = 0.1370 vf_loss = 0.0420 grad_norm = 5.2484 nat_grad_norm = 0.0648 cg_residual = 1.4413 step_size = 0.4116 reward = -0.0000 fps = 7 mse_loss = 0.5953 
2022-05-01 19:59:14.879748 - gail/main.py:164 - [TRPO] iter = 2302000 dist_mean = 0.0608 dist_std = 0.1369 vf_loss = 0.1530 grad_norm = 2.7249 nat_grad_norm = 0.0515 cg_residual = 1.4764 step_size = 0.5950 reward = -0.0000 fps = 6 mse_loss = 0.5190 
2022-05-01 19:59:24.227621 - gail/main.py:164 - [TRPO] iter = 2303000 dist_mean = 0.0326 dist_std = 0.1372 vf_loss = 0.0178 grad_norm = 6.3339 nat_grad_norm = 0.0680 cg_residual = 1.1879 step_size = 0.4137 reward = 0.0000 fps = 6 mse_loss = 0.4812 
2022-05-01 19:59:33.888631 - gail/main.py:164 - [TRPO] iter = 2304000 dist_mean = -0.0017 dist_std = 0.1371 vf_loss = 0.0126 grad_norm = 5.0418 nat_grad_norm = 0.0753 cg_residual = 0.9215 step_size = 0.4700 reward = 0.0000 fps = 6 mse_loss = 0.5513 
2022-05-01 19:59:43.506372 - gail/main.py:164 - [TRPO] iter = 2305000 dist_mean = 0.0281 dist_std = 0.1371 vf_loss = 0.0160 grad_norm = 3.4623 nat_grad_norm = 0.0814 cg_residual = 1.6729 step_size = 0.4456 reward = 0.0000 fps = 5 mse_loss = 0.5382 
2022-05-01 19:59:43.740215 - gail/main.py:191 - [Discriminator] iter = 2305000 loss = -0.2109 grad_norm = 3.0829 grad_penalty = 0.0408 regularization = 0.0000 true_logits = -0.2187 fake_logits = -0.4704 true_prob = 0.4193 fake_prob = 0.3909 
2022-05-01 20:01:49.947926 - gail/main.py:132 - [Evaluate] iter = 2305000 episode={ returns = 3444.5467 lengths = 1000 } discounted_episode={ returns = 2133.7804 lengths = 1000 } 
2022-05-01 20:01:59.338131 - gail/main.py:164 - [TRPO] iter = 2306000 dist_mean = 0.0230 dist_std = 0.1368 vf_loss = 0.0267 grad_norm = 4.5320 nat_grad_norm = 0.0664 cg_residual = 1.3790 step_size = 0.4614 reward = 0.0000 fps = 7 mse_loss = 0.5371 
2022-05-01 20:02:08.988118 - gail/main.py:164 - [TRPO] iter = 2307000 dist_mean = 0.0348 dist_std = 0.1368 vf_loss = 0.0606 grad_norm = 4.9442 nat_grad_norm = 0.0631 cg_residual = 1.8635 step_size = 0.4483 reward = 0.0000 fps = 6 mse_loss = 0.5602 
2022-05-01 20:02:18.550887 - gail/main.py:164 - [TRPO] iter = 2308000 dist_mean = 0.0272 dist_std = 0.1366 vf_loss = 0.0211 grad_norm = 3.1676 nat_grad_norm = 0.0666 cg_residual = 1.7479 step_size = 0.5326 reward = -0.0000 fps = 6 mse_loss = 0.5704 
2022-05-01 20:02:28.069206 - gail/main.py:164 - [TRPO] iter = 2309000 dist_mean = 0.0400 dist_std = 0.1366 vf_loss = 0.0169 grad_norm = 3.9626 nat_grad_norm = 0.0928 cg_residual = 2.6381 step_size = 0.3725 reward = -0.0000 fps = 6 mse_loss = 0.5371 
2022-05-01 20:02:37.557137 - gail/main.py:164 - [TRPO] iter = 2310000 dist_mean = 0.0198 dist_std = 0.1366 vf_loss = 0.0381 grad_norm = 4.0830 nat_grad_norm = 0.0545 cg_residual = 1.0933 step_size = 0.5312 reward = 0.0000 fps = 5 mse_loss = 0.5235 
2022-05-01 20:02:37.785084 - gail/main.py:191 - [Discriminator] iter = 2310000 loss = -0.2832 grad_norm = 3.0859 grad_penalty = 0.0367 regularization = 0.0000 true_logits = -0.1548 fake_logits = -0.4746 true_prob = 0.4420 fake_prob = 0.3918 
2022-05-01 20:04:47.044794 - gail/main.py:132 - [Evaluate] iter = 2310000 episode={ returns = 3463.9714 lengths = 1000 } discounted_episode={ returns = 2142.8940 lengths = 1000 } 
2022-05-01 20:04:56.722122 - gail/main.py:164 - [TRPO] iter = 2311000 dist_mean = -0.0122 dist_std = 0.1364 vf_loss = 0.0148 grad_norm = 4.3275 nat_grad_norm = 0.0613 cg_residual = 1.2672 step_size = 0.5385 reward = 0.0000 fps = 7 mse_loss = 0.5267 
2022-05-01 20:05:06.380920 - gail/main.py:164 - [TRPO] iter = 2312000 dist_mean = 0.0088 dist_std = 0.1365 vf_loss = 0.0429 grad_norm = 4.2587 nat_grad_norm = 0.0564 cg_residual = 0.6895 step_size = 0.5421 reward = -0.0000 fps = 6 mse_loss = 0.5555 
2022-05-01 20:05:16.136929 - gail/main.py:164 - [TRPO] iter = 2313000 dist_mean = 0.0042 dist_std = 0.1365 vf_loss = 0.0340 grad_norm = 4.3698 nat_grad_norm = 0.0542 cg_residual = 1.2027 step_size = 0.5255 reward = 0.0000 fps = 6 mse_loss = 0.5491 
2022-05-01 20:05:25.770646 - gail/main.py:164 - [TRPO] iter = 2314000 dist_mean = -0.0023 dist_std = 0.1365 vf_loss = 0.0212 grad_norm = 4.7249 nat_grad_norm = 0.0871 cg_residual = 2.9448 step_size = 0.4176 reward = -0.0000 fps = 5 mse_loss = 0.5958 
2022-05-01 20:05:35.470788 - gail/main.py:164 - [TRPO] iter = 2315000 dist_mean = -0.0016 dist_std = 0.1364 vf_loss = 0.0174 grad_norm = 4.6623 nat_grad_norm = 0.0945 cg_residual = 1.1018 step_size = 0.3859 reward = 0.0000 fps = 5 mse_loss = 0.5591 
2022-05-01 20:05:35.710921 - gail/main.py:191 - [Discriminator] iter = 2315000 loss = -0.2374 grad_norm = 3.7914 grad_penalty = 0.0462 regularization = 0.0000 true_logits = -0.1298 fake_logits = -0.4135 true_prob = 0.4528 fake_prob = 0.4084 
2022-05-01 20:07:43.855163 - gail/main.py:132 - [Evaluate] iter = 2315000 episode={ returns = 3477.3067 lengths = 1000 } discounted_episode={ returns = 2150.6214 lengths = 1000 } 
2022-05-01 20:07:53.414308 - gail/main.py:164 - [TRPO] iter = 2316000 dist_mean = 0.0201 dist_std = 0.1364 vf_loss = 0.0330 grad_norm = 2.9944 nat_grad_norm = 0.0694 cg_residual = 1.4788 step_size = 0.4968 reward = -0.0000 fps = 7 mse_loss = 0.5520 
2022-05-01 20:08:03.179377 - gail/main.py:164 - [TRPO] iter = 2317000 dist_mean = 0.0489 dist_std = 0.1362 vf_loss = 0.0392 grad_norm = 4.5752 nat_grad_norm = 0.0620 cg_residual = 1.6603 step_size = 0.4823 reward = 0.0000 fps = 6 mse_loss = 0.5404 
2022-05-01 20:08:13.080350 - gail/main.py:164 - [TRPO] iter = 2318000 dist_mean = 0.0096 dist_std = 0.1365 vf_loss = 0.0159 grad_norm = 4.8387 nat_grad_norm = 0.0604 cg_residual = 1.2283 step_size = 0.5159 reward = -0.0000 fps = 6 mse_loss = 0.5543 
2022-05-01 20:08:22.860239 - gail/main.py:164 - [TRPO] iter = 2319000 dist_mean = -0.0092 dist_std = 0.1363 vf_loss = 0.0183 grad_norm = 2.9625 nat_grad_norm = 0.0617 cg_residual = 1.4580 step_size = 0.5400 reward = -0.0000 fps = 5 mse_loss = 0.5332 
2022-05-01 20:08:32.413955 - gail/main.py:164 - [TRPO] iter = 2320000 dist_mean = 0.0153 dist_std = 0.1359 vf_loss = 0.0266 grad_norm = 5.6215 nat_grad_norm = 0.0777 cg_residual = 1.3885 step_size = 0.4028 reward = 0.0000 fps = 5 mse_loss = 0.5580 
2022-05-01 20:08:32.626948 - gail/main.py:191 - [Discriminator] iter = 2320000 loss = -0.2942 grad_norm = 3.9021 grad_penalty = 0.0505 regularization = 0.0000 true_logits = -0.1561 fake_logits = -0.5008 true_prob = 0.4541 fake_prob = 0.3961 
2022-05-01 20:10:40.444639 - gail/main.py:132 - [Evaluate] iter = 2320000 episode={ returns = 3470.6433 lengths = 1000 } discounted_episode={ returns = 2146.4979 lengths = 1000 } 
2022-05-01 20:10:50.024502 - gail/main.py:164 - [TRPO] iter = 2321000 dist_mean = 0.0132 dist_std = 0.1360 vf_loss = 0.0228 grad_norm = 5.4365 nat_grad_norm = 0.0992 cg_residual = 2.2403 step_size = 0.3491 reward = 0.0000 fps = 7 mse_loss = 0.5230 
2022-05-01 20:10:59.809310 - gail/main.py:164 - [TRPO] iter = 2322000 dist_mean = 0.0335 dist_std = 0.1360 vf_loss = 0.0358 grad_norm = 3.7413 nat_grad_norm = 0.0579 cg_residual = 1.0281 step_size = 0.5740 reward = 0.0000 fps = 6 mse_loss = 0.5554 
2022-05-01 20:11:09.766822 - gail/main.py:164 - [TRPO] iter = 2323000 dist_mean = 0.0545 dist_std = 0.1361 vf_loss = 0.0397 grad_norm = 3.7899 nat_grad_norm = 0.0671 cg_residual = 1.3543 step_size = 0.4918 reward = 0.0000 fps = 6 mse_loss = 0.5257 
2022-05-01 20:11:19.228692 - gail/main.py:164 - [TRPO] iter = 2324000 dist_mean = 0.0500 dist_std = 0.1360 vf_loss = 0.0349 grad_norm = 3.8930 nat_grad_norm = 0.0515 cg_residual = 1.0808 step_size = 0.5767 reward = 0.0000 fps = 6 mse_loss = 0.5565 
2022-05-01 20:11:28.624273 - gail/main.py:164 - [TRPO] iter = 2325000 dist_mean = 0.0499 dist_std = 0.1359 vf_loss = 0.0420 grad_norm = 3.7477 nat_grad_norm = 0.0622 cg_residual = 1.1679 step_size = 0.4707 reward = -0.0000 fps = 5 mse_loss = 0.5148 
2022-05-01 20:11:28.913159 - gail/main.py:191 - [Discriminator] iter = 2325000 loss = -0.2416 grad_norm = 3.7451 grad_penalty = 0.0388 regularization = 0.0000 true_logits = -0.1227 fake_logits = -0.4031 true_prob = 0.4628 fake_prob = 0.4112 
2022-05-01 20:13:39.046652 - gail/main.py:132 - [Evaluate] iter = 2325000 episode={ returns = 3502.1248 lengths = 1000 } discounted_episode={ returns = 2164.3987 lengths = 1000 } 
2022-05-01 20:13:48.233586 - gail/main.py:164 - [TRPO] iter = 2326000 dist_mean = 0.0532 dist_std = 0.1357 vf_loss = 0.0100 grad_norm = 5.2886 nat_grad_norm = 0.0646 cg_residual = 2.5801 step_size = 0.4049 reward = 0.0000 fps = 7 mse_loss = 0.5510 
2022-05-01 20:13:57.804319 - gail/main.py:164 - [TRPO] iter = 2327000 dist_mean = 0.0457 dist_std = 0.1359 vf_loss = 0.0305 grad_norm = 3.6392 nat_grad_norm = 0.0618 cg_residual = 1.3925 step_size = 0.5230 reward = 0.0000 fps = 6 mse_loss = 0.5579 
2022-05-01 20:14:07.801095 - gail/main.py:164 - [TRPO] iter = 2328000 dist_mean = 0.0240 dist_std = 0.1358 vf_loss = 0.0205 grad_norm = 6.4588 nat_grad_norm = 0.0594 cg_residual = 1.3794 step_size = 0.4266 reward = -0.0000 fps = 6 mse_loss = 0.5192 
2022-05-01 20:14:17.538569 - gail/main.py:164 - [TRPO] iter = 2329000 dist_mean = 0.0273 dist_std = 0.1357 vf_loss = 0.0123 grad_norm = 4.2148 nat_grad_norm = 0.0533 cg_residual = 1.1017 step_size = 0.4731 reward = -0.0000 fps = 5 mse_loss = 0.4872 
2022-05-01 20:14:27.061103 - gail/main.py:164 - [TRPO] iter = 2330000 dist_mean = 0.0480 dist_std = 0.1357 vf_loss = 0.0148 grad_norm = 3.2093 nat_grad_norm = 0.0832 cg_residual = 2.2287 step_size = 0.4591 reward = 0.0000 fps = 5 mse_loss = 0.5509 
2022-05-01 20:14:27.278610 - gail/main.py:191 - [Discriminator] iter = 2330000 loss = -0.2545 grad_norm = 4.8114 grad_penalty = 0.0403 regularization = 0.0000 true_logits = -0.0562 fake_logits = -0.3510 true_prob = 0.4777 fake_prob = 0.4222 
2022-05-01 20:16:37.404097 - gail/main.py:132 - [Evaluate] iter = 2330000 episode={ returns = 3515.9140 lengths = 1000 } discounted_episode={ returns = 2173.6903 lengths = 1000 } 
2022-05-01 20:16:46.490713 - gail/main.py:164 - [TRPO] iter = 2331000 dist_mean = 0.0389 dist_std = 0.1355 vf_loss = 0.0499 grad_norm = 3.0872 nat_grad_norm = 0.0644 cg_residual = 1.8468 step_size = 0.5209 reward = 0.0000 fps = 7 mse_loss = 0.5198 
2022-05-01 20:16:55.673548 - gail/main.py:164 - [TRPO] iter = 2332000 dist_mean = 0.0454 dist_std = 0.1354 vf_loss = 0.0135 grad_norm = 6.5677 nat_grad_norm = 0.0821 cg_residual = 2.6141 step_size = 0.3661 reward = 0.0000 fps = 6 mse_loss = 0.5141 
2022-05-01 20:17:04.761356 - gail/main.py:164 - [TRPO] iter = 2333000 dist_mean = 0.0594 dist_std = 0.1354 vf_loss = 0.0716 grad_norm = 2.8017 nat_grad_norm = 0.0714 cg_residual = 1.2906 step_size = 0.5009 reward = -0.0000 fps = 6 mse_loss = 0.5297 
2022-05-01 20:17:14.066946 - gail/main.py:164 - [TRPO] iter = 2334000 dist_mean = 0.0531 dist_std = 0.1356 vf_loss = 0.0564 grad_norm = 2.9532 nat_grad_norm = 0.0545 cg_residual = 0.8751 step_size = 0.5549 reward = -0.0000 fps = 5 mse_loss = 0.5268 
2022-05-01 20:17:23.430375 - gail/main.py:164 - [TRPO] iter = 2335000 dist_mean = 0.0485 dist_std = 0.1358 vf_loss = 0.0342 grad_norm = 3.1951 nat_grad_norm = 0.0676 cg_residual = 1.9154 step_size = 0.4683 reward = -0.0000 fps = 5 mse_loss = 0.5033 
2022-05-01 20:17:23.657195 - gail/main.py:191 - [Discriminator] iter = 2335000 loss = -0.2906 grad_norm = 3.6717 grad_penalty = 0.0381 regularization = 0.0000 true_logits = 0.0228 fake_logits = -0.3059 true_prob = 0.4929 fake_prob = 0.4302 
